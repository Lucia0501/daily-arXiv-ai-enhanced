<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 15]
- [eess.SP](#eess.SP) [Total: 22]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Differentially Private Community Detection in $h$-uniform Hypergraphs](https://arxiv.org/abs/2512.12031)
*Javad Zahedi Moghaddam,Aria Nosratinia*

Main category: cs.IT

TL;DR: 该论文研究了在保护超图连接隐私条件下的精确恢复阈值，提出了三种差分隐私机制并分析了它们的隐私预算与超图参数的关系。


<details>
  <summary>Details</summary>
Motivation: 研究在保护超图连接隐私的前提下，如何实现社区检测的精确恢复。随着超图数据应用的增加，如何在差分隐私约束下进行有效的图分析成为一个重要问题。

Method: 使用h-均匀超图随机块模型(h-HSBM)，研究三种差分隐私机制：基于稳定性的机制、基于采样的机制和基于扰动的机制。分析每种机制在(ε,δ)-超边差分隐私下的精确恢复阈值。

Result: 计算了每种机制的精确恢复阈值，发现基于采样的机制和随机响应机制能保证纯ε-超边差分隐私(δ=0)，而基于稳定性的机制无法达到这一隐私水平。隐私预算的最小值随簇内超边密度与跨簇超边密度比值的对数增长。

Conclusion: 不同隐私机制对精确恢复能力的影响不同，隐私预算与超图参数的关系因机制而异。基于稳定性和贝叶斯采样的机制需要隐私预算随密度比对数增长，而随机响应机制仅依赖于超图大小。

Abstract: This paper studies the exact recovery threshold subject to preserving the privacy of connections in $h$-uniform hypergraphs. Privacy is characterized by the $(ε, δ)$-hyperedge differential privacy (DP), an extension of the notion of $(ε, δ)$-edge DP in the literature. The hypergraph observations are modeled through a $h$-uniform stochastic block model ($h$-HSBM) in the dense regime. We investigate three differentially private mechanisms: stability-based, sampling-based, and perturbation-based mechanisms. We calculate the exact recovery threshold for each mechanism and study the contraction of the exact recovery region due to the privacy budget, $(ε, δ)$. Sampling-based mechanisms and randomized response mechanisms guarantee pure $ε$-hyperedge DP where $δ=0$, while the stability-based mechanisms cannot achieve this level of privacy. The dependence of the limits of the privacy budget on the parameters of the $h$-uniform hypergraph is studied. More precisely, it is proven rigorously that the minimum privacy budget scales logarithmically with the ratio between the density of in-cluster hyperedges and the cross-cluster hyperedges for stability-based and Bayesian sampling-based mechanisms, while this budget depends only on the size of the hypergraph for the randomized response mechanism.

</details>


### [2] [A Framework for Scalable Digital Twin Deployment in Smart Campus Building Facility Management](https://arxiv.org/abs/2512.12149)
*Thyda Siv*

Main category: cs.IT

TL;DR: 本研究提出了一个用于智能校园建筑的可扩展数字孪生部署框架，通过整合3D激光扫描、BIM建模和物联网数据可视化，支持设施运营和维护。


<details>
  <summary>Details</summary>
Motivation: 数字孪生为校园环境中的设施管理提供了重要机遇，但现有研究往往局限于孤立领域（如点云几何或能源分析），缺乏能够整合建筑几何、设备元数据和运营数据的可扩展、互操作的工作流程。

Method: 方法包括：(1) 使用地面激光扫描和结构化点云处理进行实景捕捉；(2) 开发包含建筑、机械、电气、管道、输送和传感器系统的丰富BIM模型；(3) 创建数字孪生环境，在数字孪生管理平台中连接设备元数据、维护策略和模拟物联网数据。

Result: 在佐治亚理工学院Price Gilbert建筑的案例研究中，成功建模了509个设备项目并嵌入OmniClass分类到数字孪生中，开发了10个交互式仪表板可视化系统性能。结果表明该框架实现了集中资产文档管理、改进的系统可视性以及增强的预防性和反应性维护工作流程。

Conclusion: 尽管大多数物联网数据因现有传感器基础设施有限而采用模拟方式，但原型验证了可扩展数字孪生用于设施管理的可行性，并为实时监控、分析集成和未来自主建筑运营建立了参考模型。

Abstract: Digital twin (DT) offers significant opportunities for enhancing facility management (FM) in campus environments. However, existing research often focuses narrowly on isolated domains, such as point-cloud geometry or energy analytics, without providing a scalable and interoperable workflow that integrates building geometry, equipment metadata, and operational data into a unified FM platform. This study proposes a comprehensive framework for scalable digital-twin deployment in smart campus buildings by integrating 3D laser scanning, BIM modeling, and IoT-enabled data visualization to support facility operations and maintenance. The methodology includes: (1) reality capture using terrestrial laser scanning and structured point-cloud processing; (2) development of an enriched BIM model incorporating architectural, mechanical, electrical, plumbing, conveying, and sensor systems; and (3) creation of a digital-twin environment that links equipment metadata, maintenance policies, and simulated IoT data within a digital-twin management platform. A case study of the Price Gilbert Building at Georgia Tech demonstrates the implementation of this workflow. A total of 509 equipment items were modeled and embedded with OmniClass classifications into the digital twin. Ten interactive dashboards were developed to visualize system performance. Results show that the proposed framework enables centralized asset documentation, improved system visibility, and enhanced preventive and reactive maintenance workflows. Although most IoT data were simulated due to limited existing sensor infrastructure, the prototype validates the feasibility of a scalable digital twin for facility management and establishes a reference model for real-time monitoring, analytics integration, and future autonomous building operations.

</details>


### [3] [Large and Small Model Collaboration for Air Interface](https://arxiv.org/abs/2512.12170)
*Yiming Cui,Jiajia Guo,Xiao Li,Chao-Kai Wen,Shi Jin*

Main category: cs.IT

TL;DR: 提出LASCO和E-LASCO框架，通过大模型与小模型协作实现无线通信中的环境特定适配，解决大模型直接微调的成本和效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要依赖大模型的通用知识，忽视了环境特定适配的潜在收益。直接微调大模型存在训练成本高、多用户场景推理效率低、灾难性遗忘风险以及模型参数访问受限等问题。

Method: 建立协作框架：大模型作为通用信道知识库，小模型作为轻量级插件捕获环境特定知识。针对CSI反馈任务实例化LASCO框架：大模型生成初始CSI重建，通过参考SAM和代理SAM学习环境引起的重建偏移，并将偏移传回大模型。E-LASCO进一步引入可学习的协作系数来控制不同环境中大模型和小模型的贡献度。

Result: 数值结果表明，LASCO和E-LASCO使大模型能够以显著降低的训练成本、更少的数据收集需求和更快的适配速度实现环境特定的性能提升。

Conclusion: 提出的协作框架有效解决了大模型在无线通信中环境特定适配的挑战，通过大小模型协作实现了高效、低成本的自适应性能提升。

Abstract: Large artificial intelligence models (LAMs) have shown strong capability in wireless communications, yet existing works mainly rely on their generalized knowledge across environments while overlooking the potential gains of environment-specific adaptation. Directly fine-tuning LAMs for adaptation is often impractical due to prohibitive training costs, low inference efficiency in multi-user scenarios, and the risk of catastrophic forgetting, in addition to the limited accessibility of model parameters. To address these limitations, we establish a collaborative framework for air interface. In this framework, unlike prior approaches that either depend solely on LAMs or require direct fine-tuning, LAMs are exploited as a universal channel knowledge base while small artificial intelligence models (SAMs) are employed as lightweight plugins to capture environment-specific knowledge, facilitating efficient environment-specific adaptation of LAMs. Subsequently, we instantiate this framework for CSI feedback tasks, and develop a large and small collaboration framework for CSI feedback, referred to as LASCO. LASCO operates by letting the base LAM produce an initial CSI reconstruction, learning the environment-induced reconstruction shift through a reference SAM and a proxy SAM, and transferring this shift back to the LAM. To further enhance adaptability, we introduce elastic-LASCO (E-LASCO), which augments LASCO with learnable collaboration coefficients that control the contribution of LAMs and SAMs across different environments. Numerical results demonstrate that LASCO and E-LASCO enables LAMs to achieve environment-specific performance gains with significantly reduced training costs, lower data collection requirements, and faster adaptation speed.

</details>


### [4] [Hulls of Free Linear Codes over a Non-Unital Ring](https://arxiv.org/abs/2512.12335)
*Anup Kushwaha,Om Prakash*

Main category: cs.IT

TL;DR: 研究非幺环E上自由线性码的壳码，包括壳的生成矩阵、构造方法、置换等价性和壳变化问题，并分类长度≤8的最优自由E-线性码


<details>
  <summary>Details</summary>
Motivation: 研究非幺环E上自由线性码的壳码性质，探索壳码的构造方法和等价关系，为编码理论提供新的数学工具

Method: 1. 分析E-线性码各种壳的剩余码和挠码；2. 推导自由E-线性码壳的生成矩阵显式形式；3. 提出四种递增构造方法从较小长度和壳秩构造更大码；4. 研究自由E-线性码的置换等价性和壳变化问题

Result: 1. 获得了自由E-线性码壳的生成矩阵显式形式；2. 提出了有效的递增构造方法；3. 分析了置换等价性和壳变化；4. 分类了长度≤8的最优自由E-线性码

Conclusion: 该研究为非幺环E上的自由线性码壳码提供了系统的理论框架，包括构造方法、等价性分析和最优码分类，为编码理论在非传统环上的应用奠定了基础

Abstract: This paper investigates the hull codes of free linear codes over a non-unital ring $ E= \langle κ,τ\mid 2 κ=2 τ=0,~ κ^2=κ,~ τ^2=τ,~ κτ=κ,~ τκ=τ\rangle$. Initially, we examine the residue and torsion codes of various hulls of $E$-linear codes and obtain an explicit form of the generator matrix of the hull of a free $E$-linear code. Then, we propose four build-up construction methods to construct codes with a larger length and hull-rank from codes with a smaller length and hull-rank. Some illustrative examples are also given to support our build-up construction methods. Subsequently, we study the permutation equivalence of two free $E$-linear codes and discuss the hull-variation problem. As an application, we classify optimal free $E$-linear codes for lengths up to $8$.

</details>


### [5] [ElasticVR: Elastic Task Computing in Multi-User Multi-Connectivity Wireless Virtual Reality (VR) Systems](https://arxiv.org/abs/2512.12366)
*Babak Badnava,Jacob Chakareski,Morteza Hashemi*

Main category: cs.IT

TL;DR: ElasticVR框架通过可扩展的360度视频分块和多连接边缘计算，使用多智能体深度强化学习优化VR应用的QoE和能耗


<details>
  <summary>Details</summary>
Motivation: 高保真360度视频流需要大量计算和带宽资源，现有VR系统缺乏弹性计算能力来适应不同用户和系统资源

Method: 提出ElasticVR框架，集成可扩展360度视频分块到边缘-客户端多连接架构，使用两种多智能体深度强化学习方法：集中式训练执行的CPPG和集中式训练分散式执行的IPPG

Result: 相比无弹性计算的VR系统，PSNR提升43.21%，响应时间降低42.35%，能耗降低56.83%

Conclusion: ElasticVR框架通过弹性计算卸载和多智能体强化学习，有效平衡了通信、计算、能耗和QoE之间的权衡，提高了VR系统的性能和可扩展性

Abstract: Diverse emerging VR applications integrate streaming of high fidelity 360 video content that requires ample amounts of computation and data rate. Scalable 360 video tiling enables having elastic VR computational tasks that can be scaled adaptively in computation and data rate based on the available user and system resources. We integrate scalable 360 video tiling in an edge-client wireless multi-connectivity architecture for joint elastic task computation offloading across multiple VR users called ElasticVR. To balance the trade-offs in communication, computation, energy consumption, and QoE that arise herein, we formulate a constrained QoE and energy optimization problem that integrates the multi-user/multi-connectivity action space with the elasticity of VR computational tasks. The ElasticVR framework introduces two multi-agent deep reinforcement learning solutions, namely CPPG and IPPG. CPPG adopts a centralized training and centralized execution approach to capture the coupling between users' communication and computational demands. This leads to globally coordinated decisions at the cost of increased computational overheads and limited scalability. To address the latter challenges, we also explore an alternative strategy denoted IPPG that adopts a centralized training with decentralized execution paradigm. IPPG leverages shared information and parameter sharing to learn robust policies; however, during execution, each user takes action independently based on its local state information only. The decentralized execution alleviates the communication and computation overhead of centralized decision-making and improves scalability. We show that the ElasticVR framework improves the PSNR by 43.21%, while reducing the response time and energy consumption by 42.35% and 56.83%, respectively, compared with a case where no elasticity is incorporated into VR computations.

</details>


### [6] [Linear Codes with Certain Dimension of Hermitian Hulls](https://arxiv.org/abs/2512.12519)
*Jiabin Wang,Jinquan Luo*

Main category: cs.IT

TL;DR: 研究有限域上酉空间中Hermitian ℓ-互补码的计数公式和渐近性质，发现Hermitian自正交码与无限制码的渐近重量分布相似，并证明当字母表大小趋于无穷时，Hermitian自正交MDS码是渐近稠密的。


<details>
  <summary>Details</summary>
Motivation: 研究Hermitian ℓ-互补码的计数和渐近性质，特别是Hermitian自正交码的渐近行为，探索在字母表大小趋于无穷时MDS码的密度特性。

Method: 在有限域F_q^2上的酉空间中，推导Hermitian ℓ-互补码的封闭形式计数公式，分析Hermitian自正交码与无限制码的渐近重量分布相似性，研究最小距离至少为d的Hermitian自正交码的渐近行为。

Result: 得到了Hermitian ℓ-互补码的计数公式封闭表达式，发现了Hermitian自正交码与无限制码的渐近重量分布相似性，证明了当字母表大小趋于无穷时，Hermitian自正交MDS码是渐近稠密的。

Conclusion: Hermitian ℓ-互补码具有可计算的计数公式，Hermitian自正交码在渐近意义上与无限制码有相似的重量分布，且在字母表足够大时，Hermitian自正交MDS码是普遍存在的。

Abstract: In this paper, we study the enumerative and asymptotic properties related to Hermitian $\ell$-complementary codes on the unitary space over $\F_{q^2}$. We provide some closed form expressions for the counting formulas of Hermitian $\ell$-complementary codes. There is a similarity in the asymptotic weight distribution between Hermitian self-orthogonal codes and unrestricted codes. Furthermore, we study the asymptotic behavior of Hermitian self-orthogonal codes whose minimum distance is at least $d$. In particular, we conclude that MDS codes within the class of Hermitian self-orthogonal codes are asymptotically dense when the alphabet size approaches to infinity.

</details>


### [7] [Vertical Heterogeneous Networks Beyond 5G: CoMP Coverage Enhancement and Optimization](https://arxiv.org/abs/2512.12563)
*Tian Shi,Wenkun Wen,Peiran Wu,Minghua Xia*

Main category: cs.IT

TL;DR: 该论文提出了一种基于协调多点传输的垂直异构网络框架，通过无人机与地面基站的联合传输来增强稀疏空中用户的覆盖性能，并研究了随机和优化两种无人机部署策略。


<details>
  <summary>Details</summary>
Motivation: 低空无线网络对低空经济发展至关重要，但在动态三维空间中为稀疏分布的空中用户提供可靠连接仍面临重大挑战。现有网络难以有效覆盖高移动性和难以到达的环境中的空中用户。

Method: 提出协调多点传输框架，使无人机基站和地面基站能够进行联合传输。考虑两种无人机部署策略：1) 随机部署，使用随机几何分析推导闭合覆盖表达式；2) 优化部署，使用覆盖感知的加权K-means聚类算法最大化服务不足区域的协作覆盖。

Result: 理论分析和蒙特卡洛模拟表明，所提出的CoMP使能的垂直异构网络显著提高了下行链路覆盖概率，特别是在稀疏空中用户场景下。优化部署策略相比随机部署能更好地提升覆盖性能。

Conclusion: 智能无人机协调和几何感知部署能够实现低空无线网络的鲁棒自适应连接。该研究为超越5G的垂直异构网络提供了有效的覆盖增强解决方案，特别适用于稀疏空中用户场景。

Abstract: Low-altitude wireless networks are increasingly vital for the low-altitude economy, enabling wireless coverage in high-mobility and hard-to-reach environments. However, providing reliable connectivity to sparsely distributed aerial users in dynamic three-dimensional (3D) spaces remains a significant challenge. This paper investigates downlink coverage enhancement in vertical heterogeneous networks (VHetNets) beyond 5G, where uncrewed aerial vehicles (UAVs) operate as emerging aerial base stations (ABSs) alongside legacy terrestrial base stations (TBSs). To improve coverage performance, we propose a coordinated multi-point (CoMP) transmission framework that enables joint transmission from ABSs and TBSs. This approach mitigates the limitations of non-uniform user distributions and enhances reliability for sparse aerial users. Two UAV deployment strategies are considered: \textit{i)} random UAV placement, analyzed using stochastic geometry to derive closed-form coverage expressions, and \textit{ii)} optimized UAV placement using a coverage-aware weighted $K$-means clustering algorithm to maximize cooperative coverage in underserved areas. Theoretical analyses and Monte Carlo simulations demonstrate that the proposed CoMP-enabled VHetNet significantly improves downlink coverage probability, particularly in scenarios with sparse aerial users. These findings highlight the potential of intelligent UAV coordination and geometry-aware deployment to enable robust, adaptive connectivity in low-altitude wireless networks.

</details>


### [8] [Linear Binary Codes Correcting One or More Errors](https://arxiv.org/abs/2512.12591)
*Timofei Izhitskii*

Main category: cs.IT

TL;DR: 本文研究线性二进制码，针对单错误纠正情况给出了达到汉明界的构造方法，并推导了最小码字长度的精确表达式；针对一般情况，通过陪集结构分析推导了线性码参数的简单下界。


<details>
  <summary>Details</summary>
Motivation: 研究能够纠正一个或多个错误的线性二进制码，旨在找到高效的纠错码构造方法，特别是对于单错误纠正情况，探索达到理论极限（汉明界）的码构造。

Method: 对于单错误纠正情况，采用构造性方法达到汉明界；对于一般情况，通过分析线性码的陪集结构来推导参数下界。

Result: 对于单错误纠正码，证明了汉明界可以通过构造方法达到，并推导出了最小码字长度的精确表达式；对于一般线性码，从陪集分析中得到了参数的简单下界。

Conclusion: 本文为线性二进制纠错码提供了重要的理论结果：单错误纠正码可以达到理论最优，而通过陪集分析得到的下界为一般线性码的设计提供了理论指导。

Abstract: This paper examines linear binary codes capable of correcting one or more errors. For the single-error-correcting case, it is shown that the Hamming bound is achieved by a constructive method, and an exact expression for the minimal codeword length is derived. For the general case, a simple lower bound for the parameters of linear codes is derived from an analysis of the coset structure.

</details>


### [9] [C-PASS: Center-Fed Pinching Antenna System](https://arxiv.org/abs/2512.12619)
*Xu Gan,Yuanwei Liu*

Main category: cs.IT

TL;DR: 提出了一种新型的中心馈电夹持天线系统(C-PASS)架构，通过从中心端口馈电实现空间复用增益，相比传统端馈PASS可获得两倍自由度并提升容量性能。


<details>
  <summary>Details</summary>
Motivation: 传统端馈夹持天线系统(PASS)存在性能限制，需要新的架构设计来提升无线通信系统的容量和自由度。

Method: 提出中心馈电C-PASS架构，信号从中心输入端口馈入并向波导两侧传播，在单个波导中实现空间复用增益。推导了自由度和功率缩放定律的闭式表达式。

Result: C-PASS相比传统PASS可获得两倍自由度，并额外获得O(P_T ln^4 N/N^2)的多路复用增益，其中P_T为发射功率，N为夹持天线数量。数值结果验证了容量显著提升。

Conclusion: C-PASS架构通过中心馈电设计有效提升了无线通信系统的容量性能，为未来天线系统设计提供了新的方向。

Abstract: A novel architecture of the center-fed pinching antenna system (C-PASS) is proposed. In contrast to the conventional end-fed PASS, signals are fed from the center input ports and propagate towards both sides of the waveguide. By doing so, spatial-multiplexing gain can be achieved in a single waveguide. Based on the proposed C-PASS, closed-form expressions for the degree of freedom (DoF) and power scaling laws are derived. These theoretical results reveal that C-PASS can achieve \emph{twice} the DoF and an additional multiplexing gain of $\mathcal{O}(P_T \ln^4 N/N^2)$ compared to the conventional PASS, where $P_T$ and $N$ represent the transmit power and pinching antenna number, respectively. Numerical results are provided to demonstrate that substantial capacity improvements can be achieved through the enhanced DoF and multiplexing gain of the C-PASS.

</details>


### [10] [From Information Freshness to Semantics of Information and Goal-oriented Communications](https://arxiv.org/abs/2512.12758)
*Jiping Luo,Erfan Delfani,Mehrdad Salimnejad,Nikolaos Pappas*

Main category: cs.IT

TL;DR: 论文系统梳理了从传统失真度量到信息新鲜度再到语义感知通信的演进，提出了面向任务的语义感知通信统一框架，为6G及未来网络设计提供指导。


<details>
  <summary>Details</summary>
Motivation: 未来无线网络需要支持实时数据驱动的网络物理系统，传统基于准确性、吞吐量和延迟的通信范式已不足以满足需求，因为信息的价值取决于其与特定任务的语义相关性。

Method: 通过统一框架梳理从经典失真度量到信息新鲜度再到语义感知通信的演进，系统化现有语义感知度量，包括内容和版本感知度量、上下文相关失真公式、历史相关错误持续性度量，并基于MDP和Lyapunov优化方法分析最优调度策略。

Result: 建立了面向任务的语义感知通信统一框架，展示了如何通过选择性生成和传输任务相关信息显著提高效率、可靠性和任务性能，为6G及未来网络设计提供指导。

Conclusion: 语义感知通信框架能够克服传统准确性或新鲜度中心设计的局限性，通过整合信息论、控制论和网络视角，为未来网络物理系统的通信设计提供新范式。

Abstract: Future wireless networks must support real-time, data-driven cyber-physical systems in which communication is tightly coupled with sensing, inference, control, and decision-making. Traditional communication paradigms centered on accuracy, throughput, and latency are increasingly inadequate for these systems, where the value of information depends on its semantic relevance to a specific task. This paper provides a unified exposition of the progression from classical distortion-based frameworks, through information freshness metrics such as the Age of Information (AoI) and its variants, to the emerging paradigm of goal-oriented semantics-aware communication. We organize and systematize existing semantics-aware metrics, including content- and version-aware measures, context-dependent distortion formulations, and history-dependent error persistence metrics that capture lasting impact and urgency. Within this framework, we highlight how these metrics address the limitations of purely accuracy- or freshness-centric designs, and how they collectively enable the selective generation and transmission of only task-relevant information. We further review analytical tools based on Markov decision process (MDP) and Lyapunov optimization methods that have been employed to characterize optimal or near-optimal timing and scheduling policies under semantic performance criteria and communication constraints. By synthesizing these developments into a coherent framework, the paper clarifies the design principles underlying goal-oriented, semantics-aware communication systems. It illustrates how they can significantly improve efficiency, reliability, and task performance. The presented perspective aims to serve as a bridge between information-theoretic, control-theoretic, and networking viewpoints, and to guide the design of semantic communication architectures for 6G and beyond.

</details>


### [11] [Information-Theoretic Limits of Integrated Sensing and Communication with Finite Learning Capacity](https://arxiv.org/abs/2512.13292)
*Farshad Rostami Ghadi,F. Javier Lopez-Martinez,Kai-Kit Wong,Christos Masouros*

Main category: cs.IT

TL;DR: 该论文提出了一个统一的AI辅助ISAC信息论框架，引入AI容量预算概念来量化有限学习能力对联合通信感知性能的约束，推导了可达速率-感知区域边界，并建立了学习-信息权衡定律。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术被集成到ISAC系统中，学习组件的有限表示能力会限制联合通信和感知性能。需要建立一个理论框架来量化这种约束，为下一代ISAC系统的模型规模、波形和硬件协同设计提供指导。

Method: 提出统一的AI辅助ISAC信息论框架，引入AI容量预算概念；推导可达速率-感知区域的上下界；对于高斯信道，将有限学习容量建模为等效加性噪声；扩展到瑞利和莱斯衰落以及MIMO系统；优化学习约束下的资源分配；建立学习-信息权衡定律；提出变分训练方法。

Result: 建立了AI容量预算与性能边界的数学关系；在高斯信道下得到封闭形式的通信速率和感知失真表达式；推导了资源分配的最优条件；建立了学习表示能力与性能前沿之间的权衡定律；提出了实用的训练方法。

Conclusion: 该框架为AI辅助ISAC系统提供了理论基础，量化了学习能力约束对性能的影响，推导的标度定律为下一代ISAC系统的协同设计提供了定量指导，有助于平衡模型复杂度与系统性能。

Abstract: This paper develops a unified information-theoretic framework for artificial-intelligence (AI)-aided integrated sensing and communication (ISAC), where a learning component with limited representational capacity is embedded within the transceiver loop. The study introduces the concept of an AI capacity budget to quantify how the finite ability of a learning model constrains joint communication and sensing performance. Under this framework, the paper derives both converse (upper) and achievability (lower) bounds that define the achievable rate-sensing region. For Gaussian channels, the effect of limited learning capacity is shown to behave as an equivalent additive noise, allowing simple analytical expressions for the resulting communication rate and sensing distortion. The theory is then extended to Rayleigh and Rician fading as well as to multiple-input multiple-output (MIMO) systems through new matrix inequalities and a constructive mapping between AI capacity and effective noise covariance. Resource allocation between sensing and communication is optimized under this learning constraint, yielding closed-form conditions in the Gaussian case. A general learning-information trade-off law is also established, linking the representational power of the learning module to the achievable performance frontier. Finally, a practical variational training procedure is proposed to enforce the capacity constraint and to guide empirical evaluation. The derived scaling laws provide quantitative insight for co-designing model size, waveform, and hardware in next-generation ISAC systems.

</details>


### [12] [Machine learning discovers new champion codes](https://arxiv.org/abs/2512.13370)
*Yang-Hui He,Alexander Kasprzyk,Q Le,Dmitrii Riabchenko*

Main category: cs.IT

TL;DR: 使用Transformer预测线性码的最小汉明距离，结合遗传算法搜索，开发出发现最优线性码的新方法，有效缩小搜索空间。


<details>
  <summary>Details</summary>
Motivation: 线性纠错码是现代数字通信和存储系统的数学基础，但识别最优线性码（达到或超过已知最佳最小汉明距离的码）仍然具有挑战性。需要开发新方法来更有效地发现这些最优码。

Method: 训练Transformer模型来预测一类线性码的最小汉明距离，然后将其与遗传算法配对，在搜索空间中进行优化搜索。这种组合方法能够有效减少发现最优码所需的搜索空间。

Result: 该方法成功应用于研究和构建多种纠错码，包括广义环面码、Reed-Muller码、Bose-Chaudhuri-Hocquenghem码、代数几何码，并可能扩展到量子码。

Conclusion: Transformer与遗传算法的结合为发现最优线性码提供了一种新颖有效的方法，显著提高了搜索效率，在纠错码领域具有广泛的应用前景。

Abstract: Linear error-correcting codes form the mathematical backbone of modern digital communication and storage systems, but identifying champion linear codes (linear codes achieving or exceeding the best known minimum Hamming distance) remains challenging. By training a transformer to predict the minimum Hamming distance of a class of linear codes and pairing it with a genetic algorithm over the search space, we develop a novel method for discovering champion codes. This model effectively reduces the search space of linear codes needed to achieve champion codes. Our results present the use of this method in the study and construction of error-correcting codes, applicable to codes such as generalised toric, Reed-Muller, Bose-Chaudhuri-Hocquenghem, algebrogeometric, and potentially quantum codes.

</details>


### [13] [Two Families of Linear Codes Containing Non-GRS MDS Codes](https://arxiv.org/abs/2512.13429)
*Kanat Abdukhalikov,Gyanendra K. Verma*

Main category: cs.IT

TL;DR: 通过修改广义Reed-Solomon码的生成矩阵构造了两类新的线性码，研究了它们的MDS性质、非GRS MDS子族、自正交和自对偶特性


<details>
  <summary>Details</summary>
Motivation: 在广义Reed-Solomon码的基础上构造新的线性码家族，探索具有MDS性质但不同于传统GRS码的新码类，并研究其代数特性

Method: 通过修改GRS码的生成矩阵构造两类新线性码，推导其校验矩阵，建立MDS性质的充要条件，识别非GRS MDS子族，分析自正交和自对偶特性

Result: 成功构造了两类新的线性码家族，获得了明确的校验矩阵表达式，建立了MDS性质的完整判据，发现了非GRS的MDS码子族，给出了自正交和自对偶码的构造方法和具体示例

Conclusion: 提出的构造方法能够产生具有良好代数特性的新线性码家族，特别是非GRS的MDS码为编码理论提供了新的研究方向，自正交和自对偶码的构造具有实际应用价值

Abstract: We construct two new families of linear codes by modifying the generator matrices of generalized Reed-Solomon (GRS) codes. For these codes, we explicitly derive parity-check matrices and establish necessary and sufficient conditions ensuring the MDS property. Additionally, we explore subfamilies within these constructions that are non-GRS MDS codes. We also characterize their self-orthogonal and self-dual properties and present some explicit constructions and examples.

</details>


### [14] [From Zipf's Law to Neural Scaling through Heaps' Law and Hilberg's Hypothesis](https://arxiv.org/abs/2512.13491)
*Łukasz Dębowski*

Main category: cs.IT

TL;DR: 论文证明了神经缩放定律是Zipf定律的推论，通过建立词汇增长定律（Heaps' law）、熵缩放假设（Hilberg's hypothesis）到神经缩放定律的推导链条。


<details>
  <summary>Details</summary>
Motivation: 探索机器学习中的神经缩放定律和定量语言学中的Zipf定律之间的演绎关系，揭示这两个在不同领域讨论的定律之间的内在联系。

Method: 通过系统推导建立四个统计定律之间的逻辑链条：从Zipf定律推导Heaps'定律（词汇增长定律），从Heaps'定律推导Hilberg假设（熵缩放假设），再从Hilberg假设推导神经缩放定律。使用Santa Fe过程作为满足所有四个定律的玩具示例进行说明。

Result: 在特定广泛假设下，神经缩放定律是Zipf定律的推论，建立了两个看似独立定律之间的数学联系。

Conclusion: 神经缩放定律和Zipf定律之间存在深刻的数学联系，神经缩放定律可以从Zipf定律推导出来，这为理解基础模型的缩放行为提供了新的理论视角。

Abstract: We inspect the deductive connection between the neural scaling law and Zipf's law -- two statements discussed in machine learning and quantitative linguistics. The neural scaling law describes how the cross entropy rate of a foundation model -- such as a large language model -- changes with respect to the amount of training tokens, parameters, and compute. By contrast, Zipf's law posits that the distribution of tokens exhibits a power law tail. Whereas similar claims have been made in more specific settings, we show that the neural scaling law is a consequence of Zipf's law under certain broad assumptions that we reveal systematically. The derivation steps are as follows: We derive Heaps' law on the vocabulary growth from Zipf's law, Hilberg's hypothesis on the entropy scaling from Heaps' law, and the neural scaling from Hilberg's hypothesis. We illustrate these inference steps by a toy example of the Santa Fe process that satisfies all the four statistical laws.

</details>


### [15] [Hyper-Minrank: A Unified Hypergraph Characterization of Multi-Sender Index Coding](https://arxiv.org/abs/2512.13615)
*Ali Khalesi,Petros Elia*

Main category: cs.IT

TL;DR: 本文提出了一种超图公式，将经典的Bar-Yossef等人范式推广到多发送者索引编码(MSIC)设置，建立了紧致的可达性-逆等价关系，并提供了计算超最小秩的精确算法。


<details>
  <summary>Details</summary>
Motivation: 现有索引编码研究主要关注单发送者场景，而实际通信系统如多发送者缓存辅助通信、编码计算、分布式存储和边缘/卫星系统通常涉及多个发送者。需要将经典索引编码理论扩展到多发送者设置，以统一处理这些实际应用场景。

Method: 引入4-正则侧信息超图G和新的邻接表示A_G，设计包含侧信息和跨发送者信号抵消的特殊超边，提出简单的子超图有效性拟合准则。建立了线性多发送者索引码与有效拟合之间的等价关系。

Result: 证明了最优标量线性广播长度等于超最小秩l**lin(G)=hyperminrank(G)，建立了紧致的可达性-逆等价关系。提供了计算hyperminrank(G)的精确算法，在某些机制下其复杂度渐近优于近似LT-CMAR解。推导了Haemers型界限的超图类比。

Conclusion: 该超图框架成功将经典索引编码理论推广到多发送者设置，为嵌入式索引编码、多发送者缓存辅助通信、编码计算、分布式存储和边缘/卫星系统提供了统一的设计目标，超最小秩可作为这些应用的核心性能指标。

Abstract: This work introduces a hypergraph formulation that generalizes the classical paradigm of Bar-Yossef et al. to the multi-sender index coding (MSIC) setting. Central to the model is a 4-regular side-information hypergraph G, a new adjacency representation A_G = [A_1 ... A_N], and a simple fitting criterion for sub-hypergraph validity, in the presence of specially designed hyperedges that capture both side information and cross-sender signal cancellation. This formulation establishes a tight achievability-converse equivalence for the general N-sender, K-receiver problem: every valid fitting induces a valid linear multi-sender index code, every linear code induces a valid fitting, and the optimal scalar linear broadcast length equals the hyper-minrank l**lin(G) = hyperminrank(G) = min*{A fits G} sum_{n=1}^N rank(A_n). Beyond this exact characterization, the approach yields hypergraph analogues of Haemers-type bounds on the broadcast length, including a clique-cover upper bound and a lower bound via the clique number of a carefully defined complement hypergraph. Algorithmically, we provide an exact procedure to compute hyperminrank(G), and show that in certain regimes its complexity is asymptotically better than approximate LT-CMAR solutions. The framework captures well-known settings such as embedded index coding, and applies directly to multi-sender cache-aided communications, coded computation, distributed storage, and edge/satellite systems, where hyperminrank can serve as a unified design target.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [16] [Modeling and Analysis of VOC-based Interplant Molecular Communication Channel](https://arxiv.org/abs/2512.12035)
*Bitop Maitra,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 论文提出了一个完整的VOC分子通信端到端框架，将植物间通信分为发射、信道传播和接收三个阶段，分析各阶段的衰减和延迟，发现VOC信道具有低通特性，带宽和容量受距离、风速和噪声影响，生物约束限制了端到端信道只能传输慢变信号。


<details>
  <summary>Details</summary>
Motivation: VOC分子通信具有开发长距离、生物兼容通信系统的巨大潜力，能够连接纳米和微米级设备。然而，目前缺乏从ICT角度对VOC植物间通信的全面分析框架。

Method: 提出一个端到端VOC植物间通信框架，将通信过程分为三个阶段：发射（叶片VOC生物合成和释放）、信道传播（湍流风中的平流扩散，使用高斯烟团模型处理应激诱导VOC释放，高斯烟羽模型处理组成型VOC释放）、接收（接收植物VOC吸收和生理响应）。每个阶段分析其衰减和延迟特性。

Result: 数值结果表明VOC信道表现出低通特性，带宽和容量受距离、风速和噪声的显著影响。虽然物理信道支持中等频率，但发射端的生物约束限制了端到端信道只能传输慢变信号。

Conclusion: VOC分子通信为长距离生物兼容通信提供了有前景的途径，但实际应用受到生物约束的限制，主要适用于慢变信号传输。该框架为VOC通信系统的设计和优化提供了理论基础。

Abstract: Molecular communication (MC) enables information transfer using particles inspired by biological systems. Volatile Organic Compounds (VOCs) are one of the most abundant and diverse classes of signaling molecules used by living or non-living objects. VOC-based MC holds great promise in developing long-range, bio-compatible communication systems capable of interfacing nano- and micro-scale devices. In this paper, we present a comprehensive end-to-end framework for VOC-based interplant MC from an ICT perspective. The communication process is divided into three stages: transmission (VOC biosynthesis and emission from leaves), channel propagation (advection-diffusion in turbulent wind via Gaussian puff for stress-induced VOC release and Gaussian plume for constitutive VOC release), and reception (VOC uptake and physiological response in the receiver plant). Each stage is analyzed by its attenuation and delay. Numerical results demonstrate that VOC-based channels exhibit low-pass behavior, with bandwidth and capacity heavily influenced by distance, wind velocity, and noise. Though the physical channel supports moderate frequencies, biological constraints at the transmitter restrict the end-to-end channel to slow-varying signals.

</details>


### [17] [Hierarchical Deep Learning for Joint Turbulence and PE Estimation in Multi-Aperture FSO Systems](https://arxiv.org/abs/2512.12178)
*Mohammad Taghi Dabiri,Meysam Ghanbari,Rula Ammuri,Mazen Hasna,Khalid Qaraqe*

Main category: eess.SP

TL;DR: 提出一种多孔径FSO接收器架构和分层深度学习框架，首次实现发射器指向误差、接收器到达角波动和湍流衰落的联合估计。


<details>
  <summary>Details</summary>
Motivation: 现有文献孤立处理自由空间光通信中的各种损伤，而信号中的乘性耦合限制了传统估计器，无法同时恢复这三个关键参数。

Method: 1) 多孔径FSO接收器架构，利用透镜阵列的空间多样性解耦效应；2) 分层深度学习框架，顺序估计到达角、发射器指向误差和湍流系数。

Result: 该方法达到接近MAP的精度，计算成本降低数个数量级，在估计精度和泛化能力上显著优于端到端学习基线。

Conclusion: 这是首个实现这三个关键参数实际联合估计的工作，为可靠、抗湍流的多孔径FSO系统铺平了道路。

Abstract: Accurate characterization of free-space optical (FSO) channels requires joint estimation of transmitter pointing errors, receiver angle-of-arrival (AoA) fluctuations, and turbulence-induced fading. However, existing literature addresses these impairments in isolation, since their multiplicative coupling in the received signal severely limits conventional estimators and prevents simultaneous recovery. In this paper, we introduce a novel multi-aperture FSO receiver architecture that leverages spatial diversity across a lens array to decouple these intertwined effects. Building on this hardware design, we propose a hierarchical deep learning framework that sequentially estimates AoA, transmitter pointing error, and turbulence coefficients. This decomposition significantly reduces learning complexity and enables robust inference even under strong atmospheric fading. Simulation results demonstrate that the proposed method achieves near-MAP accuracy with orders-of-magnitude lower computational cost, and substantially outperforms end-to-end learning baselines in terms of estimation accuracy and generalization. To the best of our knowledge, this is the first work to demonstrate practical joint estimation of these three key parameters, paving the way for reliable, turbulence-resilient multi-aperture FSO systems.

</details>


### [18] [A Sensing Dataset Protocol for Benchmarking and Multi-Task Wireless Sensing](https://arxiv.org/abs/2512.12180)
*Jiawei Huang,Di Zhang,Yuanhao Cui,Xiaowen Cao,Tony Xiao Han,Xiaojun Jing,Christos Masouros*

Main category: eess.SP

TL;DR: SDP提出了一种无线感知数据集协议和基准框架，通过统一的数据块模式、信号对齐和CP-ALS池化，为多模态多任务感知研究提供可复现的基础。


<details>
  <summary>Details</summary>
Motivation: 现有无线感知数据集和流程在感知模态上碎片化，阻碍了公平比较、迁移和可复现性，需要统一的协议和基准框架。

Method: SDP协议通过轻量级同步、频时对齐和重采样将异构无线信号映射到统一感知数据块模式，CP-ALS池化阶段提供保留多径、频谱和时间结构的任务无关表示。

Result: 在跨用户分割实验中，SDP显著减少了种子间的方差（约88%），同时保持了竞争性的准确性和延迟，验证了其作为多模态多任务感知研究可复现基础的价值。

Conclusion: SDP为大规模无线感知提供了协议级规范和基准框架，解决了现有数据集碎片化问题，为感知研究提供了可复现的基础。

Abstract: Wireless sensing has become a fundamental enabler for intelligent environments, supporting applications such as human detection, activity recognition, localization, and vital sign monitoring. Despite rapid advances, existing datasets and pipelines remain fragmented across sensing modalities, hindering fair comparison, transfer, and reproducibility. We propose the Sensing Dataset Protocol (SDP), a protocol-level specification and benchmark framework for large-scale wireless sensing. SDP defines how heterogeneous wireless signals are mapped into a unified perception data-block schema through lightweight synchronization, frequency-time alignment, and resampling, while a Canonical Polyadic-Alternating Least Squares (CP-ALS) pooling stage provides a task-agnostic representation that preserves multipath, spectral, and temporal structures. Built upon this protocol, a unified benchmark is established for detection, recognition, and vital-sign estimation with consistent preprocessing, training, and evaluation. Experiments under the cross-user split demonstrate that SDP significantly reduces variance (approximately 88%) across seeds while maintaining competitive accuracy and latency, confirming its value as a reproducible foundation for multi-modal and multitask sensing research.

</details>


### [19] [Learning-Driven Dual-Line Laser Scanning for Fast and Accurate LEO Satellite Positioning](https://arxiv.org/abs/2512.12181)
*Mohammad Taghi Dabiri,Rula Ammuri,Mazen Hasna,Khalid Qaraqe*

Main category: eess.SP

TL;DR: 提出一种基于学习的双线激光扫描框架，用于快速精确的卫星定位，相比传统高斯光束方案，在1-2ms内实现7-10米定位误差


<details>
  <summary>Details</summary>
Motivation: LEO卫星光通信需要毫秒级波束对准以实现可靠高速通信，传统高斯光束采集系统依赖多序列光束或机械转向，存在延迟和复杂性

Method: 采用正交线形激光束进行结构化光学扫描，建立包含大气衰减、湍流和MRR反射的物理模型，训练数据驱动的神经估计器将接收光能模式映射到卫星二维位置

Result: 学习驱动方法实现近MAP精度，典型误差7-10米，确定性扫描时间1-2毫秒；传统两阶段高斯光束方案误差相当但随机传感持续时间可达5毫秒

Conclusion: 该框架在定位精度、计算复杂度和传感延迟之间提供了有利权衡，是下一代光学LEO跟踪系统的实用候选方案

Abstract: Accurate and low-latency positioning is a key enabler for optical links with Low Earth Orbit (LEO) satellites, where millisecond-level beam alignment is required to maintain reliable high-data-rate communication. This paper presents a learning-driven dual-line laser scanning framework for fast and precise satellite positioning. Unlike conventional Gaussian-beam acquisition systems that rely on multiple sequential beams or mechanical steering, the proposed approach employs two orthogonal line-shaped laser beams to perform structured optical scanning over the ambiguity region without any moving parts. A physics-based model incorporating atmospheric attenuation, turbulence, and MRR-based reflection is developed, and a data-driven neural estimator is trained to map received optical energy patterns to the satellite's two-dimensional position. Simulation results demonstrate that the learning-driven method achieves near-MAP accuracy with typical errors of 7-10 m and deterministic scanning time of 1-2 ms, while conventional two-stage Gaussian-beam schemes exhibit comparable errors but random sensing durations of up to 5 ms. The proposed framework therefore offers a favorable trade-off between positioning accuracy, computational complexity, and sensing latency, making it a practical candidate for next-generation optical LEO tracking systems.

</details>


### [20] [MRR-Based Line-Laser Scanning for Reliable Vehicular Positioning and Optical Communication](https://arxiv.org/abs/2512.12186)
*Mohammad Taghi Dabiri,Hossein Safi,Rula Ammuri,Mazen Hasna,Khalid Qaraqe,Harald Haas,Iman Tavakkolnia*

Main category: eess.SP

TL;DR: 提出一种无需机械跟踪的光学联合感知定位通信系统，结合结构化线激光照明和车辆上的调制后向反射器阵列，通过正交线激光扫描实现高速公路环境下的连续广域覆盖。


<details>
  <summary>Details</summary>
Motivation: 高速车辆环境需要能够同时进行感知、定位和通信的光学系统，而无需机械跟踪。现有的光学和集成感知通信方法通常依赖点光源发射器或基于摄像头的接收器，在高速公路动态环境下限制了空间覆盖范围和更新速率。

Method: 采用结构化线激光照明与车辆上的调制后向反射器阵列相结合。使用两个正交线激光进行同步纵向和横向扫描，提供道路上的连续广域覆盖。开发了覆盖驱动的分析框架来建模光束发散、扫描几何和驻留时间分配之间的耦合关系，并设计了优化方案来调整扫描和发散参数以实现均匀覆盖和功率效率。

Result: 仿真结果表明，在固定扫描周期内，空间覆盖均匀性、链路稳定性和可靠性都有显著改善。该系统为下一代车辆JSPC网络的可扩展、抗湍流光架构提供了实用途径。

Conclusion: 这项工作引入了一类新的无跟踪光学JSPC系统，通过结合结构化线激光照明和调制后向反射器阵列，为高速车辆环境提供了连续、广域的覆盖解决方案，为下一代车辆网络的抗湍流光架构建立了实用路径。

Abstract: High-speed vehicular environments require optical systems capable of joint sensing, positioning, and communication (JSPC) without mechanical tracking. Existing optical and integrated sensing-communication approaches often rely on point-source emitters or camera-based receivers, limiting spatial coverage and update rate under highway dynamics. This work introduces a new class of tracking-free optical JSPC systems that combine structured line-laser illumination with modulating retroreflector (MRR) arrays on vehicles. Two orthogonal line lasers perform synchronized longitudinal and transverse scanning to provide continuous, wide-area coverage across the roadway. A coverage-driven analytical framework models the coupling between beam divergence, scan geometry, and dwell-time allocation, enabling joint evaluation of sensing reliability and communication quality. An optimization scheme is developed to adapt scanning and divergence parameters for uniform coverage and power efficiency. Simulation results demonstrate significant improvements in spatial coverage uniformity, link stability, and reliability within a fixed scan period. These results establish a practical pathway toward scalable, turbulence-resilient optical architectures for next-generation vehicular JSPC networks.

</details>


### [21] [Rotatable Antenna Array-Enhanced Null Steering: Performance Analysis and Optimization](https://arxiv.org/abs/2512.12204)
*Yingqi Wen,Weidong Mei,Yike Xie,Beixiong Zheng,Zhi Chen,Boyu Ning*

Main category: eess.SP

TL;DR: 提出可旋转天线阵列(RAA)架构，通过三维旋转控制增强波束成形灵活性，特别是零陷导引能力，相比传统固定方向天线阵列能显著放宽角度分离要求。


<details>
  <summary>Details</summary>
Motivation: 传统固定方向天线阵列在波束成形灵活性方面受限，特别是在零陷导引方面自由度有限。需要一种新架构来增强空间灵活性，以更好地抑制多个干扰方向。

Method: 提出可旋转天线阵列架构，通过优化三维旋转角度最大化期望方向波束增益同时零陷多个干扰方向。针对特殊情况推导理论条件，对一般情况提出序列更新算法，结合吉布斯采样避免局部最优。

Result: 理论分析表明RAA相比FOA能显著放宽有效零陷导引所需的角度分离要求。仿真结果验证了分析结论，显示RAA在零陷导引性能上优于传统FOA阵列。

Conclusion: 可旋转天线阵列通过三维旋转控制提供了增强的空间灵活性，能有效解决传统固定方向天线阵列在零陷导引方面的局限性，为无线通信系统提供了更好的干扰抑制能力。

Abstract: Conventional fixed-orientation antenna (FOA) arrays offer limited degrees of freedom (DoF) for flexible beamforming such as null steering. To address this limitation, we propose a new rotatable antenna array (RAA) architecture in this paper, which enables three-dimensional (3D) rotational control of an antenna array to provide enhanced spatial flexibility for null steering. To characterize its performance, we aim to jointly optimize the 3D rotational angles of the RAA, to maximize the beam gain over a given desired direction, while nulling those over multiple interference directions under zero-forcing (ZF) beamforming. However, this problem is non-convex and challenging to tackle due to the highly nonlinear expression of the beam gain in terms of the rotational angles. To gain insights, we first examine several special cases including both isotropic and directional antenna radiation patterns, deriving the conditions under which full beam gain can be achieved over the desired direction while meeting the nulling constraints for interference directions. These conditions clearly indicate that compared with FOA arrays, RAAs can significantly relax the angular separation requirement for achieving effective null steering. For other general cases, we propose a sequential update algorithm, that iteratively refines the 3D rotational angles by discretizing the 3D angular search space. To avoid undesired local optimum, a Gibbs sampling (GS) procedure is also employed between two consecutive rounds of sequential update for solution exploration. Simulation results verify our analytical results and show superior null-steering performance of RAAs to FOA arrays.

</details>


### [22] [Movable Access Points in Visible Light Communications: Opportunities, Challenges and Future Directions](https://arxiv.org/abs/2512.12214)
*Sylvester Aboagye,Telex M. N. Ngatched*

Main category: eess.SP

TL;DR: 本文提出了一种基于可移动接入点(MAPs)的可见光通信系统，通过动态重新定位AP来确保视距连接和对齐，在动态环境中优于RIS辅助、固定AP和仅RIS的VLC系统。


<details>
  <summary>Details</summary>
Motivation: 可见光通信(VLC)虽然具有频谱丰富、安全性高和基础设施已部署等优势，但其性能受设备方向、视距链路遮挡、发射器半角和接收器视场等因素影响。RIS虽然能缓解遮挡和移动性问题，但其数据速率远低于直接视距链路。

Method: 提出可移动接入点(MAPs)辅助的VLC系统概念，通过动态重新定位接入点来提供新的自由度，确保视距连接和发射器-接收器对齐，同时为移动用户提供超高数据速率。

Result: 仿真结果表明，在动态环境中，MAPs辅助的VLC系统性能优于RIS辅助、固定AP和仅RIS的VLC系统。

Conclusion: MAPs为VLC系统提供了有前景的解决方案，能够应对遮挡、方向问题和移动性挑战，同时保持高数据速率。文章还概述了关键挑战和未来研究方向，包括与新兴无线技术的集成。

Abstract: Visible light communication (VLC) is expected to be a key component of future wireless networks due to its abundant license-free spectrum, inherent high-level security, and the already deployed lighting infrastructure. VLC performance, however, depends on device orientation and the availability of an unobstructed line-of-sight (LoS) link, with transmitter semi-angle and receiver field-of-view (FoV) further affecting alignment, coverage, and reliability. Reconfigurable intelligent surfaces (RISs) can mitigate blockages, orientation issues, and mobility challenges, but their data rates remain far below those of direct LoS links. This article introduces the novel concept of movable access points (MAPs)-aided VLC systems, where dynamically repositioned APs provide new degrees of freedom to ensure LoS connectivity, and transmitter-receiver alignment while providing ultra-high data rates for mobile users. Simulation results show MAPs outperform RIS-aided, fixed-AP, and RIS-only VLC systems in dynamic environments. The article also outlines key challenges and future research directions, including integration with emerging wireless technologies.

</details>


### [23] [Robust Energy-Efficient Sleep-Mode Strategy for Multi-RIS-Aided Cell-Free Massive MIMO](https://arxiv.org/abs/2512.12223)
*Hongyi Luo,Wenyu Song,Daniel K. C. So,Zahra Mobini,Zhiguo Ding*

Main category: eess.SP

TL;DR: 本文提出了一种用于无小区大规模MIMO系统的节能传输方案，通过联合协调活跃AP和多个无源RIS，在低负载期间动态关闭部分AP，利用RIS维持覆盖，显著提升能效。


<details>
  <summary>Details</summary>
Motivation: 随着无线网络能耗激增，现有研究通常假设持续高流量负载，忽略了用户需求的动态性，导致低需求期间AP利用率不足和不必要的能耗。需要解决无小区大规模MIMO系统在低负载期间的能效挑战。

Method: 提出动态AP睡眠模式策略，选择性关闭部分AP，同时利用附近RIS维持覆盖。将能效最大化问题建模为分数规划问题，采用Dinkelbach方法结合交替优化迭代求解三个耦合子问题：1) 使用混合分支定界和贪心算法进行AP选择；2) 采用序列凸近似方法优化发射功率，以启发式迫零策略初始化；3) 使用梯度投影优化RIS相移。

Result: 仿真结果表明，所提方案在低和中度用户场景下，相比现有方法实现了显著更高的能效。

Conclusion: 通过联合协调AP睡眠模式和RIS辅助覆盖，该方案有效解决了无小区大规模MIMO系统在动态负载下的能效优化问题，为6G网络节能提供了有前景的解决方案。

Abstract: With the explosive growth of data traffic and the ubiquitous connectivity of wireless devices, the energy demands of wireless networks have inevitably escalated. Reconfigurable intelligent surface (RIS) has emerged as a promising solution for 6G networks due to its energy efficiency (EE) and low cost, while cell-free massive multiple-input multiple-output (CF-mMIMO) was proposed as an innovative network architecture without fixed cell boundaries to enhance these measures even further. However, existing studies often assume consistently high traffic loads, neglecting the dynamic nature of user demand. This can result in underutilized access points (APs) and unnecessary energy expenditure during low-demand periods. To tackle the challenge of EE in CF-mMIMO systems during low load periods, this paper proposes a novel energy-efficient transmission scheme that jointly coordinates active APs and multiple passive RISs. Specifically, a dynamic AP sleep-mode strategy is designed, where certain APs are selectively deactivated while nearby RISs assist in maintaining coverage. We formulate the EE maximization objective as a fractional programming problem and adopt the Dinkelbach method in conjunction with alternating optimization (AO) to iteratively solve the three coupled subproblems: (i) AP selection via a hybrid branch-and-bound (BnB) and greedy algorithm, (ii) transmit power optimization using a sequential convex approximation (SCA) method, initialized by a heuristic zero-forcing strategy, and (iii) RIS phase shift optimization using gradient projection. Simulation results show that the proposed scheme achieves significantly higher EE than existing methods in both low and moderate user scenarios.

</details>


### [24] [WATOS: Efficient LLM Training Strategies and Architecture Co-exploration for Wafer-scale Chip](https://arxiv.org/abs/2512.12279)
*Huizheng Wang,Zichuan Wang,Hongbin Wang,Jingxiang Hou,Taiquan Wei,Chao Li,Yang Hu,Shouyi Yin*

Main category: eess.SP

TL;DR: WATOS是一个协同探索框架，用于优化大语言模型训练策略与晶圆级架构设计，通过硬件模板定义和并行策略探索，相比现有方法实现了显著的吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 训练大语言模型对计算、内存和互连带宽要求极高，晶圆级集成虽然提供了高密度集成方案，但有限的晶圆面积需要在计算、内存和通信资源之间做出权衡。现有方法无法有效解决这些挑战。

Method: 提出WATOS协同探索框架：1) 定义高度可配置的硬件模板来探索晶圆级芯片的最优架构参数；2) 利用晶圆级芯片的高D2D带宽和细粒度操作优势，探索最优并行化和资源分配策略，解决LLM训练中的内存利用率不足问题。

Result: 相比最先进的Megatron框架和Cerebras的权重流晶圆训练策略，WATOS在各种LLM模型上分别实现了平均2.74倍和1.53倍的整体吞吐量提升。同时揭示了晶圆级架构设计的重要见解。

Conclusion: WATOS框架成功解决了晶圆级LLM训练中的架构与策略协同优化问题，显著提升了训练性能，并为晶圆级架构设计提供了有价值的见解。

Abstract: Training large language models (LLMs) imposes extreme demands on computation, memory capacity, and interconnect bandwidth, driven by their ever-increasing parameter scales and intensive data movement. Wafer-scale integration offers a promising solution by densely integrating multiple single-die chips with high-speed die-to-die (D2D) interconnects. However, the limited wafer area necessitates trade-offs among compute, memory, and communication resources. Fully harnessing the potential of wafer-scale integration while mitigating its architectural constraints is essential for maximizing LLM training performance. This imposes significant challenges for the co-optimization of architecture and training strategies. Unfortunately, existing approaches all fall short in addressing these challenges.
  To bridge the gap, we propose WATOS, a co-exploration framework for LLM training strategy and wafer-scale architecture. We first define a highly configurable hardware template designed to explore optimal architectural parameters for wafer-scale chips. Based on it, we capitalize on the high D2D bandwidth and fine-grained operation advantages inherent to wafer-scale chips to explore optimal parallelism and resource allocation strategies, effectively addressing the memory underutilization issues during LLM training. Compared to the state-of-the-art (SOTA) LLM training framework Megatron and Cerebras' weight streaming wafer training strategy, WATOS can achieve an average overall throughput improvement of 2.74x and 1.53x across various LLM models, respectively. In addition, we leverage WATOS to reveal intriguing insights about wafer-scale architecture design with the training of LLM workloads.

</details>


### [25] [XR Capacity Enhancement through Multi-Connected XR Tethering Groups](https://arxiv.org/abs/2512.12368)
*Muhammad Ahsen,Boyan Yanakiev,Claudio Rosa,Ramoni Adeogun*

Main category: eess.SP

TL;DR: 本文研究5G-A网络中通过多连接XR系留组提升XR容量的方法，采用选择合并和软合并两种协作方式，结合增强的联合OLLA算法，显著提高了XR容量和eMBB吞吐量。


<details>
  <summary>Details</summary>
Motivation: 5G-A网络中XR应用因高吞吐量、低延迟和高可靠性要求而容量受限，需要创新方案来提升下行链路XR容量。

Method: 提出多连接XR系留组，包含XR设备和协作的5G-A设备，研究选择合并和软合并两种协作方式，设计联合HARQ反馈处理算法和增强的联合OLLA算法。

Result: 软合并XR系留组在纯XR用户场景下提升容量23-42%，在XR与eMBB共存场景下提升38-173%；增强联合OLLA算法在单设备CSI报告下也能实现类似性能增益。

Conclusion: 多连接XR系留组特别是软合并方案能显著提升5G-A网络中XR容量，增强的联合OLLA算法能有效利用多连接优势，同时改善eMBB吞吐量。

Abstract: Extended Reality (XR) applications have limited capacity in 5th generation-advanced (5G-A) cellular networks due to high throughput requirements coupled with strict latency and high reliability constraints. To enhance XR capacity in the downlink (DL), this paper investigates multi-connected XR tethering groups (TGrs), comprising an XR device and a cooperating 5G-A device. This paper presents investigations for two types of cooperation within XR TGr, i.e., selection combining (SC) and soft combining and their impact on the XR capacity of the network. These investigations consider joint hybrid automatic repeat request (HARQ) feedback processing algorithm and also propose enhanced joint Outer Loop Link Adaptation (OLLA) algorithm to leverage the benefits of multi-connectivity. These enhancements aim to improve the spectral efficiency of the network by limiting HARQ retransmissions and enabling the use of higher modulation and coding scheme (MCS) indices for given signal-to-interference-plus-noise ratio (SINR), all while maintaining or operating below than the target block error rate (BLER). Dynamic system-level simulation demonstrate that XR TGrs with soft combining achieve performance improvements of 23 - 42% in XR capacity with only XR users and 38-173% in the coexistence scenarios consisting of XR users and enhanced mobile broadband (eMBB) user. Furthermore, the enhanced joint OLLA algorithm enables similar performance gains even when only one device per XR TGr provides channel state information (CSI) reports, compared to scenarios where both devices report CSI. Notably, XR TGrs with soft combining also enhance eMBB throughput in coexistence scenarios.

</details>


### [26] [Comparing Stochastic and Ray-tracing Datasets in Machine Learning for Wireless Applications](https://arxiv.org/abs/2512.12449)
*João Morais,Akshay Malhotra,Shahab Hamidi-Rad,Ahmed Alkhateeb*

Main category: eess.SP

TL;DR: 该研究探讨了无线系统中机器学习评估时，标准化随机信道模型与射线追踪数据的适用场景差异，发现随机模型评估可能高估或低估实际性能，提出了任务感知的混合使用方案。


<details>
  <summary>Details</summary>
Motivation: 无线系统机器学习研究通常使用标准化随机信道模型（如TDL/CDL/UMa），但这些模型的结构假设可能与真实传播环境存在差异。需要明确这些模型何时足够，何时需要使用更接近真实世界的射线追踪数据。

Method: 通过实证研究，在两个代表性任务（CSI压缩和时序信道预测）上，采用域内训练、跨域评估和小数据微调三种协议，对比分析随机信道模型和射线追踪数据的表现差异。

Result: 研究发现：1）仅使用随机模型评估可能高估或低估相对于射线追踪数据的性能；2）随机模型适用于可扩展的预训练和不依赖强时空耦合的任务；3）当任务依赖强时空耦合时，预训练和评估应基于空间一致或几何相似的射线追踪场景。

Conclusion: 提出了任务感知的混合使用方案：随机模型可用于可扩展预训练和弱时空耦合任务，而强时空耦合任务需要基于射线追踪数据。为未来基准测试和标准化讨论提供了初步指导。

Abstract: Machine learning for wireless systems is commonly studied using standardized stochastic channel models (e.g., TDL/CDL/UMa) because of their legacy in wireless communication standardization and their ability to generate data at scale. However, some of their structural assumptions may diverge from real-world propagation. This paper asks when these models are sufficient and when ray-traced (RT) data - a proxy for the real world - provides tangible benefits. To answer these questions, we conduct an empirical study on two representative tasks: CSI compression and temporal channel prediction. Models are trained and evaluated using in-domain, cross-domain, and small-data fine-tuning protocols. Across settings, we observe that stochastic-only evaluation may over- or under-estimate performance relative to RT. These findings support a task-aware recipe where stochastic models can be leveraged for scalable pre-training and for tasks that do not rely on strong spatiotemporal coupling. When that coupling matters, pre-training and evaluation should be grounded in spatially consistent or geometrically similar RT scenarios. This study provides initial guidance to inform future discussions on benchmarking and standardization.

</details>


### [27] [Wavelet-Packet-based Noise Signatures With Higher-Order Statistics for Anomaly Prediction](https://arxiv.org/abs/2512.12528)
*Indrakshi Dey,Ilias Cherkaoui,Mohamed Khalafalla Hassan*

Main category: eess.SP

TL;DR: 首个针对融合离散时间信号的噪声中心异常预测方法，利用小波包变换分离结构与残差，高阶统计量量化非高斯性和非线性耦合，构建紧凑噪声特征，通过分析校准的马氏距离检测器实现闭式决策规则。


<details>
  <summary>Details</summary>
Motivation: 开发首个针对融合离散时间信号的噪声中心异常预测方法，旨在通过分析信号残差中的噪声特征来检测异常，传统方法可能忽略残差中的非高斯性和非线性耦合信息。

Method: 1. 使用小波包变换进行时频展开，通过正交投影分离信号结构与残差；2. 应用高阶统计量（特别是三阶累积量及其双谱解释）量化残差的非高斯性和非线性耦合；3. 构建紧凑噪声特征；4. 设计分析校准的马氏距离检测器，产生具有非中心卡方性能的闭式决策规则。

Result: 提出了首个噪声中心异常预测框架，建立了正交性、能量保持、累积量的高斯零行为以及所得检验统计量的理论性质，通过命题和证明验证了方法的理论基础。

Conclusion: 该方法为融合离散时间信号的异常预测提供了新的噪声中心视角，通过小波包变换和高阶统计量有效提取残差特征，分析校准的检测器提供了理论保证的闭式决策规则。

Abstract: This note develops the first-ever noise-centric anomaly prediction method for a fused discrete-time signal. A Wavelet Packet Transform (WPT) provides a time--frequency expansion in which structure and residual can be separated via orthogonal projection. Higher-Order Statistics (HOS), particularly the third-order cumulant (and its bispectral interpretation), quantify non-Gaussianity and nonlinear coupling in the extracted residual. Compact noise signatures are constructed and an analytically calibrated Mahalanobis detector yields a closed-form decision rule with non-central chi-square performance under mean-shift alternatives. Propositions and proofs establish orthonormality, energy preservation, Gaussian-null behavior of cumulants, and the resulting test statistics.

</details>


### [28] [Power Consumption and Energy Efficiency of Mid-Band XL-MIMO: Modeling, Scaling Laws, and Performance Insights](https://arxiv.org/abs/2512.12725)
*Jiachen Tian,Yu Han,Xiao Li,Shi Jin,Chao-Kai Wen*

Main category: eess.SP

TL;DR: 该论文研究了中频段超大规模MIMO系统的能效问题，提出了综合功耗模型和吞吐量分析框架，推导了能效与关键系统参数的缩放规律，验证了中频段XL-MIMO在能效方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 中频段超大规模MIMO虽然能通过扩展带宽和增大天线孔径提供更高吞吐量，但系统维度扩大导致功耗问题严重，需要深入研究高效系统设计和部署方案。

Method: 提出了综合功耗模型，涵盖主要硬件组件和信号处理过程的功耗；考虑典型近场传播特性，推导了吞吐量的闭式近似；建立了能效分析框架，推导了能效与关键系统配置的缩放规律；扩展比较了代表性多天线技术。

Result: 数值结果验证了吞吐量分析的紧密度和能效评估的有效性；揭示了中频段XL-MIMO系统在能效方面的潜力；展示了该技术在能效方面相对于其他多天线技术的优越性。

Conclusion: 中频段XL-MIMO系统具有显著的能效潜力，提出的分析框架和缩放规律为系统设计提供了有价值的指导，有助于实现未来通信系统的高能效部署。

Abstract: Mid-band extra-large-scale multiple-input multiple-output (XL-MIMO), emerging as a critical enabler for future communication systems, is expected to deliver significantly higher throughput by leveraging the extended bandwidth and enlarged antenna aperture. However, power consumption remains a significant concern due to the enlarged system dimension, underscoring the need for thorough investigations into efficient system design and deployment. To this end, an in-depth study is conducted on mid-band XL-MIMO systems. Specifically, a comprehensive power consumption model is proposed, encompassing the power consumption of major hardware components and signal processing procedures, while capturing the influence of key system parameters. Considering typical near-field propagation characteristics, closed-form approximations of throughput are derived, providing an analytical framework for assessing energy efficiency (EE). Based on the proposed framework, the scaling law of EE with respect to key system configurations is derived, offering valuable insights for system design. Subsequently, extensions and comparisons are conducted among representative multi-antenna technologies, demonstrating the superiority of mid-band XL-MIMO in EE. Extensive numerical results not only verify the tightness of the throughput analysis but also validate the EE evaluations, unveiling the potential of energy-efficient mid-band XL-MIMO systems.

</details>


### [29] [Channel Estimation for Full-duplex Multi-tag Ambient Backscatter Communication Systems with I/Q Imbalance](https://arxiv.org/abs/2512.12811)
*Saeed Abdallah,Mahmoud A. Albreem,Bassel Al Homssi,Mohamed Saad,Abdulmalik Alwarafy*

Main category: eess.SP

TL;DR: 提出针对全双工多标签环境反向散射通信系统的三阶段训练协议和信道估计方案，包括导频估计和两种半盲估计方法，以解决多标签、自干扰和I/Q不平衡带来的信道估计挑战。


<details>
  <summary>Details</summary>
Motivation: 全双工多标签环境反向散射通信系统对下一代物联网网络至关重要，但多个标签、自干扰和I/Q不平衡等硬件损伤使得准确信道估计成为有效干扰管理的关键。大量信道参数和信号镜像分量的存在需要精心设计信道估计阶段以防止性能下降。

Method: 提出新颖的三阶段训练协议和导频估计方案，确保信号正交性并避免误差平台。同时提出两种半盲估计器：基于决策导向准则和基于期望条件最大化框架，利用导频和数据符号实现更高估计精度。

Result: 导频估计器和ECM估计器分别接近其克拉美罗界，DD估计器性能介于两者之间。三种方案通过不同的性能与计算复杂度权衡支持不同的应用场景。

Conclusion: 提出的三阶段训练协议和三种信道估计方案有效解决了全双工多标签AmBC系统的信道估计挑战，为不同应用场景提供了性能与复杂度的灵活权衡。

Abstract: Ambient backscatter communication (AmBC) has emerged as a highly attractive paradigm for energy-efficient communication. Full-duplex multi-tag AmBC systems provide the scalability and efficient spectrum utilization essential for next generation Internet-of-Things (IoT) networks. However, the presence of multiple tags, self-interference and hardware impairments such as inphase/quadrature (I/Q) imbalance, makes accurate channel estimation indispensable for efficient interference management. The large number of channel parameters and the presence of mirror images of each signal component necessitate careful design of the channel estimation phase to prevent performance degradation. In this work, we propose a novel three-stage training protocol and pilot-based estimation scheme that ensure signal orthogonality and successfully avoid error floors. We also propose two semi-blind estimators, one based on decision-directed (DD) criterion and the other on the expectation conditional maximization (ECM) framework. By exploiting both pilots and data symbols, these two estimators achieve higher estimation accuracy than pilot-based estimation, at the cost of additional complexity. Cramer-Rao bounds (CRBs) for both types of estimation are also derived. The pilot-based estimator and the ECM estimator approach their respective CRBs, while the DD estimator performs mid-way between them. The three proposed solutions support different use cases by offering distinct tradeoffs between performance and computational complexity.

</details>


### [30] [A Comprehensive Survey of Channel Estimation Techniques for OTFS in 6G and Beyond Wireless Networks](https://arxiv.org/abs/2512.13032)
*Emir Aslandogan,Haci Ilhan,Burak Ahmet Ozden,Erdogan Aydin,Ertugrul Basar,Miaowen Wen,Marco Di Renzo,Vincent Poor*

Main category: eess.SP

TL;DR: 本文系统综述了OTFS调制系统中的信道估计技术，涵盖从基础到前沿的各种方法，包括时延-多普勒域和时频域估计、多种算法框架、联合估计与检测策略，以及与下一代无线系统的集成挑战。


<details>
  <summary>Details</summary>
Motivation: OTFS调制专门针对高移动性场景和多普勒效应挑战设计，将信号投影到时延-多普勒域，使信道呈现稀疏和准静态特性。然而，需要系统性的信道估计技术来充分发挥其在高移动性、严重多径效应和快速时变信道条件下的优势。

Method: 文章系统性地综述了OTFS系统的信道估计技术，包括：1）时延-多普勒域和时频域估计方法（分离导频、嵌入导频、叠加导频）；2）多种算法框架（贝叶斯学习、匹配追踪、消息传递、深度学习等）；3）联合信道估计与信号检测策略；4）与下一代无线系统的集成（大规模MIMO、毫米波、可重构智能表面、集成感知与通信）。

Result: 文章全面梳理了OTFS信道估计的研究现状，展示了各种技术在不同场景下的适用性和性能特点，为高移动性无线通信系统的设计和优化提供了系统性的技术参考。

Conclusion: OTFS调制通过时延-多普勒域变换为高移动性场景提供了优越的信道估计性能，但面临泄漏抑制、多普勒干扰缓解、脉冲噪声处理、信令开销、保护间隔、峰均功率比、波束倾斜效应和硬件损伤等关键实现挑战，需要进一步研究解决。

Abstract: Orthogonal time-frequency space (OTFS) modulation has emerged as a powerful wireless communication technology that is specifically designed to address the challenges of high-mobility scenarios and significant Doppler effects. Unlike conventional modulation schemes that operate in the time-frequency (TF) domain, OTFS projects signals to the delay-Doppler (DD) domain, where wireless channels exhibit sparse and quasi-static characteristics. This fundamental transformation enables superior channel estimation (CE) performance in challenging propagation environments characterized by high-mobility, severe multipath effects, and rapidly time-varying channel conditions. This article provides a systematic examination of CE techniques for OTFS systems, covering the extensive research landscape from foundational methods to cutting-edge approaches. We present a detailed analysis of DD and TF domain CE techniques presented in the literature, including separate pilot, embedded pilot, and superimposed pilot approaches. The article encompasses various algorithmic frameworks including Bayesian learning, matching pursuit-based techniques, message passing algorithms, deep learning (DL)-based methods, and recent CE approaches. Additionally, we explore joint CE and signal detection (SD) strategies, the integration of OTFS with next-generation wireless systems including massive multiple-input multiple-output (MIMO), millimeter wave (mmWave) communications, reconfigurable intelligent surfaces (RISs), and integrated sensing and communication (ISAC) systems. Critical implementation challenges are presented, including leakage suppression, inter-Doppler interference mitigation, impulsive noise handling, signaling overhead reduction, guard space requirements, peak-to-average power ratio (PAPR) management, beam squint effects, and hardware impairments.

</details>


### [31] [MR Fingerprinting for Imaging Brain Hemodynamics and Oxygenation](https://arxiv.org/abs/2512.13224)
*T. Coudert,A. Delphin,A. Barrier,E L Barbier,B. Lemasson,J M Warnking,T. Christen*

Main category: eess.SP

TL;DR: 本文综述了磁共振指纹技术（MRF）在脑血流动力学、氧合和灌注定量方面的研究进展，重点介绍了血管模拟几何模型、新序列以及结合机器学习和深度学习的重建技术，并讨论了临床转化前景。


<details>
  <summary>Details</summary>
Motivation: 过去十年中，磁共振指纹技术在脑血流动力学、氧合和灌注定量方面显示出巨大潜力，但需要系统总结该领域的最新进展，包括模拟模型、重建框架的改进以及临床转化面临的挑战。

Method: 本文采用文献综述方法，系统梳理了血管MRF研究的关键进展，重点关注血管模拟的几何模型创新、新型序列设计以及结合机器学习和深度学习的先进重建技术。

Result: 综述显示，模拟模型和重建框架的进步显著提高了血管参数估计的准确性，机器学习和深度学习算法在重建技术中展现出优势，该技术已在临床前和临床研究中得到应用。

Conclusion: 磁共振指纹技术在血管参数定量方面具有重要潜力，但需要进一步解决临床转化中的技术挑战，未来发展方向包括优化模型、改进算法和推进临床应用验证。

Abstract: Over the past decade, several studies have explored the potential of magnetic resonance fingerprinting (MRF) for the quantification of brain hemodynamics, oxygenation, and perfusion. Recent advances in simulation models and reconstruction frameworks have also significantly enhanced the accuracy of vascular parameter estimation. This review provides an overview of key vascular MRF studies, emphasizing advancements in geometrical models for vascular simulations, novel sequences, and state-of-the-art reconstruction techniques incorporating machine learning and deep learning algorithms. Both pre-clinical and clinical applications are discussed. Based on these findings, we outline future directions and development areas that need to be addressed to facilitate their clinical translation. Evidence Level N/A. Technical Efficacy Stage 1.

</details>


### [32] [Interference-Free RIS-Aided Cell-Free Massive MIMO with Physical Layer Security](https://arxiv.org/abs/2512.13243)
*Sumeyra Hassan,Bin Li,Yalcin Sadi,Erdal Panayirci,H. Vincent Poor*

Main category: eess.SP

TL;DR: 提出了一种基于可重构智能表面的无蜂窝大规模MIMO框架，通过联合优化主动波束成形、用户功率分配和RIS相位矩阵来增强物理层安全性和抑制多用户干扰。


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络需要增强物理层安全性并抑制多用户干扰，特别是在密集无线环境中。传统方法在安全性和干扰抑制方面存在局限，需要更有效的解决方案。

Method: 设计了基于CSI的预编码器抑制多用户干扰，采用交替优化框架联合优化主动波束成形、用户功率分配和RIS相位矩阵，利用黎曼流形优化和黎曼共轭梯度算法解决高度非凸的RIS相位设计问题。

Result: 仿真结果表明，所提框架能有效提升安全总速率并消除干扰，证明了其在密集无线环境中构建安全可扩展无蜂窝大规模MIMO网络的潜力。

Conclusion: 该RIS辅助的无蜂窝大规模MIMO框架为下一代无线网络提供了有效的物理层安全增强和干扰抑制解决方案，特别适用于密集无线环境。

Abstract: In this paper, a reconfigurable intelligent surface (RIS) assisted cell free massive MIMO (CFmMIMO) framework is designed to enhance physical layer security (PLS) and mitigate multi user (MU) interference in next generation wireless networks. A channel state information (CSI) based precoder is designed at the access point (AP) to suppress MU interference, enabling interference free reception for the legitimate users. To further enhance secrecy performance, we formulate a joint optimization problem that maximizes the secrecy sum rate using an alternating optimization (AO) framework, which iteratively updates the active beamforming at the AP, user power allocation, and the RIS phase shift matrix. The highly nonconvex problem is addressed under the Riemannian manifold optimization (RMO) framework and solved using a Riemannian Conjugate Gradient (RCG) algorithm for RIS phase shift design. Simulation results verify that the proposed framework effectively enhances the secrecy sum rate and eliminates interference, demonstrating its potential for secure and scalable CFmMIMO networks in dense wireless environments.

</details>


### [33] [From Nodes to Edges: Edge-Based Laplacians for Brain Signal Processing](https://arxiv.org/abs/2512.13420)
*Andrea Santoro,Marco Nurisso,Giovanni Petri*

Main category: eess.SP

TL;DR: 本文提出基于边的图信号处理方法分析脑网络，相比传统节点方法能更好地捕捉脑区间的协同波动信息，在任务解码中表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统图信号处理方法主要关注节点信号，无法有效捕捉脑网络中发生在边上的重要动态信息，需要开发边中心的GSP方法来更全面地理解脑功能组织。

Method: 采用边中心的图信号处理方法，使用一维Hodge拉普拉斯算子描述结构连接性，处理定义在边上的信号来捕捉脑区间的协同波动信息。

Result: 基于边的方法在静态和动态场景下都比传统节点方法获得更高的任务解码准确率，揭示了脑功能组织的独特方面。

Conclusion: 边聚焦的GSP策略在加深对脑连接性和功能动态理解方面具有重要前景，能够揭示传统节点方法无法捕捉的重要信息。

Abstract: Traditional graph signal processing (GSP) methods applied to brain networks focus on signals defined on the nodes. Thus, they are unable to capture potentially important dynamics occurring on the edges. In this work, we adopt an edge-centric GSP approach to analyze edge signals constructed from 100 unrelated subjects of the Human Connectome Project. Specifically, we describe structural connectivity through the lens of the 1-dimensional Hodge Laplacian, processing signals defined on edges to capture co-fluctuation information between brain regions. We demonstrate that edge-based approaches achieve superior task decoding accuracy in static and dynamic scenarios compared to conventional node-based techniques, thereby unveiling unique aspects of brain functional organization. These findings underscore the promise of edge-focused GSP strategies for deepening our understanding of brain connectivity and functional dynamics.

</details>


### [34] [Interference Mitigation Recommender System using U-Net Autoencoders](https://arxiv.org/abs/2512.13533)
*Hiten Prakash Kothari,R. Michael Buehrer*

Main category: eess.SP

TL;DR: 提出模块化推荐系统，根据干扰特征自动选择最佳干扰抑制策略，集成分类、预测和专用U-Net自编码器，在动态通信环境中提升抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 现有干扰抑制方法在不同干扰条件下效果不一，需要自适应系统根据实际干扰特征动态选择最优策略，以提升通信系统在动态环境中的鲁棒性。

Method: 设计三阶段模块化系统：SPS分类器识别干扰参数，SIR预测器估计信干比，专用U-Net自编码器库处理不同干扰条件。推荐器根据分类和预测结果选择最佳抑制模型，支持连续干扰消除。

Result: 在不同SIR水平和调制环境下，推荐策略相比单一抑制方法显著降低误码率，提升系统鲁棒性，验证了自适应模型选择架构的有效性。

Conclusion: 模块化推荐系统通过智能选择干扰抑制策略，在动态通信环境中展现出优越的抗干扰性能，为自适应通信系统设计提供了新思路。

Abstract: Building on the previous work on interference mitigation, this paper introduces a modular recommender system that automatically selects the most effective interference mitigation strategy based on the interference characteristics present in the received signal. The system integrates three key stages: an SPS classifier module, a SIR predictor, and a bank of specialized U-Net autoencoders designed for different interference conditions. The classification block identifies the parameters required for cancellation. The recommender then directs the signal to the appropriate mitigation model, optionally incorporating SIR-based decisions for scenarios where successive interference cancellation may be advantageous. Experiments conducted across diverse SIR levels and modulation environments show that the recommender strategy improves robustness and reduces BER compared to using any single mitigation method alone. The results demonstrate the potential of adaptive, model-selective architectures to enhance interference resilience in dynamic communication environments.

</details>


### [35] [On the Ability of Deep Learning to Detect Signals with Unknown Parameters](https://arxiv.org/abs/2512.13542)
*Tom Anders,Hiten Prakash Kothari,R. Michael Buehrer*

Main category: eess.SP

TL;DR: 该论文研究使用深度神经网络进行信号检测，与统计方法和匹配滤波器比较，在AWGN噪声中检测未知参数信号。


<details>
  <summary>Details</summary>
Motivation: 在信号处理中，检测未知参数信号是一个基本问题。传统方法如匹配滤波器需要完美信号知识，而实际中信号参数未知，缺乏最优检测器。深度神经网络在假设检验问题中表现出色，因此探索其在原始I/Q信号层面的应用。

Method: 使用基于深度神经网络的方法进行信号检测，训练和评估两种机器学习算法，应用于三种感兴趣信号模型。还训练了一个统一数据集模型，在所有信号类型上进行评估。目标是最大化检测概率Pd，同时保持恒定的虚警概率PFA。

Result: 论文比较了DNN方法与统计方法及匹配滤波器的性能。具体结果未在摘要中给出，但评估了不同信号模型下的检测性能。

Conclusion: 深度神经网络方法在信号检测问题上具有潜力，能够处理未知参数信号，并与传统统计方法和匹配滤波器基准进行比较。

Abstract: In many signal processing applications, including communications, sonar, radar, and localization, a fundamental problem is the detection of a signal of interest in background noise, known as signal detection [1] [2]. A simple version of this problem is the detection of a signal of interest with unknown parameters in Additive White Gaussian Noise (AWGN). When the parameters defining the signal are not known, an optimal detector (in the Neyman-Pearson sense) does not exist. An upper bound on the performance of any detector is the matched filter, which implies perfect sample by sample knowledge of the signal of interest. In recent years Deep Neural Networks (DNNs) have proven to be very effective at hypothesis testing problems such as object detection and image classification. This paper examines the application of DNN-based approaches to the signal detection problem at the raw I/Q level and compares them to statistically based approaches as well as the Matched Filter. These methods aim to maximize the Probability of Detection Pd while maintaining a constant Probability of False Alarm PF A. Two Machine Learning (ML) algorithms are trained and assessed on this signal detection problem, across three signal of interest models. A model was also trained on a unified dataset and assessed across all signals of interest.

</details>


### [36] [A new data weighted averaging algorithm to reduce tones in the signal band](https://arxiv.org/abs/2512.13605)
*Marta Laguna,Juana M. Martínez-Heredia,Manuel G. Satué*

Main category: eess.SP

TL;DR: 本文分析了DWA方法在Σ-Δ调制器中产生杂散音调的机制，并提出了一种改进的DWA方法来消除这些杂散音调。


<details>
  <summary>Details</summary>
Motivation: 多比特Σ-Δ调制器通过降低时钟频率和增加量化器级数来平衡复杂度与速度，但多位数模转换器(DAC)会降低系统性能。现有的数据加权平均(DWA)方法虽然能减少DAC误差的敏感性，但会在信号带内产生杂散音调。

Method: 分析了DWA产生杂散音调的机制，并提出了一种改进的DWA方法来消除这些杂散音调。

Result: 提出的改进DWA方法能够有效消除传统DWA方法在信号带内产生的杂散音调问题。

Conclusion: 改进的DWA方法解决了传统DWA在减少DAC误差敏感性时产生的杂散音调问题，提高了多比特Σ-Δ调制器的整体性能。

Abstract: Digital/Analog converters based on sigma-delta modulation are simple and unexpensive circuits featuring a signal bandwidth limited by speed constraints. Multi-bit modulators allow balancing complexity and speed by reducing the clock frequency and increasing the number of levels in the quantizer. In this case, the multi-bit digital to analog block (DAC) can reduce the performance of the entire system. Data Weighted Averaging (DWA) methods have been proposed to reduce the vulnerability to DAC errors at the cost of spurious tones in the signal band. This work analyzes the tone producing mechanism and proposes a modification of the DWA to remove spurious tones.

</details>


### [37] [Performance Limits of Hardware-Constrained THz Inter-Satellite MIMO-ISAC Systems](https://arxiv.org/abs/2512.13652)
*Haofan Dong,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 该论文建立了太赫兹卫星间链路中MIMO ISAC系统在恒定包络约束下的理论性能极限，揭示了硬件失真导致的容量上限，并推导了传感误差随导频开销的闭式缩放规律。


<details>
  <summary>Details</summary>
Motivation: 太赫兹卫星间链路虽然提供巨大带宽，但受到星载功率和热预算的严格限制。现有研究缺乏在恒定包络传输约束下，考虑硬件失真（功率放大器非线性、ADC量化、振荡器相位噪声）对MIMO ISAC系统性能影响的统一理论框架。

Method: 提出统一链路预算框架，通过频谱一致性原则整合宽带波束斜视、孔径指向误差和有色噪声源。在恒定加速度运动模型下，利用Whittle-Fisher信息矩阵推导传感边界，得到闭式缩放规律。采用数值仿真验证理论分析。

Result: 硬件失真导致无法通过增加发射功率克服的容量上限。传感精度随阵列尺寸改善（RMSE ∝ 1/√(N_t N_r)），但临界SNR具有尺度不变性。动态状态估计误差方差随导频开销α按α^{-5}缩放，在α<0.16时进入操作不可行区域。

Conclusion: 该研究为硬件高效的太赫兹卫星间链路星座设计提供了理论指导：硬件失真限制系统性能，传感和通信性能随阵列尺寸呈现不同缩放规律，导频开销存在临界阈值，这些发现对实际系统设计具有重要意义。

Abstract: Terahertz inter-satellite links (THz-ISL) offer unprecedented bandwidth for future space networks but face fundamental constraints from onboard power and thermal budgets. This paper establishes theoretical performance limits for MIMO Integrated Sensing and Communication (ISAC) systems under per-element constant-envelope (CE) transmission constraints. We demonstrate that hardware distortions -- specifically power amplifier nonlinearity, ADC quantization, and oscillator phase noise -- impose a capacity ceiling that cannot be overcome by increasing transmit power. A unified link budget framework integrates wideband beam squint, aperture pointing errors, and colored noise sources through a spectral consistency principle that ensures residual phase noise is counted exactly once across communication and sensing analyses. The sensing bounds are derived via the Whittle-Fisher Information Matrix under a Constant Acceleration kinematic model with jerk noise, yielding closed-form scaling laws: residual phase noise variance scales as $α^{-1}$ while dynamic state-estimation error (DSE) variance scales as $α^{-5}$ with pilot overhead $α$. Numerical results show divergent MIMO scaling: sensing precision improves with array size ($\mathrm{RMSE} \propto 1/\sqrt{N_t N_r}$), while the critical SNR exhibits scale invariance regarding array size, implying that the distortion-limited transition point stabilizes regardless of the array scale. The steep $α^{-5}$ DSE scaling creates an operationally infeasible region at $α< α^* \approx 0.16$, where $α^* = (C_{\mathrm{DSE}}/C_{\mathrm{PN}})^{1/4}$ -- a constraint-driven threshold under the adopted baseline for LEO operation. These findings provide design guidelines for hardware-efficient THz-ISL constellations.

</details>
