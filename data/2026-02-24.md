<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 8]
- [eess.SP](#eess.SP) [Total: 20]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Turbo Coded Single Sideband OFDM-OQAM Signaling through Frequency Selective Rayleigh Fading Channels](https://arxiv.org/abs/2602.18881)
*Kasturi Vasudevan*

Main category: cs.IT

TL;DR: 研究Turbo编码OFDM-OQAM信号在频率选择性瑞利衰落信道中，存在载波频率偏移和高斯白噪声时的误码率性能，提出使用根升余弦脉冲及其希尔伯特变换作为复值发射滤波器，接收端使用简单匹配滤波器。


<details>
  <summary>Details</summary>
Motivation: 研究在频率选择性瑞利衰落信道中，存在载波频率偏移和高斯白噪声干扰时，Turbo编码OFDM-OQAM系统的误码率性能，填补该领域的研究空白。

Method: 使用根升余弦脉冲及其希尔伯特变换作为复值发射滤波器，接收端采用简单匹配滤波器，系统类似于单边带调制。采用Turbo编码和子载波分集技术，提出帧检测、两步载波频率偏移估计、信道估计和噪声方差估计的离散时间算法。

Result: 提出的系统相比未编码系统显著改善了误码率性能，通过Turbo编码和子载波分集技术有效对抗频率选择性衰落和载波频率偏移的影响。

Conclusion: 该研究提出了一种新颖的Turbo编码OFDM-OQAM系统设计，采用根升余弦脉冲及其希尔伯特变换作为复值发射滤波器，结合Turbo编码和子载波分集，有效提升了在频率选择性瑞利衰落信道中的误码率性能，填补了该领域的研究空白。

Abstract: This work investigates the bit-error-rate (BER) performance of turbo coded orthogonal frequency division multiplexed - offset quadrature amplitude modulated (OFDM- OQAM) signals transmitted through frequency selective Rayleigh fading channels in the presence of carrier frequency offset (CFO) and additive white Gaussian noise (AWGN). The highlight of this work is to use the root raised cosine (RRC) pulse and its Hilbert transform as the complex-valued transmit filter and a simple matched filter at the receiver. The proposed system is similar to single sideband (SSB) modulation, that has roots in analog communications. Turbo code and subcarrier diversity is employed to improve the BER performance over that of an uncoded system. Discrete-time algorithms for frame detection, two-step CFO, channel and noise variance estimation have been proposed. A single transmit and receive antenna is assumed. Similar work has not been done earlier.

</details>


### [2] [Derivation Depth as an Information Metric: Axioms, Coding Theorems, and Storage--Computation Tradeoffs](https://arxiv.org/abs/2602.19137)
*Jianfeng Xu*

Main category: cs.IT

TL;DR: 论文提出推导深度作为衡量基于给定前提回答查询所需推理努力的可计算度量，建立了查询描述复杂度与推导深度的基本界限，并揭示了存储与计算之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏对推理过程中计算努力的量化度量，难以评估查询回答的复杂性。需要一种可计算的指标来理解信息检索和推理的效率，特别是在处理大规模知识库时。

Method: 将信息建模为连接抽象知识与物理载体的双层结构，区分核心事实与操作捷径。定义推导深度并证明其可计算性，通过编码推理轨迹和应用信息论不可压缩性论证建立基本界限。

Result: 建立了推导深度与查询描述复杂度之间的基本界限：对于频繁访问的信息丰富查询，最小描述长度与深度乘以知识库大小的对数成正比。发现了存储-计算权衡：超过临界阈值的查询缓存比重新计算更经济。

Conclusion: 推导深度为量化推理努力提供了理论基础，揭示了存储与计算之间的基本权衡。提出的缓存分配优化问题具有近似保证解，框架可扩展到处理噪声或不完整知识库。

Abstract: We introduce derivation depth-a computable metric of the reasoning effort needed to answer a query based on a given set of premises. We model information as a two-layered structure linking abstract knowledge with physical carriers, and separate essential core facts from operational shortcuts. For any finite premise base, we define and prove the computability of derivation depth. By encoding reasoning traces and applying information-theoretic incompressibility arguments, we establish fundamental bounds linking depth to the descriptive complexity of queries. For frequently asked, information-rich queries, the minimal description length grows proportionally to depth times the logarithm of the knowledge base size. This leads to a practical storage-computation tradeoff: queries accessed beyond a critical threshold become cheaper to cache than recompute. We formulate optimal cache allocation as a mathematical optimization problem solvable with approximation guarantees and extend the framework to handle noisy or incomplete knowledge bases.

</details>


### [3] [Physics-Compliant Modeling and Optimization of MIMO Systems Aided by Microwave Linear Analog Computers](https://arxiv.org/abs/2602.19379)
*Matteo Nerini,Bruno Clerckx*

Main category: cs.IT

TL;DR: 本文建立了考虑天线互耦的微波线性模拟计算机（MiLAC）辅助MIMO系统的物理合规模型，推导了互耦感知的MiLAC优化问题闭式解，证明了互耦对MiLAC系统有益，且MiLAC性能优于无匹配网络的数字架构。


<details>
  <summary>Details</summary>
Motivation: 现有MiLAC辅助通信研究依赖理想化信道模型并忽略天线互耦，但MiLAC在射频处理，互耦不仅影响信道特性，还改变MiLAC实现的线性变换操作，因此需要建立考虑互耦的物理合规模型。

Method: 使用多端口网络理论建立考虑互耦的MiLAC辅助MIMO系统物理合规模型，推导发射端、接收端或两端使用MiLAC的端到端系统模型，并公式化互耦感知的MiLAC优化问题，获得最大化接收信号功率的闭式全局最优解。

Result: 1. 互耦在MiLAC辅助系统中平均有益；2. 考虑互耦时，MiLAC性能相当于配备匹配网络的数字架构，但使用更少射频链；3. 考虑互耦时，MiLAC始终优于无匹配网络的数字架构。数值仿真验证了理论发现。

Conclusion: 本文建立了考虑天线互耦的MiLAC系统物理合规模型，证明了互耦对MiLAC性能的积极影响，为MiLAC辅助MIMO系统的实际设计和优化提供了理论基础。

Abstract: Microwave linear analog computer (MiLAC) has emerged as a promising architecture for implementing linear multiple-input multiple-output (MIMO) processing in the analog domain, with radio frequency (RF) signals. Existing studies on MiLAC-aided communications rely on idealized channel models and neglect antenna mutual coupling. However, since MiLAC performs processing at RF, mutual coupling becomes critical and alters the implemented operation, not only the channel characteristics. In this paper, we develop a physics-compliant model for MiLAC-aided MIMO systems accounting for mutual coupling with multiport network theory. We derive end-to-end system models for scenarios with MiLACs at the transmitter, the receiver, or both, showing how mutual coupling impacts the linear transformation implemented by the MiLACs. Furthermore, we formulate and solve a mutual coupling aware MiLAC optimization problem, deriving a closed-form globally optimal solution that maximizes the received signal power. We establish the fundamental performance limits of MiLAC with mutual coupling, and derive three analytical results. First, mutual coupling is beneficial in MiLAC-aided systems, on average. Second, with mutual coupling, MiLAC performs as digital architectures equipped with a matching network, while having fewer RF chains. Third, with mutual coupling, MiLAC always outperforms digital architectures with no matching network. Numerical simulations confirm our theoretical findings.

</details>


### [4] [Toward a Quiet Wireless World: Multi-Cell Pinching-Antenna Transmission](https://arxiv.org/abs/2602.19459)
*Zhiguo Ding*

Main category: cs.IT

TL;DR: 应用捏合天线技术实现多小区干扰管理，通过近距离传输降低功耗，从"喊叫"变为"耳语"式通信


<details>
  <summary>Details</summary>
Motivation: 传统天线多小区干扰管理导致功耗过高，特别是服务小区边缘用户时需要基站以高功率传输来克服严重的大尺度路径损耗

Method: 采用捏合天线技术进行多小区干扰管理，通过将收发对近距离放置实现低功率传输

Result: 多小区捏合天线传输能够创建一个"安静"的无线世界，用户QoS需求可以通过低发射功率满足

Conclusion: 捏合天线技术为多小区干扰管理提供了一种有效的低功耗解决方案，实现从高功率"喊叫"到低功率"耳语"的转变

Abstract: Conventional-antenna-based multi-cell interference management can lead to excessive power consumption. For example, in order to serve those users which are close to the cell edge, base stations often must transmit at very high power levels to overcome severe large-scale path-loss, i.e., the base stations have to ``shout" at the users to realize the users' target quality of service (QoS). This letter focuses on the application of pinching antennas to multi-cell interference management and demonstrates that the use of multi-cell pinching-antenna transmission leads to a quiet wireless world. In particular, each transceiver pair can be positioned in close proximity, and hence the users' QoS requirements can be met with only low transmit power, i.e., via ``whispering" rather than high-power transmission.

</details>


### [5] [Physics-Aware, Shannon-Optimal Compression via Arithmetic Coding for Distributional Fidelity](https://arxiv.org/abs/2602.19476)
*Cristiano Fanelli*

Main category: cs.IT

TL;DR: 提出基于算术编码的物理感知无损压缩方法，通过比较压缩码长差异来量化数据集间的分布一致性，作为生成AI合成数据保真度的评估指标。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI广泛用于合成数据生成，需要可靠的方法来验证合成数据与原始训练数据的分布一致性。传统方法面临数据量增长和维度增加的挑战，需要一种全局、可解释且理论最优的保真度评估指标。

Method: 使用算术编码对数据集进行无损可逆压缩，基于物理信息概率表示。通过比较不同数据集在相同物理参考分布下的压缩码长差异来量化分布差异，差异码长直接对应负对数似然差异。

Result: 该方法定义的保真度度量是全局的、可解释的、分量可加的，且在香农意义下渐近最优。相比gzip等通用压缩算法，该方法获得更高的压缩比，同时码长差异直接对应分布差异。

Conclusion: 基于算术编码的物理感知无损压缩不仅是一种压缩技术，更是测量数据集间保真度的有效工具，为生成AI合成数据的验证提供了理论严谨且实用的评估框架。

Abstract: Assessing whether two datasets are distributionally consistent has become a central theme in modern scientific analysis, particularly as generative artificial intelligence is increasingly used to produce synthetic datasets whose fidelity must be rigorously validated against the original data on which they are trained, a task made more challenging by the continued growth in data volume and problem dimensionality. In this work, we propose the use of arithmetic coding to provide a lossless and invertible compression of datasets under a physics-informed probabilistic representation. Datasets that share the same underlying physical correlations admit comparable optimal descriptions, while discrepancies in those correlations-arising from miscalibration, mismodeling, or bias-manifest as an irreducible excess in code length. This excess codelength defines an operational fidelity metric, quantified directly in bits through differences in achievable compression length relative to a physics-inspired reference distribution. We demonstrate that this metric is global, interpretable, additive across components, and asymptotically optimal in the Shannon sense. Moreover, we show that differences in codelength correspond to differences in expected negative log-likelihood evaluated under the same physics-informed reference model. As a byproduct, we also demonstrate that our compression approach achieves a higher compression ratio than traditional general-purpose algorithms such as gzip. Our results establish lossless, physics-aware compression based on arithmetic coding not as an end in itself, but as a measurement instrument for testing the fidelity between datasets.

</details>


### [6] [Nacrith: Neural Lossless Compression via Ensemble Context Modeling and High-Precision CDF Coding](https://arxiv.org/abs/2602.19626)
*Roberto Tacconelli*

Main category: cs.IT

TL;DR: Nacrith是一个基于135M参数Transformer语言模型的损失压缩系统，通过多项技术创新在文本压缩上超越了传统压缩方法和现有神经压缩方法，同时实现了高效推理。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的压缩方法存在量化开销大、推理速度慢、无法处理任意二进制文件等问题。Nacrith旨在构建一个高效、通用且压缩性能优越的神经压缩系统。

Method: 结合135M参数Transformer语言模型与轻量级在线预测器集成，采用32位算术编码器。引入8项关键技术：CDF精度提升、token级N-gram模型、自适应log-space偏置头、置信度跳过机制、混合二进制格式、高效推理后端、多GPU并行压缩、KV缓存滑动窗口优化。

Result: 在alice29.txt上达到0.918 bpb，优于gzip 3.1倍、bzip2 2.5倍、CMIX v21 44%、ts_zip 20%。在enwik8上达到0.9389 bpb，超越ts_zip 15%、FineZip 8%。在未见文本上达到0.723 bpb，证明非记忆伪影。

Conclusion: Nacrith展示了小规模LLM与精心设计的系统优化相结合，可以在压缩性能上超越传统方法和现有神经压缩方法，同时保持高效推理和低资源需求，为神经压缩的实际应用提供了可行方案。

Abstract: We present Nacrith, a lossless compression system that combines a 135M-parameter transformer language model (SmolLM2-135M) with an ensemble of lightweight online predictors and a 32-bit arithmetic coder. Beyond the base LLM-plus-arithmetic-coding paradigm, Nacrith introduces several contributions: (1) a CDF precision upgrade from 2^16 to 2^24 that eliminates ~75% of quantization overhead caused by minimum-probability floors in large vocabularies; (2) a token-level N-gram model for fast local predictions; (3) an adaptive log-space bias head correcting per-document LLM errors via online gradient descent; (4) confidence-based LLM skip for accelerating highly predictable tokens; (5) a hybrid binary format (NC06) extending neural compression to arbitrary binary files--to our knowledge a first among LLM-based compressors; (6) a llama.cpp inference backend achieving ~7x faster single-token decode than PyTorch; (7) parallel multi-GPU compression across up to 8 workers; and (8) native KV cache sliding window reducing per-slide cost by ~37x. The system requires only ~500 MB of GGUF weights and ~1.2 GB VRAM per worker, running on consumer GPUs.
  On alice29.txt (Canterbury Corpus, 152 KB), Nacrith achieves 0.918 bits per byte (bpb)--outperforming gzip by 3.1x, bzip2 by 2.5x, CMIX v21 by 44%, and ts_zip by 20%, while compressing below the 0th-, 1st-, and 2nd-order byte-level Shannon entropy bounds. On enwik8 (100 MB), Nacrith achieves 0.9389 bpb (11.74%), surpassing ts_zip (~1.11 bpb) by 15% and FineZip (1.024 bpb) by 8% despite using a 60x smaller model with no fine-tuning. An out-of-distribution evaluation on a document published after the model's training cutoff confirms these gains are not memorization artifacts, achieving 0.723 bpb on unseen text.

</details>


### [7] [Secure Communications, Sensing, and Computing Towards Next-Generation Networks](https://arxiv.org/abs/2602.19942)
*Ruiqi Liu,Beixiong Zheng,Jemin Lee,Si-Hyeon Lee,Georges Kaddoum,Onur Günlü,Deniz Gündüz*

Main category: cs.IT

TL;DR: 该论文全面调研了集成无线通信-感知-计算系统中的安全与隐私威胁及防护措施，涵盖物理层安全、语义通信、感知安全、分布式计算安全，并提出统一安全框架。


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络正从传统连接向集成感知与计算能力演进，这种融合带来了新的安全挑战。系统复杂性增加、攻击面扩大、数据密集型AI应用带来的隐私问题，都迫切需要全面研究集成无线系统的安全防护。

Method: 采用系统性文献调研方法：1) 回顾通信网络的物理层安全技术；2) 分析语义和语用通信的安全隐私影响及跨层设计方法；3) 从信号源、传播信道、感知目标三个层面识别感知功能的安全隐私风险；4) 讨论分布式计算中的数据泄露、弱认证等风险及安全编码计算方法；5) 提出面向集成通信-感知-计算架构的统一安全框架。

Result: 论文系统梳理了集成无线系统中各层面的安全威胁：通信层面的物理层安全挑战、语义通信的隐私风险；感知层面的信号源、信道、目标三个维度的安全漏洞；计算层面的分布式计算安全风险。同时总结了相应的防护策略，包括最先进的防御技术和安全编码计算方法。

Conclusion: 集成通信-感知-计算系统面临复杂的安全挑战，需要端到端的统一安全框架。论文为未来无线系统的安全防护提供了全面指导，强调了跨层设计、安全编码计算和统一安全架构的重要性。

Abstract: Next-generation wireless networks are progressing beyond conventional connectivity to incorporate emerging sensing and computing capabilities. This convergence gives rise to integrated systems that enable not only uninterrupted communication, but also environmental awareness, intelligent decision-making, and novel applications that take advantage of these combined features. At the same time, this integration brings substantial security challenges. As computing, sensing, and communication become more tightly intertwined, the overall complexity of the system increases, creating new vulnerabilities and expanding the attack surface. The widespread deployment of data-heavy artificial intelligence applications further amplifies concerns regarding data security and privacy. This paper presents a comprehensive survey of security and privacy threats, along with potential countermeasures, in integrated wireless systems. We first review physical-layer security techniques for communication networks, and then investigate the security and privacy implications of semantic and pragmatic communications and their associated cross-layer design methodologies. For sensing functionalities, we pinpoint security and privacy risks at the levels of signal sources, propagation channels, and sensing targets, and summarize state-of-the-art defense strategies for each. The growing computational requirements of these applications drive the need for distributed computing over the network, which introduces additional risks such as data leakage, weak authentication, and multiple points of failure. We subsequently discuss secure coded computing approaches that can help overcome several of these challenges. Finally, we introduce unified security frameworks tailored to integrated communication-sensing-computing architectures, offering an end-to-end perspective on protecting future wireless systems.

</details>


### [8] [Enormous Fluid Antenna Systems (E-FAS)--Part II: Channel Estimation](https://arxiv.org/abs/2602.20127)
*Farshad Rostami Ghadi,Kai-Kit Wong,Masoud Kaveh,Hao Xu,Baiyang Liu,Kin-Fai Tong,Chan-Byoung Chae*

Main category: cs.IT

TL;DR: 本文首次全面分析了在基于导频的信道估计下E-FAS辅助下行链路传输，揭示了在单用户和多用户场景下由于信道估计误差导致的性能限制现象。


<details>
  <summary>Details</summary>
Motivation: 虽然先前研究在完美信道状态信息下展示了E-FAS的巨大功率增益，但实际信道获取对E-FAS性能的影响尚未充分探索。本文旨在分析在导频信道估计下E-FAS的实际性能。

Method: 开发了端到端等效信道的估计框架，推导了MMSE信道估计及其误差统计量的闭式表达式。分析了单用户和多用户操作，考虑了训练开销，研究了零迫预编码和空间复用增益与导频开销的权衡。

Result: 单用户场景下揭示了由于残余自干扰导致的SNR饱和现象；多用户场景下系统在高SNR区域因残余用户间干扰而变得干扰受限。尽管存在CSI不完美和训练成本，E-FAS仍保持显著性能优势。

Conclusion: E-FAS在非完美CSI下仍具有显著性能优势，其放大的大规模信道增益提供了鲁棒性。研究为实际E-FAS系统设计提供了理论基础。

Abstract: Enormous fluid antenna systems (E-FAS) have recently emerged as a new wireless architecture in which intelligent metasurfaces act as guided electromagnetic interfaces, enabling surface-wave (SW) propagation with much lower attenuation and more control than conventional space-wave transmission. While prior work has reported substantial power gains under perfect channel state information (CSI), the impact of practical channel acquisition on E-FAS performance remains largely unexplored. This paper presents the first comprehensive analysis of E-FAS-assisted downlink transmission under pilot-based channel estimation. We develop an estimation framework for the equivalent end-to-end channel and derive closed-form expressions for the statistics of the minimum mean-square-error (MMSE) channel estimate and its estimation error. Building on these results, we analyze both single-user and multiuser operation while explicitly accounting for the training overhead. For the single-user case, we characterize the outage probability and achievable rate with imperfect CSI, and reveal an inherent signal-to-noise ratio (SNR) saturation phenomenon caused by residual self-interference. For the multiuser case, we study zero-forcing (ZF) precoding based on imperfect channel estimates and show that the system becomes interference-limited in the high SNR regime because of residual inter-user interference. Furthermore, we quantify the trade-off between spatial multiplexing gains and pilot overhead when the number of users increases. Analytical findings are validated via Monte Carlo simulations and benchmarked against least-squares (LS) estimation and conventional non-E-FAS transmission. The results reveal that despite CSI imperfections and training costs, E-FAS retains substantial performance advantages and provides robustness enabled by its amplified large-scale channel gain.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [9] [ZUNA: Flexible EEG Superresolution with Position-Aware Diffusion Autoencoders](https://arxiv.org/abs/2602.18478)
*Christopher Warner,Jonas Mago,JR Huml,Mohamed Osman,Beren Millidge*

Main category: eess.SP

TL;DR: ZUNA是一个380M参数的掩码扩散自编码器，用于EEG信号的任意电极位置和数量的掩码通道填充与超分辨率任务，在208个公共数据集上训练，性能优于传统插值方法且具有良好泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决EEG信号处理中传统插值方法（如球面样条插值）的局限性，以及现有深度学习方法在跨数据集和电极位置泛化能力不足的问题，开发一个能够处理任意电极配置的通用EEG信号重建模型。

Method: 使用掩码扩散自编码器架构，将多通道EEG信号分块为短时间窗口，通过4D旋转位置编码（x,y,z,t）注入时空结构，在208个公共数据集（约200万通道小时）上使用重建和重度通道丢弃目标进行训练。

Result: ZUNA显著优于常用的球面样条插值方法，在高丢弃率下优势更明显；相比其他深度学习方法，ZUNA能够跨数据集和电极位置泛化，可直接应用于新数据集；模型计算效率高，适合实际部署。

Conclusion: ZUNA是一个通用、可泛化的EEG信号重建模型，能够处理任意电极配置，性能优于传统方法，并提供了开源实现以促进EEG分析管道的可重复比较和下游应用。

Abstract: We present \texttt{ZUNA}, a 380M-parameter masked diffusion autoencoder trained to perform masked channel infilling and superresolution for arbitrary electrode numbers and positions in EEG signals. The \texttt{ZUNA} architecture tokenizes multichannel EEG into short temporal windows and injects spatiotemporal structure via a 4D rotary positional encoding over (x,y,z,t), enabling inference on arbitrary channel subsets and positions. We train ZUNA on an aggregated and harmonized corpus spanning 208 public datasets containing approximately 2 million channel-hours using a combined reconstruction and heavy channel-dropout objective. We show that \texttt{ZUNA} substantially improves over ubiquitous spherical-spline interpolation methods, with the gap widening at higher dropout rates. Crucially, compared to other deep learning methods in this space, \texttt{ZUNA}'s performance \emph{generalizes} across datasets and channel positions allowing it to be applied directly to novel datasets and problems. Despite its generative capabilities, \texttt{ZUNA} remains computationally practical for deployment. We release Apache-2.0 weights and an MNE-compatible preprocessing/inference stack to encourage reproducible comparisons and downstream use in EEG analysis pipelines.

</details>


### [10] [Heterogeneity-agnostic AI/ML-assisted beam selection for multi-panel arrays](https://arxiv.org/abs/2602.18678)
*Ibrahim Kilinc,Robert W. Heath*

Main category: eess.SP

TL;DR: 提出一种支持天线异构的AI/ML波束选择算法，通过预测与天线配置无关的无线传播特性来实现通用性


<details>
  <summary>Details</summary>
Motivation: 现有基于AI/ML的波束选择方法依赖位置信息，但天线硬件异构（尺寸、方向、码本、元件模式、极化角度等差异）限制了方法的可行性和泛化能力。需要开发能适应不同天线配置的通用模型，而不是为每种配置单独训练模型

Method: 1) 推导解耦传播特性与天线配置的RSRP模型；2) 提出优化框架从波束成形RSRP测量中提取传播变量（AoA、AoD、包含路径增益和信道去极化的矩阵）；3) 开发三阶段自回归网络从用户位置预测这些变量，从而计算任意天线配置的RSRP并进行波束选择

Result: 仿真结果显示，该异构无关方法在有/无天线异构情况下都能提供接近理想选择（genie-aided selection）的频谱效率

Conclusion: 提出的方法实现了天线异构无关的波束选择，无需为不同天线配置重新训练或维护多个模型，在保持高性能的同时解决了实际部署中的异构挑战

Abstract: AI/ML-based beam selection methods coupled with location information effectively reduce beam training overhead. Unfortunately, heterogeneous antenna hardware with varying dimensions, orientations, codebooks, element patterns, and polarization angles limits their feasibility and generalization. This challenge requires either a heterogeneity-agnostic model functional under these variations, or developing many models for each configuration, which is infeasible and expensive in practice. In this paper, we propose a unifying AI/ML-based beam selection algorithm supporting antenna heterogeneity by predicting wireless propagation characteristics independent of antenna configuration. We derive a reference signal received power (RSRP) model that decouples propagation characteristics from antenna configuration. We propose an optimization framework to extract propagation variables consisting of angle-of-arrival (AoA), angle-of-departure (AoD), and a matrix incorporating path gain and channel depolarization from beamformed RSRP measurements. We develop a three-stage autoregressive network to predict these variables from user location, enabling RSRP calculation and beam selection for arbitrary antenna configurations without retraining or having a separate model for each configuration. Simulation results show our heterogeneity-agnostic method provides spectral efficiency close to that of genie-aided selection both with and without antenna heterogeneity.

</details>


### [11] [Channel-Correlation-Based Access Point Selection and Pilot Power Allocation for Cell-Free Massive MIMO](https://arxiv.org/abs/2602.18875)
*Saeed Mohammadzadeh,Rodrigo C. De Lamare,Kanapathippillai Cumanan,Hien Quoc Ngo*

Main category: eess.SP

TL;DR: 提出动态AP选择和导频功率分配框架，通过分层聚类算法将AP分组，减少用户间干扰并提升频谱效率


<details>
  <summary>Details</summary>
Motivation: 解决CFmMIMO系统中用户间干扰问题，提高频谱效率，同时减少CSI估计开销和网络更新负担

Method: 开发分层相关性聚类算法对AP分组，引入用户容量约束防止硬件过载，采用加权和速率最大化问题并通过二次变换迭代求解导频功率分配

Result: 显著提升频谱效率，在高密度多用户场景下保持性能，收敛速度优于基准方案

Conclusion: 提出的DAPPA框架有效缓解了用户间干扰，提高了系统性能，同时减少了CSI估计开销，具有良好的可扩展性

Abstract: This paper proposes a dynamic access point (AP) selection and pilot power allocation (DAPPA) framework for uplink cell-free massive multiple-input multiple-output (CFmMIMO) systems, aiming to mitigate inter-user interference and improve overall spectral efficiency (SE). A hierarchical correlation-based clustering algorithm is developed to group APs according to their channel correlation, enabling each user to be associated with APs that simultaneously provide strong channel gains and low mutual correlation. This association ensures reliable connectivity, maximizes coherent combining gains, and reduces inter-user interference, while also allowing the number of AP clusters to be adjusted flexibly, without the need to reorganize the network completely. By maintaining links to low-correlated APs, the proposed scheme reduces the need for frequent channel state information (CSI) estimation and minimizes network-wide update overhead. To enhance scalability, a user-capacity constraint per AP is incorporated, preventing hardware overload and alleviating the effects of pilot reuse. Furthermore, an effective pilot power allocation strategy is introduced to boost the signal-to-interference-plus-noise ratio (SINR) during channel training. This is formulated as a weighted sum-rate maximization (WSRM) problem and solved iteratively using a quadratic transform, which enables efficient optimization while ensuring fairness and high-quality service across all users. Numerical results demonstrate that the proposed method delivers significant SE gains, maintains performance in high-density multi-user scenarios, and converges faster than benchmark schemes.

</details>


### [12] [A Spatial Similarity-Guided Pilot Assignment and Access Point Selection for Cell-Free Massive MIMO Networks](https://arxiv.org/abs/2602.18901)
*Saeed Mohammadzadeh,Kanapathippillai Cumanan,Pei Liu,Hien Quoc Ngo*

Main category: eess.SP

TL;DR: 本文研究了上行无小区大规模MIMO系统中的导频分配和接入点选择策略，提出了基于信道相似性的导频分配和AP选择方案，以提高干扰管理和频谱效率。


<details>
  <summary>Details</summary>
Motivation: 在密集部署的无小区大规模MIMO系统中，导频污染和干扰管理是限制频谱效率的关键挑战。传统方法未能充分利用信道相似性信息来优化导频分配和AP选择。

Method: 提出CAPA（信道相似性感知导频分配）策略，通过评估用户间信道相似性动态分配导频序列，使信道相似性高的用户获得正交导频以减少导频污染。随后引入AP选择算法，优先选择低相关性AP以减少干扰并增强空间分集，同时保持稳健的用户-AP连接并最小化AP间冗余。

Result: 仿真结果表明，所提出的策略在动态用户场景下显著提高了频谱效率，特别是在密集网络部署中效果更为明显。

Conclusion: 结合信道相似性感知的导频分配和AP选择策略能够有效管理干扰并提升无小区大规模MIMO系统的频谱效率，为密集网络部署提供了有效的解决方案。

Abstract: This paper investigates pilot assignment and access point (AP) selection strategies for uplink cell-free massive multiple-input multiple-output (CF-mMIMO) systems. We propose channel similarity-aware pilot assignment (CAPA) and AP selection schemes to improve interference management and, consequently, spectral efficiency (SE). The pilot assignment strategy dynamically allocates pilot sequences by evaluating inter-user channel similarity, ensuring that users (UEs) with high channel similarity are assigned orthogonal pilots to mitigate pilot contamination. Subsequently, an AP selection algorithm is introduced that prioritizes the selection of low-correlation APs to reduce interference and enhance spatial diversity. This selection process maintains robust UE-AP links while minimizing inter-AP redundancy. The combined approach significantly improves SE, particularly in dense network deployments. Simulation results are provided to demonstrate the effectiveness of the proposed strategies under dynamic UE scenarios.

</details>


### [13] [Event-Triggered Gossip for Distributed Learning](https://arxiv.org/abs/2602.19116)
*Zhiyuan Zhai,Xiaojun Yuan,Wei Ni,Xin Wang,Rui Zhang,Geoffrey Ye Li*

Main category: eess.SP

TL;DR: 提出基于事件触发的分布式学习框架，通过自适应通信控制机制减少节点间通信开销，相比传统全通信基线减少71.61%的点对点传输，性能损失很小。


<details>
  <summary>Details</summary>
Motivation: 分布式学习面临节点间通信瓶颈问题，传统方法需要频繁通信，导致通信开销大。需要设计一种能自主决定何时通信的机制来降低通信成本。

Method: 开发事件触发的gossip框架，引入自适应通信控制机制，每个节点基于本地模型偏差自主决定何时与邻居交换模型信息，支持非凸目标函数。

Result: 在非凸目标下分析了框架的遍历收敛性，仿真结果显示相比最先进的分布式学习方法，通信开销显著降低，点对点传输减少71.61%，性能损失很小。

Conclusion: 提出的框架能有效降低分布式学习的通信开销，在保持良好性能的同时大幅减少节点间通信，为通信受限的分布式网络提供了高效学习方案。

Abstract: While distributed learning offers a new learning paradigm for distributed network with no central coordination, it is constrained by communication bottleneck between nodes.
  We develop a new event-triggered gossip framework for distributed learning to reduce inter-node communication overhead. The framework introduces an adaptive communication control mechanism that enables each node to autonomously decide in a fully decentralized fashion when to exchange model information with its neighbors based on local model deviations. We analyze the ergodic convergence of the proposed framework under noconvex objectives and interpret the convergence guarantees under different triggering conditions. Simulation results show that the proposed framework achieves substantially lower communication overhead than the state-of-the-art distributed learning methods, reducing cumulative point-to-point transmissions by \textbf{71.61\%} with only a marginal performance loss, compared with the conventional full-communication baseline.

</details>


### [14] [Dual Security for MIMO-OFDM ISAC Systems: Artificial Ghosts or Artificial Noise](https://arxiv.org/abs/2602.20045)
*Yinchao Yang,Prabhat Raj Gautam,Yathreb Bouazizi,Michael Breza,Julie McCann*

Main category: eess.SP

TL;DR: 该论文提出了一种双层双安全ISAC框架，通过人工噪声和人工鬼影技术，在不需窃听者信道状态信息的情况下，同时保护通信和感知安全。


<details>
  <summary>Details</summary>
Motivation: ISAC系统虽然能高效共享无线资源，但也带来了新的基于感知的安全漏洞。攻击者不仅能窃听通信消息，还能被动利用目标回波推断感知参数，而用户无法察觉。目前ISAC系统中通信和感知安全的联合保护尚未得到充分研究。

Method: 提出双层双安全ISAC框架：1）联合设计发射波束赋形器，注入人工噪声干扰通信窃听者；2）故意扭曲感知窃听者可用的参考信号以削弱其感知能力；3）生成具有虚假角度-距离-速度剖面的人工鬼影，合法接收器能抑制这些鬼影而感知窃听者不能，从而降低其正确检测真实目标的概率。

Result: 数值结果表明，所提框架能有效增强通信和感知安全性，同时保持通信用户和合法感知接收器的性能。

Conclusion: 该研究填补了ISAC系统中通信和感知安全联合保护的空白，提出的双层双安全框架为应对被动感知窃听和通信窃听提供了有效解决方案，且无需窃听者的信道状态信息。

Abstract: Integrated sensing and communication (ISAC) enables the efficient sharing of wireless resources to support emerging applications, but it also gives rise to new sensing-based security vulnerabilities. Here, potential communication security threats whereby confidential messages intended for legitimate users are intercepted, but also unauthorized receivers (Eves) can passively exploit target echoes to infer sensing parameters without users being aware. Despite these risks, the joint protection of sensing and communication security in ISAC systems remains unexplored. To address this challenge, this paper proposes a two-layer dual-secure ISAC framework that simultaneously protects sensing and communication against passive sensing Eves and communication Eves, without requiring their channel state information (CSI). Specifically, transmit beamformers are jointly designed to inject artificial noise (AN) to introduce interference to communication Eves, while deliberately distorting the reference signal available to sensing Eves to impair their sensing capability. Furthermore, the proposed design generates artificial ghosts (AGs) with fake angle-range-velocity profiles observable by all receivers. Legitimate receivers can suppress these AGs, whereas sensing Eves cannot, thereby significantly reducing their probability of correctly detecting the true targets. Numerical results demonstrate that the proposed framework effectively enhances both communication and sensing security, while preserving the performance of communication users and legitimate sensing receivers.

</details>


### [15] [Downlink Beamforming Design for NOMA Using Convolutional Neural Networks](https://arxiv.org/abs/2602.19136)
*Chentong Li,Saeed Mohammadzadeh,Kanapathippillai Cumanan,Octavia A. Dobre*

Main category: eess.SP

TL;DR: 提出基于CNN的波束赋形设计方法，用于下行NOMA系统，以解决发射功率最小化问题，显著降低计算复杂度


<details>
  <summary>Details</summary>
Motivation: 传统NOMA和波束赋形技术虽然能支持大规模连接，但最优波束赋形方案通常依赖复杂迭代算法和优化方法，导致计算负担和延迟增加，不适合延迟敏感应用

Method: 提出基于卷积神经网络(CNN)的方法，利用信道状态信息的两种表示作为输入特征，生成归一化的波束赋形向量

Result: 仿真结果显示，CNN方案能接近最优标签性能，同时相比传统高复杂度算法显著减少计算时间，增强了实时应用的实用性

Conclusion: CNN-based beamforming设计为NOMA系统提供了一种高效、低延迟的解决方案，适合未来无线网络中的实时应用

Abstract: Non-orthogonal multiple access (NOMA) and beamforming are well-established techniques for enabling massive connectivity in future wireless networks. However, many optimal beamforming solutions rely on highly complex iterative algorithms and optimization methods, resulting in an increase in computational burden and latency, making them less suitable for delay-sensitive applications and services. To address these challenges, we propose an effective convolutional neural network (CNN)-based approach for beamforming design in downlink NOMA systems to solve the transmit power minimization problem. The proposed method utilizes two representations of channel state information as input features to produce normalized beamforming vectors. Simulation results show that the CNN-based solution closely approximates the optimal label performance while significantly reducing computational time compared to conventional high-complexity algorithms, enhancing its practicality for real-time applications.

</details>


### [16] [A data-driven model-free physical-informed deep operator network for solving nonlinear dynamic system](https://arxiv.org/abs/2602.19262)
*Jieming Sun,Lichun Li*

Main category: eess.SP

TL;DR: 提出一种基于少量数据的无模型物理信息深度算子网络框架，用于学习非线性动态系统


<details>
  <summary>Details</summary>
Motivation: 现有物理信息深度算子网络要么需要已知系统数学公式，要么需要大量场景数据。但在某些动态系统中，既难以获得精确数学公式，也难以获得大量数据，只能获取少量实验数据或有限数学信息。

Method: 首先探索可用数据的短期依赖性，使用代理机器学习模型提取短期依赖性。然后将该代理模型作为物理信息部分整合到DeepOnet中。最后训练构建的DeepOnet来模拟给定控制输入和初始条件下的系统动态响应。

Result: 在不同系统上的数值实验证实，该DeepOnet框架能够有效学习近似某些非线性动态系统的动态响应。

Conclusion: 提出了一种基于少量数据的无模型物理信息深度算子网络框架，能够有效学习非线性动态系统的动态响应，解决了在缺乏精确数学公式和大量数据情况下的系统建模问题。

Abstract: The existing physical-informed Deep Operator Networks are mostly based on either the well-known mathematical formula of the system or huge amounts of data for different scenarios. However, in some cases, it is difficult to get the exact mathematical formula and vast amounts of data in some dynamic systems, we can only get a few experimental data or limited mathematical information. To address the cases, we propose a data-driven model-free physical-informed Deep Operator Network (DeepOnet) framework to learn the nonlinear dynamic systems from few available data. We first explore the short-term dependence of the available data and use a surrogate machine learning model to extract the short-term dependence. Then, the surrogate machine learning model is incorporated into the DeepOnet as the physical information part. Then, the constructed DeepOnet is trained to simulate the system's dynamic response for given control inputs and initial conditions. Numerical experiments on different systems confirm that our DeepOnet framework learns to approximate the dynamic response of some nonlinear dynamic systems effectively.

</details>


### [17] [Elevation-Aware Supplementary Uplink for Direct Satellite-to-Device Communications](https://arxiv.org/abs/2602.19427)
*Rajan Shrestha,Hayder Al-Hraishawi*

Main category: eess.SP

TL;DR: 论文提出了一种基于辅助上行链路(SUL)技术的卫星直连设备通信增强方案，通过利用LEO卫星轨道几何特性，开发了仰角感知的SUL框架，根据仰角相关的链路余量估计自适应选择上行载波，从而在低仰角和波束边缘区域扩展上行覆盖范围。


<details>
  <summary>Details</summary>
Motivation: 卫星直连设备通信面临长传播距离、严重路径损耗和严格用户设备功率限制等挑战，特别是在低仰角和波束边缘区域，上行链路可靠性尤为困难。需要一种解决方案来增强上行链路鲁棒性，同时保持用户设备的功率效率。

Method: 提出仰角感知的SUL框架，利用LEO卫星轨道的可预测几何特性，根据仰角相关的链路余量估计自适应调整跨频段的上行操作。用户设备可在主上行载波或低频SUL载波上传输，并引入带迟滞的仰角感知SUL激活算法来指导上行载波选择，避免频繁切换。

Result: 仿真结果表明，提出的SUL框架能够向低仰角和波束边缘区域扩展有效上行覆盖范围，提高卫星过境期间的上行可用性，并在现实的用户设备功率约束下实现稳定操作，上行切换次数最小化。

Conclusion: SUL技术可有效集成到卫星直连设备系统中，通过仰角感知的自适应载波选择策略，显著增强上行链路鲁棒性，扩展覆盖范围，同时保持用户设备的功率效率，为全球卫星通信提供更可靠的解决方案。

Abstract: Direct satellite-to-device (DS2D) communication enables standard mobile devices to connect directly to low Earth orbit (LEO) satellites, providing global coverage without reliance on terrestrial infrastructure. However, the DS2D uplink is fundamentally constrained by long propagation distances, severe path loss, and stringent user equipment (UE) power limits, making uplink reliability particularly challenging at low elevation angles and beam edges. This paper investigates the integration of supplementary uplink (SUL) technology into DS2D systems to enhance uplink robustness while preserving UE power efficiency. Leveraging the predictable geometry of LEO satellite orbits, we develop an elevation-aware SUL framework that adapts uplink operation across frequency bands based on elevation-dependent link margin estimates. The proposed approach schedules the UE to transmit on either a primary uplink carrier or a lower-frequency SUL carrier. An elevation-aware SUL activation algorithm with hysteresis is introduced to guide uplink carrier selection while preventing frequent switching. Simulation results demonstrate that the proposed SUL framework extends effective uplink coverage toward low-elevation and beam-edge regions, improves uplink availability over a satellite pass, and achieves stable operation with a minimal number of uplink transitions under realistic UE power constraints.

</details>


### [18] [An LLM-Enabled Frequency-Aware Flow Diffusion Model for Natural-Language-Guided Power System Scenario Generation](https://arxiv.org/abs/2602.19522)
*Zhenghao Zhou,Yiyan Li,Fei Xie,Lu Wang,Bo Wang,Jiansheng Wang,Zheng Yan,Mo-Yuen Chow*

Main category: eess.SP

TL;DR: 提出LFFD框架，使用自然语言指导电力系统场景生成，结合LLM语义转换和流扩散模型，解决现有方法用户便利性和生成灵活性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有AI场景生成方法（如条件生成对抗网络）主要依赖固定长度的数值条件向量来控制生成结果，在用户便利性和生成灵活性方面面临挑战。电力系统规划与运行需要多样可控的场景生成（如风电、光伏、负荷等）。

Method: 1. 引入预训练LLM模块将非结构化自然语言生成请求转换为有序语义空间；2. 采用流扩散模型（使用整流流匹配目标）实现高效高质量场景生成，以LLM输出作为模型输入；3. 训练过程中引入频率感知多目标优化算法缓解频率偏差问题；4. 设计双智能体框架创建文本-场景训练样本对并标准化语义评估。

Result: 基于大规模光伏和负荷数据集的实验证明了所提方法的有效性。

Conclusion: 提出的LFFD框架能够通过自然语言指导生成电力系统场景，解决了现有方法在用户便利性和生成灵活性方面的局限性，为电力系统规划与运行提供了更便捷的场景生成工具。

Abstract: Diverse and controllable scenario generation (e.g., wind, solar, load, etc.) is critical for robust power system planning and operation. As AI-based scenario generation methods are becoming the mainstream, existing methods (e.g., Conditional Generative Adversarial Nets) mainly rely on a fixed-length numerical conditioning vector to control the generation results, facing challenges in user conveniency and generation flexibility. In this paper, a natural-language-guided scenario generation framework, named LLM-enabled Frequency-aware Flow Diffusion (LFFD), is proposed to enable users to generate desired scenarios using plain human language. First, a pretrained LLM module is introduced to convert generation requests described by unstructured natural languages into ordered semantic space. Second, instead of using standard diffusion models, a flow diffusion model employing a rectified flow matching objective is introduced to achieve efficient and high-quality scenario generation, taking the LLM output as the model input. During the model training process, a frequency-aware multi-objective optimization algorithm is introduced to mitigate the frequency-bias issue. Meanwhile, a dual-agent framework is designed to create text-scenario training sample pairs as well as to standardize semantic evaluation. Experiments based on large-scale photovoltaic and load datasets demonstrate the effectiveness of the proposed method.

</details>


### [19] [Dynamic Sensor Scheduling Based on Node Partitioning of Graphs](https://arxiv.org/abs/2602.19561)
*Ryouke Ikura,Junya Hara,Hiroshi Higashi,Yuichi Tanaka*

Main category: eess.SP

TL;DR: 提出一种基于图信号采样理论的动态传感器调度方法，通过图节点分区生成多个同等信息量的节点子集，以应对电池消耗集中和传感器故障问题，并适应信号子空间的动态变化。


<details>
  <summary>Details</summary>
Motivation: 在传感器网络应用中，需要多个同等信息量的节点子集顺序激活，以提高网络对集中电池消耗和传感器故障的鲁棒性。同时，这些子集的质量会动态变化，需要适应这些变化。

Method: 基于图信号采样理论提出图节点分区方法，将问题建模为基于图信号子空间先验的DC优化问题，使用近端DC算法求解。为适应在线场景，从历史数据自适应估计信号子空间并顺序更新分区先验。

Result: 在合成和真实世界传感器网络数据上的数值实验表明，相比替代方法，所提方法实现了更低的平均均方误差。

Conclusion: 提出的动态传感器调度方法通过图节点分区有效解决了传感器网络中的鲁棒性和适应性需求，在信号重建误差方面优于现有方法。

Abstract: This paper proposes a dynamic sensor scheduling method for sensor networks. In sensor network applications, we often need multiple equally-informative node subsets that are activated sequentially to make a sensor network robust against concentrated battery consumption and sensor failures. In addition, quality of these subsets changes dynamically and thus we must adapt those changes. To find those node subsets, we propose a graph node partitioning method based on sampling theory for graph signals. We aim to minimize the average reconstruction error for signals obtained at all node subsets, in contrast to conventional single subset selection. The graph node partitioning problem is formulated as a difference-of-convex (DC) optimization based on a subspace prior of graph signals, and is solved by the proximal DC algorithm. It guarantees convergence to a critical point. To accommodate the online scenario where the signal subspace and optimal partitioning may change over time, we adaptively estimate the signal subspace from historical data and sequentially update the prior for our partitioning method. Numerical experiments on synthetic and real-world sensor network data demonstrate that the proposed method achieves lower average mean squared errors compared to alternative methods.

</details>


### [20] [Extracting Patterns of Chemical Information from Differential Mobility Spectrometry Measurements under Varying Conditions of Humidity and Temperature](https://arxiv.org/abs/2602.19572)
*Philipp Müller,Gary A. Eiceman,Anton Rauhameri,Anton Kontunen,Antti Roine,Niku Oksala,Antti Vehkaoja,Maiju Lepomäki*

Main category: eess.SP

TL;DR: 本文提出使用回归模型标准化差分迁移谱(DMS)测量数据，以消除湿度和温度变化对手术烟雾分析的影响，无需严格控制环境条件。


<details>
  <summary>Details</summary>
Motivation: DMS技术可用于分析手术烟雾中的挥发性有机化合物，但其测量结果受湿度和温度影响，导致不同环境条件下的数据难以比较。传统方法需要严格控制环境条件，但这在实际应用中往往不可行。

Method: 分析1852个猪脂肪和肌肉组织手术烟雾的DMS测量数据，确认湿度和温度的影响。对原始和归一化的DMS测量数据拟合回归模型，利用记录的湿度和温度来估计特定组织类型的DMS测量值。

Result: 分析证实DMS测量结果明显依赖于湿度和温度。通过电压标准化和多元回归模型训练，可以在特定环境条件下估计手术烟雾的DMS测量值，这是消除标准化测量条件需求的第一步。

Conclusion: 通过标准化DMS测量数据并训练回归模型，可以克服湿度和温度变化对DMS测量的影响，为无需严格控制环境条件的DMS应用铺平道路。

Abstract: Differential Mobility Spectrometry (DMS), also known as Field Asymmetric Ion Mobility Spectrometry, is a rapid and affordable technology for extracting information from gas phase samples containing complex volatile organic compounds, and can therefore be used for analyzing surgical smoke. One obstacle to its widespread application is the dependence of DMS measurements on humidity and, to a lesser degree, temperature, making comparison of data measured under different environmental conditions arbitrary. The commonly used solution is to regulate these environmental conditions to some predefined humidity and temperature levels. However, this approach is often unfeasible or even impossible. Therefore, in this paper we analyzed a dataset of 1,852 DMS measurements of surgical smoke evaporated from porcine adipose and muscle tissue to get an understanding of the impact of varying humidity and temperature on DMS measurements. Our analysis confirmed clear dependence of the measurements on these two factors. To overcome this challenge, we fitted regression models to raw and normalized DMS measurement data. Subsequently, these models were used for estimating DMS measurements for known tissue types based on recorded humidity and temperatures. Our test suggests that it is possible to estimate DMS measurements of surgical smoke from porcine adipose and muscle tissue under specific environmental conditions by standardizing DMS measurements separation voltage-wise and training multivariate regression models on the normalized data, which is the first step in removing the need for standardized measurement conditions.

</details>


### [21] [Active IoT User Detection in Near-Field with Location Information](https://arxiv.org/abs/2602.19613)
*Gabriel Martins de Jesus,Richard Demo Souza,Onel Luis Alcaraz López*

Main category: eess.SP

TL;DR: 本文提出了一种利用用户位置先验知识来增强近场物联网网络中活跃用户检测的方法，通过重建用户的视距信道分量来辅助检测过程。


<details>
  <summary>Details</summary>
Motivation: 在近场物联网网络中，传统的活跃用户检测方法性能有限。考虑到用户通常分布在基站瑞利距离内的半圆形区域，可以利用用户的位置信息来重建视距信道分量，从而提升检测性能。

Method: 基站利用用户位置估计重建其视距信道分量，结合用户导频序列增强接收信号与活跃用户之间的相关性。将位置辅助的活跃用户检测建模为凸优化问题，采用交替方向乘子法求解。

Result: 在完美位置估计和强视距条件下，所提方法显著优于基线方法。鲁棒性分析表明，只要位置估计误差保持在系统参数确定的范围内，性能优势依然存在。

Conclusion: 利用位置先验知识可以有效提升近场物联网网络中的活跃用户检测性能，即使在位置估计存在一定误差的情况下仍能保持优势，但该方法计算复杂度较高且需要用户位置信息。

Abstract: In this paper, we address active users detection (AUD) in near-field Internet of Things (IoT) networks by exploring prior knowledge of users' locations. We consider a scenario where users are distributed in a semi-circular area within the Rayleigh distance of a multi-antenna base station (BS). We propose the BS to use location estimates of the users to reconstruct their line-of-sight (LoS) channel components, hence assisting the AUD process. For this, the BS combines these reconstructed channels with users' pilot sequences, enhancing the correlation between received signals and active users. We formulate the location-aided AUD as a convex optimization problem, solved via the alternating direction method of multipliers (ADMM). {Our proposal has a higher computational complexity compared to the baseline ADMM approach where location information is not used. Moreover, the proposal requires location information of users, which can be readily informed if users are static, or inferred via established localization algorithms if they are mobile.} Simulation results compare our proposal against the baseline across varying systems parameters, such as number of users, pilot length and LoS component strength. We demonstrate that under perfect location estimation and strong LoS, our proposed method significantly outperforms the baseline. Furthermore, robustness analysis shows that performance gains persist under imperfect location estimation, provided the estimation error remains within bounds determined by the system parameters.

</details>


### [22] [Topological Signal Processing for 3D Point Cloud Data](https://arxiv.org/abs/2602.19636)
*Tiziana Cattai,Stefania Sardellitti,Stefania Colonnese,Sergio Barbarossa*

Main category: eess.SP

TL;DR: 将拓扑信号处理框架应用于基于单纯复形表示的3D点云分析，引入高阶拉普拉斯算子处理三角网格上的信号，可同时表征节点颜色属性和三角形重心几何信息


<details>
  <summary>Details</summary>
Motivation: 传统方法无法同时处理点云的几何和属性信息，需要一种统一的拓扑框架来表征3D点云的几何结构和颜色属性

Method: 基于离散外微积分理论，引入高阶拉普拉斯算子处理三角网格信号，将颜色属性建模为节点上的3D向量，几何信息建模为三角形重心上的3D向量

Result: 在合成点云上实现了精确的颜色重建，对稀疏数据具有鲁棒性，在噪声点云坐标情况下能进行几何细化

Conclusion: 提出的方法提供了基于拓扑的表征框架，可有效处理点云的几何和属性信息，为点云分析提供了新的工具

Abstract: Our goal in this paper is to apply the topological signal processing (TSP) framework to the analysis of 3D Point Clouds (PCs) represented on simplicial complexes. Building on Discrete Exterior Calculus (DEC) theory for vector fields, we introduce higher-order Laplacian operators that enable the processing of signals over triangular meshes. Unlike traditional approaches, the proposed approach allows us to characterize both color attributes, modeled as 3D vectors on nodes, and geometry, modeled as 3D vectors on the barycenter of each triangle. Then, we show as TSP tools may efficiently be used to sample, recover and filter PCs attributes treating them as edge signals. Numerical results on synthetic PCs demonstrate accurate color reconstruction with robustness to sparse data and geometry refinement in the case of noisy PC coordinates. The proposed approach provides a topology-based representation to characterize the geometry and attributes of PCs.

</details>


### [23] [Hardware-Accelerated Geometrical Simulation of Biological and Engineered In-Air Ultrasonic Systems](https://arxiv.org/abs/2602.19652)
*Wouter Jansen,Jan Steckel*

Main category: eess.SP

TL;DR: SonoTraceUE是一个基于Unreal Engine的高保真声学仿真框架，使用硬件加速的射线追踪镜面反射模型和基于曲率的蒙特卡洛衍射模型，可在动态多材料环境中实现近实时声学传感仿真。


<details>
  <summary>Details</summary>
Motivation: 当前工业监测和自主机器人中空中声学传感器的部署日益增长，但现有仿真框架在开发验证这些系统时面临挑战：基于波的方法计算成本高，几何声学求解器缺乏对动态场景、复杂衍射或闭环机器人集成的支持。

Method: 开发了SonoTraceUE作为Unreal Engine插件，采用硬件加速的射线追踪镜面反射模型和基于曲率的蒙特卡洛衍射模型，支持动态多材料环境中的主动和被动声学传感仿真。

Result: 通过生物声学研究和机器人实验两个不同实验领域验证，结果显示SonoTraceUE与真实世界的光谱和空间数据具有高度相关性。

Conclusion: 该框架为合成数据生成、生物声学假设测试以及使用声学传感的闭环机器人系统的快速原型设计提供了一个多功能平台。

Abstract: The deployment of in-air acoustic sensors for industrial monitoring and autonomous robotics has grown significantly, often drawing inspiration from biological echolocation. However, developing and validating these systems in existing simulation frameworks remains challenging due to the computational cost of simulating high-frequency wave propagation in large, dynamic, and complex environments. While wave-based methods offer high accuracy, they scale poorly with frequency and volume. Conversely, existing geometric acoustic solvers often lack support for dynamic scenes, complex diffraction, or closed-loop robotic integration. In this work, we introduce SonoTraceUE, a high-fidelity acoustic simulation framework built as a plugin for Unreal Engine. By using a hardware-accelerated ray tracing-based specular reflection model, and a curvature-based Monte Carlo diffraction model, the system enables near real-time simulation of active and passive acoustic sensing in dynamic, multi-material environments. We validate the framework through two distinct experimental domains: a bioacoustic study and a robotics experiment. Our results demonstrate that SonoTraceUE achieves high correlation with real-world spectral and spatial data. The framework provides a versatile platform for synthetic data generation, hypothesis testing in bioacoustics, and the rapid prototyping of closed-loop robotic systems that use acoustic sensing.

</details>


### [24] [Breaking the CP Limit: Robust Long-Range OFDM Sensing via Interference Cleaning](https://arxiv.org/abs/2602.19877)
*Umut Utku Erdem,Lucas Giroto,Benedikt Geiger,Taewon Jeong,Silvio Mandelli,Christian Karle,Benjamin Nuss,Laurent Schmalen,Thomas Zwick*

Main category: eess.SP

TL;DR: 本文针对OFDM雷达和通感一体化系统中，目标回波超过循环前缀时长导致的ISI/ICI干扰问题，提出了两种框架：联合干扰消除与相干补偿方法，以及基于全重构的滑动窗口方案，在计算成本和目标检测性能之间提供灵活权衡。


<details>
  <summary>Details</summary>
Motivation: 传统OFDM雷达系统的探测范围受限于循环前缀时长，超过该时长的目标回波会引起ISI和ICI干扰，导致检测性能下降、雷达图像干扰噪声基底升高，以及窗口失配导致的信号功率损失。现有方法在恢复有用信号和抑制干扰之间存在权衡，特别是在多目标场景中。

Method: 提出了两种框架：1）联合干扰消除与相干补偿方法：这是逐次干扰消除算法的高效演进，利用高精度Chirp Z变换估计和频域相干补偿来恢复弱远距离目标；2）基于全重构的滑动窗口方案：通过滑动接收窗口捕获最优信号能量，同时对所有检测到的目标进行全信号重构。

Result: 数值结果表明，两种方法都优于现有最先进的基准方法。联合干扰消除方法能有效对抗ISI/ICI干扰噪声基底升高，而滑动窗口方案在需要最大精度时提供最优性能。

Conclusion: 本文提出的两种框架解决了OFDM雷达系统中远距离目标检测的ISI/ICI干扰问题，提供了在计算成本和检测性能之间的灵活权衡，显著提升了系统在超出循环前缀范围的目标检测能力。

Abstract: In orthogonal frequency-division multiplexing-based radar and integrated sensing and communication systems, the sensing range is traditionally limited by the round-trip time corresponding to the cyclic prefix duration. Targets whose echoes arrive after this duration induce intersymbol interference (ISI) and associated intercarrier interference (ICI), which significantly degrade detection performance, elevate the interference-noise floor in the radar image, and reduce the useful signal power due to window mismatch. Existing methods face a trade-off between recovering useful signal and suppressing interference, particularly in multi-target scenarios. This paper proposes two frameworks to resolve this dilemma, offering a flexible trade-off between computational cost and target detection performance. First, a signal model is derived, demonstrating that ISI and ICI-oriented interference often dominates thermal noise in high-dynamic-range scenarios. To combat the ISI and ICI-based interference-noise floor increase, joint-interference cancellation with coherent compensation is proposed. This approach is an efficient evolution of the successive-interference cancellation algorithm, utilizing high-precision chirp Z-transform estimation and frequency-domain coherent compensation to recover weak distant targets. For scenarios requiring maximum precision, the full reconstruction-based sliding window scheme is presented, which shifts the receive window to capture optimal signal energy while performing full-signal reconstruction for all detected targets. Numerical results show that both methods outperform state-of-the-art benchmarks.

</details>


### [25] [Rethinking Chronological Causal Discovery with Signal Processing](https://arxiv.org/abs/2602.19903)
*Kurt Butler,Damian Machlanski,Panagiotis Dimitrakopoulos,Sotirios A. Tsaftaris*

Main category: eess.SP

TL;DR: 论文研究了因果发现方法对采样率与时间窗口长度不匹配的敏感性，发现传统和现代方法都对这些超参数敏感，并探讨了信号处理视角的理解。


<details>
  <summary>Details</summary>
Motivation: 现实世界中因果发现通常基于规则时间间隔的观测数据，但这些采样时间可能与底层生物或物理事件的实际发生时间不匹配。论文旨在探究这种时间不匹配对因果发现方法性能的影响。

Method: 通过实证和理论分析，研究采样率和时间窗口长度变化对因果发现方法性能的影响。考察了经典和最新的因果发现方法对这些超参数的敏感性。

Result: 研究表明，无论是经典还是近期的因果发现方法都对采样率和时间窗口长度这些超参数表现出敏感性。性能会随着这些参数的变化而显著波动。

Conclusion: 因果发现方法对采样率与时间窗口长度不匹配具有敏感性，信号处理领域的思路可能有助于理解这些现象，并为改进方法提供方向。

Abstract: Causal discovery problems use a set of observations to deduce causality between variables in the real world, typically to answer questions about biological or physical systems. These observations are often recorded at regular time intervals, determined by a user or a machine, depending on the experiment design. There is generally no guarantee that the timing of these recordings matches the timing of the underlying biological or physical events. In this paper, we examine the sensitivity of causal discovery methods to this potential mismatch. We consider empirical and theoretical evidence to understand how causal discovery performance is impacted by changes of sampling rate and window length. We demonstrate that both classical and recent causal discovery methods exhibit sensitivity to these hyperparameters, and we discuss how ideas from signal processing may help us understand these phenomena.

</details>


### [26] [From High-Level Requirements to KPIs: Conformal Signal Temporal Logic Learning for Wireless Communications](https://arxiv.org/abs/2602.20018)
*Jiechen Chen,Michele Polese,Osvaldo Simeone*

Main category: eess.SP

TL;DR: 提出C-STLL框架，通过信号时序逻辑学习和符合性校准，从RAN的KPI数据中提取可解释的时序模式，用于预测QoE并保证可靠性。


<details>
  <summary>Details</summary>
Motivation: 软体化无线接入网络（如O-RAN）产生大量KPI数据，但如何从低层KPI测量中提取可解释的、能预测高层QoE需求的信息是一个挑战。需要既相关（能捕捉预测用户级结果的时序模式）又可解释（提供可验证的洞察）的方法。

Method: 提出符合性信号时序逻辑学习（C-STLL）框架：1）利用信号时序逻辑（STL）学习区分满足QoE要求的KPI轨迹的可解释公式；2）基于Learn Then Test框架的符合性校准程序，包装现有STL学习算法，确保可靠性；3）通过多重假设检验验证的接受和停止规则，联合优化可靠性、公式复杂性和多样性。

Result: 在ns-3网络模拟器的移动游戏场景实验中，C-STLL能有效将风险控制在目标水平以下，同时返回紧凑、多样的可解释时序规范集，将KPI行为与QoE结果关联起来。

Conclusion: C-STLL框架成功解决了从RAN KPI数据中提取可解释、可靠时序模式的问题，为网络优化提供了可验证的洞察，并具有形式化保证。

Abstract: Softwarized radio access networks (RANs), such as those based on the Open RAN (O-RAN) architecture, generate rich streams of key performance indicators (KPIs) that can be leveraged to extract actionable intelligence for network optimization. However, bridging the gap between low-level KPI measurements and high-level requirements, such as quality of experience (QoE), requires methods that are both relevant, capturing temporal patterns predictive of user-level outcomes, and interpretable, providing human-readable insights that operators can validate and act upon. This paper introduces conformal signal temporal logic learning (C-STLL), a framework that addresses both requirements. C-STLL leverages signal temporal logic (STL), a formal language for specifying temporal properties of time series, to learn interpretable formulas that distinguish KPI traces satisfying high-level requirements from those that do not. To ensure reliability, C-STLL wraps around existing STL learning algorithms with a conformal calibration procedure based on the Learn Then Test (LTT) framework. This procedure produces a set of STL formulas with formal guarantees: with high probability, the set contains at least one formula achieving a user-specified accuracy level. The calibration jointly optimizes for reliability, formula complexity, and diversity through principled acceptance and stopping rules validated via multiple hypothesis testing. Experiments using the ns-3 network simulator on a mobile gaming scenario demonstrate that C-STLL effectively controls risk below target levels while returning compact, diverse sets of interpretable temporal specifications that relate KPI behavior to QoE outcomes.

</details>


### [27] [Digital Twin--Driven Adaptive Wavelet Strategy for Efficient 6G Backbone Network Telemetry](https://arxiv.org/abs/2602.20034)
*Alexandre Barbosa de Lima,Xavier Hesselbach,José Roberto de Almeida Amazonas*

Main category: eess.SP

TL;DR: 该论文建立了MERA张量网络与paraunitary滤波器组的等价关系，提出一种学习自适应小波的方法，在保证正交性和完美重构的同时，在LRD网络流量压缩上优于经典小波。


<details>
  <summary>Details</summary>
Motivation: 经典正交小波虽然保证完美重构，但基于固定基函数，对多项式光滑信号优化，在处理具有分形频谱特征的信号时压缩效果不佳。而学习方法虽然具有自适应性，但通常通过软惩罚来强制正交性，牺牲了结构保证。

Method: 建立多尺度纠缠重整化Ansatz（MERA）张量网络与paraunitary滤波器组的严格等价关系，通过流形约束优化学习自适应小波，同时保证精确正交性、完美重构和能量守恒。

Result: 在长程依赖（LRD）网络流量验证中，学习到的滤波器在六个MAWI骨干网络流量迹（2020-2025，314Mbps-1.75Gbps）上比经典小波高出0.5-3.8dB PSNR，同时保持Hurst指数在估计不确定性范围内（|ΔH| ≤ 0.03）。

Conclusion: MERA启发的小波为6G数字孪生同步中的遥测压缩提供了一种原则性方法，既能保证结构特性，又能实现更好的压缩性能。

Abstract: Classical orthogonal wavelets guarantee perfect reconstruction but rely on fixed bases optimized for polynomial smoothness, achieving suboptimal compression on signals with fractal spectral signatures. Conversely, learned methods offer adaptivity but typically enforce orthogonality via soft penalties, sacrificing structural guarantees.
  This work establishes a rigorous equivalence between Multiscale Entanglement Renormalization Ansatz (MERA) tensor networks and paraunitary filter banks. The resulting framework learns adaptive wavelets while enforcing exact orthogonality through manifold-constrained optimization, guaranteeing perfect reconstruction and energy conservation throughout training.
  Validation on Long-Range Dependent (LRD) network traffic demonstrates that learned filters outperform classical wavelets by 0.5--3.8~dB PSNR on six MAWI backbone traces (2020--2025, 314~Mbps--1.75~Gbps) while preserving the Hurst exponent within estimation uncertainty ($|ΔH| \le 0.03$). These results establish MERA-inspired wavelets as a principled approach for telemetry compression in 6G digital twin synchronization.

</details>


### [28] [On the Spatial Consistency of Sub-Terahertz Channel Characteristics for Beyond-6G Systems](https://arxiv.org/abs/2602.20039)
*Hossein Amininasab,Huda Farooqui,Dmitri Moltchanov,Sergey Andreev,Michele Polese,Mikko Valkama,Josep M. Jornet*

Main category: eess.SP

TL;DR: 该研究通过实验测量验证了在140-150 GHz频段室内环境中，信道特性（时延扩展、角度时延扩展、K因子）在数十厘米距离内保持相对稳定，这可以显著降低射线追踪计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 在sub-THz频段（100-300 GHz）进行射线追踪信道建模时，理论上需要在波长尺度上进行密集采样，计算量极大。但实际中信道特性可能在更大距离上保持稳定，本研究旨在通过实验验证这种空间一致性程度。

Method: 在室内大厅环境中进行了大规模测量活动，频率范围为140-150 GHz，测量点间距从2.5毫米到1米，系统性地研究了信道特性的空间变化。

Result: 实验结果显示，信道特性（包括时延扩展、角度时延扩展和K因子）在数十厘米距离内变化很小。在稳定的视距方向，网格分辨率可放宽至10-50个波长（145 GHz），而非视距区域则需要更精细的分辨率。

Conclusion: sub-THz信道在室内环境中表现出显著的空间一致性，这可以大幅降低射线追踪的计算复杂度。对于较粗的网格，需要采用高级插值技术来捕捉快速变化的散射分量。

Abstract: Ray tracing is a versatile approach for precise sub-terahertz (sub-THz, 100-300 GHz) channel modeling when designing new mechanisms for beyond-6G cellular systems. Theoretically, wireless channels may exhibit variations over wavelength distances. In the sub-THz band, close-to-millimeter wavelengths thus require extremely large computational efforts for ray-tracing modeling. However, in practice, channel characteristics may remain quantitatively similar over much larger distances, which can drastically decrease computational efforts. The aim of this study is to experimentally characterize the degree of spatial consistency in sub-THz channel characteristics. To this end, we performed a large-scale measurement campaign in the 140-150 GHz frequency band in an indoor-hall (InH) environment and characterized the channel at separation distances from 2.5 mm up to 1 m. Our results show that channel characteristics including delay spread, angular delay spread, and K-factor change only slightly over multiple tens of centimeter distances. This implies that, in the considered InH environment, the mesh grid can be in the range of 10-50 wavelengths (at 145 GHz) along stable line-of-sight (LoS) directions, while a finer resolution is needed in regions not dominated by LoS. For coarser grids, advanced interpolation is required to capture rapidly varying scattered components.

</details>
