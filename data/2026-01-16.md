<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 41]
- [eess.SP](#eess.SP) [Total: 10]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [High signal-to-noise ratio asymptotics of entropy-constrained Gaussian channel capacity](https://arxiv.org/abs/2601.09864)
*Adway Girish,Shlomo Shamai,Emre Telatar*

Main category: cs.IT

TL;DR: 在高信噪比渐近条件下，高斯信道在输入熵约束下的容量达到分布是离散高斯分布，支撑在缩放整数格上，输入熵与容量之间的差距随信噪比指数衰减。


<details>
  <summary>Details</summary>
Motivation: 研究高斯信道在输入熵约束下的容量问题，特别关注高信噪比渐近条件下的最优输入分布特性，探索输入熵与信道容量之间的关系。

Method: 在渐近高信噪比条件下分析高斯信道的容量问题，证明容量达到分布是离散高斯分布，支撑在缩放整数格上，并分析输入熵与容量差距的衰减特性。

Result: 当信噪比趋于无穷大时，容量达到分布是离散高斯分布，支撑在缩放整数格上；输入熵与容量之间的差距随信噪比指数衰减到零，并表征了该指数衰减率。

Conclusion: 在高信噪比渐近条件下，输入熵约束高斯信道的最优输入分布具有离散结构，输入熵与信道容量之间的差距呈指数衰减，为高信噪比通信系统设计提供了理论指导。

Abstract: We study the input-entropy-constrained Gaussian channel capacity problem in the asymptotic high signal-to-noise ratio (SNR) regime. We show that the capacity-achieving distribution as SNR goes to infinity is given by a discrete Gaussian distribution supported on a scaled integer lattice. Further, we show that the gap between the input entropy and the capacity decreases to zero exponentially in SNR, and characterize this exponent.

</details>


### [2] [One-Cold Poisson Channel: A Simple Continuous-Time Channel with Zero Dispersion](https://arxiv.org/abs/2601.09894)
*Cheuk Ting Li*

Main category: cs.IT

TL;DR: 本文介绍了一冷泊松信道（OCPC），这是一种极其简单的连续时间无记忆信道，具有容量1、零信道色散和简并的信息谱分布，是已知唯一具有闭式最优非渐近错误概率公式的非平凡信道。


<details>
  <summary>Details</summary>
Motivation: 研究动机是寻找一种极其简单的连续时间无记忆信道模型，该模型具有闭式最优非渐近错误概率公式，并可作为信息的基本计量单位（替代比特），同时具有潜在的光通信应用价值。

Method: 提出了一冷泊松信道（OCPC）模型，其中发射器每次选择衰减多个频带中的一个。特别研究了完美OCPC（频带数量无限的情况），分析了其容量、信道色散、信息谱分布等特性，并研究了非渐近编码和信道仿真结果。

Result: 完美OCPC具有容量1、零信道色散，信息谱分布为在1处的简并分布。它是已知唯一具有闭式最优非渐近错误概率公式的非平凡（离散或连续时间）无记忆信道。完美反馈下的OCPC可推广前缀码。

Conclusion: OCPC是一种极其简单的连续时间无记忆信道，可作为无限可分的信息基本计量单位（替代比特），具有潜在的光通信应用价值，并为非渐近编码和信道仿真提供了理论基础。

Abstract: We introduce the one-cold Poisson channel (OCPC), where the transmitter chooses one of several frequency bands to attenuate at a time. In particular, the perfect OCPC, where the number of bands is unlimited, is an extremely simple continuous-time memoryless channel. It has a capacity 1, zero channel dispersion, and an information spectrum being the degenerate distribution at 1. It is the only known nontrivial (discrete or continuous-time) memoryless channel with a closed-form formula for its optimal non-asymptotic error probability, making it the simplest channel in this sense. A potential application is optical communication with a tunable band rejection filter. Due to its simplicity, we may use it as a basic currency of information that is infinitely divisible, as an alternative to bits which are not infinitely divisible. OCPC with perfect feedback gives a generalization of prefix codes. We also study non-asymptotic coding and channel simulation results for the general OCPC.

</details>


### [3] [Learning-Augmented Perfectly Secure Collaborative Matrix Multiplication](https://arxiv.org/abs/2601.09916)
*Zixuan He,Mohammad Reza Deylam Salehi,Derya Malak,Photios A. Stavrou*

Main category: cs.IT

TL;DR: 提出了一种用于多方计算中矩阵乘法的完美安全协议，保证信息论隐私和正确性，并引入了学习增强扩展以提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 在多方计算环境中，如何在保证完美安全性的同时高效执行矩阵乘法运算是一个重要挑战。现有方案需要在安全性和计算效率之间权衡，特别是在大规模矩阵运算时。

Method: 使用稀疏掩码多项式编码子矩阵，结合系数对齐和Beaver式随机性确保完美保密性。还引入了基于张量分解的本地块乘法学习增强扩展。

Result: 协议在阈值以下的任何合谋方只能观察到均匀随机份额，恢复阈值达到最优。学习增强版本在保持隐私和恢复保证的同时，随着矩阵维度增长可提供高达80%的计算效率提升。

Conclusion: 该工作提出了一个理论上最优的完美安全矩阵乘法协议，并通过学习增强扩展实现了可扩展的计算效率，为安全多方计算中的大规模矩阵运算提供了实用解决方案。

Abstract: This paper presents a perfectly secure matrix multiplication (PSMM) protocol for multiparty computation (MPC) of $\mathrm{A}^{\top}\mathrm{B}$ over finite fields. The proposed scheme guarantees correctness and information-theoretic privacy against threshold-bounded, semi-honest colluding agents, under explicit local storage constraints. Our scheme encodes submatrices as evaluations of sparse masking polynomials and combines coefficient alignment with Beaver-style randomness to ensure perfect secrecy. We demonstrate that any colluding set of parties below the security threshold observes uniformly random shares, and that the recovery threshold is optimal, matching existing information-theoretic limits. Building on this framework, we introduce a learning-augmented extension that integrates tensor-decomposition-based local block multiplication, capturing both classical and learned low-rank methods. We demonstrate that the proposed learning-based PSMM preserves privacy and recovery guarantees for MPC, while providing scalable computational efficiency gains (up to $80\%$) as the matrix dimensions grow.

</details>


### [4] [Reconstructing Reed-Solomon Codes from Multiple Noisy Channel Outputs](https://arxiv.org/abs/2601.09947)
*Shubhransh Singhvi,Han Mao Kiah,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 研究序列重构问题，针对RS码在q元DMS替换信道下的高效重构算法，推导出依赖于(p,K)的显式速率阈值


<details>
  <summary>Details</summary>
Motivation: Levenshtein在2001年提出的序列重构问题考虑发送方传输码字，接收方观察到K个独立噪声版本。本研究旨在解决当每个输出被q元离散无记忆对称替换信道（替换概率p）破坏时的高效重构问题

Method: 针对Reed-Solomon码，将Koetter-Vardy软判决译码算法适配为高效重构算法。对于足够大的分组长度和字母表大小，推导出依赖于(p,K)的显式速率阈值

Result: 当码率R低于该阈值时，可以以任意小的错误概率重构传输的码字。算法在足够大的参数下有效

Conclusion: 成功将软判决译码技术应用于序列重构问题，为RS码在DMS替换信道下的高效重构提供了理论保证和实用算法

Abstract: The sequence reconstruction problem, introduced by Levenshtein in 2001, considers a communication setting in which a sender transmits a codeword and the receiver observes K independent noisy versions of this codeword. In this work, we study the problem of efficient reconstruction when each of the $K$ outputs is corrupted by a $q$-ary discrete memoryless symmetric (DMS) substitution channel with substitution probability $p$. Focusing on Reed-Solomon (RS) codes, we adapt the Koetter-Vardy soft-decision decoding algorithm to obtain an efficient reconstruction algorithm. For sufficiently large blocklength and alphabet size, we derive an explicit rate threshold, depending only on $(p, K)$, such that the transmitted codeword can be reconstructed with arbitrarily small probability of error whenever the code rate $R$ lies below this threshold.

</details>


### [5] [Private Information Retrieval for Graph-based Replication with Minimal Subpacketization](https://arxiv.org/abs/2601.09957)
*Vayur Shanbhag,Prasad Krishnan*

Main category: cs.IT

TL;DR: 提出两种新的基于图复制数据库的私有信息检索方案，具有最小子分组化（单位子分组化），适用于星形图和一般图，在某些情况下比现有方案有更好的速率。


<details>
  <summary>Details</summary>
Motivation: 在基于图复制的私有信息检索系统中，需要在保持高检索速率的同时降低子分组化（文件分割大小），因为子分组化限制了协议执行时的文件大小。现有方案在子分组化和速率之间存在权衡，需要设计具有最小子分组化且保持高速率的方案。

Method: 提出了两种新的PIR方案：1）针对星形图（特殊图类）的方案；2）针对一般图的方案，使用独立集进行图分解。两种方案都具有单位子分组化（最小子分组化）。

Result: 1）星形图方案在一般星形图上比现有低子分组化方案有更好的速率；2）一般图方案在完全图上速率低于先前方案，但在某些特定图类上能实现比已知方案更高的速率；3）扩展到多重图时，在完全多重图上比先前方案有更高速率。

Conclusion: 成功设计了具有最小子分组化的私有信息检索方案，针对不同图结构优化了速率性能，在特定图类上超越了现有方案，为图复制数据库的PIR协议设计提供了新的有效方法。

Abstract: We design new minimal-subpacketization schemes for information-theoretic private information retrieval on graph-based replicated databases. In graph-based replication, the system consists of $K$ files replicated across $N$ servers according to a graph with $N$ vertices and $K$ edges. The client wants to retrieve one desired file, while keeping the index of the desired file private from each server via a query-response protocol. We seek PIR protocols that have (a) high rate, which is the ratio of the file-size to the total download cost, and (b) low subpacketization, which acts as a constraint on the size of the files for executing the protocol. We report two new schemes which have unit-subpacketization (which is minimal): (i) for a special class of graphs known as star graphs, and (ii) for general graphs. Our star-graph scheme has a better rate than previously known schemes with low subpacketization for general star graphs. Our scheme for general graphs uses a decomposition of the graph via independent sets. This scheme achieves a rate lower than prior schemes for the complete graph, however it can achieve higher rates than known for some specific graph classes. An extension of our scheme to the case of multigraphs achieves a higher rate than previous schemes for the complete multi-graph.

</details>


### [6] [On the Leaky Private Information Retrieval with Side Information](https://arxiv.org/abs/2601.09960)
*Yingying Huangfu,Tian Bai*

Main category: cs.IT

TL;DR: 本文研究了具有侧信息的泄露隐私私有信息检索（L-PIR-SI），通过放宽完美隐私要求来提高通信效率，提出了统一的概率框架量化隐私泄露，并建立了泄露、侧信息和检索效率之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 虽然PIR-SI在完美隐私下的容量已有部分研究，但受控信息泄露对这些设置的影响尚未解决。现有研究要么要求完美隐私（通信效率低），要么没有考虑侧信息，缺乏统一的框架来分析隐私泄露、侧信息和检索效率之间的权衡。

Method: 提出了统一的概率框架来构建L-PIR-SI方案，使用参数ε量化隐私泄露（符合差分隐私标准）。该框架能够处理W-隐私和(W,S)-隐私两种设置，并推导了可实现的下载成本。

Result: 结果展示了泄露、侧信息和检索效率之间的权衡关系：当ε→0时恢复PIR-SI的容量；当没有侧信息时退化为已知的泄露-PIR边界。这是首次系统研究这三者之间的关系。

Conclusion: 本文首次研究了具有侧信息的泄露隐私私有信息检索问题，建立了统一的概率框架，揭示了隐私泄露、侧信息和通信效率之间的基本权衡，为实际应用中的隐私-效率权衡提供了理论基础。

Abstract: This paper investigates the problem of leaky-private Private Information Retrieval with Side Information (L-PIR-SI), which relaxes the requirement of perfect privacy to achieve improved communication efficiency in the presence of side information. While the capacities of PIR-SI under both $W$-privacy and $(W,S)$-privacy have been partially explored, the impact of controlled information leakage in these settings remains unaddressed. We propose a unified probabilistic framework to construct L-PIR-SI schemes where the privacy leakage is quantified by a parameter $\varepsilon$, consistent with differential privacy standards. We characterize the achievable download costs and show that our results generalize several landmark results in the PIR literature: they recover the capacity of PIR-SI when $\varepsilon \to 0$, and reduce to the known bounds for leaky-PIR when side information is absent. This work provides the first look at the trade-offs between leakage, side information, and retrieval efficiency.

</details>


### [7] [Fundamental Limits of Coded Polynomial Aggregation](https://arxiv.org/abs/2601.10028)
*Xi Zhong,Jörg Kliewer,Mingyue Ji*

Main category: cs.IT

TL;DR: 扩展编码多项式聚合到容错分布式计算系统，建立基于非故障节点模式精确恢复的理论框架，证明所需响应数少于传统方法，并给出可行性阈值和构造方案。


<details>
  <summary>Details</summary>
Motivation: 传统编码多项式计算需要逐个解码每个项，响应需求量大。本文旨在将编码多项式聚合扩展到容错分布式计算系统，减少所需工作节点响应数量，提高系统效率。

Method: 提出容错感知的编码多项式聚合框架，考虑预定义的非故障节点模式集合。建立精确恢复的必要充分条件，识别交集大小阈值，并提供可行的CPA方案构造方法。

Result: 证明所需工作节点响应数少于基于逐个解码的多项式编码计算，建立了可行性由非故障节点模式的交集结构决定的理论，识别出精确恢复的阈值条件。

Conclusion: 容错感知CPA能显著减少分布式计算中的响应需求，理论阈值在实践中是紧的，为容错分布式计算系统提供了高效的聚合恢复方案。

Abstract: Coded polynomial aggregation (CPA) enables the master to directly recover a weighted aggregation of polynomial evaluations without individually decoding each term, thereby reducing the number of required worker responses. In this paper, we extend CPA to straggler-aware distributed computing systems and introduce a straggler-aware CPA framework with pre-specified non-straggler patterns, where exact recovery is required only for a given collection of admissible non-straggler sets. Our main result shows that exact recovery of the desired aggregation is achievable with fewer worker responses than required by polynomial coded computing based on individual decoding, and that feasibility is fundamentally characterized by the intersection structure of the non-straggler patterns. In particular, we establish necessary and sufficient conditions for exact recovery in straggler-aware CPA and identify an intersection-size threshold that is sufficient to guarantee exact recovery. We further prove that this threshold becomes both necessary and sufficient when the number of admissible non-straggler sets is sufficiently large. We also provide an explicit construction of feasible CPA schemes whenever the intersection size exceeds the derived threshold. Finally, simulations reveal a sharp feasibility transition at the predicted threshold, providing empirical evidence that the bound is tight in practice.

</details>


### [8] [Optimal Proximity Gap for Folded Reed--Solomon Codes via Subspace Designs](https://arxiv.org/abs/2601.10047)
*Fernando Granha Jeronimo,Lenny Liu,Pranav Rajpal*

Main category: cs.IT

TL;DR: 论文研究了折叠里德-所罗门码的邻近间隙性质，证明了在最优容量区域内存在(δ,ε)-邻近间隙，扩展了先前对仿射子空间的研究结果。


<details>
  <summary>Details</summary>
Motivation: 研究折叠里德-所罗门码的邻近间隙性质有两个主要动机：1）FRS码已知能达到最优列表解码半径（容量区域），因此自然要问是否能在该区域内展示类似的邻近间隙；2）最近研究显示FRS码具有类似随机线性码的性质，这与RS码和基于AEL的码的性质相关。

Method: 采用与Ben-Sasson等人研究仿射子空间类似的分析框架，但针对折叠里德-所罗门码。该方法自然地适用于合适的子空间设计码。核心是利用FRS码的列表解码算法特性，特别是它们在容量区域内的有效性。

Result: 论文肯定地回答了研究问题：折叠里德-所罗门码确实在最优容量区域内展示(δ,ε)-邻近间隙性质。这一结果扩展了先前对RS码在Johnson界区域内邻近间隙的研究。

Conclusion: 折叠里德-所罗门码在最优列表解码容量区域内具有邻近间隙性质，这一框架可推广到合适的子空间设计码。这一发现连接了FRS码与随机线性码性质的研究，为编码理论中的邻近间隙分析提供了新视角。

Abstract: A collection of sets satisfies a $(δ,\varepsilon)$-proximity gap with respect to some property if for every set in the collection, either (i) all members of the set are $δ$-close to the property in (relative) Hamming distance, or (ii) only a small $\varepsilon$-fraction of members are $δ$-close to the property.
  In a seminal work, Ben-Sasson \textit{et al.}\ showed that the collection of affine subspaces exhibits a $(δ,\varepsilon)$-proximity gap with respect to the property of being Reed--Solomon (RS) codewords with $δ$ up to the so-called Johnson bound for list decoding. Their technique relies on the Guruswami--Sudan list decoding algorithm for RS codes, which is guaranteed to work in the Johnson bound regime.
  Folded Reed--Solomon (FRS) codes are known to achieve the optimal list decoding radius $δ$, a regime known as capacity. Moreover, a rich line of list decoding algorithms was developed for FRS codes. It is then natural to ask if FRS codes can be shown to exhibit an analogous $(δ,\varepsilon)$-proximity gap, but up to the so-called optimal capacity regime. We answer this question in the affirmative (and the framework naturally applies more generally to suitable subspace-design codes).
  An additional motivation to understand proximity gaps for FRS codes is the recent results [BCDZ'25] showing that they exhibit properties similar to random linear codes, which were previously shown to be related to properties of RS codes with random evaluation points in [LMS'25], as well as codes over constant-size alphabet based on AEL [JS'25].

</details>


### [9] [Function Correcting Codes for Maximally-Unbalanced Boolean Functions](https://arxiv.org/abs/2601.10135)
*Rajlaxmi Pandey,Shiven Bajpai,Anjana A Mahesh,B. Sundar Rajan*

Main category: cs.IT

TL;DR: 研究针对最大不平衡布尔函数的最优单错误纠正函数纠正码，分析其距离矩阵结构对AWGN信道下误码性能的影响


<details>
  <summary>Details</summary>
Motivation: 函数纠正码可以在不完整恢复消息的情况下可靠计算函数值，但现有研究对最优单错误纠正FCC的结构及其对性能影响了解不足

Method: 通过关联码字距离矩阵分析最优SEFCC结构，识别不同FCC类别，在AWGN信道上评估软判决和硬判决解码下的性能

Result: 不同距离矩阵结构的FCC在数据BER和函数错误行为上表现显著差异，代码结构的影响强烈依赖于解码策略

Conclusion: FCC的结构特性对错误性能有重要影响，解码策略选择应与代码结构相匹配以获得最佳性能

Abstract: Function-Correcting Codes (FCCs) enable reliable computation of a function of a $k$-bit message over noisy channels without requiring full message recovery. In this work, we study optimal single-error correcting FCCs (SEFCCs) for maximally-unbalanced Boolean functions, where $k$ denotes the message length and $t$ denotes the error-correction capability. We analyze the structure of optimal SEFCC constructions through their associated codeword distance matrices and identify distinct FCC classes based on this structure. We then examine the impact of these structural differences on error performance by evaluating representative FCCs over the additive white Gaussian noise (AWGN) channel using both soft-decision and hard-decision decoding. The results show that FCCs with different distance-matrix structures can exhibit markedly different Data BER and function error behavior, and that the influence of code structure depends strongly on the decoding strategy.

</details>


### [10] [On Existence of Girth-8 QC-LDPC Code with Large Column Weight: Combining Mirror-sequence with Classification Modulo Ten](https://arxiv.org/abs/2601.10170)
*Guohua Zhang,Xiangya Liu,Jianhua Zhang,Yi Fang*

Main category: cs.IT

TL;DR: 本文在GCD框架下，通过引入镜像序列和新行重组方案，代数构造了列重为7和8、长度极短、围长为8的QC-LDPC码，将连续循环矩阵尺寸的下界提升了约20%。


<details>
  <summary>Details</summary>
Motivation: 构造具有大围长的准循环LDPC码在信道编码、压缩感知和分布式存储系统中至关重要。主要挑战是如何用代数方法（而非搜索方法）获得尽可能短的码长（即尽可能小的循环矩阵尺寸）。

Method: 在先前提出的GCD框架基础上，引入镜像序列概念并采用新的行重组方案，以代数方式构造列重为7和8、任意行重、长度极短、围长为8的QC-LDPC码。

Result: 对于列重7和8，连续循环矩阵尺寸的下界相比现有基准均提升了约20%。新构造还能提供比新下界小约25%的循环矩阵尺寸。

Conclusion: 通过创新的代数方法，成功构造了列重更高（7和8）、长度更短、围长为8的QC-LDPC码，显著改进了循环矩阵尺寸的下界，为相关应用提供了更优的码构造方案。

Abstract: Quasi-cyclic (QC) LDPC codes with large girths play a crucial role in several research and application fields, including channel coding, compressed sensing and distributed storage systems. A major challenge in respect of the code construction is how to obtain such codes with the shortest possible length (or equivalently, the smallest possible circulant size) using algebraic methods instead of search methods. The greatest-common-divisor (GCD) framework we previously proposed has algebraically constructed QC-LDPC codes with column weights of 5 and 6, very short lengths, and a girth of 8. By introducing the concept of a mirror sequence and adopting a new row-regrouping scheme, QC-LDPC codes with column weights of 7 and 8, very short lengths, and a girth of 8 are proposed for arbitrary row weights in this article via an algebraic manner under the GCD framework. Thanks to these novel algebraic methods, the lower bounds (for column weights 7 and 8) on consecutive circulant sizes are both improved by asymptotically about 20%, compared with the existing benchmarks. Furthermore, these new constructions can also offer circulant sizes asymptotically about 25% smaller than the novel bounds.

</details>


### [11] [A Low-Complexity Architecture for Multi-access Coded Caching Systems with Arbitrary User-cache Access Topology](https://arxiv.org/abs/2601.10175)
*Ting Yang,Minquan Cheng,Xinping Yi,Robert Caiming Qiu,Giuseppe Caire*

Main category: cs.IT

TL;DR: 提出基于图神经网络的通用学习框架，用于解决任意用户-缓存访问拓扑下的多接入编码缓存问题，在保持接近最优传输负载的同时大幅降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有MACC模型依赖高度结构化的连接设计，无法处理任意用户-缓存访问拓扑。需要一种通用且低复杂度的传输方案，以应对大规模系统中的计算挑战。

Method: 1) 建立基于图的通用框架，将解码冲突建模为冲突图，传输设计转化为图着色问题；2) 使用图神经网络构建学习框架，高效生成近最优编码多播传输；3) 扩展无编码缓存放置的索引编码下界到任意访问拓扑。

Result: 提出的学习方案传输负载接近DSatur算法和下界，同时计算时间显著减少。图神经网络框架能够泛化到不同访问拓扑和用户数量。

Conclusion: 该学习框架为任意拓扑MACC问题提供了高效实用的解决方案，在保持接近最优性能的同时大幅降低计算复杂度，具有很好的泛化能力。

Abstract: This paper studies the multi-access coded caching (MACC) problem under arbitrary user-cache access topologies, extending existing models that rely on highly structured and combinatorially designed connectivity. We consider a MACC system consisting of a single server, multiple cache nodes, and multiple user nodes. Each user can access an arbitrary subset of cache nodes to retrieve cached content. The objective is to design a general and low-complexity delivery scheme under fixed cache placement for arbitrary access topologies. We propose a universal graph-based framework for modeling the MACC delivery problem, where decoding conflicts among requested packets are captured by a conflict graph and the delivery design is reduced to a graph coloring problem. In this formulation, a lower transmission load corresponds to using fewer colors. The classical greedy coloring algorithm DSatur achieves a transmission load close to the index-coding converse bound, providing a tight benchmark, but its computational complexity becomes prohibitive for large-scale graphs. To overcome this limitation, we develop a learning-based framework using graph neural networks that efficiently constructs near-optimal coded multicast transmissions and generalizes across diverse access topologies and varying numbers of users. In addition, we extend the index-coding converse bound for uncoded cache placement to arbitrary access topologies and propose a low-complexity greedy approximation. Numerical results demonstrate that the proposed learning-based scheme achieves transmission loads close to those of DSatur and the converse bound while significantly reducing computational time.

</details>


### [12] [Error-Correcting Codes for the Sum Channel](https://arxiv.org/abs/2601.10256)
*Lyan Abboud,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 本文提出了一种新的信道模型——和信道，用于分布式存储和DNA数据存储。构建了可纠正两个删除的编码，冗余度为2⌈log₂log₂n⌉ + O(ℓ²)，当ℓ=2时证明冗余度接近最优。还提出了纠正单个替换的编码，冗余度为⌈log₂(ℓ+1)⌉比特，接近最优。


<details>
  <summary>Details</summary>
Motivation: 受分布式存储和DNA数据存储应用的启发，提出和信道模型。该模型将ℓ行二进制矩阵作为输入，输出(ℓ+1)行矩阵，其中前ℓ行等于输入，最后一行是前ℓ行的奇偶校验和行。需要设计能够纠正删除和替换错误的编码方案。

Method: 1. 定义和信道模型：输入ℓ行二进制矩阵，输出(ℓ+1)行矩阵，最后一行是前ℓ行的奇偶校验和。
2. 构建两删除纠正编码：使用冗余度2⌈log₂log₂n⌉ + O(ℓ²)的编码方案。
3. 当ℓ=2时，证明冗余度上界为⌈log₂log₂n⌉ + O(1)，表明所提编码的冗余度在因子2内接近最优。
4. 构建单替换纠正编码：使用⌈log₂(ℓ+1)⌉比特冗余，证明该编码在1比特内接近最优。

Result: 1. 成功构建了可纠正两个删除的编码，冗余度为2⌈log₂log₂n⌉ + O(ℓ²)。
2. 当ℓ=2时，证明冗余度上界为⌈log₂log₂n⌉ + O(1)，表明所提编码的冗余度在因子2内接近最优。
3. 构建了可纠正单个替换的编码，冗余度为⌈log₂(ℓ+1)⌉比特，证明该编码在1比特内接近最优。

Conclusion: 本文提出的和信道模型及其编码方案在分布式存储和DNA数据存储中具有实际应用价值。两删除纠正编码的冗余度接近最优，单替换纠正编码几乎达到最优。这些结果为相关存储系统的错误纠正提供了有效的编码方案。

Abstract: We introduce the sum channel, a new channel model motivated by applications in distributed storage and DNA data storage. In the error-free case, it takes as input an $\ell$-row binary matrix and outputs an $(\ell+1)$-row matrix whose first $\ell$ rows equal the input and whose last row is their parity (sum) row. We construct a two-deletion-correcting code with redundancy $2\lceil\log_2\log_2 n\rceil + O(\ell^2)$ for $\ell$-row inputs. When $\ell=2$, we establish an upper bound of $\lceil\log_2\log_2 n\rceil + O(1)$, implying that our redundancy is optimal up to a factor of 2. We also present a code correcting a single substitution with $\lceil \log_2(\ell+1)\rceil$ redundant bits and prove that it is within one bit of optimality.

</details>


### [13] [Transmission Mask Analysis for Range-Doppler Sensing in Half-Duplex ISAC](https://arxiv.org/abs/2601.10259)
*Dikai Liu,Yifeng Xiong,Marco Lops,Fan Liu,Jianhua Zhang*

Main category: cs.IT

TL;DR: 分析半双工ISAC中MASM的周期性传输掩码，推导其闭式期望距离-多普勒响应，揭示距离旁瓣的多普勒不变性，并证明在动态环境下CDS掩码的最优性


<details>
  <summary>Details</summary>
Motivation: 研究半双工集成感知与通信系统中掩码调制的周期性传输掩码，旨在优化距离-多普勒响应特性，解决距离旁瓣和多普勒旁瓣之间的权衡问题

Method: 分析周期性传输掩码的闭式期望距离-多普勒响应，研究循环差集（特别是Singer CDS）在不同动态环境下的最优性，分析掩码自相关函数与多普勒旁瓣能量的关系

Result: 距离旁瓣具有多普勒不变性，将距离旁瓣最优性扩展到二维设置；对于距离主瓣，周期性掩码产生稀疏多普勒旁瓣：CDS在中等动态环境下是极小极大最优的，而在高动态环境下多普勒旁瓣能量是掩码自相关的凹函数

Conclusion: 周期性掩码设计在半双工ISAC系统中具有重要理论价值，揭示了距离旁瓣的多普勒不变性和主瓣波动与多普勒旁瓣之间的固有权衡，为实际系统设计提供了理论指导

Abstract: In this paper, we analyze the periodic transmission masks for MASked Modulation (MASM) in half-duplex integrated sensing and communication (ISAC), and derive their closed-form expected range-Doppler response $\mathbb{E}\{r(k,l,ν)\}$. We show that range sidelobes ($k\neq l$) are Doppler-invariant, extending the range-sidelobe optimality to the 2-D setting. For the range mainlobe ($k=l$), periodic masking yields sparse Doppler sidelobes: Cyclic difference sets (CDSs) (in particular Singer CDSs) are minimax-optimal in a moderately dynamic regime, while in a highly dynamic regime the Doppler-sidelobe energy is a concave function of the mask autocorrelation, revealing an inevitable tradeoff with mainlobe fluctuation.

</details>


### [14] [Algebraic Properties of PAC Codes](https://arxiv.org/abs/2601.10262)
*Vlad-Florin Dragoi,Mohammad Rowshan*

Main category: cs.IT

TL;DR: 本文分析了极化调整卷积码，定义了广义多项式极化码类，推导了其结构性质如对偶性、最小距离等


<details>
  <summary>Details</summary>
Motivation: 研究极化码和Reed-Muller码的代数表示，扩展PAC码和反向PAC码的理论框架，建立更一般的编码结构

Method: 使用极化码和Reed-Muller码的代数表示方法，定义广义多项式极化码类，推导其结构性质

Result: 建立了广义多项式极化码的理论框架，推导了对偶性、最小距离等结构性质，获得了最小重量码字数目的结构限制

Conclusion: 广义多项式极化码为PAC码和反向PAC码提供了统一的代数框架，其结构性质分析有助于理解这类编码的性能特征

Abstract: We analyze polarization-adjusted convolutional codes using the algebraic representation of polar and Reed-Muller codes. We define a large class of codes, called generalized polynomial polar codes which include PAC codes and Reverse PAC codes. We derive structural properties of generalized polynomial polar codes, such as duality, minimum distance. We also deduce some structural limits in terms of number of minimum weight codewords, and dimension of monomial sub-code.

</details>


### [15] [On the Capacity of Noisy Frequency-based Channels](https://arxiv.org/abs/2601.10329)
*Yuval Gerzon,Ilan Shomorony,Nir Weinberger*

Main category: cs.IT

TL;DR: 研究噪声频率信道的容量，针对DNA数据存储中的短分子机制，信息通过项目类型的频率而非顺序编码。信道输出是通过随机采样和噪声项目识别形成的直方图。


<details>
  <summary>Details</summary>
Motivation: 研究DNA数据存储中短分子机制的噪声频率信道容量。在短分子机制中，信息通过项目类型的频率而非顺序编码，但之前的研究主要关注无噪声情况，识别噪声的影响尚未完全表征。

Method: 1. 通过随机降解和数据处理不等式推导信道容量的反界；2. 基于多项式采样过程的泊松化建立可达界，分析带符号间干扰的向量泊松信道；3. 改进Feinstein界中信息密度的集中不等式，明确表征识别噪声导致的互信息加性损失。

Result: 建立了噪声频率信道的容量界限，包括反界和可达界。将结果应用于DNA存储信道的短分子机制，量化了识别噪声对可靠存储比特总数缩放的影响。

Conclusion: 该研究首次系统分析了DNA数据存储中短分子机制的噪声频率信道容量，建立了理论界限并量化了识别噪声对存储容量的影响，为实际DNA存储系统设计提供了理论基础。

Abstract: We investigate the capacity of noisy frequency-based channels, motivated by DNA data storage in the short-molecule regime, where information is encoded in the frequency of items types rather than their order. The channel output is a histogram formed by random sampling of items, followed by noisy item identification. While the capacity of the noiseless frequency-based channel has been previously addressed, the effect of identification noise has not been fully characterized. We present a converse bound on the channel capacity that follows from stochastic degradation and the data processing inequality. We then establish an achievable bound, which is based on a Poissonization of the multinomial sampling process, and an analysis of the resulting vector Poisson channel with inter-symbol interference. This analysis refines concentration inequalities for the information density used in Feinstein bound, and explicitly characterizes an additive loss in the mutual information due to identification noise. We apply our results to a DNA storage channel in the short-molecule regime, and quantify the resulting loss in the scaling of the total number of reliably stored bits.

</details>


### [16] [Codebook Design for Limited Feedback in Near-Field XL-MIMO Systems](https://arxiv.org/abs/2601.10391)
*Liujia Yao,Changsheng You,Zixuan Huang,Chao Zhou,Zhaohui Yang,Xiaoyang Li*

Main category: cs.IT

TL;DR: 提出针对XL-MIMO FDD系统的用户分布自适应码本设计，通过联合优化角度-距离采样和比特分配，显著降低反馈开销并提升速率性能。


<details>
  <summary>Details</summary>
Motivation: 现有XL-MIMO码本设计（如极域码本）未充分考虑实际用户分布，导致反馈开销过大。需要设计更高效的反馈码本以适应实际用户分布特征。

Method: 1. 针对均匀分布场景，建立和速率最大化问题，联合优化角度-距离采样和比特分配；2. 使用Voronoi分区证明均匀角度采样最优；3. 对距离采样设计，推导接收功率紧下界，提出几何采样作为高质量次优解；4. 扩展至非均匀分布，采用交替采样方法；5. 理论分析反馈比特分配趋势。

Result: 1. 均匀角度采样最优；2. 几何采样最大化接收功率下界；3. 理论表明随着阵列增大，比特分配更倾向于距离采样；4. 数值结果验证了所提码本在各种系统设置下的优越速率性能和鲁棒性，相比基准方案（包括广泛使用的极域码本）获得显著增益。

Conclusion: 提出的用户分布自适应码本设计能有效降低XL-MIMO FDD系统的反馈开销，提升系统性能，为实际部署提供了高效解决方案。

Abstract: In this paper, we study efficient codebook design for limited feedback in extremely large-scale multiple-input-multiple-output (XL-MIMO) frequency division duplexing (FDD) systems. It is worth noting that existing codebook designs for XL-MIMO, such as polar-domain codebook, have not well taken into account user (location) distribution in practice, thereby incurring excessive feedback overhead. To address this issue, we propose in this paper a novel and efficient feedback codebook tailored to user distribution. To this end, we first consider a typical scenario where users are uniformly distributed within a specific polar-region, based on which a sum-rate maximization problem is formulated to jointly optimize angle-range samples and bit allocation among angle/range feedback. This problem is challenging to solve due to the lack of a closed-form expression for the received power in terms of angle and range samples. By leveraging a Voronoi partitioning approach, we show that uniform angle sampling is optimal for received power maximization. For more challenging range sampling design, we obtain a tight lower-bound on the received power and show that geometric sampling, where the ratio between adjacent samples is constant, can maximize the lower bound and thus serves as a high-quality suboptimal solution. We then extend the proposed framework to accommodate more general non-uniform user distribution via an alternating sampling method. Furthermore, theoretical analysis reveals that as the array size increases, the optimal allocation of feedback bits increasingly favors range samples at the expense of angle samples. Finally, numerical results validate the superior rate performance and robustness of the proposed codebook design under various system setups, achieving significant gains over benchmark schemes, including the widely used polar-domain codebook.

</details>


### [17] [Convertible Codes for Data and Device Heterogeneity](https://arxiv.org/abs/2601.10341)
*Anina Gruica,Benjamin Jany,Stanislav Kruglik*

Main category: cs.IT

TL;DR: 本文研究分布式存储系统中的异构性问题，提出使用可转换码和Reed-Muller码分别处理设备异构性和数据异构性，并首次将两者结合。


<details>
  <summary>Details</summary>
Motivation: 分布式存储系统面临两大挑战：数据异构性（访问需求不均匀）和设备异构性（节点可靠性随时间变化）。现有方法通常单独处理这些问题，需要一种能同时应对两种异构性的解决方案。

Method: 1. 研究可转换码，用于在合并机制中以最小成本将一种编码转换为另一种编码，处理设备异构性
2. 推导线性码转换的读写成本一般下界
3. 专注于Reed-Muller码处理数据异构性
4. 构建显式转换程序，首次将两种异构性处理机制结合

Result: 1. 推导出适用于任意线性码的读写成本一般下界
2. 为Reed-Muller码构建了显式转换程序
3. 首次实现了同时处理数据异构性和设备异构性的分布式存储方案

Conclusion: 本文通过可转换码和Reed-Muller码的结合，为分布式存储系统提供了一种同时处理数据异构性和设备异构性的有效方法，推导的理论下界和显式转换程序为实际系统设计提供了理论基础。

Abstract: Distributed storage systems must handle both data heterogeneity, arising from non-uniform access demands, and device heterogeneity, caused by time-varying node reliability. In this paper, we study convertible codes, which enable the transformation of one code into another with minimum cost in the merge regime, addressing the latter. We derive general lower bounds on the read and write costs of linear code conversion, applicable to arbitrary linear codes. We then focus on Reed-Muller codes, which efficiently handle data heterogeneity, addressing the former issue, and construct explicit conversion procedures that, for the first time, combine both forms of heterogeneity for distributed data storage.

</details>


### [18] [Breaking the Storage-Bandwidth Tradeoff in Distributed Storage with Quantum Entanglement](https://arxiv.org/abs/2601.10676)
*Lei Hu,Mohamed Nomeir,Alptug Aytekin,Sennur Ulukus*

Main category: cs.IT

TL;DR: 量子分布式存储系统中，通过量子通信和纠缠资源可以显著改善存储-修复带宽权衡，在某些条件下甚至能同时最小化存储和修复带宽，突破了经典系统的限制。


<details>
  <summary>Details</summary>
Motivation: 研究量子资源在分布式存储系统中的应用，探索量子通信如何改善经典分布式存储系统中的存储-修复带宽权衡问题。

Method: 在(n,k,d)分布式存储系统中，允许辅助节点通过量子信道向新节点传输经典信息，新节点通过对接收到的量子态进行测量来生成存储。利用幸存节点之间共享的量子纠缠资源。

Result: 完全刻画了存储与修复带宽之间的基本权衡关系。相比经典系统，量子纠缠能显著改善最优存储-带宽权衡，特别是在最小存储再生点。当d≥2k-2时，存在一个操作点可以同时最小化存储和修复带宽。

Conclusion: 量子通信引入了一种全新的工作模式，打破了经典设置中的权衡关系，为分布式存储系统提供了根本性的改进。

Abstract: This work investigates the use of quantum resources in distributed storage systems. Consider an $(n,k,d)$ distributed storage system in which a file is stored across $n$ nodes such that any $k$ nodes suffice to reconstruct the file. When a node fails, any $d$ helper nodes transmit information to a newcomer to rebuild the system. In contrast to the classical repair, where helper nodes transmit classical bits, we allow them to send classical information over quantum channels to the newcomer. The newcomer then generates its storage by performing appropriate measurements on the received quantum states. In this setting, we fully characterize the fundamental tradeoff between storage and repair bandwidth (total communication cost). Compared to classical systems, the optimal storage--bandwidth tradeoff can be significantly improved with the enhancement of quantum entanglement shared only among the surviving nodes, particularly at the minimum-storage regenerating point. Remarkably, we show that when $d \geq 2k-2$, there exists an operating point at which \textit{both storage and repair bandwidth are simultaneously minimized}. This phenomenon breaks the tradeoff in the classical setting and reveals a fundamentally new regime enabled by quantum communication.

</details>


### [19] [A New Construction Structure on MISO Coded Caching with Linear Subpacketization: Half-Sum Disjoint Packing](https://arxiv.org/abs/2601.10353)
*Bowen Zheng,Minquan Cheng,Kai Wan,Giuseppe Caire*

Main category: cs.IT

TL;DR: 提出基于L-half-sum disjoint packing (HSDP)的MISO编码缓存方案，在F=K（线性子分组）条件下显著降低子分组复杂度，仅轻微牺牲和自由度性能。


<details>
  <summary>Details</summary>
Motivation: 现有MISO编码缓存方案虽然能达到最大和自由度，但子分组数随用户数指数增长，计算复杂度高。需要设计在保持较大和自由度的同时具有低子分组复杂度的方案。

Method: 基于拉丁方框架，将F=K的MAPDA设计转化为L-HSDP组合结构构造。1-HSDP对应NHSDP用于共享链路编码缓存，通过构造L-HSDP获得新方案。

Result: 提出的L-HSDP方案相比指数子分组方案显著降低子分组复杂度，仅轻微牺牲和自由度；相比现有线性子分组方案，同时实现更高和自由度和更低子分组。

Conclusion: 通过L-HSDP组合结构设计MISO编码缓存方案，在F=K条件下有效平衡了和自由度和子分组复杂度，为实际系统部署提供了实用方案。

Abstract: In the $(L,K,M,N)$ cache-aided multiple-input single-output (MISO) broadcast channel (BC) system, the server is equipped with $L$ antennas and communicates with $K$ single-antenna users through a wireless broadcast channel where the server has a library containing $N$ files, and each user is equipped with a cache of size $M$ files. Under the constraints of uncoded placement and one-shot linear delivery strategies, many schemes achieve the maximum sum Degree-of-Freedom (sum-DoF). However, for general parameters $L$, $M$, and $N$, their subpacketizations increase exponentially with the number of users. We aim to design a MISO coded caching scheme that achieves a large sum-DoF with low subpacketization $F$. An interesting combinatorial structure, called the multiple-antenna placement delivery array (MAPDA), can be used to generate MISO coded caching schemes under these two strategies; moreover, all existing schemes with these strategies can be represented by the corresponding MAPDAs. In this paper, we study the case with $F=K$ (i.e., $F$ grows linearly with $K$) by investigating MAPDAs. Specifically, based on the framework of Latin squares, we transform the design of MAPDA with $F=K$ into the construction of a combinatorial structure called the $L$-half-sum disjoint packing (HSDP). It is worth noting that a $1$-HSDP is exactly the concept of NHSDP, which is used to generate the shared-link coded caching scheme with $F=K$. By constructing $L$-HSDPs, we obtain a class of new schemes with $F=K$. Finally, theoretical and numerical analyses show that our $L$-HSDP schemes significantly reduce subpacketization compared to existing schemes with exponential subpacketization, while only slightly sacrificing sum-DoF, and achieve both a higher sum-DoF and lower subpacketization than the existing schemes with linear subpacketization.

</details>


### [20] [Generalized Weight Structure of Polar Codes: Selected Template Polynomials](https://arxiv.org/abs/2601.10362)
*Mohammad Rowshan,Vlad-Florin Dragoi*

Main category: cs.IT

TL;DR: 本文开发了一个统一代数框架，通过LTA群作用和特定模板结构，计算极化码中码字的汉明重量并推导多重性公式。


<details>
  <summary>Details</summary>
Motivation: 极化码可视为递减单项式码，具有丰富的代数结构，受下三角仿射(LTA)群支配。需要开发系统方法来计算码字汉明重量并理解其重量谱结构。

Method: 建立通用框架：1) 计算单项式和的码字汉明重量；2) 将重量表达为规范二元形式；3) 推导生成低/中重量谱的关键结构模板(不相交和、嵌套块、互补翻转)；4) 结合LTA群作用推导显式多重性公式。

Result: 获得了码字汉明重量的规范二元表达式，推导了生成重量谱的结构模板，结合LTA群作用得到了显式多重性公式，形成了统一的代数方法来表征和枚举码字。

Conclusion: 本文提出的代数框架系统地解决了极化码中码字重量计算和枚举问题，通过LTA群作用和结构模板的统一处理，为极化码的重量谱分析提供了强有力的数学工具。

Abstract: Polar codes can be viewed as decreasing monomial codes, revealing a rich algebraic structure governed by the lower-triangular affine (LTA) group. We develop a general framework to compute the Hamming weight of codewords generated by sums of monomials, express these weights in a canonical dyadic form, and derive closed expressions for key structural templates (disjoint sums, nested blocks, complementary flips) that generate the low and intermediate weight spectrum. Combining these templates with the LTA group action, we obtain explicit multiplicity formulas, yielding a unified algebraic method to characterize and enumerate codewords.

</details>


### [21] [A Hybrid Reliability--Weight Framework for Construction of Polar Codes](https://arxiv.org/abs/2601.10376)
*Mohammad Rowshan,Vlad-Florin Dragoi*

Main category: cs.IT

TL;DR: 提出一种混合（可靠性-权重）比特信道排序方法，结合可靠性排序和最小权重码字贡献，优化极化码的短中长度性能


<details>
  <summary>Details</summary>
Motivation: 传统极化码基于可靠性排序构造，虽然能保证容量可达性，但在短中长度下可能产生较差的低权重谱。需要结合代数分析的最小权重码字贡献来改进构造方法

Method: 定义混合比特信道排序，结合可靠性（Bhattacharyya因子）和权重贡献（最小权重码字轨道枚举）。通过截断的SC/ML联合界代理优化，在递减单项式码类中最小化该代理

Result: 混合构造在短中长度BPSK-AWGN信道上展示了可靠性构造和混合构造之间的权衡，改善了最小距离、重数和联合界近似。证明混合设计是可靠性构造的局部扰动，其渐近影响随码长增加而消失

Conclusion: 混合比特信道排序方法有效结合了可靠性排序和权重贡献，优化了极化码在短中长度下的性能，同时保持了渐近容量可达特性

Abstract: Polar codes are usually constructed by ranking synthetic bit-channels according to reliability, which guarantees capacity-achieving behavior but can yield poor low-weight spectra at short and moderate lengths. Recent algebraic results express the contribution of individual bit-channels to the multiplicities of minimum and near-minimum weight codewords in closed form. In this work we combine these insights into a mixed (reliability--weight) bit-channel ordering. We define a per-bit cost whose distance term is derived from orbit enumeration of minimum-weight codewords and scaled by a Bhattacharyya-type factor, and show that the resulting mixed construction minimises a truncated SC/ML union-bound surrogate within a class of decreasing monomial codes. We relate the mixed metric to error events in SCL decoding via a pruning/ML decomposition, and prove that mixed designs act as local perturbations of reliability-based constructions whose asymptotic impact vanishes as code-length approaches infinity. Numerical results for short and moderate lengths on BPSK-AWGN, implemented via Gaussian approximation and closed-form weight contributions, illustrate the trade-off between pure reliability-based and mixed constructions in terms of minimum distance, multiplicity, and union-bound approximations. All proofs are deferred to the appendices.

</details>


### [22] [Multiaccess Coded Caching with Heterogeneous Retrieval Costs](https://arxiv.org/abs/2601.10394)
*Wenbo Huang,Minquan Cheng,Kai Wan,Xiaojun Li,Robert Caiming Qiu,Giuseppe Caire*

Main category: cs.IT

TL;DR: 本文提出了一种基于叠加编码的成本感知多接入编码缓存框架，通过优化缓存放置来最小化包含缓存访问成本和广播成本的总系统成本。


<details>
  <summary>Details</summary>
Motivation: 现有MACC系统假设用户从连接的缓存节点检索内容没有通信成本，但实际中用户从不同缓存节点检索内容成本不同，服务器向用户传输内容也有成本。需要设计成本感知的MACC系统来最小化总系统成本。

Method: 提出基于叠加编码的新型编码缓存框架，将Cheng等人的MACC方案分层。推导出优化缓存放置以最小化系统成本的成本感知优化问题，利用最优解的稀疏性提出复杂度降低的结构感知算法。

Result: 仿真结果表明，在异构检索成本场景下，所提方案始终优于Cheng等人的方案。

Conclusion: 本文提出的成本感知MACC框架能有效降低系统总成本，特别是在异构缓存访问成本场景下表现优异，为实际部署提供了更实用的解决方案。

Abstract: The multiaccess coded caching (MACC) system, as formulated by Hachem {\it et al.}, consists of a central server with a library of $N$ files, connected to $K$ cache-less users via an error-free shared link, and $K$ cache nodes, each equipped with cache memory of size $M$ files. Each user can access $L$ neighboring cache nodes under a cyclic wrap-around topology. Most existing studies operate under the strong assumption that users can retrieve content from their connected cache nodes at no communication cost. In practice, each user retrieves content from its $L$ different connected cache nodes at varying costs. Additionally, the server also incurs certain costs to transmit the content to the users. In this paper, we focus on a cost-aware MACC system and aim to minimize the total system cost, which includes cache-access costs and broadcast costs. Firstly, we propose a novel coded caching framework based on superposition coding, where the MACC schemes of Cheng \textit{et al.} are layered. Then, a cost-aware optimization problem is derived that optimizes cache placement and minimizes system cost. By identifying a sparsity property of the optimal solution, we propose a structure-aware algorithm with reduced complexity. Simulation results demonstrate that our proposed scheme consistently outperforms the scheme of Cheng {\it et al.} in scenarios with heterogeneous retrieval costs.

</details>


### [23] [Placement Delivery Array for Cache-Aided MIMO Systems](https://arxiv.org/abs/2601.10422)
*Yifei Huang,Kai Wan,Minquan Cheng,Jinyan Wang,Giuseppe Caire*

Main category: cs.IT

TL;DR: 提出MIMO-PDA统一结构，推导出MIMO缓存网络的最大和自由度上界，并构建两种实现最大和自由度的方案，其中第二种方案在保持性能的同时指数级降低子分组复杂度。


<details>
  <summary>Details</summary>
Motivation: 在MIMO缓存网络中，现有方案难以同时实现最大和自由度与低子分组复杂度。子分组复杂度过高会带来巨大的存储和计算开销，限制了实际应用。

Method: 首先提出MIMO-PDA统一组合结构，用于描述无编码放置和单次迫零传输。基于此推导和自由度上界，然后构建两种MIMO-PDA方案：第一种在严格参数约束下实现线性子分组复杂度，第二种在更宽松约束下实现有序指数级子分组复杂度。

Result: 推导出和自由度上界为min{KG, Gt+G⌈L/G⌉}，与现有最优结果一致。两种方案均能实现最大和自由度，其中第二种方案相比现有方案指数级降低子分组复杂度。

Conclusion: MIMO-PDA框架为MIMO缓存网络提供了系统设计方法，所提方案在保持最大和自由度的同时显著降低了子分组复杂度，具有重要理论和实际意义。

Abstract: We consider a $(G,L,K,M,N)$ cache-aided multiple-input multiple-output (MIMO) network, where a server equipped with $L$ antennas and a library of $N$ equal-size files communicates with $K$ users, each equipped with $G$ antennas and a cache of size $M$ files, over a wireless interference channel. Each user requests an arbitrary file from the library. The goal is to design coded caching schemes that simultaneously achieve the maximum sum degrees of freedom (sum-DoF) and low subpacketization. In this paper, we first introduce a unified combinatorial structure, termed the MIMO placement delivery array (MIMO-PDA), which characterizes uncoded placement and one-shot zero-forcing delivery. By analyzing the combinatorial properties of MIMO-PDAs, we derive a sum-DoF upper bound of $\min\{KG, Gt+G\lceil L/G \rceil\}$, where $t=KM/N$, which coincides with the optimal DoF characterization in prior work by Tehrani \emph{et al.}. Based on this upper bound, we present two novel constructions of MIMO-PDAs that achieve the maximum sum-DoF. The first construction achieves linear subpacketization under stringent parameter constraints, while the second achieves ordered exponential subpacketization under substantially milder constraints. Theoretical analysis and numerical comparisons demonstrate that the second construction exponentially reduces subpacketization compared to existing schemes while preserving the maximum sum-DoF.

</details>


### [24] [Energy-Efficient Probabilistic Semantic Communication Over Visible Light Networks With Rate Splitting](https://arxiv.org/abs/2601.10452)
*Zhouxiang Zhao,Zhaohui Yang,Mingzhe Chen,Chen Zhu,Xin Tong,Zhaoyang Zhang*

Main category: cs.IT

TL;DR: 该论文研究可见光通信系统中基于概率语义通信的能量效率最大化问题，通过联合优化波束成形、直流偏置、公共速率分配和语义压缩比，提出交替优化算法提高系统性能。


<details>
  <summary>Details</summary>
Motivation: 可见光通信具有优于传统射频系统的物理层优势，但其与语义通信等高层次技术的结合尚未充分探索。在资源受限的VLC系统中，语义压缩会带来额外计算开销，而知识库需要同步更新，因此需要解决能量效率最大化问题。

Method: 采用概率图表示知识库，使用速率分割多址接入同时传输知识和信息数据。提出基于连续凸逼近和Dinkelbach方法的交替优化算法，联合优化传输波束成形、直流偏置、公共速率分配和语义压缩比。

Result: 仿真结果表明所提方法能有效提高系统能量效率，在考虑通信和计算成本的情况下，通过优化多个参数实现性能提升。

Conclusion: 该研究为可见光通信与概率语义通信的集成提供了有效的能量效率优化方案，通过联合优化多个系统参数和采用先进的优化算法，为未来无线通信系统的发展提供了重要参考。

Abstract: Visible light communication (VLC) is emerging as a key technology for future wireless communication systems due to its unique physical-layer advantages over traditional radio-frequency (RF)-based systems. However, its integration with higher-layer techniques, such as semantic communication, remains underexplored. This paper investigates the energy efficiency maximization problem in a resource-constrained VLC-based probabilistic semantic communication (PSCom) system. In the considered model, light-emitting diode (LED) transmitters perform semantic compression to reduce data size, which incurs additional computation overhead. The compressed semantic information is transmitted to the users for semantic inference using a shared knowledge base that requires periodic updates to ensure synchronization. In the PSCom system, the knowledge base is represented by probabilistic graphs. To enable simultaneous transmission of both knowledge and information data, rate splitting multiple access (RSMA) is employed. The optimization problem focuses on maximizing energy efficiency by jointly optimizing transmit beamforming, direct current (DC) bias, common rate allocation, and semantic compression ratio, while accounting for both communication and computation costs. To solve this problem, an alternating optimization algorithm based on successive convex approximation (SCA) and Dinkelbach method is developed. Simulation results demonstrate the effectiveness of the proposed approach.

</details>


### [25] [Joint Source-Channel Coding for ISAC: Distortion Tradeoffs and Separation Theorems](https://arxiv.org/abs/2601.10470)
*Gefei Peng,Youlong Wu*

Main category: cs.IT

TL;DR: 本文为ISAC系统建立了信息论框架，证明了分离信源信道编码可以达到联合最优性，并分析了通信与感知之间的性能权衡关系。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信(ISAC)系统能够同时实现高效通信和环境感知，但需要刻画感知与通信之间的性能权衡关系。本文旨在从信息论角度建立ISAC系统的性能权衡理论框架。

Method: 采用联合信源信道编码(JSCC)框架，包含带有信道状态估计器和联合编码器的发射机、状态相关无记忆信道、以及带有联合解码器的接收机。从信息论角度分析信道容量、通信失真、感知失真和估计成本之间的权衡关系。

Result: 建立了ISAC系统中信道容量、通信失真、感知失真和估计成本之间的权衡关系。证明了在该设置下，分离的信源和信道编码可以达到联合最优性。通过二进制设置的示例验证了理论结果。

Conclusion: 本文为ISAC系统提供了信息论基础，证明了分离编码在特定条件下可以达到最优性能，为实际系统设计提供了理论指导。

Abstract: Integrated Sensing and Communication (ISAC) systems have garnered significant attention due to their capability to simultaneously achieve efficient communication and environmental sensing. A core objective in this field is characterizing the performance tradeoff between sensing and communication. In this paper, we consider a joint source-channel coding (JSCC) framework for the ISAC system that consists of a transmitter with a channel state estimator and a joint source-channel encoder, a state-dependent memoryless channel, and a receiver with a joint source-channel decoder. From an information-theoretic perspective, we establish the tradeoff relationships among channel capacity, distortions in both communication and sensing processes, and the estimation cost. We prove that the separate source and channel coding can achieve joint optimality in this setting. An illustrative example of a binary setting is also provided to validate our theoretical results.

</details>


### [26] [A Construction Framework of Coded Caching Scheme for Multi-Access MIMO Systems via Knapsack Problem](https://arxiv.org/abs/2601.10484)
*Siying Luo,Youlong Wu,Mingming Zhang,Minquan Cheng,Dianhua Wu*

Main category: cs.IT

TL;DR: 该论文研究了具有组合拓扑的多接入多输入单输出网络中的编码缓存问题，提出了一种基于0-1背包问题的多天线放置交付阵列设计方法，在提高和自由度同时保持较低的子分组复杂度。


<details>
  <summary>Details</summary>
Motivation: 在多接入MISO网络中，现有方案难以同时实现高和自由度与低子分组复杂度。组合拓扑结构使得缓存设计变得复杂，需要一种能平衡性能与复杂度的优化框架。

Method: 将多天线放置交付阵列设计建模为0-1背包问题，最大化可达到的自由度，将复杂的组合缓存结构转化为可处理的优化框架，产生高效的缓存放置和灵活的交付策略。

Result: 在组合拓扑网络中，所提方案比现有方案获得更高的和自由度；在相同缓存大小约束下，子分组水平与现有线性子分组方案相当；在特定系统条件下达到理论最大和自由度min{L+KM/N, K}，并进一步降低子分组复杂度。

Conclusion: 提出的基于优化框架的缓存方案能有效平衡和自由度与子分组复杂度，对于特定组合结构还能获得更高和自由度和更低子分组，为多接入MISO网络中的编码缓存提供了有效解决方案。

Abstract: This paper investigates the coded caching problem in a multi-access multiple-input single-output (MAMISO) network with the combinatorial topology. The considered system consists of a server containing $N$ files, $Λ$ cache nodes, and $K$ cache-less users, where each user can access a unique subset of $r$ cache nodes. The server is equipped with $L$ transmit antennas. Our objective is to design a caching scheme that simultaneously achieves a high sum Degree of Freedom (sum-DoF) and low subpacketization complexity. To address this challenge, we formulate the design of multi-antenna placement delivery arrays (MAPDA) as a $0$--$1$ knapsack problem to maximize the achievable DoF, thereby transforming the complex combinatorial caching structure into a tractable optimization framework that yields efficient cache placement and flexible delivery strategies. Theoretical and numerical analyses demonstrate that: for networks with combinatorial topologies, the proposed scheme achieves a higher sum-DoF than existing schemes. Under identical cache size constraints, the subpacketization level remains comparable to existing linear subpacketization schemes. Moreover, under specific system conditions, the proposed scheme attains the theoretical maximum sum-DoF of $\min\{L+KM/N, K\}$ while achieving further reductions subpacketization. For particular combinatorial structures, we further derive optimized constructions that achieve even higher sum-DoF with lower subpacketization. ```

</details>


### [27] [Coded Caching for Combinatorial Multi-Access Hotplug Networks from $t$-Designs](https://arxiv.org/abs/2601.10503)
*Dhruv Pratap Singh,Anjana A. Mahesh,B. Sundar Rajan*

Main category: cs.IT

TL;DR: 本文提出了一种基于t设计的组合多接入热插拔编码缓存方案，通过推广HpPDA框架，在缓存部分离线时仍能保证用户解码，实现了灵活的内存-速率权衡和较低的子分组化。


<details>
  <summary>Details</summary>
Motivation: 现有热插拔编码缓存模型假设用户只能访问单个缓存，而实际组合多接入网络中用户可访问多个缓存，且交付阶段只有部分缓存在线。需要扩展现有框架以支持这种更一般的场景。

Method: 首先将热插拔放置交付阵列(HpPDA)框架推广到组合多接入设置，然后提出基于t设计的编码缓存方案。通过设计参数确保每个活跃用户能访问足够多的编码子文件来解码请求文件，并消除冗余组播传输。

Result: 提出的t方案实现了灵活的内存-速率权衡，在某些内存区间优于现有热插拔编码缓存方案。通过适当参数选择可消除冗余传输，降低子分组化需求。

Conclusion: 该工作将热插拔编码缓存扩展到组合多接入网络，提出了基于t设计的有效方案，在缓存部分离线时仍能保证性能，为实际网络部署提供了更实用的解决方案。

Abstract: We study hotplug coded caching in combinatorial multi-access networks, which generalizes existing hotplug coded caching models by allowing users to access multiple caches, while only a subset of caches is online during the delivery phase. We first generalize the Hotplug Placement Delivery Array (HpPDA) framework to the combinatorial multi-access setting. Based on this generalized framework, we propose a t-design-based coded caching scheme for combinatorial multi-access networks. We characterize a class of design parameters under which every active user has access to a sufficient number of coded subfiles to decode its requested file, and show that appropriate parameter choices allow for the elimination of redundant multicast transmissions. As a result, the proposed scheme achieves a family of rate memory trade offs with flexible subpacketization. We present numerical comparisons illustrating that the proposed t-scheme outperforms existing hotplug coded caching schemes in certain memory regimes.

</details>


### [28] [A New Construction Structure on Coded Caching with Linear Subpacketization: Non-Half-Sum Latin Rectangle](https://arxiv.org/abs/2601.10505)
*Yongcheng Yang,Minquan Cheng,Kai Wan,Giuseppe Caire*

Main category: cs.IT

TL;DR: 本文提出了一种新的组合结构NHSLR，将线性编码缓存的子分组化从F=K扩展到F=O(K)，实现了线性可扩展的子分组化，同时进一步降低了传输负载。


<details>
  <summary>Details</summary>
Motivation: 编码缓存是缓解网络拥塞的有效方法，但现有方案在低子分组化和低传输负载之间存在权衡。现有方案要么需要指数级或多项式级子分组化，要么线性子分组化方案导致传输负载过高。最近提出的NHSDP框架实现了F=K的线性子分组化，但仍有改进空间。

Method: 提出了一种新的组合结构——非半和拉丁矩形(NHSLR)，扩展了线性编码缓存方案的框架，从F=K扩展到更广泛的F=O(K)场景。通过构造NHSLR，获得了一类新的编码缓存方案。

Result: 新方案实现了线性可扩展的子分组化，同时进一步降低了传输负载。理论分析和数值分析表明，该方案不仅比现有线性子分组化方案具有更低的传输负载，而且接近某些指数子分组化方案的性能。

Conclusion: NHSLR结构为编码缓存方案设计提供了新的框架，在子分组化和传输负载之间取得了更好的平衡，为实际应用提供了更优的解决方案。

Abstract: Coded caching is recognized as an effective method for alleviating network congestion during peak periods by leveraging local caching and coded multicasting gains. The key challenge in designing coded caching schemes lies in simultaneously achieving low subpacketization and low transmission load. Most existing schemes require exponential or polynomial subpacketization levels, while some linear subpacketization schemes often result in excessive transmission load. Recently, Cheng et al. proposed a construction framework for linear coded caching schemes called Non-Half-Sum Disjoint Packing (NHSDP), where the subpacketization equals the number of users $K$. This paper introduces a novel combinatorial structure, termed the Non-Half-Sum Latin Rectangle (NHSLR), which extends the framework of linear coded caching schemes from $F=K$ (i.e., the construction via NHSDP) to a broader scenario with $F=\mathcal{O}(K)$. By constructing NHSLR, we have obtained a new class of coded caching schemes that achieves linearly scalable subpacketization, while further reducing the transmission load compared with the NHSDP scheme. Theoretical and numerical analyses demonstrate that the proposed schemes not only achieves lower transmission load than existing linear subpacketization schemes but also approaches the performance of certain exponential subpacketization schemes.

</details>


### [29] [A New Construction Structure on Multi-access Coded Caching with Linear Subpacketization: Cyclic Multi-Access Non-Half-Sum Disjoint Packing](https://arxiv.org/abs/2601.10510)
*Mengyuan Li,Minquan Cheng,Kai Wan,Giuseppe Caire*

Main category: cs.IT

TL;DR: 提出一种基于CMA-NHSDP组合结构的多接入编码缓存方案，在保持线性子分组化(F=K)的同时实现较低传输负载。


<details>
  <summary>Details</summary>
Motivation: 现有多接入编码缓存方案存在矛盾：性能好的方案子分组化指数增长，而线性/多项式子分组化的方案传输负载较高。需要设计在保持线性子分组化的同时降低传输负载的方案。

Method: 将NHSDP（非半和不相交包装）结构扩展到多接入系统，提出CMA-NHSDP（循环多接入非半和不相交包装）组合结构，基于此构造新的多接入编码缓存方案。

Result: 理论分析和数值比较表明，所提方案在线性子分组化条件下比现有方案传输负载更低，在某些情况下甚至优于指数子分组化的方案。

Conclusion: CMA-NHSDP结构为多接入编码缓存系统提供了一种有效设计框架，在子分组化复杂度和传输性能之间取得了良好平衡。

Abstract: We consider the $(K,L,M,N)$ multi-access coded caching system introduced by Hachem et al., which consists of a central server with $N$ files and $K$ cache nodes, each of memory size $M$, where each user can access $L$ cache nodes in a cyclic wrap-around fashion. At present, several existing schemes achieve competitive transmission performance, but their subpacketization levels grow exponentially with the number of users. In contrast, schemes with linear or polynomial subpacketization always incur higher transmission loads. We aim to design a multi-access coded caching scheme with linear subpacketization $F$ while maintaining low transmission load. Recently, Cheng et al. proposed a construction framework for coded caching schemes with linear subpacketization (i.e., $F=K$) called non-half-sum disjoint packing (NHSDP). Inspired by this structure, we introduce a novel combinatorial structure named cyclic multi-access non-half-sum disjoint packing (CMA-NHSDP) by extending NHSDP to MACC system. By constructing CMA-NHSDP, we obtain a new class of multi-access coded caching schemes. Theoretical and numerical analyses show that our scheme achieves lower transmission loads than some existing schemes with linear subpacketization. Moreover, the proposed schemes achieves lower transmission load compared to existing schemes with exponential subpacketization in some case.

</details>


### [30] [On the suboptimality of linear codes for binary distributed hypothesis testing](https://arxiv.org/abs/2601.10526)
*Adway Girish,Robinson D. H. Cung,Emre Telatar*

Main category: cs.IT

TL;DR: 研究二元分布式假设检验问题，两个代理观察相关二元向量，以相同速率向中央决策者传输压缩信息。分析线性压缩方案，证明截断在某些情况下是最佳线性方案，但线性编码整体上可能不是最优的。


<details>
  <summary>Details</summary>
Motivation: 研究分布式假设检验中的压缩方案优化问题，探索线性压缩方案在二元向量相关检测中的性能极限，特别关注截断方案的最优性条件。

Method: 研究线性压缩方案，分析截断方案在特定情况下的最优性：1）检测相同幅度但符号相反的相关性；2）检测独立性或反对独立性。通过数值证据支持截断在符号相反相关性检测中的最优性猜想。计算经典随机编码指数进行比较。

Result: 证明截断在两种情况下是最佳线性方案：1）检测相同幅度但符号相反的相关性；2）检测独立性或反对独立性。数值证据支持截断在符号相反相关性检测中是最佳线性编码的猜想。对于独立性检测，截断（以及任何线性编码）严格劣于随机编码方案。

Conclusion: 截断在某些特定二元分布式假设检验场景中是最佳线性压缩方案，但线性编码整体上可能不是最优的，特别是在独立性检测任务中，随机编码方案表现更优。

Abstract: We study a binary distributed hypothesis testing problem where two agents observe correlated binary vectors and communicate compressed information at the same rate to a central decision maker. In particular, we study linear compression schemes and show that simple truncation is the best linear scheme in two cases: (1) testing opposite signs of the same magnitude of correlation, and (2) testing for or against independence. We conjecture, supported by numerical evidence, that truncation is the best linear code for testing any correlations of opposite signs. Further, for testing against independence, we also compute classical random coding exponents and show that truncation, and consequently any linear code, is strictly suboptimal.

</details>


### [31] [Network Integrated Sensing and Communication](https://arxiv.org/abs/2601.10538)
*Edward Andrews,Lawrence Ong,Duy T. Ngo,Yao Liu,Min Li*

Main category: cs.IT

TL;DR: 该论文研究了网络级ISAC（集成感知与通信）系统，分析了感知覆盖与通信路由之间的基本权衡，为6G异构网络设计提供关键见解。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC研究主要集中在链路级设计，但大规模部署需要理解网络级性能。本文旨在研究网络级ISAC模型中感知覆盖与通信路由之间的基本权衡。

Method: 提出一个新颖的优化框架，捕捉多节点路由和感知覆盖之间的相互作用。针对一维路径网络提供完整的感知-吞吐量区域分析，并将其扩展到一般网络拓扑。

Result: 对于一维路径网络，提供了完整的感知-吞吐量区域解析表征。对于一般网络拓扑，证明了感知-吞吐量帕累托边界是分段线性的，并为每个分段提供了物理解释。

Conclusion: 研究揭示了感知覆盖与通信路由之间的基本权衡，为未来6G异构网络设计提供了关键见解，证明了网络级ISAC性能可以通过解析方法表征。

Abstract: Integrated sensing and communication (ISAC) is a cornerstone technology for 6G networks, offering unified support for high-rate communication and high-accuracy sensing. While existing literature extensively covers link-level designs, the transition toward large-scale deployment necessitates a fundamental understanding of network-level performance. This paper investigates a network ISAC model where a source node communicates with a destination via a relay network, while intermediate nodes concurrently perform cooperative sensing over specific spatial regions. We formulate a novel optimization framework that captures the interplay between multi-node routing and sensing coverage. For a one-dimensional path network, we provide an analytical characterization of the complete sensing-throughput region. Extending this to general network topologies, we establish that the sensing-throughput Pareto boundary is piecewise linear and provide physical interpretations for each segment. Our results reveal the fundamental trade-offs between sensing coverage and communication routing, offering key insights for the design of future 6G heterogeneous networks.

</details>


### [32] [Error-Correcting Codes for Two Bursts of t1-Deletion-t2-Insertion with Low Computational Complexity](https://arxiv.org/abs/2601.10540)
*Yajuan Liu,Tolga M. Duman*

Main category: cs.IT

TL;DR: 该论文研究能纠正多个突发(t₁,t₂)-DI（删除-插入）错误的纠错码构造，建立了三种错误模式的等价关系，推导了码率上下界，并提出了低复杂度构造方法。


<details>
  <summary>Details</summary>
Motivation: DNA数据存储和文档同步等实际场景中会出现同时包含插入、删除和替换的突发错误，需要能够纠正此类错误的信道编码。

Method: 1) 建立三种突发(t₁,t₂)-DI错误模式的等价关系；2) 推导两个突发(t₁,t₂)-DI错误码的码率上下界；3) 提出两个突发(t₁,t₂)-DI错误码的具体构造方法。

Result: 证明了三种错误模式的等价性，得到了码率上下界，提出的构造方法相比基于症候压缩的技术显著降低了计算复杂度。

Conclusion: 该研究为处理多个突发删除-插入错误提供了理论框架和实用构造，在DNA存储和文档同步等应用中有重要价值。

Abstract: Burst errors involving simultaneous insertions, deletions, and substitutions occur in practical scenarios, including DNA data storage and document synchronization, motivating developments of channel codes that can correct such errors. In this paper, we address the problem of constructing error-correcting codes (ECCs) capable of handling multiple bursts of $t_1$-deletion-$t_2$-insertion ($(t_1,t_2)$-DI) errors, where each burst consists of $t_1$ deletions followed by $t_2$ insertions in a binary sequence. We make three key contributions: Firstly, we establish the fundamental equivalence of (1) two bursts of $(t_1,t_2)$-DI ECCs, (2) two bursts of $(t_2,t_1)$-DI ECCs, and (3) one burst each of $(t_1,t_2)$-DI and $(t_2,t_1)$-DI ECCs. Then, we derive lower and upper bounds on the code size of two bursts of $(t_1,t_2)$-DI ECCs, which can naturally be extended to the case of multiple bursts. Finally, we present constructions of two bursts of $(t_1,t_2)$-DI ECCs. Compared to the codes obtained by the syndrome compression technique, the resulting codes achieve significantly lower computational complexity.

</details>


### [33] [Sparse Signal Recovery from Random Measurements](https://arxiv.org/abs/2601.10569)
*Siu-Wing Cheng,Man Ting Wong*

Main category: cs.IT

TL;DR: 提出一种无需优化或解线性系统的压缩感知信号重构方法，仅需对数级随机测量矩阵，时间复杂度为O(kn log n)


<details>
  <summary>Details</summary>
Motivation: 传统压缩感知方法需要解决优化问题或线性系统，计算复杂度高。本文旨在开发一种更简单、更高效的重构方法，避免复杂的优化过程。

Method: 使用Θ(log n)个随机测量矩阵，每个维度为k×n，其中k=Θ(s log n)，s是信号稀疏度。通过简单的算法直接确定信号值，无需优化求解。

Result: 方法能在O(kn log n)时间内重构信号，并成功应用于确定信号支撑集。实验表明在二进制信号上表现良好，与基于优化的方法相比具有竞争力。

Conclusion: 提出了一种新颖的压缩感知信号重构方法，避免了传统优化问题，计算效率高，特别适用于稀疏信号恢复，为压缩感知提供了新的简单解决方案。

Abstract: Given the compressed sensing measurements of an unknown vector $z \in \mathbb{R}^n$ using random matrices, we present a simple method to determine $z$ without solving any optimization problem or linear system. Our method uses $Θ(\log n)$ random sensing matrices in $\mathbb{R}^{k \times n}$ and runs in $O(kn\log n)$ time, where $k = Θ(s\log n)$ and $s$ is the number of nonzero coordinates in $z$. We adapt our method to determine the support set of $z$ and experimentally compare with some optimization-based methods on binary signals.

</details>


### [34] [Fundamental Limits of Multi-User Distributed Computing of Linearly Separable Functions](https://arxiv.org/abs/2601.10603)
*K. K. Krishnan Namboodiri,Elizabath Peter,Derya Malak,Petros Elia*

Main category: cs.IT

TL;DR: 该论文建立了多用户分布式计算线性可分函数的基本极限，研究了通信与计算之间的权衡，提出了任务分配和传输的联合设计方案，并证明了在实数域和有限域中的最优性。


<details>
  <summary>Details</summary>
Motivation: 研究多用户分布式计算线性可分函数的基本性能极限，解决通信与计算之间的根本权衡问题。在分布式计算系统中，服务器计算能力有限，通信带宽受限，需要设计高效的计算方案来降低通信成本。

Method: 提出了一个分布式计算方案，联合设计任务分配和传输策略。对于给定的参数K、L、M、Δ，设计服务器计算子函数的方式以及向用户传输线性组合的方式。使用新颖的逆定理证明实数域中的最优性，使用基于计数论证的逆定理分析有限域中的性能。

Result: 提出的方案在各种条件下实现了实数域中的最优性能，并在有限域中表征了方案的性能。建立了通信与计算之间的基本权衡关系，为多用户分布式计算线性可分函数提供了理论基础。

Conclusion: 该工作建立了多用户分布式计算线性可分函数的基本极限，提出的联合设计方案在实数域中达到最优，为分布式计算系统的设计提供了理论指导，揭示了通信与计算之间的根本权衡。

Abstract: This work establishes the fundamental limits of the classical problem of multi-user distributed computing of linearly separable functions. In particular, we consider a distributed computing setting involving $L$ users, each requesting a linearly separable function over $K$ basis subfunctions from a master node, who is assisted by $N$ distributed servers. At the core of this problem lies a fundamental tradeoff between communication and computation: each server can compute up to $M$ subfunctions, and each server can communicate linear combinations of their locally computed subfunctions outputs to at most $Δ$ users. The objective is to design a distributed computing scheme that reduces the communication cost (total amount of data from servers to users), and towards this, for any given $K$, $L$, $M$, and $Δ$, we propose a distributed computing scheme that jointly designs the task assignment and transmissions, and shows that the scheme achieves optimal performance in the real field under various conditions using a novel converse. We also characterize the performance of the scheme in the finite field using another converse based on counting arguments.

</details>


### [35] [Basis-Spline Assisted Coded Computing: Strategies and Error Bounds](https://arxiv.org/abs/2601.10616)
*Rimpi Borah,J. Harshan,V. Lalitha*

Main category: cs.IT

TL;DR: 提出基于三次B样条插值的编码计算框架，用于处理非多项式函数的分布式计算，相比现有Berrut方法显著提升精度和稳定性


<details>
  <summary>Details</summary>
Motivation: 现有Berrut近似编码计算方法在处理非多项式函数时，由于Berrut插值具有全局支撑特性，当延迟节点数量较大时精度会显著下降，需要更稳定准确的方法

Method: 提出基于三次B样条插值的编码计算框架，利用B样条的局部支撑和平滑特性，在master节点重构服务器端函数评估值，增强稳定性和精度

Result: 建立了B样条插值在编码计算中的系统集成方法，推导了关于服务器数量和延迟节点数量的近似误差理论界限，相比Berrut方法在各种非多项式函数上表现显著更优

Conclusion: 基于B样条的编码计算框架能有效解决非多项式函数分布式计算中的精度问题，特别在延迟节点较多时相比现有方法具有明显优势

Abstract: Coded computing has become a key framework for reliable distributed computation over decentralized networks, effectively mitigating the impact of stragglers. Although there exists a wide range of coded computing methods to handle both polynomial and non-polynomial functions, computing methods for the latter class have received traction due its inherent challenges in reconstructing non-polynomial functions using a finite number of evaluations. Among them, the state-of-the-art method is Berrut Approximated coded computing, wherein Berrut interpolants, are used for approximating the non-polynomial function. However, since Berrut interpolants have global support characteristics, such methods are known to offer degraded accuracy when the number of stragglers is large. To address this challenge, we propose a coded computing framework based on cubic B-spline interpolation. In our approach, server-side function evaluations are reconstructed at the master node using B-splines, exploiting their local support and smoothness properties to enhance stability and accuracy. We provide a systematic methodology for integrating B-spline interpolation into coded computing and derive theoretical bounds on approximation error in terms of the number of servers and stragglers. Comparative analysis demonstrates that our framework significantly outperforms Berrut-based methods for various non-polynomial functions.

</details>


### [36] [Converse Bounds for Sun-Jafar-type Weak Private Information Retrieval](https://arxiv.org/abs/2601.10643)
*Chandan Anand,Jayesh Seshadri,Prasad Krishnan,Gowtham R. Kurri*

Main category: cs.IT

TL;DR: 本文证明了Chandan等人提出的WPIR方案在特定条件下的最优性，并展示了当阈值约束不满足时可以获得更高速率


<details>
  <summary>Details</summary>
Motivation: Chandan等人提出了新的弱私有信息检索(WPIR)方案，并给出了速率-隐私权衡的表达式，但这些权衡是否在各类方案中最优尚不清楚

Method: 通过理论证明和反例分析，研究Sun-Jafar型和Banawan-Ulukus型WPIR方案在特定条件下的最优性

Result: 证明了Chandan等人的方案在无合谋复制存储和特定阈值约束下的MDS编码及T-合谋场景中的最优性；当阈值约束不满足时，给出了可以获得更高速率的反例

Conclusion: 本文确定了Chandan等人WPIR方案的最优性条件，揭示了系统参数阈值约束对方案性能的关键影响，为WPIR方案设计提供了理论指导

Abstract: Building on the well-established capacity-achieving schemes of Sun-Jafar (for replicated storage) and the closely related scheme of Banawan-Ulukus (for MDS-coded setting), a recent work by Chandan et al. proposed new classes of weak private information retrieval (WPIR) schemes for the collusion-free (replication and MDS-coded) setting, as well as for the $T$-colluding scenario. In their work, Chandan et al. characterized the expressions for the rate-privacy trade-offs for these classes of WPIR schemes, under the mutual information leakage and maximal leakage metrics. Explicit achievable trade-offs for the same were also presented, which were shown to be competitive or better than prior WPIR schemes. However, the class-wise optimality of the reported trade-offs were unknown. In this work, we show that the explicit rate-privacy trade-offs reported for the Sun-Jafar-type schemes by Chandan et al. are optimal for the non-colluding and replicated setting. Furthermore, we prove the class-wise optimality for Banawan-Ulukus-type MDS-WPIR and Sun-Jafar-type $T$-colluding WPIR schemes, under threshold-constraints on the system parameters. When these threshold-constraints do not hold, we present counter-examples which show that even higher rates than those reported before can be achieved.

</details>


### [37] [One-Shot Broadcast Joint Source-Channel Coding with Codebook Diversity](https://arxiv.org/abs/2601.10648)
*Joseph Rowan,Buu Phan,Ashish Khisti*

Main category: cs.IT

TL;DR: 研究单次联合信源信道编码广播场景，其中源编码一次广播给K个解码器，至少一个解码器需在最大失真约束下恢复源。发现使用不相交码本可获得码本分集增益，不同于信道分集增益。


<details>
  <summary>Details</summary>
Motivation: 研究多解码器广播场景下的单次联合信源信道编码问题，探索如何通过码本设计提高至少一个解码器成功恢复源的概率，特别是在独立信道条件下。

Method: 提出不相交码本编码方案，利用泊松匹配引理推导一阶和二阶可达界；进一步提出混合编码方案，将解码器分组以平衡码本分集和信道分集。

Result: 在二进制对称信道上的数值结果表明，混合方法优于完全共享码本或完全不相交码本的策略，展示了码本分集增益的实际效果。

Conclusion: 在单次联合信源信道编码广播中，不相交码本设计可带来码本分集增益，混合编码方案能有效平衡码本分集和信道分集，提高系统性能。

Abstract: We study a one-shot joint source-channel coding setting where the source is encoded once and broadcast to $K$ decoders through independent channels. Success is predicated on at least one decoder recovering the source within a maximum distortion constraint. We find that in the one-shot regime, utilizing disjoint codebooks at each decoder yields a codebook diversity gain, distinct from the channel diversity gain that may be expected when several decoders observe independent realizations of the channel's output but share the same codebook. Coding schemes are introduced that leverage this phenomenon, where first- and second-order achievability bounds are derived via an adaptation of the Poisson matching lemma (Li and Anantharam, 2021) which allows for multiple decoders using disjoint codebooks. We further propose a hybrid coding scheme that partitions decoders into groups to optimally balance codebook and channel diversity. Numerical results on the binary symmetric channel demonstrate that the hybrid approach outperforms strategies where the decoders' codebooks are either fully shared or disjoint.

</details>


### [38] [Synchronizing Probabilities in Model-Driven Lossless Compression](https://arxiv.org/abs/2601.10678)
*Aviv Adler,Jennifer Tang*

Main category: cs.IT

TL;DR: PMATIC是一种概率匹配区间编码算法，能够容忍神经网络预测中的微小差异，解决模型驱动压缩中的预测不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络能够有效估计符号概率用于无损压缩，但压缩器和解压器必须具有完全匹配的预测概率。由于硬件、软件或计算顺序的差异，神经网络模型经常产生非确定性的微小差异，导致解码失败。

Method: 提出概率匹配区间编码（PMATIC），这是一种模型无关的算法，能够容忍有界的预测不匹配，同时保持低开销。PMATIC使用预测概率，可作为算术编码器的直接替代品集成到模型驱动压缩工具中。

Result: 理论分析证明了PMATIC的正确性和性能界限，在文本数据上的实验验证表明，当与先进的预测模型配合使用时，PMATIC对预测不匹配具有鲁棒性，并且压缩率优于标准现代压缩工具。

Conclusion: PMATIC解决了模型驱动压缩中的关键预测不匹配问题，使深度神经网络能够更可靠地应用于无损数据压缩，同时保持高压缩效率。

Abstract: It is well-known in the field of lossless data compression that probabilistic next-symbol prediction can be used to compress sequences of symbols. Deep neural networks are able to capture rich dependencies in data, offering a powerful means of estimating these probabilities and hence an avenue towards more effective compression algorithms. However, both compressor and decompressor must have exactly matching predictions; even small non-deterministic differences (which often happen with learned models due to hardware, software, or computation order) can lead to cascading decoding failures. In this paper, we formalize the problem of prediction mismatch in model-driven compression, and introduce Probability Matching Interval Coding (PMATIC), a model-agnostic algorithm that tolerates bounded prediction mismatch with low overhead. PMATIC works with the predicted probabilities, making it compatible as a drop-in replacement for the arithmetic encoder in model-driven compression tools. We show theoretical correctness and performance bounds for PMATIC, and validate these results on text data. These results confirm that, when paired an advanced prediction model, PMATIC is robust to prediction mismatch while achieving compression rates that out-perform standard modern compression tools.

</details>


### [39] [Implementation of Oblivious Transfer over Binary-Input AWGN Channels by Polar Codes](https://arxiv.org/abs/2601.10682)
*Pin-Hsun Lin,Hadi Aghaee,Christian Deppe,Eduard A. Jorswieck,Holger Boche*

Main category: cs.IT

TL;DR: 基于极化码在二进制输入加性高斯白噪声信道上的二选一不经意传输协议，利用极化变换的自同构实现完美接收者隐私和渐进发送者隐私


<details>
  <summary>Details</summary>
Motivation: 在二进制输入加性高斯白噪声信道上实现安全的不经意传输协议，同时保证接收者和发送者的隐私安全

Method: 使用极化码，通过极化变换的自同构连接两个解码器视图，公开从相应的自同构群中随机选择编码器，在选定的坏比特信道上故意注入随机性

Result: 在任何有限块长度下实现完美的接收者隐私，通过信道极化结合隐私放大获得渐进的发送者隐私，推导了松弛的可靠性准则并评估了有限块长度性能

Conclusion: 该方案在二进制输入加性高斯白噪声信道上实现了安全的不经意传输，将极化变换的自同构表征为比特信道索引的比特级置换，并利用此结构推导和优化了可实现的有限块长度OT速率

Abstract: We develop a one-out-of-two-oblivious transfer protocol over the binary-input additive white Gaussian noise channel using polar codes. The scheme uses two decoder views linked by automorphisms of the polar transform and publicly draws the encoder at random from the corresponding automorphism group. This yields perfect receiver privacy at any finite blocklength, since the public encoder distribution is independent of the receiver's choice bit. Sender privacy is obtained asymptotically via channel polarization combined with privacy amplification. Because the construction deliberately injects randomness on selected bad bit-channels, we derive a relaxed reliability criterion and evaluate finite-blocklength performance. Finally, we characterize the polar-transform automorphisms as bit-level permutations of bit-channel indices, and exploit this structure to derive and optimize an achievable finite-blocklength OT rate.

</details>


### [40] [Improved Constructions of Reed-Solomon Codes with Optimal Repair Bandwidth](https://arxiv.org/abs/2601.10685)
*Jing Qiu,Weijun Fang,Shu-Tao Xia,Fang-Wei Fu*

Main category: cs.IT

TL;DR: 改进的RS-MSR码构造，消除了素数模s同余1的限制，显著降低了子分组化程度并扩展了可行参数范围


<details>
  <summary>Details</summary>
Motivation: 现有RS-MSR码构造要求素数p_i ≡ 1 (mod s)，限制了参数选择和增加了子分组化程度，需要更灵活的构造方法

Method: 提出改进的RS-MSR码构造，消除p_i ≡ 1 (mod s)的同余条件限制，使用更一般的素数选择

Result: 子分组化程度降低了φ(s)^n倍（φ为欧拉函数），显著扩展了RS-MSR码的可行参数范围

Conclusion: 新构造提供了更灵活、更高效的RS-MSR码设计，为分布式存储系统提供了更好的修复带宽优化方案

Abstract: Maximum-distance-separable (MDS) codes are widely used in distributed storage, yet naive repair of a single erasure in an $[n,k]$ MDS code downloads the entire contents of $k$ nodes. Minimum Storage Regenerating (MSR) codes (Dimakis et al., 2010) minimize repair bandwidth by contacting $d>k$ helpers and downloading only a fraction of data from each. Guruswami and Wootters first proposed a linear repair scheme for Reed-Solomon (RS) codes, showing that they can be repaired with lower bandwidth than the naive approach. The existence of RS codes achieving the MSR point (RS-MSR codes) nevertheless remained open until the breakthrough construction of Tamo, Barg, and Ye, which yields RS-MSR codes with subpacketization $\ell = s \prod_{i=1}^n p_i$, where $p_i$ are distinct primes satisfying $p_i \equiv 1 \pmod{s}$ and $s=d+1-k$.
  In this paper, we present an improved construction of RS-MSR codes by eliminating the congruence condition $p_i \equiv 1 \pmod{s}$. Consequently, our construction reduces the subpacketization by a multiplicative factor of $φ(s)^n$ ( $φ(\cdot)$ is Euler's totient function) and broadens the range of feasible parameters for RS-MSR codes.

</details>


### [41] [Perfect Secret Key Generation for a class of Hypergraphical Sources](https://arxiv.org/abs/2601.10697)
*Manuj Mukherjee,Sagnik Chatterjee,Alhad Sethi*

Main category: cs.IT

TL;DR: 本文扩展了PIN模型到超图，提出了两种完美密钥生成方案：一种基于星超图打包的完整t-均匀超图方案，另一种针对3-均匀超图的2比特方案。


<details>
  <summary>Details</summary>
Motivation: Nitinawarat和Narayan提出的PIN模型完美密钥生成方案基于图的组合性质（生成树打包率）。本文旨在将这一模型推广到超图，利用超图的组合性质设计类似的完美密钥生成方案。

Method: 1. 对于完整的t-均匀超图，利用星超图打包，设计每个星图生成$\binom{m-2}{t-2}$比特完美密钥的方案。2. 针对3-均匀星超图（其投影为环），提出2比特完美密钥生成方案，然后扩展到一般3-均匀超图，结合星图打包和图哈密顿打包。

Result: 1. 完整t-均匀超图的方案达到了容量上限。2. 3-均匀超图的方案对某些超图类别也达到了容量上限。

Conclusion: 成功将PIN模型推广到超图，提出了两种基于超图组合性质的完美密钥生成方案，其中一些方案达到了容量上限，为超图环境下的密钥生成提供了新方法。

Abstract: Nitinawarat and Narayan proposed a perfect secret key generation scheme for the so-called \emph{pairwise independent network (PIN) model} by exploiting the combinatorial properties of the underlying graph, namely the spanning tree packing rate. This work considers a generalization of the PIN model where the underlying graph is replaced with a hypergraph, and makes progress towards designing similar perfect secret key generation schemes by exploiting the combinatorial properties of the hypergraph.
  Our contributions are two-fold. We first provide a capacity achieving scheme for a complete $t$-uniform hypergraph on $m$ vertices by leveraging a packing of the complete $t$-uniform hypergraphs by what we refer to as star hypergraphs, and designing a scheme that gives $\binom{m-2}{t-2}$ bits of perfect secret key per star graph. Our second contribution is a 2-bit perfect secret key generation scheme for 3-uniform star hypergraphs whose projections are cycles. This scheme is then extended to a perfect secret key generation scheme for generic 3-uniform hypergraphs by exploiting star graph packing of 3-uniform hypergraphs and Hamiltonian packings of graphs. The scheme is then shown to be capacity achieving for certain classes of hypergraphs.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [42] [Distributed Hypothesis Testing Under A Covertness Constraint](https://arxiv.org/abs/2601.09837)
*Ismaila Salihou Adamou,Michèle Wigger*

Main category: eess.SP

TL;DR: 研究分布式假设检验中的隐蔽性约束问题，在部分连接DMC信道下，Stein指数与无监督者但传感器可发送k个无噪声比特的情况相同，且无需共享密钥。


<details>
  <summary>Details</summary>
Motivation: 研究分布式假设检验中的隐蔽性约束问题，要求在零假设下外部监督者无法检测传感器与决策中心之间是否存在通信。这扩展了传统隐蔽通信研究，特别关注非警报情况下的性能。

Method: 针对部分连接离散无记忆信道（DMC），推导了Stein指数的理论界限；对于全连接DMC，提出了可实现的Stein指数方案。所有编码方案都不需要传感器和决策中心共享密钥，且隐蔽性约束随观测长度n呈（几乎）指数衰减。

Result: 部分连接DMC下的Stein指数与无监督者但传感器可发送k个无噪声比特的情况相同（k是n的亚线性函数）。全连接DMC下提出的Stein指数可以改善决策中心的本地指数。隐蔽性约束随n呈（几乎）指数衰减，这与传统隐蔽通信不同。

Conclusion: 分布式假设检验在隐蔽性约束下可以实现与传统隐蔽通信不同的性能特征，特别是在部分连接DMC信道中，Stein指数具有简洁的表达式，且无需共享密钥的方案是可行的，这为隐蔽通信系统设计提供了新的思路。

Abstract: We study distributed hypothesis testing under a covertness constraint in the non-alert situation, which requires that under the null-hypothesis an external warden be unable to detect whether communication between the sensor and the decision center is taking place. We characterize the achievable Stein exponent of this setup when the channel from the sensor to the decision center is a partially-connected discrete memoryless channel (DMC), i.e., when certain output symbols can only be induced by some of the inputs. The Stein-exponent in this case, does not depend on the specific transition law of the DMC and equals Shalaby and Papamarcou's exponent without a warden but where the sensor can send $k$ noise-free bits to the decision center, for $k$ a function that is sublinear in the observation length $n$. For fully-connected DMCs, we propose an achievable Stein-exponent and show that it can improve over the local exponent at the decision center. All our coding schemes do not require that the sensor and decision center share a common secret key, as commonly assumed in covert communication. Moreover, in our schemes the divergence covertness constraint vanishes (almost) exponentially fast in the obervation length $n$, again, an atypical behaviour for covert communication.

</details>


### [43] [Towards Native Intelligence: 6G-LLM Trained with Reinforcement Learning from NDT Feedback](https://arxiv.org/abs/2601.09992)
*Zhuoran Xiao,Tao Tao,Chenhui Ye,Yunbo Hu,Yijia Feng,Tianyu Jiao,Liyu Cai*

Main category: eess.SP

TL;DR: 本文提出了一种名为RLDTF（基于数字孪生反馈的强化学习）的新训练范式，用于6G-LLM，通过数字孪生生成奖励信号，结合强化学习实现动态优化决策，显著提升了编排准确性和解决方案最优性。


<details>
  <summary>Details</summary>
Motivation: 当前构建6G-LLM的方法依赖于大规模人工标注语料，这在现实场景中难以获取，且纯离线训练的模型缺乏持续自我改进能力，无法适应无线通信环境的高度动态需求。

Method: 提出RLDTF训练范式：利用网络数字孪生根据编排结果生成奖励信号，采用强化学习动态指导模型进行最优决策，并引入加权令牌机制提高输出准确性。

Result: 综合实验结果表明，所提框架在编排准确性和解决方案最优性方面显著优于现有最先进的基线方法。

Conclusion: RLDTF框架有效解决了6G-LLM训练中的语料依赖和自适应能力限制问题，为网络原生智能的实现提供了可行路径。

Abstract: Owing to its comprehensive understanding of upper-layer application requirements and the capabilities of practical communication systems, the 6G-LLM (6G domain large language model) offers a promising pathway toward realizing network native intelligence. Serving as the system orchestrator, the 6G-LLM drives a paradigm shift that fundamentally departs from existing rule-based approaches, which primarily rely on modular, experience-driven optimization. By contrast, the 6G-LLM substantially enhances network flexibility and adaptability. Nevertheless, current efforts to construct 6G-LLMs are constrained by their reliance on large-scale, meticulously curated, human-authored corpora, which are impractical to obtain in real-world scenarios. Moreover, purely offline-trained models lack the capacity for continual self-improvement, limiting their ability to adapt to the highly dynamic requirements of wireless communication environments. To overcome these limitations, we propose a novel training paradigm termed RLDTF (Reinforcement Learning from Digital Twin Feedback) for 6G-LLMs. This framework leverages network digital twins to generate reward signals based on orchestration outcomes, while employing reinforcement learning to guide the model toward optimal decision-making dynamically. Furthermore, we introduce a weighted token mechanism to improve output accuracy. Comprehensive experimental results demonstrate that our proposed framework significantly outperforms state-of-the-art baselines in orchestration accuracy and solution optimality.

</details>


### [44] [Clustering-Based User Selection in Federated Learning: Metadata Exploitation for 3GPP Networks](https://arxiv.org/abs/2601.10013)
*Ce Zheng,Shiyao Ma,Ke Zhang,Chen Sun,Wenqi Zhang*

Main category: eess.SP

TL;DR: 提出基于元数据的联邦学习框架，通过泊松点过程数据划分和聚类用户选择策略，解决非IID数据相关性问题，提升模型性能与收敛稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习模拟常依赖不现实的数据划分，且现有用户选择方法忽略了用户间数据相关性，导致模型性能受限，特别是在非IID场景下。

Method: 1) 基于齐次泊松点过程(HPPP)的数据划分模型，捕捉数据量的异质性和用户数据集间的自然重叠；2) 基于元数据（如用户位置）的聚类用户选择策略，减少数据相关性并增强训练轮次间的标签多样性。

Result: 在FMNIST和CIFAR-10数据集上的实验表明，该框架在非IID场景下显著提升模型性能、稳定性和收敛速度，在IID设置下保持可比性能，尤其在每轮选择用户数较少时优势更明显。

Conclusion: 该元数据驱动的联邦学习框架能有效应对现实部署中的挑战，提升联邦学习性能，为未来标准化提供指导。

Abstract: Federated learning (FL) enables collaborative model training without sharing raw user data, but conventional simulations often rely on unrealistic data partitioning and current user selection methods ignore data correlation among users. To address these challenges, this paper proposes a metadatadriven FL framework. We first introduce a novel data partition model based on a homogeneous Poisson point process (HPPP), capturing both heterogeneity in data quantity and natural overlap among user datasets. Building on this model, we develop a clustering-based user selection strategy that leverages metadata, such as user location, to reduce data correlation and enhance label diversity across training rounds. Extensive experiments on FMNIST and CIFAR-10 demonstrate that the proposed framework improves model performance, stability, and convergence in non-IID scenarios, while maintaining comparable performance under IID settings. Furthermore, the method shows pronounced advantages when the number of selected users per round is small. These findings highlight the framework's potential for enhancing FL performance in realistic deployments and guiding future standardization.

</details>


### [45] [Microwave Linear Analog Computer (MiLAC)-aided Multiuser MISO: Fundamental Limits and Beamforming Design](https://arxiv.org/abs/2601.10060)
*Zheyu Wu,Matteo Nerini,Bruno Clerckx*

Main category: eess.SP

TL;DR: 微波线性模拟计算机(MiLAC)辅助的波束成形在6G巨型MIMO系统中，相比数字波束成形灵活性稍低但优于传统相移器模拟波束成形，提出的混合数字-MiLAC架构能以更少的射频链实现数字波束成形的灵活性。


<details>
  <summary>Details</summary>
Motivation: 随着无线通信系统向6G演进，巨型MIMO成为关键技术，但面临可扩展性挑战。MiLAC作为纯模拟域波束成形方法，有望解决这一问题，但其波束成形灵活性和设计原理尚不明确。

Method: 首先严格表征MiLAC可实现的波束成形矩阵集合，证明其灵活性介于数字波束成形和传统相移器模拟波束成形之间。提出混合数字-MiLAC架构，当射频链数等于数据流数时即可实现数字波束成形灵活性。针对MU-MISO系统，将MiLAC约束重构为凸线性矩阵不等式，建立低维子空间特性降低问题维度，提出基于WMMSE的算法。

Result: 仿真结果表明，MiLAC辅助波束成形在巨型MIMO系统中性能接近数字波束成形。相比混合波束成形，在避免符号级数字处理和启用低分辨率DAC的情况下，能以更低的硬件和计算复杂度实现相当或更优的性能。

Conclusion: MiLAC为6G巨型MIMO系统提供了一种有前景的波束成形解决方案，在性能、灵活性和硬件复杂度之间取得了良好平衡，特别适合大规模天线阵列应用。

Abstract: As wireless communication systems evolve toward the 6G era, ultra-massive/gigantic MIMO is envisioned as a key enabling technology. Recently, microwave linear analog computer (MiLAC) has emerged as a promising approach to realize beamforming entirely in the analog domain, thereby alleviating the scalability challenges associated with gigantic MIMO. In this paper, we investigate the fundamental beamforming flexibility and design of lossless and reciprocal MiLAC-aided beamforming for MU-MISO systems. We first provide a rigorous characterization of the set of beamforming matrices achievable by MiLAC. Based on this characterization, we prove that MiLAC-aided beamforming does not generally achieve the full flexibility of digital beamforming, while offering greater flexibility than conventional phase-shifter-based analog beamforming. Furthermore, we propose a hybrid digital-MiLAC architecture and show that it achieves digital beamforming flexibility when the number of radio frequency (RF) chains equals the number of data streams, halving that required by conventional hybrid beamforming. We then formulate the MiLAC-aided sum-rate maximization problem for MU-MISO systems. To solve the problem efficiently, we reformulate the MiLAC-related constraints as a convex linear matrix inequality and establish a low-dimensional subspace property that significantly reduces the problem dimension. Leveraging these results, we propose WMMSE-based algorithms for solving the resulting problem. Simulation results demonstrate that MiLAC-aided beamforming achieves performance close to that of digital beamforming in gigantic MIMO systems. Compared with hybrid beamforming, it achieves comparable or superior performance with lower hardware and computational complexity by avoiding symbol-level digital processing and enabling low-resolution digital-to-analog converters (DACs).

</details>


### [46] [P-norm based Fractional-Order Robust Subband Adaptive Filtering Algorithm for Impulsive Noise and Noisy Input](https://arxiv.org/abs/2601.10074)
*Jianhong Ye,Haiquan Zhao,Yi Peng*

Main category: eess.SP

TL;DR: 提出基于分数阶随机梯度下降的FoNSPN算法，用于处理α稳定噪声环境（0<α≤1）下的鲁棒自适应滤波问题。


<details>
  <summary>Details</summary>
Motivation: 现有的NSPN算法在α稳定噪声环境（1<α≤2）中表现良好，但在处理0<α≤1的噪声输入或加性噪声时性能显著下降。需要开发更鲁棒的算法来处理更严重的脉冲噪声环境。

Method: 将分数阶随机梯度下降（FoSGD）方法整合到MPE框架中，提出分数阶NSPN（FoNSPN）算法。分析了步长的收敛范围、分数阶β的理论取值范围，并建立了理论稳态均方偏差（MSD）模型。

Result: 在各种脉冲噪声环境下的仿真实验证实，提出的FoNSPN算法优于现有的最先进算法，在0<α≤1的噪声条件下表现出更好的鲁棒性。

Conclusion: FoNSPN算法通过引入分数阶优化方法，有效解决了NSPN算法在严重脉冲噪声环境下的性能退化问题，为α稳定噪声环境中的自适应滤波提供了更鲁棒的解决方案。

Abstract: Building upon the mean p-power error (MPE) criterion, the normalized subband p-norm (NSPN) algorithm demonstrates superior robustness in $α$-stable noise environments ($1 < α\leq 2$) through effective utilization of low-order moment hidden in robust loss functions. Nevertheless, its performance degrades significantly when processing noise input or additive noise characterized by $α$-stable processes ($0 < α\leq 1$). To overcome these limitations, we propose a novel fractional-order NSPN (FoNSPN) algorithm that incorporates the fractional-order stochastic gradient descent (FoSGD) method into the MPE framework. Additionally, this paper also analyzes the convergence range of its step-size, the theoretical domain of values for the fractional-order $β$, and establishes the theoretical steady-state mean square deviation (MSD) model. Simulations conducted in diverse impulsive noise environments confirm the superiority of the proposed FoNSPN algorithm against existing state-of-the-art algorithms.

</details>


### [47] [Service Provisioning and Path Planning with Obstacle Avoidance for Low-Altitude Wireless Networks](https://arxiv.org/abs/2601.10179)
*Senning Wan,Bin Li,Hongbin Chen,Lei Liu*

Main category: eess.SP

TL;DR: 本文研究在异构通信网络中，考虑地面障碍物约束下，无人机作为空中基站的3D部署问题，通过联合优化无人机轨迹、波束赋形和关联策略来最大化用户满意度。


<details>
  <summary>Details</summary>
Motivation: 异构通信网络中，无人机作为空中基站部署面临地面障碍物、用户数据需求多样化、无人机电池耗尽等约束，需要提供个性化服务并确保服务质量。

Method: 采用块坐标下降法将问题分解为两个子问题：波束赋形子问题使用基于二分法的注水算法；轨迹和关联子问题使用基于近端策略优化的深度强化学习算法学习自适应控制策略。

Result: 仿真结果表明，所提方案在收敛速度和整体系统性能方面优于基线方案，实现了高效关联和精确避障。

Conclusion: 该研究提出的联合优化框架能有效解决异构网络中无人机3D部署问题，在障碍物约束下最大化用户满意度，为无人机辅助通信系统提供了实用解决方案。

Abstract: This paper investigates the three-dimensional (3D) deployment of uncrewed aerial vehicles (UAVs) as aerial base stations in heterogeneous communication networks under constraints imposed by diverse ground obstacles. Given the diverse data demands of user equipments (UEs), a user satisfaction model is developed to provide personalized services. In particular, when a UE is located within a ground obstacle, the UAV must approach the obstacle boundary to ensure reliable service quality. Considering constraints such as UAV failures due to battery depletion, heterogeneous UEs, and obstacles, we aim to maximize overall user satisfaction by jointly optimizing the 3D trajectories of UAVs, transmit beamforming vectors, and binary association indicators between UAVs and UEs. To address the complexity and dynamics of the problem, a block coordinate descent method is adopted to decompose it into two subproblems. The beamforming subproblem is efficiently addressed via a bisection-based water-filling algorithm. For the trajectory and association subproblem, we design a deep reinforcement learning algorithm based on proximal policy optimization to learn an adaptive control policy. Simulation results demonstrate that the proposed scheme outperforms baseline schemes in terms of convergence speed and overall system performance. Moreover, it achieves efficient association and accurate obstacle avoidance.

</details>


### [48] [BeamCKMDiff: Beam-Aware Channel Knowledge Map Construction via Diffusion Transformer](https://arxiv.org/abs/2601.10207)
*Le Zhao,Yining Wang,Xinyi Wang,Zesong Fei,Yong Zeng*

Main category: eess.SP

TL;DR: 提出BeamCKMDiff框架，使用扩散变换器结合自适应层归一化，无需站点特定采样即可构建高保真信道知识地图，支持任意连续波束赋形向量


<details>
  <summary>Details</summary>
Motivation: 现有CKM构建方法依赖稀疏采样测量，仅限于全向地图或离散码本，限制了波束赋形增益的利用，需要一种无需站点特定采样即可构建高保真CKM的方法

Method: 提出BeamCKMDiff生成框架，在扩散变换器的噪声预测网络中引入自适应层归一化机制，将连续波束嵌入作为全局控制参数注入，引导生成过程捕捉波束模式与环境几何之间的复杂耦合关系

Result: 仿真结果表明BeamCKMDiff显著优于现有基线方法，在捕捉主瓣和旁瓣方面实现了卓越的重建精度

Conclusion: BeamCKMDiff为6G网络提供了一种无需站点特定采样即可构建高保真信道知识地图的有效解决方案，能够支持任意连续波束赋形向量，有望显著提升环境感知网络的性能

Abstract: Channel knowledge map (CKM) is emerging as a critical enabler for environment-aware 6G networks, offering a site-specific database to significantly reduce pilot overhead. However, existing CKM construction methods typically rely on sparse sampling measurements and are restricted to either omnidirectional maps or discrete codebooks, hindering the exploitation of beamforming gain. To address these limitations, we propose BeamCKMDiff, a generative framework for constructing high-fidelity CKMs conditioned on arbitrary continuous beamforming vectors without site-specific sampling. Specifically, we incorporate a novel adaptive layer normalization (adaLN) mechanism into the noise prediction network of the Diffusion Transformer (DiT). This mechanism injects continuous beam embeddings as {global control parameters}, effectively steering the generative process to capture the complex coupling between beam patterns and environmental geometries. Simulation results demonstrate that BeamCKMDiff significantly outperforms state-of-the-art baselines, achieving superior reconstruction accuracy in capturing main lobes and side lobes.

</details>


### [49] [Sim2Real Deep Transfer for Per-Device CFO Calibration](https://arxiv.org/abs/2601.10264)
*Jingze Zheng,Zhiguo Shi,Shibo He,Chaojie Gu*

Main category: eess.SP

TL;DR: 提出Sim2Real迁移学习框架，通过模拟预训练和轻量级接收器适配，实现异构SDR平台的CFO校准，显著提升OFDM系统性能。


<details>
  <summary>Details</summary>
Motivation: 异构软件定义无线电平台的未校准硬件损伤导致OFDM系统CFO估计性能显著下降，现有DNN方法缺乏设备级适配能力，限制了实际部署。

Method: 采用Sim2Real迁移学习框架：1）在包含参数化硬件失真的合成OFDM信号上预训练骨干DNN；2）仅使用每个目标设备1000个真实帧微调回归层，保持硬件无关知识同时适配设备特定损伤。

Result: 在三个SDR平台（USRP B210、USRP N210、HackRF One）上实验，相比传统CP方法在室内多径条件下实现了30倍的误码率降低。

Conclusion: 该框架弥合了仿真与现实的差距，为异构无线系统中的稳健CFO估计提供了经济高效的部署方案。

Abstract: Carrier Frequency Offset (CFO) estimation in Orthogonal Frequency Division Multiplexing (OFDM) systems faces significant performance degradation across heterogeneous software-defined radio (SDR) platforms due to uncalibrated hardware impairments. Existing deep neural network (DNN)-based approaches lack device-level adaptation, limiting their practical deployment. This paper proposes a Sim2Real transfer learning framework for per-device CFO calibration, combining simulation-driven pretraining with lightweight receiver adaptation. A backbone DNN is pre-trained on synthetic OFDM signals incorporating parametric hardware distortions (e.g., phase noise, IQ imbalance), enabling generalized feature learning without costly cross-device data collection. Subsequently, only the regression layers are fine-tuned using $1,000$ real frames per target device, preserving hardware-agnostic knowledge while adapting to device-specific impairments. Experiments across three SDR families (USRP B210, USRP N210, HackRF One) achieve $30\times$ BER reduction compared to conventional CP-based methods under indoor multipath conditions. The framework bridges the simulation-to-reality gap for robust CFO estimation, enabling cost-effective deployment in heterogeneous wireless systems.

</details>


### [50] [Low-Complexity Blind Estimator of SNR and MSE for mmWave Multi-Antenna Communications](https://arxiv.org/abs/2601.10331)
*Hanyoung Park,Ji-Woong Choi*

Main category: eess.SP

TL;DR: 提出一种基于毫米波波束域稀疏性的盲估计算法，无需导频信号即可估计噪声功率、信号功率、SNR和MSE，计算复杂度低


<details>
  <summary>Details</summary>
Motivation: 毫米波信道快速变化导致传统基于导频的信道估计精度下降，现有盲估计算法计算复杂度高，难以满足实时服务需求

Method: 利用毫米波信道在波束域的固有稀疏性，使信号和噪声功率分量更易区分，提出无需真实信号先验知识的低复杂度盲估计算法

Result: 提出的算法能够有效估计平均噪声功率、信号功率、SNR和MSE，计算复杂度低，适合实时服务

Conclusion: 基于毫米波波束域稀疏性的盲估计算法为解决动态环境下的信道估计问题提供了高效实用的解决方案

Abstract: To enhance the robustness and resilience of wireless communication and meet performance requirements, various environment-reflecting metrics, such as the signal-to-noise ratio (SNR), are utilized as the system parameter. To obtain these metrics, training signals such as pilot sequences are generally employed. However, the rapid fluctuations of the millimeter-wave (mmWave) propagation channel often degrade the accuracy of such estimations. To address this challenge, various blind estimators that operate without pilot have been considered as potential solutions. However, these algorithms often involve a training phase for machine learning or a large number of iterations, which implies prohibitive computational complexity, making them difficult to employ for real-time services and the system less resilient to dynamic environment variation. In this paper, we propose blind estimators for average noise power, signal power, SNR, and mean-square error (MSE) that do not require knowledge of the ground-truth signal or involve high computational complexity. The proposed algorithm leverages the inherent sparsity of mmWave channel in beamspace domain, which makes the signal and noise power components more distinguishable.

</details>


### [51] [Achievable Degrees of Freedom Analysis and Optimization in Massive MIMO via Characteristic Mode Analysis](https://arxiv.org/abs/2601.10576)
*Shaohua Yue,Siyu Miao,Shuhao Zeng,Fenghan Lin,Boya Di*

Main category: eess.SP

TL;DR: 该论文将特征模分析(CMA)引入大规模MIMO系统的自由度分析中，不仅考虑无线信道自由度，还包含天线激励和辐射特性，建立了CMA自由度分析框架，并通过可重构全息表面天线案例验证了自由度提升。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模MIMO自由度分析主要关注无线信道自由度，忽略了天线激励和辐射特性的影响。天线特性实际上会影响MIMO系统能够传输的独立数据流数量，因此需要更全面的自由度分析框架。

Method: 采用特征模分析(CMA)建模收发天线的激励和辐射特性，建立基于CMA的自由度分析框架，推导可实现的自由度。针对可重构全息表面(RHS)天线案例，提出基于CMA的遗传算法优化天线特征模，通过改变RHS的表面电流和电场分布来最大化自由度。

Result: 建立了包含天线特性的CMA自由度分析框架，推导了可实现的自由度表达式。通过全波仿真验证了理论分析，并证明基于所提算法重构RHS天线能够有效提升系统可实现的自由度。

Conclusion: 特征模分析为大规模MIMO系统的自由度分析提供了更全面的框架，同时考虑无线信道和天线特性。通过优化天线特征模，特别是利用可重构全息表面天线，可以显著提升MIMO系统的可实现自由度，为6G通信系统设计提供了新思路。

Abstract: Massive multiple-input multiple-output (MIMO) is esteemed as a critical technology in 6G communications, providing large degrees of freedom (DoF) to improve multiplexing gain. This paper introduces characteristic mode analysis (CMA) to derive the achievable DoF. Unlike existing works primarily focusing on the DoF of the wireless channel,the excitation and radiation properties of antennas are also involved in our DoF analysis, which influences the number of independent data streams for communication of a MIMO system. Specifically, we model the excitation and radiation properties of transceiver antennas using CMA to analyze the excitation and radiation properties of antennas. The CMA-based DoF analysis framework is established and the achievable DoF is derived. A characteristic mode optimization problem of antennas is then formulated to maximize the achievable DoF. A case study where the reconfigurable holographic surface (RHS) antennas are deployed at the transceiver is investigated, and a CMA-based genetic algorithm is later proposed to solve the above problem. By changing the characteristic modes electric field and surface current distribution of RHS, the achievable DoF is enhanced. Full-wave simulation verifies the theoretical analysis on the the achievable DoF and shows that, via the reconfiguration of RHS based on the proposed algorithm, the achievable DoF is improved.

</details>
