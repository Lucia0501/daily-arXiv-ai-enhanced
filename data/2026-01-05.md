<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 7]
- [eess.SP](#eess.SP) [Total: 13]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [A repair scheme for a distributed storage system based on multivariate polynomials](https://arxiv.org/abs/2601.00120)
*Hiram H. López,Gretchen L. Matthews,Daniel Valvo*

Main category: cs.IT

TL;DR: 扩展分布式存储系统的精确修复方案：从基于单变量多项式的Reed-Solomon码扩展到基于多变量多项式的Reed-Muller码，支持单节点和多节点故障修复


<details>
  <summary>Details</summary>
Motivation: 现有基于Reed-Solomon码的精确修复方案只适用于单变量多项式，需要扩展到更通用的多变量多项式Reed-Muller码，以支持更广泛的分布式存储系统

Method: 将Reed-Solomon码的精确修复方案扩展到Reed-Muller码，提出新的修复方案，能够处理单节点故障和满足特定条件的多节点故障

Result: 成功开发了适用于Reed-Muller码的精确修复方案，该方案能够修复任何单节点故障和符合特定位置条件的多节点故障

Conclusion: 本文扩展了分布式存储系统的精确修复能力，从单变量多项式编码扩展到多变量多项式编码，为基于Reed-Muller码的存储系统提供了有效的故障修复方案

Abstract: A distributed storage system stores data across multiple nodes, with the primary objective of enabling efficient data recovery even in the event of node failures. The main goal of an exact repair scheme is to recover the data from a failed node by accessing and downloading information from the rest of the nodes. In a groundbreaking paper, ~\cite{GW} developed an exact repair scheme for a distributed storage system that is based on Reed-Solomon codes, which depend on single-variable polynomials. In these notes, we extend the repair scheme to the family of distributed storage systems based on Reed-Muller codes, which are linear codes based on multivariate polynomials. The repair scheme we propose repairs any single node failure and multiple node failures, provided the positions satisfy certain conditions.

</details>


### [2] [The permutation group of Reed-Solomon codes over arbitrary points](https://arxiv.org/abs/2601.00122)
*Eduardo Camps-Moreno,Jun Bo Lau,Hiram H. López,Welington Santos*

Main category: cs.IT

TL;DR: 证明了Reed-Solomon码的置换群由保持评估点集不变的一次多项式构成


<details>
  <summary>Details</summary>
Motivation: 研究Reed-Solomon码的置换群结构，为理解这类重要纠错码的对称性提供理论基础

Method: 通过数学证明方法，分析Reed-Solomon码的置换群与保持评估点集不变的一次多项式之间的关系

Result: 证明了Reed-Solomon码的置换群恰好由那些保持评估点集不变的一次多项式构成

Conclusion: 该结果为Reed-Solomon码置换群提供了简洁的刻画，并直接推导出评估点集为整个有限域或乘法群时的已知结果

Abstract: In this work, we prove that the permutation group of a Reed-Solomon code is given by the polynomials of degree one that leave the set of evaluation points invariant. Our results provide a straightforward proof of the well-known cases of the permutation group of the Reed-Solomon code when the set of evaluation points is the whole finite field or the multiplicative group.

</details>


### [3] [Evolution of UE in Massive MIMO Systems for 6G: From Passive to Active](https://arxiv.org/abs/2601.00251)
*Kwonyeol Park,Hyuckjin Choi,Geonho Han,Gyoseung Lee,Yeonjoon Choi,Sunwoo Park,Junil Choi*

Main category: cs.IT

TL;DR: 该论文回顾了从5G到6G演进过程中，用户设备(UE)在mMIMO系统中的角色转变——从被动收发器转变为主动参与系统性能优化的实体，重点分析了3GPP标准演进、设备实现挑战和架构创新。


<details>
  <summary>Details</summary>
Motivation: 随着无线网络发展，严格的延迟可靠性要求和高度动态的信道暴露了传统gNB中心mMIMO架构的局限性，需要重新思考UE的角色。UE正从被动收发器转变为主动贡献系统性能的实体。

Method: 通过按时间顺序回顾3GPP Release 15到19的标准演进，分析UE功能从基本CSI报告到AI/ML增强CSI和UE发起波束管理的进展。研究MPUE架构、设备智能处理和能效运行等实现挑战，并讨论实际约束下的架构创新。使用数字孪生评估验证新兴UE中心功能的影响。

Result: UE发起的波束报告在现实移动场景中提高了吞吐量，多面板架构相比单面板UE增强了链路鲁棒性。验证了新兴UE中心功能对系统性能的积极影响。

Conclusion: UE在mMIMO系统中的角色正在发生根本性转变，从被动设备转变为主动系统参与者。这一转变需要标准演进、设备架构创新和智能处理能力的提升，为6G网络发展奠定基础。

Abstract: As wireless networks continue to evolve, stringent latency and reliability requirements and highly dynamic channels expose fundamental limitations of gNB-centric massive multiple-input multiple-output (mMIMO) architectures, motivating a rethinking of the user equipment (UE) role. In response, the UE is transitioning from a passive transceiver into an active entity that directly contributes to system-level performance. In this context, this article examines the evolving role of the UE in mMIMO systems during the transition from fifth-generation (5G) to sixth-generation (6G), bridging third generation partnership project (3GPP) standardization, device implementation, and architectural innovation. Through a chronological review of 3GPP Releases 15 to 19, we highlight the progression of UE functionalities from basic channel state information (CSI) reporting to artificial intelligence (AI) and machine learning (ML)-based CSI enhancement and UE-initiated beam management. We further examine key implementation challenges, including multi-panel UE (MPUE) architectures, on-device intelligent processing, and energy-efficient operation, and then discuss corresponding architectural innovations under practical constraints. Using digital-twin-based evaluations, we validate the impact of emerging UE-centric functionalities, illustrating that UE-initiated beam reporting improves throughput in realistic mobility scenarios, while a multi-panel architecture enhances link robustness compared with a single-panel UE.

</details>


### [4] [Semantic Transmission Framework in Direct Satellite Communications](https://arxiv.org/abs/2601.00381)
*Chong Huang,Xuyang Chen,Jingfu Li,Pei Xiao,Gaojie Chen,Rahim Tafazolli*

Main category: cs.IT

TL;DR: 提出卫星通信语义传输框架，引入语义效率指标，通过决策辅助REINFORCE++算法优化传输模式选择、卫星-用户关联等，提升语义效率


<details>
  <summary>Details</summary>
Motivation: 当前卫星通信中链路预算不足已成为直接接入的瓶颈问题，需要有效的解决方案

Method: 开发卫星直接通信语义传输框架，引入带优化权重的语义效率指标，提出决策辅助REINFORCE++算法，联合优化传输模式选择、卫星-用户关联、ISL任务迁移、去噪步骤和自适应权重

Result: 数值结果表明，所提算法比基线方法获得更高的语义效率

Conclusion: 语义传输框架是解决卫星通信链路预算不足问题的有效可行方案，所提优化算法能显著提升语义效率

Abstract: Insufficient link budget has become a bottleneck problem for direct access in current satellite communications. In this paper, we develop a semantic transmission framework for direct satellite communications as an effective and viable solution to tackle this problem. To measure the tradeoffs between communication, computation, and generation quality, we introduce a semantic efficiency metric with optimized weights. The optimization aims to maximize the average semantic efficiency metric by jointly optimizing transmission mode selection, satellite-user association, ISL task migration, denoising steps, and adaptive weights, which is a complex nonlinear integer programming problem. To maximize the average semantic efficiency metric, we propose a decision-assisted REINFORCE++ algorithm that utilizes feasibility-aware action space and a critic-free stabilized policy update. Numerical results show that the proposed algorithm achieves higher semantic efficiency than baselines.

</details>


### [5] [On the burst-covering radius of binary cyclic codes](https://arxiv.org/abs/2601.00435)
*Gabriel Sac Himelfarb,Moshe Schwartz*

Main category: cs.IT

TL;DR: 该论文研究突发覆盖码，为循环码和BCH码提供更强的突发覆盖半径界限，并提出高效的突发覆盖循环码算法。


<details>
  <summary>Details</summary>
Motivation: 研究突发覆盖码及其参数界限，特别关注循环码和BCH码的突发覆盖半径分析，这对于编码理论中的错误覆盖能力分析具有重要意义。

Method: 使用线性反馈移位寄存器（LFSR）序列分析循环码的突发覆盖半径；对于BCH码，证明LFSR序列中模式频率的新界限；开发高效的突发覆盖循环码算法。

Result: 建立了突发覆盖码参数与覆盖半径的一般界限；为循环码提供了更强的突发覆盖半径界限；为二进制原始BCH码和Melas码提供了覆盖半径界限；提出了高效的突发覆盖循环码算法。

Conclusion: 该研究为突发覆盖码提供了系统的理论框架，特别在循环码和BCH码方面取得了重要进展，提出的算法具有实际应用价值，LFSR序列的模式频率界限也具有独立的理论意义。

Abstract: We define and study burst-covering codes. We provide some general bounds connecting the code parameters with its burst-covering radius. We then provide stronger bounds on the burst-covering radius of cyclic codes, by employing linear-feedback shift-register (LFSR) sequences. For the case of BCH codes we prove a new bound on pattern frequencies in LFSR sequences, which is of independent interest. Using this tool, we can bound the covering-radius of binary primitive BCH codes and Melas codes. We conclude with an efficient algorithm for burst-covering cyclic codes.

</details>


### [6] [CoCo-Fed: A Unified Framework for Memory- and Communication-Efficient Federated Learning at the Wireless Edge](https://arxiv.org/abs/2601.00549)
*Zhiheng Guo,Zhaoyang Liu,Zihan Cen,Chenyuan Feng,Xinghua Sun,Xiang Chen,Tony Q. S. Quek,Xijun Wang*

Main category: cs.IT

TL;DR: CoCo-Fed是一个压缩与组合联邦学习框架，通过双重维度降维投影解决O-RAN中大规模神经网络部署的内存和通信瓶颈，在保持收敛性的同时显著提升内存和通信效率。


<details>
  <summary>Details</summary>
Motivation: 在O-RAN架构中部署大规模神经网络面临两个关键瓶颈：1）资源受限gNB上本地训练所需的内存占用过大；2）高维模型更新在带宽有限回程链路上的全局聚合导致带宽饱和。

Method: 提出CoCo-Fed框架：本地采用双重维度降维投影梯度，使优化器能在低秩结构上运行而不增加推理参数/延迟；全局引入基于正交子空间叠加的传输协议，将层间更新投影并叠加为每个gNB的单个合并矩阵，大幅减少回程流量。

Result: 在到达角估计任务上的广泛仿真表明，CoCo-Fed在内存和通信效率方面显著优于现有基线方法，同时在非独立同分布设置下保持稳健收敛。

Conclusion: CoCo-Fed通过统一本地内存效率和全局通信减少，为O-RAN中的边缘智能提供了有效的解决方案，并建立了严格的理论基础，证明了即使在无线感知任务的无监督学习条件下也能收敛。

Abstract: The deployment of large-scale neural networks within the Open Radio Access Network (O-RAN) architecture is pivotal for enabling native edge intelligence. However, this paradigm faces two critical bottlenecks: the prohibitive memory footprint required for local training on resource-constrained gNBs, and the saturation of bandwidth-limited backhaul links during the global aggregation of high-dimensional model updates. To address these challenges, we propose CoCo-Fed, a novel Compression and Combination-based Federated learning framework that unifies local memory efficiency and global communication reduction. Locally, CoCo-Fed breaks the memory wall by performing a double-dimension down-projection of gradients, adapting the optimizer to operate on low-rank structures without introducing additional inference parameters/latency. Globally, we introduce a transmission protocol based on orthogonal subspace superposition, where layer-wise updates are projected and superimposed into a single consolidated matrix per gNB, drastically reducing the backhaul traffic. Beyond empirical designs, we establish a rigorous theoretical foundation, proving the convergence of CoCo-Fed even under unsupervised learning conditions suitable for wireless sensing tasks. Extensive simulations on an angle-of-arrival estimation task demonstrate that CoCo-Fed significantly outperforms state-of-the-art baselines in both memory and communication efficiency while maintaining robust convergence under non-IID settings.

</details>


### [7] [Universal Outlier Hypothesis Testing via Mean- and Median-Based Tests](https://arxiv.org/abs/2601.00712)
*Bernhard C. Geiger,Tobias Koch,Josipa Mihaljević,Maximilian Toller*

Main category: cs.IT

TL;DR: 论文研究了通用离群假设检验问题，提出两种方法：当离群序列数量相对于总序列数量呈亚线性增长时，使用均值估计典型分布；当离群序列数量与总序列数量成比例时，使用中位数估计典型分布，两种方法都能达到已知分布的最大似然检验的错误指数。


<details>
  <summary>Details</summary>
Motivation: 传统通用离群假设检验假设观测序列数量固定，而本文考虑观测序列数量和离群序列数量都随序列长度增长的情况。当离群序列数量与总序列数量成比例时，传统的均值估计方法性能下降，需要新的估计方法。

Method: 提出两种估计典型分布π的方法：1）当离群序列数量亚线性增长时，使用所有观测序列的均值估计π；2）当离群序列数量与总序列数量成比例时，使用所有观测序列的中位数估计π。引入典型错误指数概念来形式化分析。

Result: 均值估计方法在离群序列数量亚线性增长时能达到已知π和μ的最大似然检验的错误指数；中位数估计方法在离群序列数量成比例增长时也能达到最大似然检验的错误指数，但仅以概率趋近于1成立。

Conclusion: 在观测序列数量和离群序列数量都增长的设定下，根据离群序列的相对数量选择合适的估计方法（均值或中位数），都能达到最优错误指数性能，扩展了通用离群假设检验的理论框架。

Abstract: Universal outlier hypothesis testing refers to a hypothesis testing problem where one observes a large number of length-$n$ sequences -- the majority of which are distributed according to the typical distribution $π$ and a small number are distributed according to the outlier distribution $μ$ -- and one wishes to decide, which of these sequences are outliers without having knowledge of $π$ and $μ$. In contrast to previous works, in this paper it is assumed that both the number of observation sequences and the number of outlier sequences grow with the sequence length. In this case, the typical distribution $π$ can be estimated by computing the mean over all observation sequences, provided that the number of outlier sequences is sublinear in the total number of sequences. It is demonstrated that, in this case, one can achieve the error exponent of the maximum likelihood test that has access to both $π$ and $μ$. However, this mean-based test performs poorly when the number of outlier sequences is proportional to the total number of sequences. For this case, a median-based test is proposed that estimates $π$ as the median of all observation sequences. It is demonstrated that the median-based test achieves again the error exponent of the maximum likelihood test that has access to both $π$ and $μ$, but only with probability approaching one. To formalize this case, the typical error exponent -- similar to the typical random coding exponent introduced in the context of random coding for channel coding -- is proposed.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [8] [Neural Brain Fields: A NeRF-Inspired Approach for Generating Nonexistent EEG Electrodes](https://arxiv.org/abs/2601.00012)
*Shahar Ain Kedem,Itamar Zimerman,Eliya Nachmani*

Main category: eess.SP

TL;DR: 提出一种受NeRF启发的EEG信号处理方法，将EEG电极类比为不同视角，用神经网络编码整个信号，实现连续可视化、超分辨率重建和虚拟电极生成。


<details>
  <summary>Details</summary>
Motivation: EEG数据具有长度可变、信噪比低、个体差异大、时间漂移等挑战，且缺乏大规模干净数据集。现有深度学习方法难以有效处理EEG信号，需要新的建模方法。

Method: 受NeRF启发，将EEG电极位置类比为不同视角，训练神经网络以NeRF风格编码单个EEG样本，生成固定大小的权重向量表示整个信号。该表示支持在任意时间步和空间位置渲染EEG信号。

Result: 方法能够连续可视化脑活动（包括超分辨率），重建原始EEG信号，有效模拟不存在的电极数据。重构信号可输入标准EEG处理网络提升性能。

Conclusion: NeRF启发的EEG表示方法为解决EEG建模挑战提供了新思路，支持连续可视化、信号重建和虚拟电极生成，有望改善EEG处理网络的性能。

Abstract: Electroencephalography (EEG) data present unique modeling challenges because recordings vary in length, exhibit very low signal to noise ratios, differ significantly across participants, drift over time within sessions, and are rarely available in large and clean datasets. Consequently, developing deep learning methods that can effectively process EEG signals remains an open and important research problem. To tackle this problem, this work presents a new method inspired by Neural Radiance Fields (NeRF). In computer vision, NeRF techniques train a neural network to memorize the appearance of a 3D scene and then uses its learned parameters to render and edit the scene from any viewpoint. We draw an analogy between the discrete images captured from different viewpoints used to learn a continuous 3D scene in NeRF, and EEG electrodes positioned at different locations on the scalp, which are used to infer the underlying representation of continuous neural activity. Building on this connection, we show that a neural network can be trained on a single EEG sample in a NeRF style manner to produce a fixed size and informative weight vector that encodes the entire signal. Moreover, via this representation we can render the EEG signal at previously unseen time steps and spatial electrode positions. We demonstrate that this approach enables continuous visualization of brain activity at any desired resolution, including ultra high resolution, and reconstruction of raw EEG signals. Finally, our empirical analysis shows that this method can effectively simulate nonexistent electrodes data in EEG recordings, allowing the reconstructed signal to be fed into standard EEG processing networks to improve performance.

</details>


### [9] [Modeling Day-Long ECG Signals to Predict Heart Failure Risk with Explainable AI](https://arxiv.org/abs/2601.00014)
*Eran Zvuloni,Ronit Almog,Michael Glikson,Shany Brimer Biton,Ilan Green,Izhar Laufer,Offer Amir,Joachim A. Behar*

Main category: eess.SP

TL;DR: 使用深度学习分析24小时单导联心电图数据，可预测五年内心力衰竭风险，准确率达0.80 AUC，优于30秒片段和临床评分。


<details>
  <summary>Details</summary>
Motivation: 心力衰竭影响11.8%的65岁以上成年人，降低生活质量和寿命。预防心力衰竭可减少发病率和死亡率。需要一种非侵入性、低成本且广泛可及的预测工具。

Method: 开发DeepHHF深度学习模型，使用Technion-Leumit Holter ECG数据集（69,663条记录，47,729名患者，20年数据），训练于24小时单导联心电图数据。

Result: DeepHHF达到0.80 AUC，优于30秒片段模型和临床评分。高风险个体住院或死亡风险增加两倍。可解释性分析显示模型关注心律失常和心脏异常，关键注意力集中在上午8点至下午3点。

Conclusion: 深度学习可有效建模24小时连续心电图数据，捕捉阵发性事件和昼夜节律变化，为心力衰竭风险预测提供非侵入性、低成本且广泛可及的有前景工具。

Abstract: Heart failure (HF) affects 11.8% of adults aged 65 and older, reducing quality of life and longevity. Preventing HF can reduce morbidity and mortality. We hypothesized that artificial intelligence (AI) applied to 24-hour single-lead electrocardiogram (ECG) data could predict the risk of HF within five years. To research this, the Technion-Leumit Holter ECG (TLHE) dataset, including 69,663 recordings from 47,729 patients, collected over 20 years was used. Our deep learning model, DeepHHF, trained on 24-hour ECG recordings, achieved an area under the receiver operating characteristic curve of 0.80 that outperformed a model using 30-second segments and a clinical score. High-risk individuals identified by DeepHHF had a two-fold chance of hospitalization or death incidents. Explainability analysis showed DeepHHF focused on arrhythmias and heart abnormalities, with key attention between 8 AM and 3 PM. This study highlights the feasibility of deep learning to model 24-hour continuous ECG data, capturing paroxysmal events and circadian variations essential for reliable risk prediction. Artificial intelligence applied to single-lead Holter ECG is non-invasive, inexpensive, and widely accessible, making it a promising tool for HF risk prediction.

</details>


### [10] [Adaptive Pinching Antenna Optimization via Meta-Learning for Physical-Layer Security in Dynamic Wireless Networks](https://arxiv.org/abs/2601.00115)
*Khalid T. Musri,Akram Y. Sarhan,Osamah A. Abdullah,Hayder Al-Hraishawi*

Main category: eess.SP

TL;DR: 基于梯度的元学习框架，用于在用户位置不确定和物理层安全约束下实时控制波导夹持天线系统，通过元学习实现快速适应动态环境。


<details>
  <summary>Details</summary>
Motivation: 在动态无线环境中，用户位置不确定性和物理层安全约束对波导夹持天线系统的实时控制提出了挑战，需要能够快速适应变化的控制策略。

Method: 提出概率系统模型捕捉不完美定位对中断和安全性能的影响，建立联合天线定位和发射功率优化问题，使用模型无关元学习(MAML)学习可迁移初始化，实现少样本在线适应。

Result: 仿真结果表明，该框架在中断概率、安全性能和收敛延迟方面显著优于Reptile元学习、非元强化学习、传统优化、静态天线放置和仅功率控制方法。

Conclusion: 元学习是动态无线环境中可重构夹持天线系统安全低延迟控制的有效工具，能够快速适应变化的移动和信道条件。

Abstract: This paper develops a gradient-based meta-learning framework for real-time control of waveguided pinching-antenna systems under user-location uncertainty and physical-layer security (PLS) constraints. A probabilistic system model is introduced to capture the impact of imperfect localization on outage performance and secrecy. Based on this model, a joint antenna-positioning and transmit-power optimization problem is formulated to satisfy probabilistic reliability and secrecy requirements. To enable rapid adaptation in highly dynamic environments, the proposed approach employs model-agnostic meta-learning (MAML) to learn a transferable initialization across diverse mobility and channel conditions, allowing few-shot online adaptation using limited pilot feedback. Simulation results demonstrate that the proposed framework significantly outperforms Reptile-based meta-learning, non-meta reinforcement learning, conventional optimization, static antenna placement, and power-only control in terms of outage probability, secrecy performance, and convergence latency. These results establish meta-learning as an effective tool for secure and low-latency control of reconfigurable pinching-antenna systems in non-stationary wireless environments.

</details>


### [11] [AI-Driven Channel State Information (CSI) Extrapolation for 6G: Current Situations, Challenges and Future Research](https://arxiv.org/abs/2601.00159)
*Yuan Gao,Zichen Lu,Xinyi Wu,Wenjun Yu,Shengli Liu,Jianbo Du,Yanliang Jin,Shunqing Zhang,Xiaoli Chu,Shugong Xu*

Main category: eess.SP

TL;DR: 本文首次全面综述了6G通信系统中CSI外推技术的现状、挑战和未来方向，包括性能指标分析、模型驱动和AI驱动方法回顾、开源数据集讨论以及未来研究机会。


<details>
  <summary>Details</summary>
Motivation: 传统信道估计方法在6G高移动性、超大规模MIMO和多频段系统中面临可扩展性挑战，CSI外推技术通过部分CSI推断完整CSI来显著降低开销。目前缺乏对最先进CSI外推技术的全面综述。

Method: 1. 分析6G中CSI外推的特定性能指标（外推精度、动态场景适应性和算法成本）；2. 回顾时间和频域、天线和多域CSI外推的模型驱动和AI驱动方法；3. 总结关键见解；4. 检查可用于训练高性能AI驱动模型的开放源信道数据集和模拟器。

Result: 提供了CSI外推技术的全面综述，总结了现有方法的优缺点，识别了AI驱动方法在满足性能要求方面的潜力，并讨论了可用于模型训练的资源。

Conclusion: 本文填补了CSI外推技术全面综述的空白，分析了当前研究的关键挑战，并提出了未来研究机会，为6G通信系统优化提供了重要参考。

Abstract: CSI extrapolation is an effective method for acquiring channel state information (CSI), essential for optimizing performance of sixth-generation (6G) communication systems. Traditional channel estimation methods face scalability challenges due to the surging overhead in emerging high-mobility, extremely large-scale multiple-input multiple-output (EL-MIMO), and multi-band systems. CSI extrapolation techniques mitigate these challenges by using partial CSI to infer complete CSI, significantly reducing overhead. Despite growing interest, a comprehensive review of state-of-the-art (SOTA) CSI extrapolation techniques is lacking. This paper addresses this gap by comprehensively reviewing the current status, challenges, and future directions of CSI extrapolation for the first time. Firstly, we analyze the performance metrics specific to CSI extrapolation in 6G, including extrapolation accuracy, adaption to dynamic scenarios and algorithm costs. We then review both model-driven and artificial intelligence (AI)-driven approaches for time, frequency, antenna, and multi-domain CSI extrapolation. Key insights and takeaways from these methods are summarized. Given the promise of AI-driven methods in meeting performance requirements, we also examine the open-source channel datasets and simulators that could be used to train high-performance AI-driven CSI extrapolation models. Finally, we discuss the critical challenges of the existing research and propose perspective research opportunities.

</details>


### [12] [MIMO-AFDM Outperforms MIMO-OFDM in the Face of Hardware Impairments](https://arxiv.org/abs/2601.00502)
*Zeping Sui,Zilong Liu,Leila Musavian,Yong Liang Guan,Lie-Liang Yang,Lajos Hanzo*

Main category: eess.SP

TL;DR: 研究硬件损伤对MIMO-AFDM系统的影响，发现AFDM在硬件损伤下仍能保持全分集阶数，且比OFDM对乘性和加性损伤更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究硬件损伤（包括乘性和加性损伤）对MIMO-AFDM系统性能的影响，评估其在现实硬件不完美条件下的表现，并与传统MIMO-OFDM系统进行比较。

Method: 针对小规模MIMO-AFDM系统推导了ML检测器的紧密BER上界；针对大规模系统提出了LMMSE检测器的闭式BER近似，包括不完美信道估计场景。通过理论分析和仿真验证。

Result: 1) 硬件损伤下的AFDM系统仍能保持全分集阶数；2) 推导的BER结果能准确预测ML性能；3) MIMO-AFDM比OFDM对乘性失真（如相位噪声、载波频率偏移）更具鲁棒性；4) 在相同加性硬件损伤条件下，MIMO-AFDM始终优于MIMO-OFDM。

Conclusion: AFDM由于其固有的啁啾信号特性和离散仿射傅里叶变换的有益扩展效应，比OFDM表现出更强的ICI鲁棒性，即使在硬件损伤下也能实现最大全分集增益。

Abstract: The impact of both multiplicative and additive hardware impairments (HWIs) on multiple-input multiple-output affine frequency division multiplexing (MIMO-AFDM) systems is investigated. For small-scale MIMO-AFDM systems, a tight bit error rate (BER) upper bound associated with the maximum likelihood (ML) detector is derived. By contrast, for large-scale systems, a closed-form BER approximation associated with the linear minimum mean squared error (LMMSE) detector is presented, including realistic imperfect channel estimation scenarios. Our first key observation is that the full diversity order of a hardware-impaired AFDM system remains unaffected, which is a unique advantage. Furthermore, our analysis shows that 1) the BER results derived accurately predict the simulated ML performance in moderate-to-high signal-to-noise ratios (SNRs), while the theoretical BER curve of the LMMSE detector closely matches that of the Monte-Carlo based one. 2) MIMO-AFDM is more resilient to multiplicative distortions, such as phase noise and carrier frequency offset, compared to its orthogonal frequency division multiplexing (OFDM) counterparts. This is attributed to its inherent chirp signal characteristics; 3) MIMO-AFDM consistently achieves superior BER performance compared to conventional MIMO-OFDM systems under the same additive HWI conditions, as well as different velocity values. The latter is because MIMO-AFDM is also resilient to the additional inter-carrier interference (ICI) imposed by the nonlinear distortions of additive HWIs. In a nutshell, compared to OFDM, AFDM demonstrates stronger ICI resilience and achieves the maximum full diversity attainable gain even under HWIs, thanks to its intrinsic chirp signalling structure as well as to the beneficial spreading effect of the discrete affine Fourier transform.

</details>


### [13] [Edge AI Inference in ISCC Networks: Sensing Accuracy Analysis and Precoding Design](https://arxiv.org/abs/2601.00171)
*Lingyun Xu,Bowen Wang,Huiyong Li,Ziyang Cheng*

Main category: eess.SP

TL;DR: 该论文研究了ISCC网络中边缘AI推理的感知精度与预编码系数之间的关系，提出了判别增益(DG)来表征感知精度，并设计了有效的预编码算法来最大化DG。


<details>
  <summary>Details</summary>
Motivation: 在集成感知、通信和计算(ISCC)网络中，边缘AI推理需要同时处理感知、通信和计算任务。感知精度直接影响推理性能，而预编码系数对感知精度有重要影响。目前缺乏对感知精度与预编码系数关系的理论分析，以及相应的优化设计方法。

Method: 1. 构建了空中赋能ISCC网络的系统模型，包含分布式边缘传感器进行特征提取和边缘服务器进行分类
2. 提出了判别增益(DG)来量化感知精度
3. 推导了DG关于预编码系数的显式函数关系
4. 设计了有效的预编码算法来解决非凸的DG最大化问题

Result: 仿真结果验证了所提设计在ISCC网络中边缘推理的有效性和可行性。通过优化预编码系数，显著提高了感知精度，从而提升了边缘AI推理的性能。

Conclusion: 该工作为ISCC网络中边缘AI推理的感知精度优化提供了理论分析和实用设计方法。通过建立感知精度与预编码系数的关系，并设计有效的优化算法，实现了感知精度的显著提升，为边缘智能系统的发展提供了重要支持。

Abstract: This work explores the relationship between sensing accuracy and precoding coefficients for edge artificial intelligence (AI) inference in integrated sensing, communication and computation (ISCC) networks. We start by constructing a system model of an over-the-air-empowered ISCC network for edge AI inference, involving distributed edge sensors for feature extraction and an edge server for classification. Based on this model, we introduce a discriminant gain (DG) to characterize sensing accuracy and novelly derive an explicit function of the DG about precoding coefficients, giving valuable insights into precoding design. Guided by this, we propose an effective precoding algorithm to solve a non-convex DG-maximization problem. Simulation results verify the effectiveness and feasibility of the proposed design for edge inference in ISCC networks.

</details>


### [14] [Time--to--Digital Converter (TDC)--Based Resonant Compute--in--Memory for INT8 CNNs with Layer--Optimized SRAM Mapping](https://arxiv.org/abs/2601.00434)
*Dhandeep Challagundla,Ignatius Bezzam,Riadul Islam*

Main category: eess.SP

TL;DR: 提出基于时间域计算的存内计算架构，用时间数字转换器替代传统模数转换器，降低功耗和面积，实现高效神经网络加速


<details>
  <summary>Details</summary>
Motivation: 传统存内计算架构使用模数转换器进行模拟乘累加运算，但ADC带来显著的面积和功耗开销以及非线性问题，需要更高效的数字化方案

Method: 提出谐振时间域存内计算架构，采用8T SRAM单元实现可靠的位级乘累加运算，使用4位时间数字转换器和脉冲收缩延迟元件进行数字化，结合权重固定的数据映射策略和自动SRAM宏选择算法

Result: 在TSMC 28nm工艺上验证8KB SRAM阵列，实现320GOPS吞吐量和38.46TOPS/W能效，在六个CNN模型上推理能耗降低高达8倍，量化后精度损失最小

Conclusion: TDC-CiM架构通过时间数字转换器替代传统ADC，显著降低功耗和面积，同时保持高性能，为存内计算神经网络加速器提供了更高效的解决方案

Abstract: In recent years, Compute-in-memory (CiM) architectures have emerged as a promising solution for deep neural network (NN) accelerators. Multiply-accumulate~(MAC) is considered a {\textit de facto} unit operation in NNs. By leveraging the inherent parallel processing capabilities of CiM, NNs that require numerous MAC operations can be executed more efficiently. This is further facilitated by storing the weights in SRAM, reducing the need for extensive data movement and enhancing overall computational speed and efficiency. Traditional CiM architectures execute MAC operations in the analog domain, employing an Analog-to-Digital converter (ADC) to convert the analog MAC values into digital outputs. However, these ADCs introduce significant increase in area and power consumption, as well as introduce non-linearities. This work proposes a resonant time-domain compute-in-memory (TDC-CiM) architecture that eliminates the need for an ADC by using a time-to-digital converter (TDC) to digitize analog MAC results with lower power and area cost. A dedicated 8T SRAM cell enables reliable bitwise MAC operations, while the readout uses a 4-bit TDC with pulse-shrinking delay elements, achieving 1 GS/s sampling with a power consumption of only 1.25 mW. In addition, a weight stationary data mapping strategy combined with an automated SRAM macro selection algorithm enables scalable and energy-efficient deployment across CNN workloads. Evaluation across six CNN models shows that the algorithm reduces inference energy consumption by up to 8x when scaling SRAM size from 32~KB to 256~KB, while maintaining minimal accuracy loss after quantization. The feasibility of the proposed architecture is validated on an 8~KB SRAM memory array using TSMC 28~nm technology. The proposed TDC-CiM architecture demonstrates a throughput of 320~GOPS with an energy efficiency of 38.46~TOPS/W.

</details>


### [15] [Parametrized Sharing for Multi-Agent Hybrid DRL for Multiple Multi-Functional RISs-Aided Downlink NOMA Networks](https://arxiv.org/abs/2601.00538)
*Chi-Te Kuo,Li-Hsiang Shen,Jyun-Jhe Huang*

Main category: eess.SP

TL;DR: 提出了一种参数共享的多智能体混合深度强化学习（PMHRL）方法，用于优化多MF-RIS辅助的NOMA下行网络，实现能量效率最大化。


<details>
  <summary>Details</summary>
Motivation: 传统RIS存在信号覆盖有限和能量依赖外部供电的问题，MF-RIS通过主动RIS能力和能量收集功能，能够扩展信号覆盖并实现自持续供电，但需要优化其配置和部署以实现最佳能量效率。

Method: 提出PMHRL方法，结合多智能体PPO处理连续变量（功率分配、波束成形、MF-RIS幅度/相移/EH比率）和DQN处理离散变量（MF-RIS位置），通过参数共享方案提高学习效率。

Result: PMHRL方法相比其他基准（无参数共享、纯PPO、纯DQN）获得最高的能量效率；多MF-RIS辅助的NOMA下行网络相比无EH/放大、传统RIS、无RIS/MF-RIS部署等场景，在不同多址接入方式下都实现了最高的能量效率。

Conclusion: PMHRL方法能有效优化多MF-RIS辅助的NOMA网络，显著提升能量效率，证明了MF-RIS架构和所提优化方法的优越性。

Abstract: Multi-functional reconfigurable intelligent surface (MF-RIS) is conceived to address the communication efficiency thanks to its extended signal coverage from its active RIS capability and self-sustainability from energy harvesting (EH). We investigate the architecture of multi-MF-RISs to assist non-orthogonal multiple access (NOMA) downlink networks. We formulate an energy efficiency (EE) maximization problem by optimizing power allocation, transmit beamforming and MF-RIS configurations of amplitudes, phase-shifts and EH ratios, as well as the position of MF-RISs, while satisfying constraints of available power, user rate requirements, and self-sustainability property. We design a parametrized sharing scheme for multi-agent hybrid deep reinforcement learning (PMHRL), where the multi-agent proximal policy optimization (PPO) and deep-Q network (DQN) handle continuous and discrete variables, respectively. The simulation results have demonstrated that proposed PMHRL has the highest EE compared to other benchmarks, including cases without parametrized sharing, pure PPO and DQN. Moreover, the proposed multi-MF-RISs-aided downlink NOMA achieves the highest EE compared to scenarios of no-EH/amplification, traditional RISs, and deployment without RISs/MF-RISs under different multiple access.

</details>


### [16] [Fractional Programming for Kullback-Leibler Divergence in Hypothesis Testing](https://arxiv.org/abs/2601.00564)
*Jeongwoo Park,Seongkyu Jung,Kaiming Shen,Jeonghun Park*

Main category: eess.SP

TL;DR: 提出基于分数规划的计算高效优化框架，用于最大化Kullback-Leibler散度，显著降低计算复杂度并加速收敛


<details>
  <summary>Details</summary>
Motivation: KLD最大化在主动感知和假设检验中至关重要，但现有方法计算复杂度高，需要每次迭代进行矩阵求逆，限制了实际应用

Method: 1) 使用矩阵分数规划将KLD最大化问题转化为一系列可处理的二次子问题；2) 引入非齐次松弛技术，用闭式更新替代线性系统求解器；3) 采用STEM加速方法，将迭代方案解释为定点映射

Result: 算法将每次迭代复杂度降至二次阶，总运行时间比最先进基准方法减少数个数量级，在多个随机接入和联合感知通信场景中验证了有效性

Conclusion: 提出的基于分数规划的优化框架为KLD最大化问题提供了计算高效的解决方案，显著降低了计算复杂度并加速了收敛，适用于主动感知和假设检验等应用场景

Abstract: Maximizing the Kullback-Leibler divergence (KLD) is a fundamental problem in waveform design for active sensing and hypothesis testing, as it directly relates to the error exponent of detection probability. However, the associated optimization problem is highly nonconvex due to the intricate coupling of log-determinant and matrix trace terms. Existing solutions often suffer from high computational complexity, typically requiring matrix inversion at every iteration. In this paper, we propose a computationally efficient optimization framework based on fractional programming (FP). Our key idea is to reformulate the KLD maximization problem into a sequence of tractable quadratic subproblems using matrix FP. To further reduce complexity, we introduce a nonhomogeneous relaxation technique that replaces the costly linear system solver with a simple closed-form update, thereby reducing the per-iteration complexity to quadratic order. To compensate for the convergence speed trade-off caused by relaxation, we employ an acceleration method called STEM by interpreting the iterative scheme as a fixed-point mapping. The resulting algorithm achieves significantly faster convergence rates with low per-iteration cost. Numerical results demonstrate that our approach reduces the total runtime by orders of magnitude compared to a state-of-the-art benchmark. Finally, we apply the proposed framework to a multiple random access scenario and a joint integrated sensing and communication scenario, validating the efficacy of our framework in such applications.

</details>


### [17] [WiFo-MUD: Wireless Foundation Model for Heterogeneous Multi-User Demodulator](https://arxiv.org/abs/2601.00612)
*Zonghui Yang,Shijian Gao,Xuesong Cai,Xiang Cheng,Liuqing Yang*

Main category: eess.SP

TL;DR: WiFo-MUD：基于扩散模型的多用户解调基础模型，通过条件去噪、通信感知一致性蒸馏和动态用户分组策略，在异构配置下实现高效推理和强泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有多用户解调器在通用环境中表现不佳：经典方法难以平衡准确性和复杂度，深度学习方法在异构配置下缺乏适应性，现有扩散模型灵活性不足。需要一种能适应实际应用需求的通用解调方案。

Method: 提出WiFo-MUD扩散基础模型，包含：1）对齐用户间信噪比不平衡；2）定制化主干网络进行条件去噪；3）通信感知一致性蒸馏方法；4）动态用户分组策略以增强推理效率

Result: 在大规模异构数据集上取得最先进结果，展示了高效推理能力和在不同系统配置下的强泛化性能

Conclusion: WiFo-MUD解决了多用户解调中的关键挑战，为无线通信提供了一种通用、高效且适应性强的解调解决方案，在实际应用中具有重要价值

Abstract: Multi-user signal demodulation is critical to wireless communications, directly impacting transmission reliability and efficiency. However, existing demodulators underperform in generic multi-user environments: classical demodulators struggle to balance accuracy and complexity, while deep learning-based methods lack adaptability under heterogeneous configurations. Although diffusion models have been introduced for demodulation, their flexibility remains limited for practical use. To address these issues, this work proposes WiFo-MUD, a universal diffusion-based foundation model for multi-user demodulation. The model aligns inter-user signal-to-noise ratio imbalance and performs conditional denoising via a customized backbone. Furthermore, a communication-aware consistency distillation method and a dynamic user-grouping strategy are devised to enhance inference. WiFo-MUD achieves state-of-the-art results on large-scale heterogeneous datasets, demonstrating efficient inference and strong generalization across varying system configurations.

</details>


### [18] [Splitting Precoding with Subspace Selection and Quantized Refinement for Massive MIMO](https://arxiv.org/abs/2601.00616)
*Yasaman Khorsandmanesh,Emil Bjornson,Joakim Jalden*

Main category: eess.SP

TL;DR: 提出一种分割预编码架构，将预编码设计分离到AAS和BBU之间，以解决大规模MIMO 5G中前传容量有限的问题。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO 5G架构中有限的前传容量是一个实际瓶颈。传统的下行设计将整个预编码计算放在BBU，并通过前传传输高维预编码矩阵，导致显著的量化损失和信令开销。

Method: 提出分割预编码架构：AAS执行本地子空间选择以降低信道维度，BBU基于得到的有效信道计算优化的量化细化预编码。

Result: 数值结果表明，所提出的分割预编码策略比传统单阶段预编码实现了更高的总频谱效率。

Conclusion: 通过将预编码设计分离到AAS和BBU之间，该架构有效解决了前传容量限制问题，提高了系统性能。

Abstract: Limited fronthaul capacity is a practical bottleneck in massive multiple-input multiple-output (MIMO) 5G architectures, where a base station (BS) consists of an advanced antenna system (AAS) connected to a baseband unit (BBU). Conventional downlink designs place the entire precoding computation at the BBU and transmit a high-dimensional precoding matrix over the fronthaul, resulting in substantial quantization losses and signaling overhead. This letter proposes a splitting precoding architecture that separates the design between the AAS and BBU. The AAS performs a local subspace selection to reduce the channel dimensionality, while the BBU computes an optimized quantized refinement precoding based on the resulting effective channel. The numerical results show that the proposed splitting precoding strategy achieves higher sum spectral efficiency than conventional one-stage precoding.

</details>


### [19] [Conformal Reconfigurable Intelligent Surfaces: A Cylindrical Geometry Perspective](https://arxiv.org/abs/2601.00734)
*Filippo Pepe,Ivan Iudice,Giuseppe Castaldi,Marco Di Renzo,Vincenzo Galdi*

Main category: eess.SP

TL;DR: 该论文系统研究了圆柱形可重构智能表面，从理想表面阻抗合成到基于简单一比特超原子的实际实现，建立了分析模型并验证了其波束合成能力。


<details>
  <summary>Details</summary>
Motivation: 曲面可重构智能表面是下一代无线通信的有前景方向，能够在无人机和城市基础设施等非平面平台上实现自适应波前控制。圆柱形RIS具有实际应用潜力，但需要系统研究其设计限制和实现方法。

Method: 1. 开发精确分析和几何光学模型探索基本设计限制；2. 提出针对离散可重构架构的半解析公式；3. 使用进化优化和低复杂度策略（如最小功率无失真响应方法）进行高效波束合成；4. 通过全波仿真验证模型。

Result: 一比特RIS能够实现定向散射，具有可管理的旁瓣水平和最小的硬件复杂度。结果证实了圆柱形RIS的可行性，并为其在实际通信场景中的集成奠定了基础。

Conclusion: 圆柱形可重构智能表面具有实际应用的可行性，为将其集成到双用途无线平台中打开了大门，适用于现实世界的通信场景。

Abstract: Curved reconfigurable intelligent surfaces (RISs) represent a promising frontier for next-generation wireless communication, enabling adaptive wavefront control on nonplanar platforms such as unmanned aerial vehicles and urban infrastructure. This work presents a systematic investigation of cylindrical RISs, progressing from idealized surface-impedance synthesis to practical implementations based on simple one-bit meta-atoms. Exact analytical and geometrical-optics-based models are first developed to explore fundamental design limits, followed by a semi-analytical formulation tailored to discrete, reconfigurable architectures. This model enables efficient beam synthesis using both evolutionary optimization and low-complexity strategies, including the minimum power distortionless response method, and is validated through full-wave simulations. Results confirm that one-bit RISs can achieve directive scattering with manageable sidelobe levels and minimal hardware complexity. These findings establish the viability of cylindrical RISs and open the door to their integration into dual-use wireless platforms for real-world communication scenarios.

</details>


### [20] [Energy Efficiency Maximization of MIMO Systems through Reconfigurable Holographic Beamforming](https://arxiv.org/abs/2601.00780)
*Robert Kuku Fotock,Alessio Zappone,Agbotiname Lucky Imoize,Marco Di Renzo*

Main category: eess.SP

TL;DR: 该研究提出了一种在点对点多天线无线链路中部署可重构超表面的全息波束赋形架构，通过联合优化发射协方差矩阵和超表面反射矩阵来最大化系统能效。


<details>
  <summary>Details</summary>
Motivation: 传统全数字波束赋形架构虽然能实现显著的多路复用增益，但能耗较高。研究旨在探索通过部署可重构超表面实现全息波束赋形，在保持性能的同时显著提升系统能效。

Method: 在发射和接收天线阵列附近各部署一个可重构超表面，构建全息波束赋形结构。提出低复杂度算法联合优化发射协方差矩阵和两个超表面的反射矩阵，确保收敛到能效最大化问题的一阶最优点。针对单天线或单流传输的特殊情况，推导了超表面矩阵的闭式解。

Result: 数值性能分析表明，与实现显著多路复用增益的全数字波束赋形架构相比，基于超表面的全息波束赋形能提供显著的能效增益。提出的优化方法有效且收敛性有保证。

Conclusion: 在点对点多天线无线链路中部署可重构超表面实现全息波束赋形是提升系统能效的有效方法，即使在传统架构已实现显著多路复用增益的情况下，仍能带来可观的能效改进。

Abstract: This study considers a point-to-point wireless link, in which both the transmitter and receiver are equipped with multiple antennas. In addition, two reconfigurable metasurfaces are deployed, one in the immediate vicinity of the transmit antenna array, and one in the immediate vicinity of the receive antenna array. The resulting architecture implements a holographic beamforming structure at both the transmitter and receiver. In this scenario, the system energy efficiency is optimized with respect to the transmit covariance matrix, and the reflection matrices of the two metasurfaces. A low-complexity algorithm is developed, which is guaranteed to converge to a first-order optimal point of the energy efficiency maximization problem. Moreover, closed-form expressions are derived for the metasurface matrices in the special case of single-antenna or single-stream transmission. The two metasurfaces are considered to be nearly-passive and subject to global reflection constraints. A numerical performance analysis is conducted to assess the performance of the proposed optimization methods, showing, in particular, that the use of holographic beamforming by metasurfaces can provide significant energy efficiency gains compared to fully digital beamforming architectures, even when the latter achieve substantial multiplexing gains.

</details>
