<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 16]
- [eess.SP](#eess.SP) [Total: 15]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Study of Switched Step-size Based Filtered-x NLMS Algorithm for Active Noise Cancellation](https://arxiv.org/abs/2601.16382)
*Zhiyuan Li,Yi Yu,Hongsen He,Yuyu Zhu,Rodrigo C. de Lamare*

Main category: cs.IT

TL;DR: 提出两种改进FxNLMS算法：SSS-FxNLMS通过动态选择最优步长解决收敛速度与稳态误差的权衡问题，以及增强鲁棒性的变体以应对脉冲噪声环境。


<details>
  <summary>Details</summary>
Motivation: 传统FxNLMS算法存在两个关键限制：固定步长导致收敛速度与稳态误差之间的权衡，以及在脉冲噪声环境下性能显著下降。需要解决这些限制以提升主动噪声控制系统的性能。

Method: 1. 推导FxNLMS算法的均方偏差趋势；2. 通过比较不同步长对应的MSD趋势，为每次迭代选择最优步长，提出SSS-FxNLMS算法；3. 将鲁棒策略集成到SSS-FxNLMS中，形成鲁棒变体以应对脉冲噪声。

Result: 通过计算机仿真在不同噪声场景下验证了所提算法的有效性和优越性。SSS-FxNLMS解决了步长约束问题，鲁棒变体在脉冲噪声环境中表现出更强的性能。

Conclusion: 提出的SSS-FxNLMS算法及其鲁棒变体成功解决了传统FxNLMS算法的两个关键限制，在主动噪声控制系统中具有更好的收敛性能和鲁棒性。

Abstract: While the filtered-x normalized least mean square (FxNLMS) algorithm is widely applied due to its simple structure and easy implementation for active noise control system, it faces two critical limitations: the fixed step-size causes a trade-off between convergence rate and steady-state residual error, and its performance deteriorates significantly in impulsive noise environments. To address the step-size constraint issue, we propose the switched \mbox{step-size} FxNLMS (SSS-FxNLMS) algorithm. Specifically, we derive the \mbox{mean-square} deviation (MSD) trend of the FxNLMS algorithm, and then by comparing the MSD trends corresponding to different \mbox{step-sizes}, the optimal step-size for each iteration is selected. Furthermore, to enhance the algorithm's robustness in impulsive noise scenarios, we integrate a robust strategy into the SSS-FxNLMS algorithm, resulting in a robust variant of it. The effectiveness and superiority of the proposed algorithms has been confirmed through computer simulations in different noise scenarios.

</details>


### [2] [Two classes of LCD codes derived from $(\mathcal{L},\mathcal{P})$-TGRS codes](https://arxiv.org/abs/2601.16438)
*Ziwei Zhao,Xiaoni DU,Xingbin Qiao*

Main category: cs.IT

TL;DR: 本文从扭曲广义Reed-Solomon码构造了两类LCD码，并进一步得到LCD MDS码


<details>
  <summary>Details</summary>
Motivation: 扭曲广义Reed-Solomon码作为经典GRS码的灵活扩展，近年来受到广泛关注。本文旨在从这类码构造线性互补对偶码，特别是LCD MDS码。

Method: 首先推导了$(\mathcal{L},\mathcal{P})$-TGRS码的校验矩阵，给出了其成为AMDS码的充要条件。然后通过适当选择评估点和对扭曲项中$x^{h-1}$系数的限制，从TGRS码构造了两类LCD码。

Result: 成功构造了两类LCD码，并进一步获得了LCD MDS码。通过多个示例验证了构造方法的有效性。

Conclusion: 本文提供了一种从扭曲广义Reed-Solomon码构造LCD码和LCD MDS码的系统方法，扩展了LCD码的构造理论。

Abstract: Twisted generalized Reed-Solomon (TGRS) codes, as a flexible extension of classical generalized Reed-Solomon (GRS) codes, have attracted significant attention in recent years. In this paper, we construct two classes of LCD codes from the $(\mathcal{L},\mathcal{P})$-TGRS code $\mathcal{C}_h$ of length $n$ and dimension $k$, where $\mathcal{L}=\{0,1,\ldots,l\}$ for $l\leq n-k-1$ and $\mathcal{P}=\{h\}$ for $1\leq h\leq k-1$. First, we derive the parity check matrix of $\mathcal{C}_h$ and provide a necessary and sufficient condition for $\mathcal{C}_h$ to be an AMDS code. Then, we construct two classes of LCD codes from $\mathcal{C}_h$ by suitably choosing the evaluation points together with certain restrictions on the coefficient of $x^{h-1}$ in the polynomial associated with the twisting term. From the constructed LCD codes we further obtain two classes of LCD MDS codes. Finally, several examples are presented.

</details>


### [3] [Cramér-Rao Bound Minimization for Flexible Intelligent Metasurface-Enabled ISAC Systems](https://arxiv.org/abs/2601.16455)
*Qian Zhang,Yufei Zhao,Jiancheng An,Zheng Dong,Yong Liang Guan,Ju Liu,Chau Yuen*

Main category: cs.IT

TL;DR: 本文首次研究了柔性智能超表面(FIM)使能的ISAC系统中的CRB最小化问题，通过优化FIM表面形状和波束成形，显著降低了感知CRB同时保持通信质量。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信(ISAC)被认为是未来无线网络的关键使能技术，其中克拉美-罗界(CRB)在量化感知精度方面起着核心作用。然而，在柔性智能超表面(FIM)使能的ISAC系统中，CRB最小化问题尚未得到研究。

Method: 1) 推导了明确依赖于FIM表面形状的平均CRB表达式；2) 采用平均Fisher信息最大化作为替代目标，使用高斯-埃尔米特求积法获得目标函数的显式近似；3) 将问题分解为三个子问题：波束成形优化、发射/接收FIM表面形状优化；4) 波束成形优化使用Schur补和基于惩罚的半定松弛技术；5) 接收FIM表面形状优化采用定点方程方法，发射FIM采用投影梯度算法。

Result: 仿真结果表明，与刚性阵列相比，发射和接收FIM的表面形状优化可以显著降低平均感知CRB，同时保持通信质量，并且在多目标场景中仍然有效。

Conclusion: 本文首次研究了FIM使能ISAC系统中的CRB最小化问题，证明了FIM表面形状优化能够显著提升感知性能，为未来ISAC系统的设计提供了重要指导。

Abstract: Integrated sensing and communication (ISAC) have been widely recognized as a key enabler for future wireless networks, where the Cramér-Rao bound (CRB) plays a central role in quantifying sensing accuracy.In this paper, we present the first study on CRB minimization in flexible intelligent metasurface (FIM)-enabled ISAC systems.Specifically, we first derive an average CRB expression that explicitly depends on FIM surface shape and demonstrate that array reconfigurability can substantially reduce the CRB, thereby significantly enhancing sensing performance.Moreover, to tackle the challenging CRB minimization problem, we adopt average Fisher information maximization as a surrogate objective and use the Gauss-Hermite quadrature method to obtain an explicit approximation of the objective function.The resulting problem is then decoupled into three subproblem, i.e., beamforming optimization and transmit/receive FIM surface shape optimization.For beamforming optimization, we employ the Schur complement and penalty-based semi-definite relaxation (SDR) technique to solve it.Furthermore, we propose a fixed-point equation method and a projected gradient algorithm to optimize the surface shapes of the receive and transmit FIMs, respectively.Simulation results demonstrate that, compared to rigid arrays, surface shaping of both transmit and receive FIMs can significantly reduce the average sensing CRB while maintaining communication quality, and remains effective even in multi-target scenarios.

</details>


### [4] [Log-Likelihood Loss for Semantic Compression](https://arxiv.org/abs/2601.16461)
*Anuj Kumar Yadav,Dan Song,Yanina Shkel,Ayfer Özgür*

Main category: cs.IT

TL;DR: 研究基于指定条件分布P_{X|U}诱导的负对数似然定义的失真度量下的有损信源编码，这种对数似然失真建模了重建是语义表示而非逐点近似的压缩场景。


<details>
  <summary>Details</summary>
Motivation: 传统有损压缩关注逐点近似，但许多实际应用需要重建能够概率生成源的语义表示。对数似然失真提供了一种建模这种语义压缩的框架，其中重建不是精确复制而是能够生成类似数据的表示。

Method: 提出对数似然失真度量，定义为负对数似然 -log P_{X|U}(x|u)，其中P_{X|U}是预先指定的条件分布。在此基础上制定相应的率失真问题，并分析所得率失真函数的基本性质。

Result: 建立了对数似然失真率失真函数的基本性质，包括其与对数损失下有损压缩、任意失真度量的经典率失真问题以及完美感知率失真之间的联系。

Conclusion: 对数似然失真为语义压缩提供了统一的框架，能够连接多种压缩范式，为需要重建语义表示而非精确复制的应用场景提供了理论基础。

Abstract: We study lossy source coding under a distortion measure defined by the negative log-likelihood induced by a prescribed conditional distribution $P_{X|U}$. This \emph{log-likelihood distortion} models compression settings in which the reconstruction is a semantic representation from which the source can be probabilistically generated, rather than a pointwise approximation. We formulate the corresponding rate-distortion problem and characterize fundamental properties of the resulting rate-distortion function, including its connections to lossy compression under log-loss, classical rate-distortion problems with arbitrary distortion measures, and rate-distortion with perfect perception.

</details>


### [5] [Load Balanced ISAC Systems for URLLC Users](https://arxiv.org/abs/2601.16495)
*Shivani Singh,Amudheesan Nakkeeran,Prem Singh,Ekant Sharma,Jyotsna Bapat*

Main category: cs.IT

TL;DR: 提出一种用于集成感知与通信(ISAC)网络的能量高效负载均衡算法，在服务URLLC用户的同时检测目标，相比无负载均衡基线降低约33%功耗


<details>
  <summary>Details</summary>
Motivation: 在CF-mMIMO ISAC网络中，需要同时满足URLLC用户的高可靠低时延通信需求和目标检测的感知需求，同时降低网络总功耗

Method: 提出联合功率分配和AP负载均衡(JPALB)算法，通过混合整数非凸优化问题建模，迭代优化功率分配和AP负载，使用MRT和RZF预编码器

Result: 仿真结果显示，相比无负载均衡基线，JPALB算法能降低约33%的总功耗，同时满足通信和感知的QoS要求

Conclusion: 提出的JPALB算法能有效降低CF-mMIMO ISAC网络功耗，在保证通信和感知性能的同时实现显著的节能效果

Abstract: This paper presents an energy-efficient downlink cell-free massive multiple-input multiple-output (CF-mMIMO) integrated sensing and communication (ISAC) network that serves ultra-reliable low-latency communication (URLLC) users while simultaneously detecting a target. We propose a load-balancing algorithm that minimizes the total network power consumption; including transmit power, fixed static power, and traffic-dependent fronthaul power at the access points (APs) without degrading system performance. To this end, we formulate a mixed-integer non-convex optimization problem and introduce an iterative joint power allocation and AP load balancing (JPALB) algorithm. The algorithm aims to reduce total power usage while meeting both the communication quality-of-service (QoS) requirements of URLLC users and the sensing QoS needed for target detection. Proposed JPALB algorithm for ISAC systems was simulated with maximum-ratio transmission (MRT) and regularized zero-forcing (RZF) precoders. Simulation results show approximately 33% reduction in power consumption, using JPALB algorithm compared to a baseline with no load balancing, without compromising communication and sensing QoS requirements.

</details>


### [6] [Noise-immune and AI-enhanced DNA storage via adaptive partition mapping of digital data](https://arxiv.org/abs/2601.16518)
*Zimu Li,Bingyi Liu,Lei Zhao,Qian Zhang,Yang Liu,Jun Liu,Ke Ke,Huating Kong,Xiaolei Zuo,Chunhai Fan,Fei Wang*

Main category: cs.IT

TL;DR: 提出PJ编码方案用于DNA存储，通过分区映射和跳转旋转策略实现强噪声鲁棒性，可在任意链丢失率下解码，并在极端环境扰动下保持数据完整性。


<details>
  <summary>Details</summary>
Motivation: DNA存储作为应对信息时代和人工智能数据增长的有前景方案，但实际应用中合成、保存和测序过程中的错误限制了其应用，传统纠错码在噪声超过阈值时仍易失效。

Method: 开发了分区映射与跳转旋转(PJ)编码方案：1) 分区映射消除链间信息依赖，使链丢失表现为局部间隙而非灾难性文件失效；2) 跳转旋转策略放宽序列约束，通过可调跳转长度提供可调信息密度；3) 结合AI推理实现可控恢复。

Result: PJ编码可在任意链丢失率下解码和恢复原始文件信息，保真度随损伤增加平滑下降。实验表明：10%链丢失下仍能有效恢复文件，机器学习数据集保持分类性能；极端环境扰动（加速老化和高强度X射线辐照）后仍能成功解码图像文件。

Conclusion: PJ编码消除了对先验错误概率的依赖，建立了适用于实际保存条件的鲁棒、长期DNA存储通用框架，能够承受现实世界保存的严格条件。

Abstract: Encoding digital information into DNA sequences offers an attractive potential solution for storing rapidly growing data under the information age and the rise of artificial intelligence. However, practical implementations of DNA storage are constrained by errors introduced during synthesis, preservation, and sequencing processes, and traditional error-correcting codes remain vulnerable to noise levels that exceed predefined thresholds. Here, we developed a Partitioning-mapping with Jump-rotating (PJ) encoding scheme, which exhibits exceptional noise resilience. PJ removes cross-strand information dependencies so that strand loss manifests as localized gaps rather than catastrophic file failure. It prioritizes file decodability under arbitrary noise conditions and leverages AI-based inference to enable controllable recovery of digital information. For the intra-strand encoding, we develop a jump-rotating strategy that relaxes sequence constraints relative to conventional rotating codes and provides tunable information density via an adjustable jump length. Based on this encoding architecture, the original file information can always be decoded and recovered under any strand loss ratio, with fidelity degrading smoothly as damage increases. We demonstrate that original files can be effectively recovered even with 10% strand loss, and machine learning datasets stored under these conditions retain their classification performance. Experiments further confirmed that PJ successfully decodes image files after extreme environmental disturbance using accelerated aging and high-intensity X-ray irradiation. By eliminating reliance on prior error probabilities, PJ establishes a general framework for robust, archival DNA storage capable of withstanding the rigorous conditions of real-world preservation.

</details>


### [7] [Generalized Forms of the Kraft Inequality for Finite-State Encoders](https://arxiv.org/abs/2601.16594)
*Neri Merhav*

Main category: cs.IT

TL;DR: 本文推导了无损有限状态编码器的扩展Kraft不等式，定义了Kraft矩阵概念，证明无损编码的必要条件是Kraft矩阵谱半径不超过1，并针对不可约情况给出了多种等价形式。


<details>
  <summary>Details</summary>
Motivation: 传统Kraft不等式仅适用于前缀码，本文旨在为更一般的有限状态编码器建立类似的不等式条件，为信息无损编码提供理论保证。

Method: 定义Kraft矩阵概念，利用谱半径理论分析有限状态编码器的信息无损条件，针对不可约情况推导多种等价形式，并扩展到有边信息和有损压缩场景。

Result: 证明有限状态编码器信息无损的必要条件是Kraft矩阵谱半径≤1；对于不可约情况，Kraft和有界且独立于块长度；建立了多种谱半径等价表达式。

Conclusion: 本文建立了有限状态编码器的扩展Kraft不等式理论框架，为信息无损编码提供了谱半径判据，并展示了在边信息和有损压缩场景的扩展应用潜力。

Abstract: We derive a few extended versions of the Kraft inequality for information lossless finite-state encoders. The main basic contribution is in defining a notion of a Kraft matrix and in establishing the fact that a necessary condition for information losslessness of a finite-state encoder is that none of the eigenvalues of this matrix have modulus larger than unity, or equivalently, the generalized Kraft inequality asserts that the spectral radius of the Kraft matrix cannot exceed one. For the important special case where the FS encoder is irreducible, we derive several equivalent forms of this inequality, which are based on well known formulas for spectral radius. It also turns out that in the irreducible case, Kraft sums are bounded by a constant, independent of the block length, and thus cannot grow even in any subexponential rate. Finally, two extensions are outlined - one concerns the case of side information available to both encoder and decoder, and the other is for lossy compression.

</details>


### [8] [An Explicit Upper Bound of Generalized Quadratic Gauss Sums and Its Applications for Asymptotically Optimal Aperiodic Polyphase Sequence Design](https://arxiv.org/abs/2601.16599)
*Huaning Liu,Zilong Liu*

Main category: cs.IT

TL;DR: 本文解决了设计渐近最优非周期多相序列集的长期开放问题，通过改进广义二次高斯和的上界，并基于Chu序列和Alltop序列构建了四种系统性的最优序列集构造方法。


<details>
  <summary>Details</summary>
Motivation: 解决设计渐近最优非周期多相序列集的长期开放问题。Mow在30多年前就尝试过，但对该问题的全面理解仍然缺乏。

Method: 1. 通过递归应用Paris渐近展开并利用Fibonacci zeta函数的快速收敛性，获得了广义二次高斯和的显式上界。2. 基于这一关键发现，通过精心选择的Chu序列和Alltop序列，提出了四种系统性的构造方法，构建具有低非周期相关性和/或模糊特性的最优序列集。

Result: 1. 首次在文献中揭示了完整的Alltop序列集对其低非周期相关旁瓣是渐近最优的。2. 引入了一个新的Alltop序列子集，在整个时间偏移窗口内同时具有最优的非周期相关性和模糊特性。

Conclusion: 本文成功解决了设计渐近最优非周期多相序列集的长期开放问题，通过改进数学工具和提出新的序列构造方法，为序列设计领域做出了重要贡献。

Abstract: This work is motivated by the long-standing open problem of designing asymptotically order-optimal aperiodic polyphase sequence sets with respect to the celebrated Welch bound. Attempts were made by Mow over 30 years ago, but a comprehensive understanding to this problem is lacking. Our first key contribution is an explicit upper bound of generalized quadratic Gauss sums which is obtained by recursively applying Paris' asymptotic expansion and then bounding it by leveraging the fast convergence property of the Fibonacci zeta function. Building upon this major finding, our second key contribution includes four systematic constructions of order-optimal sequence sets with low aperiodic correlation and/or ambiguity properties via carefully selected Chu sequences and Alltop sequences. For the first time in the literature, we reveal that the full Alltop sequence set is asymptotically optimal for its low aperiodic correlation sidelobes. Besides, we introduce a novel subset of Alltop sequences possessing both order-optimal aperiodic correlation and ambiguity properties for the entire time-shift window.

</details>


### [9] [Term Coding: An Entropic Framework for Extremal Combinatorics and the Guessing--Number Sandwich Theorem](https://arxiv.org/abs/2601.16614)
*Søren Riis*

Main category: cs.IT

TL;DR: 本文提出"项编码"概念，将组合设计的存在性问题转化为极值量化问题，通过猜测数三明治定理连接项编码与图猜测数，建立了规范依赖结构，使最大编码大小满足对数增长关系。


<details>
  <summary>Details</summary>
Motivation: 将传统的拟群、设计等组合结构的存在性问题转化为定量极值问题，研究在给定项恒等式系统下，n元素字母表上最大解集的大小。

Method: 提出猜测数三明治定理，通过显式归一化和多样化约简，为每个实例构建规范有向依赖结构，使用熵和多拟阵方法计算猜测数α。

Result: 证明了最大编码大小满足log_n S_n(Γ)=α+o(1)，即S_n(Γ)=n^{α+o(1)}，其中α可通过熵方法计算，并用极值组合学和网络编码实例验证了框架。

Conclusion: 建立了项编码与图猜测数之间的桥梁，提供了统一的框架来处理组合设计和信息流约束的极值问题，展示了熵方法在量化组合结构存在性方面的应用。

Abstract: Term Coding asks: given a finite system of term identities $Γ$ in $v$ variables, how large can its solution set be on an $n$--element alphabet, when we are free to choose the interpretations of the function symbols? This turns familiar existence problems for quasigroups, designs, and related objects into quantitative extremal questions.
  We prove a guessing-number sandwich theorem that connects term coding to graph guessing numbers (graph entropy). After explicit normalisation and diversification reductions, every instance yields a canonical directed dependency structure with guessing number $α$ such that the maximum code size satisfies $\log_n \Sn(Γ)=α+o(1)$ (equivalently, $\Sn(Γ)=n^{α+o(1)}$), and $α$ can be bounded or computed using entropy and polymatroid methods.
  We illustrate the framework with examples from extremal combinatorics (Steiner-type identities, self-orthogonal Latin squares) and from information-flow / network-coding style constraints (including a five-cycle instance with fractional exponent and small storage/relay maps).

</details>


### [10] [Taming the Heavy Tail: Age-Optimal Preemption](https://arxiv.org/abs/2601.16624)
*Aimin Li,Yiğit İnce,Elif Uysal*

Main category: cs.IT

TL;DR: 本文研究连续时间联合采样与抢占问题，在一般服务时间分布下考虑采样和抢占惩罚，通过脉冲控制PDMP建模，提出高效策略迭代算法，在重尾分布下相比基准方法实现高达30倍的平均成本降低。


<details>
  <summary>Details</summary>
Motivation: 研究在一般服务时间分布下，结合采样和抢占惩罚的连续时间联合控制问题，旨在优化信息新鲜度（AoI）相关的系统性能，传统方法需要平滑性假设，本文寻求更通用的解决方案。

Method: 将系统建模为脉冲控制的分段确定性马尔可夫过程（PDMP），通过动态规划原理推导耦合积分平均成本最优性方程，避免传统HJB-QVI所需的平滑性假设。利用繁忙阶段的关键不变性将动态降维到一维繁忙起始边界，将抢占控制转化为最优停止问题。开发具有重尾加速的高效策略迭代算法，采用混合（均匀/对数间隔）动作网格和远场线性闭合技术。

Result: 在Pareto和对数正态服务时间分布下的仿真显示，相比AoI最优的非抢占采样和零等待基准方法，本文方法在重尾机制下实现了高达30倍的平均成本降低。仿真还揭示了一个反直觉的发现：在抢占机制下，延迟方差虽然通常是负担，但可以成为信息新鲜度的战略优势。

Conclusion: 本文提出了一种处理一般服务时间分布下联合采样与抢占问题的新框架，通过PDMP建模和高效算法实现了显著的性能改进，并发现了延迟方差在抢占机制下的战略价值，为信息新鲜度优化提供了新见解。

Abstract: This paper studies a continuous-time joint sampling-and-preemption problem, incorporating sampling and preemption penalties under general service-time distributions. We formulate the system as an impulse-controlled piecewise-deterministic Markov process (PDMP) and derive coupled integral average-cost optimality equations via the dynamic programming principle, thereby avoiding the smoothness assumptions typically required for an average-cost Hamilton-Jacobi-Bellman quasi-variational inequality (HJB-QVI) characterization. A key invariance in the busy phase collapses the dynamics onto a one-dimensional busy-start boundary, reducing preemption control to an optimal stopping problem. Building on this structure, we develop an efficient policy iteration algorithm with heavy-tail acceleration, employing a hybrid (uniform/log-spaced) action grid and a far-field linear closure. Simulations under Pareto and log-normal service times demonstrate substantial improvements over AoI-optimal non-preemptive sampling and zero-wait baselines, achieving up to a 30x reduction in average cost in heavy-tailed regimes. Finally, simulations uncover a counterintuitive insight: under preemption, delay variance, despite typically being a liability, can become a strategic advantage for information freshness.

</details>


### [11] [The Oval Strikes Back](https://arxiv.org/abs/2601.16628)
*Andrea Di Giusto,Alberto Ravagnani,Emina Soljanin*

Main category: cs.IT

TL;DR: 本文探讨了射影平面中卵形线在分布式存储中的应用，特别是服务率区域问题，利用卵形线与直线的关联关系构造了一类具有大量小型不相交恢复集的非系统MDS矩阵，在某些参数下其服务性能优于系统生成矩阵。


<details>
  <summary>Details</summary>
Motivation: 研究射影平面中卵形线这一经典有限几何对象在现代编码理论中的新应用，特别是解决分布式存储中的服务率区域问题，探索如何利用几何结构提升存储系统的性能。

Method: 利用射影平面中卵形线与直线的关联关系，构造一类非系统MDS矩阵，这些矩阵具有大量小型且不相交的恢复集，并分析了这些矩阵的PIR（私有信息检索）特性，提出了一步多数逻辑译码算法。

Result: 对于某些参数选择，所构造的非系统MDS矩阵的服务率区域包含了相同码的系统生成矩阵的区域，表现出更好的服务性能，同时所提出的译码算法具有较强的纠错能力。

Conclusion: 射影平面中的卵形线这一经典有限几何对象在现代编码理论中重新展现出实用价值，为分布式存储系统的性能优化提供了新的几何构造方法。

Abstract: We investigate the applications of ovals in projective planes to distributed storage, with a focus on the Service Rate Region problem. Leveraging the incidence relations between lines and ovals, we describe a class of non-systematic MDS matrices with a large number of small and disjoint recovery sets. For certain parameter choices, the service-rate region of these matrices contains the region of a systematic generator matrix for the same code, yielding better service performance. We further apply our construction to analyze the PIR properties of the considered MDS matrices and present a one-step majority-logic decoding algorithm with strong error-correcting capability. These results highlight how ovals, a classical object in finite geometry, re-emerge as a useful tool in modern coding theory.

</details>


### [12] [Stable Source Coding](https://arxiv.org/abs/2601.16680)
*Zhenduo Wen,Amin Gohari*

Main category: cs.IT

TL;DR: 研究稳定无损信源编码的压缩率，推导稳定性参数下的可达速率信息论极限


<details>
  <summary>Details</summary>
Motivation: 随机分箱等常见编码技术不稳定，微小信源序列变化可能导致输出码字完全无关，需要研究稳定编码的性能极限

Method: 使用组合论证方法，推导稳定无损信源编码的可达速率与稳定性参数的关系

Result: 建立了稳定编码的速率-稳定性权衡的信息论极限，量化了稳定性要求对压缩率的影响

Conclusion: 稳定性是信源编码的重要属性，本文为稳定编码的性能分析提供了理论基础

Abstract: A source encoder is stable if a small change in the source sequence (e.g., changing a few symbols) results in a small (or bounded) change in the output codeword. By this definition, the common technique of random binning is unstable; because the mapping is random, two nearly identical source sequences can be assigned to completely unrelated bin indices. We study compression rates of stable lossless source codes. Using combinatorial arguments, we derive information-theoretic limits on the achievable rate as a function of the stability parameters.

</details>


### [13] [Adaptive Beam Alignment using Noisy Twenty Questions Estimation with Trained Questioner](https://arxiv.org/abs/2601.16799)
*Chunsong Sun,Lin Zhou*

Main category: cs.IT

TL;DR: 提出基于噪声二十问题估计框架的自适应波束对准算法，通过训练提问器解决传统方法的可行性问题和黑盒神经网络的可解释性问题。


<details>
  <summary>Details</summary>
Motivation: 6G通信系统使用毫米波和MIMO技术，需要波束对准来克服信号衰减。传统基于扇区搜索的算法存在显著延迟问题，现有自适应算法要么依赖理想假设缺乏可行性，要么使用黑盒神经网络缺乏可解释性。

Method: 提出基于噪声二十问题估计框架的自适应波束对准算法，训练提问器来消除对理想假设的依赖。第一种方法通过导向矢量的加权求和将二十问题估计的查询映射到波束赋形向量；第二种方法使用多层全连接神经网络训练提问器以提高性能。

Result: 数值仿真表明提出的自适应波束对准算法有效，并且性能优于所有基准算法。

Conclusion: 提出的算法既避免了理想假设的可行性问题，又保持了可解释性，解决了现有方法的局限性，为6G通信系统的波束对准提供了更实用的解决方案。

Abstract: The 6G communication systems use mmWave and MIMO technologies to achieve wide bandwidth and high throughout, leading to indispensable need for beam alignment to overcome severe signal attenuation. Traditional sector-search-based beam alignment algorithms rely on sequential sampling to identify the best sector, resulting in a significant latency burden on 6G communication systems. Recently proposed adaptive beam alignment algorithms based on the active learning framework address the problem, aiming to identify the optimal sector with the fewest possible samples under an identical sector partition. Nevertheless, these algorithms either lack feasibility (Chiu, Ronquillo and Javidi, JSAC 2019) due to ideal assumptions or lack interpretability (Sohrabi, Chen and Yu, JSAC 2021) due to the use of end-to-end black-box neural networks. To avoid ideal assumptions and maintain interpretability, we address all above problems by proposing an adaptive beam alignment algorithm using the framework of noisy twenty questions estimation with a trained questioner. Specifically, we use two methods for training the questioner to eliminate reliance on ideal assumptions. The first method maps queries of twenty questions estimation to beamforming vectors via weighted summation of steering vectors, as an initial attempt to address the feasibility problem encountered in prior pioneering study by Chiu, Ronquillo and Javidi (JSAC 2019). The second method uses multi-layer fully connected neural networks to achieve improved performance while only employing them to train the questioner, which can effectively mitigate the interpretability issues in prior study by Sohrabi, Chen and Yu (JSAC 2021). Furthermore, we provide numerical simulations to illustrate the effectiveness of our proposed adaptive beam alignment algorithms and demonstrate that our algorithms outperform all benchmark algorithms.

</details>


### [14] [Privacy-Resolution Tradeoff for Adaptive Noisy Twenty Questions Estimation](https://arxiv.org/abs/2601.16825)
*Chunsong Sun,Lin Zhou*

Main category: cs.IT

TL;DR: 本文研究了带有隐私保护的噪声二十问估计问题，提出了两阶段隐私查询方案，分析了非渐进和二阶渐进性能，并讨论了隐私对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 传统自适应查询方法虽然性能更好，但存在隐私泄露风险。先前研究（COLT 2018, AISTATS 2021）仅考虑了无噪声情况，本文旨在将隐私-分辨率权衡分析扩展到更实际的噪声场景。

Method: 提出了一种两阶段隐私查询方案：第一阶段使用非自适应查询获取初步信息，第二阶段基于第一阶段结果设计自适应查询，同时通过限制查询间的信息泄露来保护隐私。

Result: 分析了该方案的非渐进和二阶渐进性能，量化了隐私约束对估计精度的影响。在无噪声特例中，该方案优于先前研究（COLT 2018, AISTATS 2021）的性能。

Conclusion: 本文成功将隐私-分辨率权衡分析扩展到噪声二十问估计问题，提出的两阶段隐私查询方案在保护隐私的同时实现了良好的估计性能，为实际应用提供了理论指导。

Abstract: We revisit noisy twenty questions estimation and study the privacy-resolution tradeoff for adaptive query procedures. Specifically, in twenty questions estimation, there are two players: an oracle and a questioner. The questioner aims to estimate target variables by posing queries to the oracle that knows the variables and using noisy responses to form reliable estimates. Typically, there are adaptive and non-adaptive query procedures. In adaptive querying, one designs the current query using previous queries and their noisy responses while in non-adaptive querying, all queries are posed simultaneously. Generally speaking, adaptive query procedures yield better performance. However, adaptive querying leads to privacy concerns, which were first studied by Tsitsiklis, Xu and Xu (COLT 2018) and by Xu, Xu and Yang (AISTATS 2021) for the noiseless case, where the oracle always provides correct answers to queries. In this paper, we generalize the above results to the more practical noisy case, by proposing a two-stage private query procedure, analyzing its non-asymptotic and second-order asymptotic achievable performance and discussing the impact of privacy concerns. Furthermore, when specialized to the noiseless case, our private query procedure achieves better performance than above-mentioned query procedures (COLT 2018, AISTATS 2021).

</details>


### [15] [Information Contraction under $(\varepsilon,δ)$-Differentially Private Mechanisms](https://arxiv.org/abs/2601.16845)
*Theshani Nuradha,Ian George,Christoph Hirche*

Main category: cs.IT

TL;DR: 该论文针对(ε,δ)-局部差分隐私机制，推导了曲棍球散度和f-散度的线性和非线性强数据处理不等式，改进了先前仅适用于(ε,0)-LDP机制的界限。


<details>
  <summary>Details</summary>
Motivation: 先前关于信息度量收缩的紧致刻画主要适用于(ε,0)-LDP机制，对于更一般的(ε,δ)-LDP机制（δ≠0）缺乏有效的分析工具。需要开发适用于所有(ε,δ)-LDP机制的数据处理不等式。

Method: 推导了曲棍球散度和f-散度的线性和非线性强数据处理不等式（SDPI），这些不等式对所有(ε,δ)-LDP机制都有效，包括δ≠0的情况。

Result: 提出的不等式要么推广了先前已知的界限，要么改进了这些可区分性度量的收缩界限，为(ε,δ)-LDP机制提供了更全面的分析工具。

Conclusion: 该工作填补了(ε,δ)-LDP机制下信息度量收缩分析的空白，为隐私机制的性能评估提供了更强大的理论工具，能够处理更一般的隐私保护场景。

Abstract: The distinguishability quantified by information measures after being processed by a private mechanism has been a useful tool in studying various statistical and operational tasks while ensuring privacy. To this end, standard data-processing inequalities and strong data-processing inequalities (SDPI) are employed. Most of the previously known and even tight characterizations of contraction of information measures, including total variation distance, hockey-stick divergences, and $f$-divergences, are applicable for $(\varepsilon,0)$-local differential private (LDP) mechanisms. In this work, we derive both linear and non-linear strong data-processing inequalities for hockey-stick divergence and $f$-divergences that are valid for all $(\varepsilon,δ)$-LDP mechanisms even when $δ\neq 0$. Our results either generalize or improve the previously known bounds on the contraction of these distinguishability measures.

</details>


### [16] [Perfect Privacy and Strong Stationary Times for Markovian Sources](https://arxiv.org/abs/2601.16857)
*Fangwei Ye,Zonghong Liu,Parimal Parag,Salim El Rouayheb*

Main category: cs.IT

TL;DR: 研究在完美信息论隐私约束下共享相关数据的问题，提出基于擦除的机制，证明在马尔可夫数据下通过窗口式擦除和顺序擦除机制可实现最优失真，且平均擦除数据量独立于数据长度。


<details>
  <summary>Details</summary>
Motivation: 研究如何在保证完美信息论隐私的前提下共享相关数据，特别关注保护初始状态同时最大化共享数据量的平衡问题。

Method: 采用擦除机制（数据要么保留原样要么被擦除），提出两种方法：1）基于窗口的擦除方案，擦除数据直到达到强平稳时间；2）最优顺序擦除机制，并证明其等价于窗口解释。

Result: 建立了完美隐私与窗口擦除方案之间的联系，证明了两种机制都能在保持隐私的同时达到最优失真，且平均擦除的数据点数量是常数，与数据长度N无关。

Conclusion: 在马尔可夫数据生成模型下，通过精心设计的擦除机制可以在保证完美隐私的同时高效共享数据，且擦除开销独立于数据规模，具有实际应用价值。

Abstract: We consider the problem of sharing correlated data under a perfect information-theoretic privacy constraint. We focus on redaction (erasure) mechanisms, in which data are either withheld or released unchanged, and measure utility by the average cardinality of the released set, equivalently, the expected Hamming distortion. Assuming the data are generated by a finite time-homogeneous Markov chain, we study the protection of the initial state while maximizing the amount of shared data. We establish a connection between perfect privacy and window-based redaction schemes, showing that erasing data up to a strong stationary time preserves privacy under suitable conditions. We further study an optimal sequential redaction mechanism and prove that it admits an equivalent window interpretation. Interestingly, we show that both mechanisms achieve the optimal distortion while redacting only a constant average number of data points, independent of the data length~$N$.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [17] [Gesture Recognition from body-Worn RFID under Missing Data](https://arxiv.org/abs/2601.16301)
*Sahar Golipoor,Richard T. Brophy,Ying Liu,Reza Ghazalian,Stephan Sigg*

Main category: eess.SP

TL;DR: 该论文提出了一种基于被动反射标签的手势识别系统，通过数据插补和图卷积神经网络处理缺失数据，在21种手势识别上达到98.13%的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决被动体戴反射标签系统中常见的数据缺失问题，提高手势识别的准确性和鲁棒性。

Method: 1) 使用线性和指数插值/外推法恢复缺失数据；2) 采用插补和基于邻近度的推理；3) 将标签构建为时序图节点，基于RSS和相位相关性建立边；4) 训练基于图的自注意力卷积神经网络。

Result: 系统在21种手势识别上达到98.13%的准确率，留一人出交叉验证准确率为89.28%。手臂标签对识别贡献最大，移除手臂标签会使准确率下降超过10%，而移除手腕标签仅下降约2%。

Conclusion: 被动反射标签结合图神经网络能有效解决数据缺失问题并实现高精度手势识别，手臂标签比手腕标签更具表达力。

Abstract: We explore hand-gesture recognition through the use of passive body-worn reflective tags. A data processing pipeline is proposed to address the issue of missing data. Specifically, missing information is recovered through linear and exponential interpolation and extrapolation. Furthermore, imputation and proximity-based inference are employed. We represent tags as nodes in a temporal graph, with edges formed based on correlations between received signal strength (RSS) and phase values across successive timestamps, and we train a graph-based convolutional neural network that exploits graph-based self-attention. The system outperforms state-of-the-art methods with an accuracy of 98.13% for the recognition of 21 gestures. We achieve 89.28% accuracy under leave-one-person-out cross-validation. We further investigate the contribution of various body locations on the recognition accuracy. Removing tags from the arms reduces accuracy by more than 10%, while removing the wrist tag only reduces accuracy by around 2%. Therefore, tag placements on the arms are more expressive for gesture recognition than on the wrist.

</details>


### [18] [Angle of Arrival Estimation for Gesture Recognition from reflective body-worn tags](https://arxiv.org/abs/2601.16303)
*Sahar Golipoor,Reza Ghazalian,Ines Lobato Mesquita,Stephan Sigg*

Main category: eess.SP

TL;DR: 利用被动反射标签进行手势识别，通过AoA跟踪显著提升识别性能


<details>
  <summary>Details</summary>
Motivation: 传统基于RSS和相位信号的手势识别在面对大量手势时难以区分相似模式，需要更有效的特征

Method: 采用AoA作为区分特征，使用MUSIC算法验证AoA估计，提出基于卡尔曼平滑的AoA跟踪方法

Result: AoA跟踪能有效区分RSS和相位无法区分的手势，结合AoA特征使手势识别系统性能提升高达15%

Conclusion: AoA跟踪是提升被动反射标签手势识别系统性能的有效方法，能显著改善识别准确率

Abstract: We investigate hand gesture recognition by leveraging passive reflective tags worn on the body. Considering a large set of gestures, distinct patterns are difficult to be captured by learning algorithms using backscattered received signal strength (RSS) and phase signals. This is because these features often exhibit similarities across signals from different gestures. To address this limitation, we explore the estimation of Angle of Arrival (AoA) as a distinguishing feature, since AoA characteristically varies during body motion. To ensure reliable estimation in our system, which employs Smart Antenna Switching (SAS), we first validate AoA estimation using the Multiple SIgnal Classification (MUSIC) algorithm while the tags are fixed at specific angles. Building on this, we propose an AoA tracking method based on Kalman smoothing. Our analysis demonstrates that, while RSS and phase alone are insufficient for distinguishing certain gesture data, AoA tracking can effectively differentiate them. To evaluate the effectiveness of AoA tracking, we implement gesture recognition system benchmarks and show that incorporating AoA features significantly boosts their performance. Improvements of up to 15% confirm the value of AoA-based enhancement.

</details>


### [19] [TransfoREM: Transformer aided 3D Radio Environment Mapping](https://arxiv.org/abs/2601.16421)
*Gautham Reddy,Ismail Guvenc,Mihail L. Sichitiu,Arupjyoti Bhuyan,Bryton Petersen,Jason Abrahamson*

Main category: eess.SP

TL;DR: TransfoREM：一种基于Transformer的3D无线电环境地图生成方法，用于预测无人机在更高空域的蜂窝网络覆盖，相比传统方法具有更好的插值能力。


<details>
  <summary>Details</summary>
Motivation: 为无人机提供可靠的蜂窝网络连接面临挑战，因为现有地面网络主要针对地面覆盖设计，无人机只能通过天线旁瓣获得有限覆盖，且飞行动态会进一步恶化连接质量。

Method: 提出TransfoREM方法，结合确定性信道模型和真实世界数据生成3D无线电环境地图。核心是使用Transformer模型，将无线电传播映射转化为序列预测任务来构建REM。

Result: TransfoREM在真实世界数据上展现出比传统Kriging和其他机器学习技术更好的插值能力。该方法设计用于基站级别的蜂窝网络集成。

Conclusion: TransfoREM能够构建可用于增强资源分配、干扰管理和空间频谱利用的无线电环境地图，为无人机蜂窝连接提供解决方案。

Abstract: Providing reliable cellular connectivity to Unmanned Aerial Vehicles (UAV) is a key challenge, as existing terrestrial networks are deployed mainly for ground-level coverage. The cellular network coverage may be available for a limited range from the antenna side lobes, with poor connectivity further exacerbated by UAV flight dynamics. In this work, we propose TransfoREM, a 3D Radio Environment Map (REM) generation method that combines deterministic channel models and real-world data to map terrestrial network coverage at higher altitudes. At the core of our solution is a transformer model that translates radio propagation mapping into a sequence prediction task to construct REMs. Our results demonstrate that TransfoREM offers improved interpolation capability on real-world data compared against conventional Kriging and other machine learning (ML) techniques. Furthermore, TransfoREM is designed for holistic integration into cellular networks at the base station (BS) level, where it can build REMs, which can then be leveraged for enhanced resource allocation, interference management, and spatial spectrum utilization.

</details>


### [20] [Auditory Attention Decoding without Spatial Information: A Diotic EEG Study](https://arxiv.org/abs/2601.16442)
*Masahiro Yoshino,Haruki Yokota,Junya Hara,Yuichi Tanaka,Hiroshi Higashi*

Main category: eess.SP

TL;DR: 本文提出了一种用于双耳同声环境的听觉注意力解码框架，通过将脑电图和语音信号映射到共享潜在空间，解决了现有方法过度依赖空间线索的问题，在双耳同声数据集上实现了72.70%的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有听觉注意力解码研究主要基于双耳分声环境，依赖空间方向线索来识别注意力，这限制了在真实世界场景（如鸡尾酒会）中的应用，因为真实场景中说话者会重叠或动态移动。需要开发不依赖空间线索的AAD方法。

Method: 提出双耳同声环境的AAD框架，消除空间线索。使用独立编码器将脑电图和语音信号映射到共享潜在空间：语音特征使用wav2vec 2.0提取，并通过2层1D CNN编码；脑电图使用BrainNetwork架构编码。通过计算脑电图和语音表示之间的余弦相似度来识别被注意的语音。

Result: 在双耳同声脑电图数据集上评估，实现了72.70%的准确率，比最先进的基于方向的AAD方法提高了22.58%。

Conclusion: 提出的双耳同声AAD框架有效消除了对空间线索的依赖，在真实世界场景中具有更好的适用性，为智能助听器和客观听力测试系统的发展提供了重要技术支撑。

Abstract: Auditory attention decoding (AAD) identifies the attended speech stream in multi-speaker environments by decoding brain signals such as electroencephalography (EEG). This technology is essential for realizing smart hearing aids that address the cocktail party problem and for facilitating objective audiometry systems. Existing AAD research mainly utilizes dichotic environments where different speech signals are presented to the left and right ears, enabling models to classify directional attention rather than speech content. However, this spatial reliance limits applicability to real-world scenarios, such as the "cocktail party" situation, where speakers overlap or move dynamically. To address this challenge, we propose an AAD framework for diotic environments where identical speech mixtures are presented to both ears, eliminating spatial cues. Our approach maps EEG and speech signals into a shared latent space using independent encoders. We extract speech features using wav2vec 2.0 and encode them with a 2-layer 1D convolutional neural network (CNN), while employing the BrainNetwork architecture for EEG encoding. The model identifies the attended speech by calculating the cosine similarity between EEG and speech representations. We evaluate our method on a diotic EEG dataset and achieve 72.70% accuracy, which is 22.58% higher than the state-of-the-art direction-based AAD method.

</details>


### [21] [Cell-Free MIMO with Rotatable Antennas: When Macro-Diversity Meets Antenna Directivity](https://arxiv.org/abs/2601.16543)
*Xingxiang Peng,Qingqing Wu,Ziyuan Zheng,Yanze Zhu,Wen Chen,Penghui Huang,Ying Gao,Honghao Wang*

Main category: eess.SP

TL;DR: 该论文研究了在无蜂窝网络中使用可旋转天线增强最差用户性能，通过联合优化波束成形和天线方向，提出两种算法实现更高的最差用户速率。


<details>
  <summary>Details</summary>
Motivation: 无蜂窝网络虽然利用分布式接入点实现宏分集，但用户几何位置和遮挡导致的信道质量差异限制了性能。可旋转天线通过调整天线主瓣方向增强不利链路，使网络能更好地利用宏分集，提高性能均匀性。

Method: 1. 提出基于交替优化的算法：迭代更新波束成形（二阶锥规划）和优化天线方向（逐次凸逼近）。2. 提出高效的两阶段方案：第一阶段使用流形感知Frank-Wolfe更新最大化比例公平对数效用函数设计天线方向；第二阶段使用基于SOCP的设计计算波束成形。

Result: 仿真结果表明，所提出的方向感知设计相比传统仅波束成形基准实现了显著更高的最差用户速率。此外，更大的天线方向性在适当方向下能增强公平性，否则可能降低最差用户性能。

Conclusion: 可旋转天线是无蜂窝网络中增强最差用户性能的有效硬件自由度。通过联合优化波束成形和天线方向，能够显著提高网络公平性和最差用户速率。天线方向性的影响取决于方向优化质量。

Abstract: Cell-free networks leverage distributed access points (APs) to achieve macro-diversity, yet their performance is often constrained by large disparities in channel quality arising from user geometry and blockages. To address this, rotatable antennas (RAs) add a lightweight hardware degree of freedom by steering the antenna boresight toward dominant propagation directions to strengthen unfavorable links, thereby enabling the network to better exploit macro-diversity for higher and more uniform performance. This paper investigates an RA-enabled cell-free downlink network and formulates a max-min rate problem that jointly optimizes transmit beamforming and antenna orientations. To tackle this challenging problem, we develop an alternating-optimization-based algorithm that iteratively updates the beamformers via a second-order cone program (SOCP) and optimizes the antenna orientations using successive convex approximation. To reduce complexity, we further propose an efficient two-stage scheme that first designs orientations by maximizing a proportional-fair log-utility using manifold-aware Frank-Wolfe updates, and then computes the beamformers using an SOCP-based design. Simulation results demonstrate that the proposed orientation-aware designs achieve a substantially higher worst-user rate than conventional beamforming-only benchmarks. Furthermore, larger antenna directivity enhances fairness with proper orientation but can degrade the worst-user performance otherwise.

</details>


### [22] [Spiking Neural Networks for Communication Systems: Encoding Schemes, Learning Algorithms, and Equalization~Techniques](https://arxiv.org/abs/2601.16550)
*Eike-Manuel Edelmann*

Main category: eess.SP

TL;DR: 该论文研究了基于脉冲神经网络(SNN)的接收机设计，用于非线性时不变频率选择性信道，提出了量化编码和基于强化学习的更新算法，显著降低了功耗和复杂度，性能优于传统人工神经网络接收机。


<details>
  <summary>Details</summary>
Motivation: 现代通信系统复杂度不断增加导致功耗上升，而脉冲神经网络(SNN)模拟人脑的事件驱动和高效能机制，具有低功耗、实时信号处理的潜力，但面临学习规则和神经编码等挑战。

Method: 1) 采用基于时间的反向传播和替代梯度作为更新规则；2) 提出新颖的量化编码(QE)作为神经编码方法；3) 比较两种基于强度调制直接检测链路的接收机架构；4) 引入基于策略梯度的更新算法(PGU)，无需反向传播优化编码参数。

Result: 1) 使用决策反馈和量化编码的接收机在性能和脉冲计数方面表现优异；2) SNN接收机显著优于ANN接收机；3) PGU算法大幅减少运行时间、复杂度和每次推理的脉冲数，同时保持性能。

Conclusion: 该论文成功开发了SNN接收机的设计和优化框架，解决了SNN优化的关键挑战，为未来设计和部署高能效SNN接收机奠定了基础。

Abstract: Machine learning with artificial neural networks (ANNs), provides solutions for the growing complexity of modern communication systems. This complexity, however, increases power consumption, making the systems energy-intensive. Spiking neural networks (SNNs) represent a novel generation of neural networks inspired by the highly efficient human brain. By emulating its event-driven and energy-efficient mechanisms, SNNs enable low-power, real-time signal processing. They differ from ANNs in two key ways: they exhibit inherent temporal dynamics and process and transmit information as short binary signals called spikes. Despite their promise, major challenges remain, e.g., identifying optimal learning rules and effective neural encoding. This thesis investigates the design of SNN-based receivers for nonlinear time-invariant frequency-selective channels. Backpropagation through time with surrogate gradients is identified as a promising update rule and the novel quantization encoding (QE) as promising neural encoding. Given the model of the intensity modulation with direct detection link, we compare two different receiver architectures based on equalization performance and spike count. Using decision feedback and QE achieves both strong performance and low spike counts. Notably, SNN-based receivers significantly outperform ANN-based counterparts. We furthermore introduce policy gradient-based update (PGU), an reinforcement learning-based update algorithm that requires no backpropagation. Using PGU, encoding parameters are optimized, drastically reducing runtime, complexity, and spikes per inference while maintaining performance. This thesis contributes a successful design and optimization framework for SNN-based receivers. By addressing key challenges in SNN optimization, it facilitates future advances in the design and deployment of energy-efficient SNN receivers.

</details>


### [23] [Real-Time Evaluation of an Ultra-Tight GNSS/INS Integration Based on Adaptive PLL Bandwidth](https://arxiv.org/abs/2601.16577)
*Gaël Pages,Priot Benoît,Guillaume Beaugendre*

Main category: eess.SP

TL;DR: 提出一种基于矢量跟踪环架构的GNSS/INS超紧耦合系统，通过INS信息自适应调整PLL带宽，可在FPGA上实现且不增加额外资源占用


<details>
  <summary>Details</summary>
Motivation: 传统矢量跟踪方案需要并行运行标量环或存储预下载星历数据，这会增加FPGA面积和存储资源消耗。需要一种更高效、资源占用更少的GNSS/INS超紧耦合实现方案。

Method: 采用矢量跟踪环架构的GNSS接收机，利用惯性导航系统信息自适应调整相位锁定环带宽。系统在环路内解码导航消息，无需并行标量环或预存星历数据。架构基于FPGA实现，包含1个捕获模块和16个跟踪通道（8个GPS L1/C和8个Galileo E1）。

Result: 提出的架构易于在FPGA等片上系统组件上实现，对现有GNSS接收机平台只需少量修改。相比经典矢量方案，不增加FPGA面积占用，也不使用额外存储资源，实现了资源高效的GNSS/INS超紧耦合。

Conclusion: 该GNSS/INS超紧耦合架构通过自适应PLL带宽调整和环路内导航消息解码，在保持高性能的同时显著降低了硬件资源需求，为嵌入式系统提供了实用的解决方案。

Abstract: In this contribution, we propose a GNSS/INS ultra-tight coupling in which the GNSS receiver architecture is based on a vector tracking loop type architecture. In the proposed approach, the phase lock loop bandwidth is adapted according to the inertial navigation system information. The latter has the advantage to be easily implementable on a System-on-Chip component such as an FPGA (Field-Programmable Gate Arrays), and can be implemented with minor modifications on an existing GNSS receiver platform. Moreover, compared to classical vector-based solutions, the proposed architecture decodes the navigation message in the loop, without the need to run scalar loops in parallel or having to store pre-downloaded ephemeris data. This architecture therefore does not increase the area occupied on the FPGA and does not use additional resources for storage. The proposed GNSS receiver architecture uses GPS L1/C and Galileo E1 signals and is composed of one acquisition module and 16 tracking channels (8 GPS and 8 Galileo) which are implemented within a FPGA (Zynq-Ultrascale).

</details>


### [24] [Learning Successive Interference Cancellation for Low-Complexity Soft-Output MIMO Detection](https://arxiv.org/abs/2601.16586)
*Benedikt Fesl,Fatih Capar*

Main category: eess.SP

TL;DR: 提出recurSIC：一种轻量级学习型MIMO检测框架，基于连续干扰消除结构，通过单次前向传播和少量参数实现可靠软硬检测，适合边缘设备。


<details>
  <summary>Details</summary>
Motivation: 5G RedCap和IoT设备需要低复杂度MIMO检测方案，同时要支持高阶调制并提供可靠软信息用于信道解码。传统机器学习方法在边缘设备上面临计算复杂度和内存限制的挑战。

Method: 基于连续干扰消除(SIC)结构设计轻量级学习框架，包含学习处理阶段，通过多路径假设跟踪生成软信息，具有可调复杂度参数，仅需单次前向传播和极少参数。

Result: 在现实无线场景中的数值结果显示，recurSIC在极低复杂度下实现了强大的硬检测和软检测性能，适合边缘受限的MIMO接收器。

Conclusion: recurSIC为边缘设备提供了一种有效的低复杂度MIMO检测解决方案，平衡了机器学习部署需求与计算资源限制之间的矛盾。

Abstract: Low-complexity multiple-input multiple-output (MIMO) detection remains a key challenge in modern wireless systems, particularly for 5G reduced capability (RedCap) and internet-of-things (IoT) devices. In this context, the growing interest in deploying machine learning on edge devices must be balanced against stringent constraints on computational complexity and memory while supporting high-order modulation. Beyond accurate hard detection, reliable soft information is equally critical, as modern receivers rely on soft-input channel decoding, imposing additional requirements on the detector design. In this work, we propose recurSIC, a lightweight learning-based MIMO detection framework that is structurally inspired by successive interference cancellation (SIC) and incorporates learned processing stages. It generates reliable soft information via multi-path hypothesis tracking with a tunable complexity parameter while requiring only a single forward pass and a minimal parameter count. Numerical results in realistic wireless scenarios show that recurSIC achieves strong hard- and soft-detection performance at very low complexity, making it well suited for edge-constrained MIMO receivers.

</details>


### [25] [Assessment of Errors of Fundamental Frequency Estimation Methods in the Presence of Voltage Fluctuations and Distortions](https://arxiv.org/abs/2601.16606)
*Antonio Bracale,Pasquale De Falco,Piotr Kuwałek,Grzegorz Wiczyński*

Main category: eess.SP

TL;DR: 该研究评估了现代电网条件下各种基频估计方法的误差，包括IEC 61000-4-30标准方法，使用模拟电网状态的测试信号进行分析。


<details>
  <summary>Details</summary>
Motivation: 基频是定义电能质量的关键参数之一，在现代电网条件下准确确定该参数至关重要。诊断目的通常需要在短时间窗口内高效估计该参数。

Method: 通过数值仿真研究，使用模拟电网状态的测试信号（包括电压波动和畸变同时发生的情况），评估各种基频估计方法的误差。

Result: 研究提供了不同基频估计方法在模拟现代电网条件下的误差评估结果，包括标准IEC 61000-4-30方法的性能表现。

Conclusion: 基于研究结果提出了相关结论，为现代电网条件下基频估计方法的选择和应用提供了参考依据。

Abstract: The fundamental frequency is one of the parameters that define power quality. Correctly determining this parameter under the conditions that prevail in modern power grids is crucial. Diagnostic purposes often require an efficient estimation of this parameter within short time windows. Therefore, this article presents the results of numerical simulation studies that allow the assessment of errors in various fundamental frequency estimation methods, including the standard IEC 61000-4-30 method, when the analyzed signal has a form similar to that found in modern power grids. For the purposes of this study, a test signal was adopted recreating the states of the power grid, including the simultaneous occurrence of voltage fluctuations and distortions. Conclusions are presented based on conducted research.

</details>


### [26] [Low-Power On-Device Gesture Recognition with Einsum Networks](https://arxiv.org/abs/2601.16662)
*Sahar Golipoor,Lingyun Yao,Martin Andraud,Stephan Sigg*

Main category: eess.SP

TL;DR: 提出基于Einsum网络的分布式资源受限设备手势识别系统，在低功耗RFID手势识别场景中表现优于基准模型


<details>
  <summary>Details</summary>
Motivation: 为分布式资源受限设备网络设计高效的手势识别系统，解决传统方法在能耗、推理可处理性和可解释性方面的限制

Method: 采用Einsum网络作为概率电路，构建包含RSS/相位处理、AoA估计、特征提取的专用硬件模块，通过决策聚合模块融合多设备输出

Result: 在低功耗、可穿戴、被动RFID手势识别场景中验证，系统性能优于基准模型

Conclusion: Einsum网络为分布式资源受限设备提供了高效、可解释的手势识别解决方案，在低功耗RFID场景中表现优异

Abstract: We design a gesture-recognition pipeline for networks of distributed, resource constrained devices utilising Einsum Networks. Einsum Networks are probabilistic circuits that feature a tractable inference, explainability, and energy efficiency. The system is validated in a scenario of low-power, body-worn, passive Radio Frequency Identification-based gesture recognition. Each constrained device includes task-specific processing units responsible for Received Signal Strength (RSS) and phase processing or Angle of Arrival (AoA) estimation, along with feature extraction, as well as dedicated Einsum hardware that processes the extracted features. The output of all constrained devices is then fused in a decision aggregation module to predict gestures. Experimental results demonstrate that the method outperforms the benchmark models.

</details>


### [27] [OFDM-Based ISAC Imaging of Extended Targets via Inverse Virtual Aperture Processing](https://arxiv.org/abs/2601.16664)
*Michael Negosanti,Lorenzo Pucci,Andrea Giorgetti*

Main category: eess.SP

TL;DR: 该研究探讨了利用逆虚拟孔径(IVA)进行车载场景中移动扩展目标成像的集成感知与通信(ISAC)系统性能，使用MIMO-OFDM波形和运动补偿技术形成IVA距离-多普勒图像。


<details>
  <summary>Details</summary>
Motivation: 随着下一代无线网络的发展，需要研究有效的集成感知与通信策略，特别是在车载场景中对移动扩展目标进行成像，以支持智能交通和车联网应用。

Method: 采用MIMO-OFDM波形作为单基地传感器，通过运动补偿技术处理目标反射的回波，形成IVA距离-多普勒图像。使用5G NR波形和3GPP Release 19中定义的车辆目标模型（作为空间分布散射点集合），通过改变子载波分配来研究感知精度与通信效率的权衡。

Result: 通过图像对比度(IC)和目标质心距离估计的均方根误差(RMSE)评估性能，结果表明系统能够有效成像移动扩展目标，并揭示了感知精度与通信效率之间的权衡关系。

Conclusion: 该研究为下一代无线网络中设计有效的感知策略提供了重要见解，特别是在车载场景中利用IVA技术进行移动目标成像方面，展示了ISAC系统在实际应用中的潜力。

Abstract: This work investigates the performance of an integrated sensing and communication (ISAC) system exploiting inverse virtual aperture (IVA) for imaging moving extended targets in vehicular scenarios. A base station (BS) operates as a monostatic sensor using MIMO-OFDM waveforms. Echoes reflected by the target are processed through motion-compensation techniques to form an IVA range-Doppler (cross-range) image. A case study considers a 5G NR waveform in the upper mid-band, with the target model defined in 3GPP Release 19, representing a vehicle as a set of spatially distributed scatterers. Performance is evaluated in terms of image contrast (IC) and the root mean squared error (RMSE) of the estimated target-centroid range. Finally, the trade-off between sensing accuracy and communication efficiency is examined by varying the subcarrier allocation for IVA imaging. The results provide insights for designing effective sensing strategies in next-generation radio networks.

</details>


### [28] [Precise Low-Current Measurement Techniques for IoT Devices: A Case Study on MoleNet](https://arxiv.org/abs/2601.16727)
*Julian Block,Andreas Könsgen,Jens Dede,Anna Förster*

Main category: eess.SP

TL;DR: 比较专用源测量单元(SMU)在测量物联网设备微小电流方面的性能，并以MoleNet物联网传感器板为例进行实际测量演示


<details>
  <summary>Details</summary>
Motivation: 物联网设备通常需要长时间电池供电，功耗是关键因素。传统万用表和示波器难以精确测量物联网设备休眠模式下的微小电流，需要更专业的测量工具

Method: 比较专用源测量单元(SMU)的性能，这些设备能够以高精度测量微小电流。以MoleNet物联网传感器板作为应用实例进行电流测量演示

Result: 专用源测量单元(SMU)相比传统测量工具更适合测量物联网设备的微小电流，特别是休眠模式下的电流消耗

Conclusion: 在部署物联网设备前，使用专用SMU进行精确的电流测量至关重要，这有助于优化设备功耗和延长电池寿命

Abstract: Power consumption is a crucial aspect of IoT devices which often have to run on a battery for an extended period of time. Therefore, supply current measurements are crucial before deploying a device in the field. Multimeters and oscilloscopes are not well suited when it comes to measuring very small currents which occur e.g. when an IoT device is in sleep mode. In this report, we compare dedicated source measurement units (SMUs) which allow to measure very small currents with high precision. As an application example, we demonstrate current measurements on our MoleNet IoT sensor board.

</details>


### [29] [A Dynamic Parametric Simulator for Fetal Heart Sounds](https://arxiv.org/abs/2601.16792)
*Yingtong Zhou,Yiang Zhou,Zhengxian Qu,Kang Liu,Ting Tan*

Main category: eess.SP

TL;DR: 提出一个可重复的动态参数模拟器，用于生成腹部胎儿心音图信号，支持fPCG处理方法的快速评估


<details>
  <summary>Details</summary>
Motivation: 胎儿心音图研究面临腹部记录数量有限、母体干扰严重、信号衰减明显等问题，导致可重复基准测试困难

Method: 结合周期级胎儿S1/S2事件合成与卷积传输模块，加入可配置的干扰和背景噪声，参数从真实腹部记录中校准以捕捉心跳变异性

Result: 生成信号在包络时间结构和频域特性上与真实记录验证一致，模拟器作为开源软件发布

Conclusion: 该模拟器支持在受控采集条件下对fPCG处理方法进行快速、可重复的评估

Abstract: Research on fetal phonocardiogram (fPCG) is challenged by the limited number of abdominal recordings, substantial maternal interference, and marked transmissioninduced signal attenuation that complicate reproducible benchmarking. We present a reproducible dynamic parametric simulator that generates long abdominal fPCG sequences by combining cycle-level fetal S1/S2 event synthesis with a convolutional transmission module and configurable interference and background noise. Model parameters are calibrated cyclewise from real abdominal recordings to capture beat-to-beat variability and to define data-driven admissible ranges for controllable synthesis. The generated signals are validated against real recordings in terms of envelope-based temporal structure and frequency-domain characteristics. The simulator is released as open software to support rapid, reproducible evaluation of fPCG processing methods under controlled acquisition conditions.

</details>


### [30] [Hierarchical Distribution Matcher Design for Probabilistic Constellation Shaping Based on a Novel Semi-Analytical Optimization Approach](https://arxiv.org/abs/2601.16847)
*Pantea Nadimi Goki,Luca Potì*

Main category: eess.SP

TL;DR: 提出了一种实用的分层分布匹配器设计方法，用于概率整形星座系统，通过分析优化能量损失、速率损失和内存需求，实现与硬件约束兼容的高效设计。


<details>
  <summary>Details</summary>
Motivation: 概率整形技术能提高光通信系统的频谱效率，但现有的分布匹配器设计在硬件实现上存在挑战。需要一种既能满足目标分布匹配速率，又能与ASIC/FPGA等实际硬件约束兼容的设计方法。

Method: 提出分层分布匹配器设计流程：1）分析估计能量损失、速率损失和内存需求的下界；2）采用半解析优化框架联合优化速率和能量损失；3）选择分层数、内存大小和块长度以优化信道容量；4）通过PAS 16QAM验证模型准确性。

Result: 在AWGN信道下，以200Gbps净数据速率和25%FEC开销，优化后的HiDM结构相比先前方案实现了2.8%的整形增益提升，且分析预测与仿真结果吻合良好。

Conclusion: 该研究提供了一种实用的分层分布匹配器设计工具，能够有效平衡性能与硬件实现约束，为概率整形系统的实际部署提供了可行的解决方案。

Abstract: A novel design procedure for practical hierarchical distribution matchers (HiDMs) in probabilistically shaped constellation systems is presented. The proposed approach enables the determination of optimal parameters for any target distribution matcher rate. Specifically, lower bounds on energy loss, rate loss, and memory requirements are analytically estimated for HiDM architectures approximating the Maxwell Boltzmann (MB) distribution. A semi analytical optimization framework is employed to jointly optimize rate and energy loss, allowing the selection of the number of hierarchical layers, memory size, and block length required to optimize channel capacity. The accuracy of the proposed model is validated through probabilistic amplitude shaping of 16QAM (PAS 16QAM), showing good agreement between analytical predictions and simulated results. The proposed analytical tool facilitates the design of HiDM structures that are compatible with practical hardware and implementation constraints, such as those imposed by state-of-the-art application-specific integrated circuits (ASICs) and field-programmable gate arrays (FPGAs). Furthermore, the performance of the optimized HiDM structure, incorporating layer selection based on lower-bound energy loss, is evaluated over the AWGN channel in terms of normalized generalized mutual information (NGMI) as a function of the optical signal-to-noise ratio (OSNR). At a net data rate of 200 Gbps with 25% forward error correction (FEC) overhead, the proposed scheme achieves a shaping gain improvement of 2.8% compared to previously reported solutions.

</details>


### [31] [IRS Compensation of Hyper-Rayleigh Fading: How Many Elements Are Needed?](https://arxiv.org/abs/2601.16915)
*Aleksey S. Gvozdarev*

Main category: eess.SP

TL;DR: 研究确定了在超瑞利衰落条件下，智能反射表面所需的最小单元数量：至少6个单元可将总链路带出最差衰落条件，14个单元可实现无超瑞利衰落。


<details>
  <summary>Details</summary>
Motivation: 在多径衰落信道中，需要确定智能反射表面所需的最小单元数量来补偿严重衰落条件，特别是量化超瑞利衰落状态下的性能需求。

Method: 使用逆幂洛马克斯分布建模衰落信道，推导单IRS单元信道的闭式统计特性，并对总IRS辅助信道的系数和瞬时信噪比统计提供紧密近似。

Result: 当源-IRS和IRS-目的地两个单链路都处于最差衰落条件时，至少需要6个IRS单元才能使总链路脱离最差衰落条件，需要14个单元才能实现无超瑞利衰落。

Conclusion: 确定了IRS系统设计的关键参数：在严重衰落条件下，6个单元是脱离最差衰落的最小配置，14个单元可实现无超瑞利衰落的稳定通信。

Abstract: The letter introduces and studies the problem of defining the minimum number of Intelligent Reflecting Surface (IRS) elements needed to compensate for heavy fading conditions in multipath fading channels. The fading severity is quantified in terms of Hyper-Rayleigh Regimes (HRRs) (i.e., full-HRR (worst-case conditions), strong-, weak-, and no-HRR), and the channel model used (Inverse Power Lomax (IPL)) was chosen since it can account for all HRRs. The research presents the derived closed-form channel coefficient envelope statistics for the single IRS-element channel with IPL statistics in both subchannels and total IRS-assisted channel, as well as tight approximations for the channel coefficient and instantaneous signal-to-noise ratio (SNR) statistics for the latter. The derived expressions helped estimate channel parameters corresponding to the specific HRRs of the total channel and demonstrate that while both single links (i.e., ''source-IRS'' and ''IRS-destination'') are in full-HRR, the minimum number of IRS elements needed to bring the total IRS-assisted link (''source-IRS-destination'') out of full-HRR is no less than $6$ (for the whole range on the IPL scale parameter corresponding full-HRR). Furthermore, the minimum number of IRS elements required to bring the total IRS-assisted link into no-HRR is $14$ (under the same conditions).

</details>
