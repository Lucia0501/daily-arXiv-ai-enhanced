<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 11]
- [eess.SP](#eess.SP) [Total: 21]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Information Gradient for Nonlinear Gaussian Channel with Applications to Task-Oriented Communication](https://arxiv.org/abs/2510.20179)
*Tadashi Wadayama*

Main category: cs.IT

TL;DR: 提出了基于梯度的参数化非线性高斯信道优化框架，通过互信息最大化实现。利用SFB方法推导出计算可行的信息梯度公式，包含输出分布的得分函数和前端函数的雅可比矩阵两个关键组件。


<details>
  <summary>Details</summary>
Motivation: 为了解决非线性高斯信道参数优化中互信息梯度计算的复杂性问题，开发一个计算可行的框架来优化参数化非线性前端。

Method: 使用SFB方法推导信息梯度公式，通过DSM学习边际输出分布的得分函数，利用VJP在自动微分框架中高效处理雅可比矩阵，实现梯度上升优化。

Result: 实验验证了信息梯度公式的正确性，并展示了在线性和非线性信道优化中的有效性。

Conclusion: 该框架实现了非线性前端的端到端优化，无需显式计算输出分布，为参数化非线性高斯信道优化提供了实用解决方案。

Abstract: We propose a gradient-based framework for optimizing parametric nonlinear
Gaussian channels via mutual information maximization. Leveraging the
score-to-Fisher bridge (SFB) methodology, we derive a computationally tractable
formula for the information gradient that is the gradient of mutual information
with respect to the parameters of the nonlinear front-end. Our formula
expresses this gradient in terms of two key components: the score function of
the marginal output distribution, which can be learned via denoising score
matching (DSM), and the Jacobian of the front-end function, which is handled
efficiently using the vector-Jacobian product (VJP) within automatic
differentiation frameworks. This enables practical parameter optimization
through gradient ascent. Furthermore, we extend this framework to task-oriented
scenarios, deriving gradients for both task-specific mutual information, where
a task variable depends on the channel input, and the information bottleneck
(IB) objective. A key advantage of our approach is that it facilitates
end-to-end optimization of the nonlinear front-end without requiring explicit
computation on the output distribution. Extensive experimental validation
confirms the correctness of our information gradient formula against analytical
solutions and demonstrates its effectiveness in optimizing both linear and
nonlinear channels toward their objectives.

</details>


### [2] [New Second-Order Achievability Bounds for Coding with Side Information via Type Deviation Convergence](https://arxiv.org/abs/2510.20241)
*Xiang Li,Cheuk Ting Li*

Main category: cs.IT

TL;DR: 提出了一个称为类型偏差收敛的二阶可达性框架，适用于网络信息论设置，特别适用于有损源编码和带成本的信道编码。改进了Wyner-Ziv问题、Heegard-Berger问题和Gelfand-Pinsker问题的二阶可达性界。


<details>
  <summary>Details</summary>
Motivation: 现有网络信息论中的二阶可达性界存在改进空间，特别是在有损源编码和带成本的信道编码方面，需要更通用的框架来提升性能边界。

Method: 提出类型偏差收敛框架，通过分析类型偏差的收敛特性来推导二阶可达性界，适用于多种网络信息论场景。

Result: 为Wyner-Ziv问题提供了改进的二阶可达性界，优于Watanabe-Kuzuoka-Tan、Yassaee-Aref-Gohari和Li-Anantharam等人的结果；同时改进了Heegard-Berger问题和Gelfand-Pinsker问题的二阶可达性界。

Conclusion: 类型偏差收敛框架是一个通用且有效的二阶可达性分析方法，能够显著改进多个网络信息论问题的性能边界，特别是在有损源编码和带成本的信道编码方面。

Abstract: We propose a framework for second-order achievability, called type deviation
convergence, that is generally applicable to settings in network information
theory, and is especially suitable for lossy source coding and channel coding
with cost. We give a second-order achievability bound for lossy source coding
with side information at the decoder (Wyner-Ziv problem) that improves upon all
known bounds (e.g., Watanabe-Kuzuoka-Tan, Yassaee-Aref-Gohari and
Li-Anantharam). We also give second-order achievability bounds for lossy
compression where side information may be absent (Heegard-Berger problem) and
channels with noncausal state information at the encoder and cost constraint
(Gelfand-Pinsker problem with cost) that improve upon previous bounds.

</details>


### [3] [A Location-Aware Hybrid Deep Learning Framework for Dynamic Near-Far Field Channel Estimation in Low-Altitude UAV Communications](https://arxiv.org/abs/2510.20277)
*Wenli Yuan,Kan Yu,Xiaowu Liu,Kaixuan Li,Qixun Zhang,Zhiyong Feng*

Main category: cs.IT

TL;DR: 提出了一种基于位置感知混合深度学习架构的统一信道估计框架，用于解决低空无人机通信中的混合近远场传播条件挑战。


<details>
  <summary>Details</summary>
Motivation: 传统信道估计方法依赖远场假设，无法捕捉近场场景的复杂信道变化，且忽略了实时收发器位置等有价值的几何先验信息。

Method: 结合CNN进行空间特征提取、BiLSTM建模时间演化、多头自注意力机制增强对判别性信道组件的关注，并嵌入实时收发器位置作为几何先验。

Result: 在归一化均方误差(NMSE)上平均至少减少30.25%，显著优于现有基准方法。

Conclusion: 所提出的位置感知混合深度学习框架能有效解决低空无人机通信中的混合近远场信道估计问题，具有优越性能。

Abstract: In low altitude UAV communications, accurate channel estimation remains
challenging due to the dynamic nature of air to ground links, exacerbated by
high node mobility and the use of large scale antenna arrays, which introduce
hybrid near and far field propagation conditions. While conventional estimation
methods rely on far field assumptions, they fail to capture the intricate
channel variations in near-field scenarios and overlook valuable geometric
priors such as real-time transceiver positions. To overcome these limitations,
this paper introduces a unified channel estimation framework based on a
location aware hybrid deep learning architecture. The proposed model
synergistically combines convolutional neural networks (CNNs) for spatial
feature extraction, bidirectional long short term memory (BiLSTM) networks for
modeling temporal evolution, and a multihead self attention mechanism to
enhance focus on discriminative channel components. Furthermore, real-time
transmitter and receiver locations are embedded as geometric priors, improving
sensitivity to distance under near field spherical wavefronts and boosting
model generalization. Extensive simulations validate the effectiveness of the
proposed approach, showing that it outperforms existing benchmarks by a
significant margin, achieving at least a 30.25% reduction in normalized mean
square error (NMSE) on average.

</details>


### [4] [Moving or Predicting? RoleAware-MAPP: A Role-Aware Transformer Framework for Movable Antenna Position Prediction to Secure Wireless Communications](https://arxiv.org/abs/2510.20293)
*Wenxu Wang,Xiaowu Liu,Wei Gong,Yujia Zhao,Kaixuan Li,Qixun Zhang,Zhiyong Feng,Kan Yu*

Main category: cs.IT

TL;DR: 本文提出RoleAware-MAPP框架，通过Transformer模型将可移动天线定位问题重构为预测任务，结合角色感知嵌入、物理信息语义特征和复合损失函数，显著提升物理层安全性能。


<details>
  <summary>Details</summary>
Motivation: 可移动天线技术面临实时优化计算复杂度和机械运动与信道变化时间不匹配的挑战，现有学习方法缺乏对合法用户与窃听者对抗交互的领域知识建模。

Method: 提出RoleAware-MAPP框架，包含：角色感知嵌入建模用户特定意图、物理信息语义特征封装信道传播特性、复合损失函数优先考虑保密性能而非几何精度。

Result: 在3GPP兼容场景下，平均保密率达到0.3569 bps/Hz，严格正保密容量达81.52%，比最强基线分别提升48.4%和5.39个百分点，在不同用户速度和噪声条件下保持稳健性能。

Conclusion: RoleAware-MAPP通过整合领域知识成功解决了可移动天线定位的关键挑战，为物理层安全提供了有效的学习驱动解决方案。

Abstract: Movable antenna (MA) technology provides a promising avenue for actively
shaping wireless channels through dynamic antenna positioning, thereby enabling
electromagnetic radiation reconstruction to enhance physical layer security
(PLS). However, its practical deployment is hindered by two major challenges:
the high computational complexity of real time optimization and a critical
temporal mismatch between slow mechanical movement and rapid channel
variations. Although data driven methods have been introduced to alleviate
online optimization burdens, they are still constrained by suboptimal training
labels derived from conventional solvers or high sample complexity in
reinforcement learning. More importantly, existing learning based approaches
often overlook communication-specific domain knowledge, particularly the
asymmetric roles and adversarial interactions between legitimate users and
eavesdroppers, which are fundamental to PLS. To address these issues, this
paper reformulates the MA positioning problem as a predictive task and
introduces RoleAware-MAPP, a novel Transformer based framework that
incorporates domain knowledge through three key components: role-aware
embeddings that model user specific intentions, physics-informed semantic
features that encapsulate channel propagation characteristics, and a composite
loss function that strategically prioritizes secrecy performance over mere
geometric accuracy. Extensive simulations under 3GPP-compliant scenarios show
that RoleAware-MAPP achieves an average secrecy rate of 0.3569 bps/Hz and a
strictly positive secrecy capacity of 81.52%, outperforming the strongest
baseline by 48.4% and 5.39 percentage points, respectively, while maintaining
robust performance across diverse user velocities and noise conditions.

</details>


### [5] [Ergodic Mutual Information and Outage Probability for SIM-Assisted Holographic MIMO Communications](https://arxiv.org/abs/2510.20307)
*Anastasios Papazafeiropoulos,Pandelis Kourtessis,Dimitra I. Kaklamani,Iakovos S. Venieris*

Main category: cs.IT

TL;DR: 本文研究了堆叠智能超表面辅助MIMO系统的遍历互信息和中断概率，使用大随机矩阵理论推导了互信息分布，并提出了基于梯度下降的优化算法来最小化中断概率。


<details>
  <summary>Details</summary>
Motivation: 堆叠智能超表面相比单层超表面能提供更好的性能，但目前文献中缺乏对SIM辅助MIMO系统的遍历互信息和中断概率的研究。

Method: 使用大随机矩阵理论工具获得互信息分布，推导基于统计信道状态信息的紧致闭式中断概率表达式，并应用梯度下降方法最小化中断概率。

Result: 仿真结果验证了理论分析，显示相比传统MIMO系统和单层超表面有性能提升，且提出的优化算法比交替优化基准更快，节省了显著开销。

Conclusion: 堆叠智能超表面在MIMO系统中具有显著性能优势，提出的分析方法有效且优化算法高效。

Abstract: Stacked intelligent metasurface (SIM) is a promising enabler for
next-generation high-capacity networks that exhibit better performance compared
to its single-layer counterpart by means of just wave propagation. However, the
study of ergodic mutual information (EMI) and outage probability for
SIM-assisted multiple-input-multiple-output (MIMO) systems is not available in
the literature. To this end, we obtain the distribution of the MI by using
large random matrix theory (RMT) tools. Next, we derive a tight closed-form
expression for the outage probability based on statistical channel state
information (CSI). Moreover, we apply the gradient descent method for the
minimization of the outage probability. Simulation results verify the
analytical results and provide fundamental insights such as the performance
enhancements compared to conventional MIMO systems and the single-layer
counterpart. Notably the proposed optimization algorithm is faster than the
alternating optimization (AO) benchmark by saving significant overhead.

</details>


### [6] [Robust Analog Lagrange Coded Computing: Theory and Algorithms via Discrete Fourier Transforms](https://arxiv.org/abs/2510.20379)
*Rimpi Borah,J. Harshan*

Main category: cs.IT

TL;DR: 提出了一个安全的模拟拉格朗日编码计算框架，能够抵御拜占庭工作节点的完整性威胁，通过DFT码纠错算法提高计算精度，并利用工作节点信任档案优化任务分配。


<details>
  <summary>Details</summary>
Motivation: 现有的ALCC框架虽然能保护数据隐私并容忍延迟节点，但无法抵御拜占庭工作节点返回错误结果的攻击，存在安全漏洞。

Method: 使用DFT码的纠错算法构建新的重构策略，并基于DFT解码器性能理论结果，提出考虑工作节点信任档案的任务分配方法。

Result: 提出的安全ALCC框架显著提高了在有限数量拜占庭工作节点存在时的计算精度，并研究了针对浮点实现精度噪声的共谋攻击鲁棒性。

Conclusion: 该框架有效增强了ALCC对拜占庭攻击的抵御能力，通过创新的重构策略和任务分配方法提升了系统的安全性和准确性。

Abstract: Analog Lagrange Coded Computing (ALCC) is a recently proposed computational
paradigm wherein certain computations over analog datasets are efficiently
performed using distributed worker nodes through floating point representation.
While the vanilla version of ALCC is known to preserve the privacy of the
datasets from the workers and also achieve resilience against stragglers, it is
not robust against Byzantine workers that return erroneous results.
Highlighting this vulnerability, we propose a secure ALCC framework that is
resilient against a wide range of integrity threats from the Byzantine workers.
As a foundational step, we use error-correction algorithms for Discrete Fourier
Transform (DFT) codes to build novel reconstruction strategies for ALCC thereby
improving its computational accuracy in the presence of a bounded number of
Byzantine workers. Furthermore, capitalizing on some theoretical results on the
performance of the DFT decoders, we propose novel strategies for distributing
the ALCC computational tasks to the workers, and show that such methods
significantly improve the accuracy when the workers' trust profiles are
available at the master server. Finally, we study the robustness of the
proposed framework against colluding attacks, and show that interesting attack
strategies can be executed by exploiting the inherent precision noise owing to
floating point implementation.

</details>


### [7] [Adversary-Aware Private Inference over Wireless Channels](https://arxiv.org/abs/2510.20518)
*Mohamed Seif,Malcolm Egan,Andrea J. Goldsmith,H. Vincent Poor*

Main category: cs.IT

TL;DR: 提出了一种保护隐私的AI感知框架，设备在将提取的特征传输到模型服务器之前应用特征变换，以防止敏感数据被重建。


<details>
  <summary>Details</summary>
Motivation: 在边缘网络中，传感器和模型服务器通常不位于同一位置，需要传输特征。由于敏感个人数据可能被对手重建，需要对特征进行变换以降低隐私泄露风险。

Method: 设备在传输提取的特征之前应用特征变换，保护个体特征隐私。

Result: 提出了一个新颖的隐私保护AI感知框架，解决了个体特征保护问题。

Conclusion: 该框架为无线边缘设备的AI感知提供了隐私保护解决方案，弥补了传统差分隐私机制在个体特征保护方面的不足。

Abstract: AI-based sensing at wireless edge devices has the potential to significantly
enhance Artificial Intelligence (AI) applications, particularly for vision and
perception tasks such as in autonomous driving and environmental monitoring. AI
systems rely both on efficient model learning and inference. In the inference
phase, features extracted from sensing data are utilized for prediction tasks
(e.g., classification or regression). In edge networks, sensors and model
servers are often not co-located, which requires communication of features. As
sensitive personal data can be reconstructed by an adversary, transformation of
the features are required to reduce the risk of privacy violations. While
differential privacy mechanisms provide a means of protecting finite datasets,
protection of individual features has not been addressed. In this paper, we
propose a novel framework for privacy-preserving AI-based sensing, where
devices apply transformations of extracted features before transmission to a
model server.

</details>


### [8] [Simultaneous Wireless Information and Power Transfer for Fluid Antenna Systems](https://arxiv.org/abs/2510.20569)
*Feilong Zhang,Jianxin Dai,Zhaohui Yang,Kai-Kit Wong,Lingyuxiu Li,Jianglin Ye*

Main category: cs.IT

TL;DR: 提出一种结合MISO流体天线与传统固定天线的通信系统，通过优化天线位置和发射协方差矩阵来提高SWIPT系统中的能量收集效率。


<details>
  <summary>Details</summary>
Motivation: 流体天线技术通过改变天线位置来提升通信速率，本文旨在利用这种技术结合传统固定天线，在SWIPT系统中提高能量接收器的能量收集效率。

Method: 在SWIPT系统中，基站向信息接收器和能量接收器发送相同信号，通过优化发射和接收流体天线位置以及发射协方差矩阵，在满足信息接收器最小SINR约束条件下最大化能量收集效率。

Result: 仿真结果表明，与传统固定位置天线相比，流体天线系统能显著提高能量接收器的能量收集效率。

Conclusion: 流体天线系统在SWIPT应用中具有显著优势，能够有效提升能量收集性能，为无线通信中的能量传输提供了新的技术途径。

Abstract: Fluid antenna is a promising wireless communication technology that enhances
communication rate by changing the antenna positions. This article proposes a
new communication system that combines multiple-input single-output (MISO)
fluid antennas with traditional fixed-position antennas, utilizing antenna
position optimization to improve energy harvesting efficiency. In this model,
we consider simultaneous wireless information and power transfer (SWIPT) which
transmits identical signals from the base station to both information receiver
(IR) and energy receiver (ER). We strive to enhance the power delivered to the
ER by fine-tuning the positions of transmit and receive fluid antennas, along
with optimizing the transmit covariance matrix, subject to a given minimum
signal-to-interference-plus-noise ratio (SINR) constraint at the IR. Simulation
results indicate that fluid antenna systems significantly enhance the energy
harvesting efficiency of the ER compared to traditional fixed-position
antennas.

</details>


### [9] [Stacked Intelligent Metasurfaces for 6G Wireless Networks: Principles, Applications, and Research Directions](https://arxiv.org/abs/2510.20572)
*Enyu Shi,Jiayi Zhang,Zhilong Liu,Ziheng Liu,Arumugam Nallanathan,Merouane Debbah,Shi Jin,Bo Ai*

Main category: cs.IT

TL;DR: 本文综述了基于堆叠智能超表面（SIM）的分布式无线网络，探讨了其在6G网络中的应用场景、系统架构、信号处理挑战及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要在高度动态环境中提供泛在连接、弹性覆盖和智能服务，而分布式无线架构如无蜂窝大规模MIMO因其可扩展性和公平性受到关注。SIM作为可重构智能表面的演进，提供了增强的电磁域处理能力。

Method: 将SIM集成到分布式无线网络中，实现先进的波域操作，包括分层框架、用户关联和联合预编码等信号处理技术。

Result: 案例研究表明SIM辅助的分布式无线网络能够实现显著的性能提升，包括高效的干扰管理、改进的能效和频谱效率，以及鲁棒的物理层安全。

Conclusion: SIM辅助的分布式无线网络为6G网络提供了有前景的解决方案，未来需要在硬件设计、能耗建模、算法开发和人工智能集成等方面进行深入研究。

Abstract: The sixth-generation (6G) wireless networks are expected to deliver
ubiquitous connectivity, resilient coverage, and intelligence-driven services
in highly dynamic environments. To achieve these goals, distributed wireless
architectures such as cell-free massive multiple-input multiple-output (MIMO)
have attracted significant attention due to their scalability and fairness.
Recently, stacked intelligent metasurfaces (SIMs) have emerged as a promising
evolution of reconfigurable intelligent surfaces, offering multi-layer
electromagnetic domain processing with enhanced controllability and spatial
degrees of freedom. By integrating SIMs into distributed wireless networks,
advanced wave-domain operations can be realized, enabling efficient
interference management, improved energy and spectral efficiency, and robust
physical-layer security. This article provides a comprehensive overview of
SIM-aided distributed wireless networks, including their application scenarios,
classification, and system architectures. Key signal processing challenges,
such as hierarchical frameworks, user association, and joint precoding, are
discussed, followed by case studies demonstrating significant performance
gains. Finally, future research directions in hardware design, energy
consumption modeling, algorithm development, and artificial intelligence
integration are highlighted, aiming to pave the way for scalable and
intelligent 6G distributed wireless networks.

</details>


### [10] [Super-Linear Growth of the Capacity-Achieving Input Support for the Amplitude-Constrained AWGN Channel](https://arxiv.org/abs/2510.20723)
*Haiyang Wang*

Main category: cs.IT

TL;DR: 本文研究了幅度受限AWGN信道容量达到最优输入分布的支撑点数量增长问题，证明了支撑点数量随幅度约束A的增加呈超线性增长。


<details>
  <summary>Details</summary>
Motivation: 虽然已知幅度受限AWGN信道的最优输入分布是离散的且具有有限个支撑点，但关于支撑点数量K(A)随幅度约束A增加的紧致界仍然是一个开放问题。

Method: 结合输出分布在总变差意义下收敛到均匀分布的性质，以及高斯混合近似中的定量限制，推导了新的解析下界。

Result: 证明了K(A)随A的增加呈超线性增长，为支撑点数量的增长行为提供了新的理论下界。

Conclusion: 该研究为幅度受限AWGN信道最优输入分布的支撑点数量增长特性提供了重要的理论进展，填补了现有文献中的空白。

Abstract: We study the growth of the support size of the capacity-achieving input
distribution for the amplitude-constrained additive white Gaussian noise (AWGN)
channel. While it is known since Smith (1971) that the optimal input is
discrete with finitely many mass points, tight bounds on the number of support
points $K(A)$ as the amplitude constraint $A$ increases remain open. Building
on recent work by Dytso \emph{et al.} (2019) and Mattingly \emph{et al.}
(2018), we derive a new analytical lower bound showing that $K(A)$ grows
super-linearly in $A$. Our approach combines total-variation convergence of the
output distribution to the uniform law with quantitative limits on Gaussian
mixture approximation.

</details>


### [11] [MIMO-Zak-OTFS with Superimposed Spread Pilots](https://arxiv.org/abs/2510.20734)
*Abhishek Bairwa,Ananthanarayanan Chockalingam*

Main category: cs.IT

TL;DR: 提出了一种用于MIMO-Zak-OTFS系统的叠加扩频导频设计和有效信道估计方法，通过在交叉模糊域分离导频序列，并结合turbo迭代来减轻导频-数据干扰。


<details>
  <summary>Details</summary>
Motivation: 在MIMO-Zak-OTFS系统中，数据与扩频导频信号叠加在同一帧中，需要有效分离不同发射天线的导频以实现良好的信道估计性能。

Method: 设计在交叉模糊域分离导频序列的扩频导频方案，通过简单读取操作估计有效信道抽头，并采用信道估计与检测之间的turbo迭代来减轻导频-数据干扰。

Result: 在2×2和3×3 MIMO-Zak-OTFS系统中，使用高斯sinc脉冲整形滤波器和车载-A信道模型的仿真结果表明，所提方法经过三次turbo迭代可获得非常好的估计/检测性能。

Conclusion: 所提出的导频设计和估计方案能够有效解决MIMO-Zak-OTFS系统中的信道估计问题，在叠加导频场景下实现高性能的信道估计和信号检测。

Abstract: In this paper, we consider the problem of spread pilot design and effective
channel estimation in multiple-input multiple-output Zak-OTFS (MIMO-Zak-OTFS)
with superimposed spread pilots, where data and spread pilot signals are
superimposed in the same frame. To achieve good estimation performance in a
MIMO setting, the spread pilots at different transmit antennas need to be
effectively separated at the receiver. Towards this, we propose a spread pilot
design that separates the pilot sequences in the cross-ambiguity domain and
enables the estimation of the effective channel taps by a simple read-off
operation. To further alleviate the effect of pilot-data interference on
performance, we carry out turbo iterations between channel estimation and
detection. Simulation results for $2\times 2$ and $3\times 3$ MIMO-Zak-OTFS
with Gaussian-sinc pulse shaping filter for vehicular-A channel model show that
the proposed pilot design and estimation scheme with three turbo iterations can
achieve very good estimation/detection performance.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [12] [SSL-SE-EEG: A Framework for Robust Learning from Unlabeled EEG Data with Self-Supervised Learning and Squeeze-Excitation Networks](https://arxiv.org/abs/2510.19829)
*Meghna Roy Chowdhury,Yi Ding,Shreyas Sen*

Main category: eess.SP

TL;DR: SSL-SE-EEG框架结合自监督学习和Squeeze-and-Excitation网络，将EEG信号转换为2D图像表示，提高特征提取能力和噪声鲁棒性，减少对标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 解决脑电图(EEG)在实际应用中面临的噪声干扰、数据缺失和标注成本高等挑战，推动脑机接口(BCI)和神经诊断的实时部署。

Method: 将EEG信号转换为结构化2D图像表示，结合自监督学习(SSL)和Squeeze-and-Excitation网络(SE-Nets)进行特征提取。

Result: 在MindBigData、TUH-AB、SEED-IV和BCI-IV数据集上达到最先进准确率（MindBigData 91%，TUH-AB 85%），适用于实时BCI应用。

Conclusion: SSL-SE-EEG为生物医学信号分析、神经工程和下一代脑机接口提供了低功耗、可扩展的解决方案。

Abstract: Electroencephalography (EEG) plays a crucial role in brain-computer
interfaces (BCIs) and neurological diagnostics, but its real-world deployment
faces challenges due to noise artifacts, missing data, and high annotation
costs. We introduce SSL-SE-EEG, a framework that integrates Self-Supervised
Learning (SSL) with Squeeze-and-Excitation Networks (SE-Nets) to enhance
feature extraction, improve noise robustness, and reduce reliance on labeled
data. Unlike conventional EEG processing techniques, SSL-SE-EEG} transforms EEG
signals into structured 2D image representations, suitable for deep learning.
Experimental validation on MindBigData, TUH-AB, SEED-IV and BCI-IV datasets
demonstrates state-of-the-art accuracy (91% in MindBigData, 85% in TUH-AB),
making it well-suited for real-time BCI applications. By enabling low-power,
scalable EEG processing, SSL-SE-EEG presents a promising solution for
biomedical signal analysis, neural engineering, and next-generation BCIs.

</details>


### [13] [Low-Latency Neural Inference on an Edge Device for Real-Time Handwriting Recognition from EEG Signals](https://arxiv.org/abs/2510.19832)
*Ovishake Sen,Raghav Soni,Darpan Virmani,Akshar Parekh,Patrick Lehman,Sarthak Jena,Adithi Katikhaneni,Adam Khalifa,Baibhab Chatterjee*

Main category: eess.SP

TL;DR: 该论文提出了一种基于EEG的脑机接口系统，通过先进的机器学习和特征提取技术，实现了高精度的实时想象手写字符解码，并在便携边缘设备上部署。


<details>
  <summary>Details</summary>
Motivation: 脑机接口为严重运动或言语障碍患者提供了恢复沟通的途径。想象手写提供了一种直观的字符级神经解码范式，但非侵入性EEG方法因信噪比低和空间分辨率差而精度受限。

Method: 收集15名参与者的32通道EEG数据，进行带通滤波和伪影子空间重建预处理，提取85个时域、频域和图域特征，使用结合时序卷积网络和多层感知器的混合架构EEdGeNet。

Result: 在NVIDIA Jetson TX2上部署时，系统达到89.83%的准确率和914.18ms每字符延迟。仅选择10个关键特征可将延迟降低4.5倍至202.6ms，准确率损失小于1%。

Conclusion: 这些结果为准确、低延迟、完全便携的非侵入性脑机接口建立了可行路径，支持实时通信应用。

Abstract: Brain-computer interfaces (BCIs) offer a pathway to restore communication for
individuals with severe motor or speech impairments. Imagined handwriting
provides an intuitive paradigm for character-level neural decoding, bridging
the gap between human intention and digital communication. While invasive
approaches such as electrocorticography (ECoG) achieve high accuracy, their
surgical risks limit widespread adoption. Non-invasive electroencephalography
(EEG) offers safer and more scalable alternatives but suffers from low
signal-to-noise ratio and spatial resolution, constraining its decoding
precision. This work demonstrates that advanced machine learning combined with
informative EEG feature extraction can overcome these barriers, enabling
real-time, high-accuracy neural decoding on portable edge devices. A 32-channel
EEG dataset was collected from fifteen participants performing imagined
handwriting. Signals were preprocessed with bandpass filtering and artifact
subspace reconstruction, followed by extraction of 85 time-, frequency-, and
graphical-domain features. A hybrid architecture, EEdGeNet, integrates a
Temporal Convolutional Network with a multilayer perceptron trained on the
extracted features. When deployed on an NVIDIA Jetson TX2, the system achieved
89.83 percent accuracy with 914.18 ms per-character latency. Selecting only ten
key features reduced latency by 4.5 times to 202.6 ms with less than 1 percent
loss in accuracy. These results establish a pathway for accurate, low-latency,
and fully portable non-invasive BCIs supporting real-time communication.

</details>


### [14] [MATLAB-Simulated Dataset for Automatic Modulation Classification in Wireless Fading Channels](https://arxiv.org/abs/2510.19985)
*M. M. Sadman Shafi,Tasnia Siddiqua Ahona,Ashraful Islam Mridha*

Main category: eess.SP

TL;DR: 本文提出了一个用于无线调制分类的标记合成数据集，包含五种数字调制方案在不同信道条件下的信号特征数据。


<details>
  <summary>Details</summary>
Motivation: 解决认知无线电、自适应通信等领域中在动态信道下进行准确调制分类的核心挑战，特别是在缺乏发射器知识的情况下。

Method: 使用MATLAB生成随机比特流，通过BPSK、QPSK、16-QAM、64-QAM和256-QAM五种调制方案进行调制，并经过Rayleigh和Rician衰落信道传输，提取统计、时域、频域等多维度特征。

Result: 创建了包含10个CSV文件的数据集，覆盖两种信道类型和五种采样频率，每个调制信号包含1000个符号，提供了完整的特征提取和信号生成MATLAB脚本。

Conclusion: 该数据集为调制分类、信号识别和无线通信研究中的机器学习模型开发和评估提供了有价值的基准资源。

Abstract: Accurate modulation classification is a core challenge in cognitive radio,
adaptive communications, spectrum analysis, and related domains, especially
under dynamic channels without transmitter knowledge. To address this need,
this article presents a labeled synthetic dataset designed for wireless
modulation classification under realistic propagation scenarios. The signals
were generated in MATLAB by modulating randomly generated bitstreams using five
digital modulation schemes: BPSK, QPSK, 16-QAM, 64-QAM, and 256-QAM. These
signals were then transmitted through Rayleigh and Rician fading channels with
standardized parameters, along with additional impairments to enhance realism
and diversity. Each modulated signal contains 1000 symbols. A comprehensive set
of features was extracted from the signals, encompassing statistical,
time-domain, frequency-domain, spectrogram-based, spectral correlation-based,
and image-processing-based descriptors such as BRISK, MSER, and GLCM. The
dataset is organized into 10 CSV files covering two channel types (Rayleigh and
Rician) across five sampling frequencies: 1 MHz, 10 MHz, 100 MHz, 500 MHz, and
1 GHz. To facilitate reproducibility and encourage further experimentation, the
MATLAB scripts used for signal generation and feature extraction are also
provided. This dataset serves as a valuable benchmark for developing and
evaluating machine learning models in modulation classification, signal
identification, and wireless communication research.

</details>


### [15] [NanoHydra: Energy-Efficient Time-Series Classification at the Edge](https://arxiv.org/abs/2510.20038)
*Cristian Cioflan,Jose Fonseca,Xiaying Wang,Luca Benini*

Main category: eess.SP

TL;DR: NanoHydra是一种面向极边缘设备的轻量级时间序列分类方法，使用二进制随机卷积核提取特征，在超低功耗GAP9微控制器上实现高效分类，能耗比现有技术低18倍。


<details>
  <summary>Details</summary>
Motivation: 在极边缘设备上实现时间序列分类是迈向智能传感器节点的关键，需要在保持分类精度的同时延长电池供电设备的寿命。

Method: 采用轻量级二进制随机卷积核从数据流中提取特征，利用GAP9微控制器的八核集群并行执行计算密集型任务。

Result: 在ECG5000数据集上达到94.47%的分类准确率，仅需0.33ms分类1秒ECG信号，每次推理能耗7.69uJ，比现有技术高效18倍。

Conclusion: NanoHydra适用于智能可穿戴设备，可实现超过四年的设备寿命，是资源受限边缘设备的有效解决方案。

Abstract: Time series classification (TSC) on extreme edge devices represents a
stepping stone towards intelligent sensor nodes that preserve user privacy and
offer real-time predictions. Resource-constrained devices require efficient
TinyML algorithms that prolong the device lifetime of battery-operated devices
without compromising the classification accuracy. We introduce NanoHydra, a
TinyML TSC methodology relying on lightweight binary random convolutional
kernels to extract meaningful features from data streams. We demonstrate our
system on the ultra-low-power GAP9 microcontroller, exploiting its eight-core
cluster for the parallel execution of computationally intensive tasks. We
achieve a classification accuracy of up to 94.47% on ECG5000 dataset,
comparable with state-of-the-art works. Our efficient NanoHydra requires only
0.33 ms to accurately classify a 1-second long ECG signal. With a modest energy
consumption of 7.69 uJ per inference, 18x more efficient than the
state-of-the-art, NanoHydra is suitable for smart wearable devices, enabling a
device lifetime of over four years.

</details>


### [16] [Semantic Communication for Task Execution and Data Reconstruction in Multi-User Scenarios](https://arxiv.org/abs/2510.20067)
*Maximilian H. V. Tillmann,Avinash Kankari,Carsten Bockelmann,Armin Dekorsy*

Main category: eess.SP

TL;DR: 提出了一个多用户语义通信系统，同时支持任务执行和数据重建，通过互信息最大化来优化这两个目标之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有的语义通信系统大多只关注任务执行或数据重建，缺乏对两者同时优化的研究，特别是在多用户场景下。

Method: 将任务执行和数据重建的联合目标表述为互信息最大化问题，使用SSIM损失函数考虑人类视觉感知，并通过凸组合来平衡两个目标。

Result: 在资源使用恒定的情况下，增加重建目标的权重可以在保持任务执行性能基本不变的同时，显著改善数据重建质量。

Conclusion: 所提出的语义通信系统能够有效平衡任务执行和数据重建，在多用户场景下实现更好的性能权衡。

Abstract: Semantic communication has gained significant attention with the advances in
machine learning. Most semantic communication works focus on either task
execution or data reconstruction, with some recent works combining the two. In
this work, we propose a semantic communication system for concurrent task
execution and data reconstruction for a multi-user scenario, which we formulate
as the maximization of mutual information. To investigate the trade-off between
the two objectives, we formulate a joint objective as a convex combination of
task execution and data reconstruction. We show that under specific
assumptions, the \ac{SSIM} loss can be obtained from the mutual information
maximization objective for data reconstruction, which takes human visual
perception into account. Furthermore, for constant resource use, we show that
by increasing the weight of the reconstruction objective up to a certain point,
the task execution performance can be kept nearly constant, while the data
reconstruction can be significantly improved.

</details>


### [17] [RIS-Aided mmWave O-RAN: Coverage Extension and User Mobility Handling](https://arxiv.org/abs/2510.20088)
*Tawfik Osman,Aditya S. Shekhawat,Abhradeep Roy,Georgios C. Trichopoulos,Ahmed Alkhateeb*

Main category: eess.SP

TL;DR: 本文设计并评估了一个基于O-RAN的RIS辅助5G系统，在28GHz毫米波频段实现了动态RIS配置和移动性管理，显著提升了信号覆盖和链路可靠性。


<details>
  <summary>Details</summary>
Motivation: 利用可重构智能表面(RIS)增强5G毫米波系统的信号覆盖和信噪比，解决传统5G系统在覆盖范围和移动性支持方面的挑战。

Method: 设计了1024单元(32×32)的1位RIS，采用模块化瓦片架构；利用O-RAN E2接口实现RIS动态控制；开发了两种UE移动性管理算法，基于接收信号功率联合跟踪和调整RIS与UE波束。

Result: 室内外场测显示RIS提供显著接收信号功率增益：室内9-20dB，室外6-18dB；移动性管理算法在实时操作中有效跟踪移动UE。

Conclusion: 研究证明了将RIS集成到O-RAN系统中的实际可行性，能够显著增强下一代蜂窝网络的覆盖范围、移动性支持和链路可靠性。

Abstract: Reconfigurable Intelligent Surfaces (RISs) can redirect electromagnetic waves
to desired directions to enhance signal coverage and/or improve signal-to-noise
ratio (SNR) at the user equipment (UE). We present the design, implementation,
and evaluation of an RIS-assisted O-RAN 5G system operating in the FR2
millimeter wave (mmWave) frequency band. We first introduce the design of 1,024
element (32 $\times$ 32) 1-bit RIS operating at the 28 GHz band, utilizing a
modular and scalable tiled architecture. Then we demonstrate how the O-RAN E2
interface can be leveraged to dynamically control RIS configurations without
modifying standard 5G signaling procedures. To evaluate the RIS-assisted 5G
system, we conducted extensive field trials in both indoor and outdoor
environments. The results of the O-RAN link coverage trials show that the
deployed RIS provides substantial received signal power gains, ranging from 9
to 20 dB and 6 to 18 dB in indoor and outdoors scenarios, respectively.
Handling UE mobility in RIS-assisted systems is challenging due to the need for
joint RIS and UE beam management. For that, we develop two UE mobility
management algorithms and evaluate them in real-time operation using the RIS
O-RAN testbed. These algorithms leverage the received signal power at the UE to
jointly track and adapt the RIS and UE beams in real time as the UE moves. The
findings draw important insights into the practical feasibility of integrating
RIS into O-RAN systems to enhance coverage, mobility support, and link
reliability in next-generation cellular networks.

</details>


### [18] [Signal Design for OTFS Dual-Functional Radar and Communications with Imperfect CSI](https://arxiv.org/abs/2510.20112)
*Borui Du,Yumeng Zhang,Christos Masouros,Bruno Clerckx*

Main category: eess.SP

TL;DR: 本文针对双功能雷达通信(DFRC)系统中的正交时频空间(OTFS)信号设计进行优化，通过联合设计导频符号和数据功率分配，在交替优化框架下最大化感知和通信性能的加权和。


<details>
  <summary>Details</summary>
Motivation: OTFS在无线感知和通信系统中具有管理移动性的显著优势，是DFRC的有力候选技术。然而，目前尚未充分探索能够完全发挥OTFS在DFRC中潜力的最优信号设计。

Method: 采用模糊函数的积分旁瓣电平(ISL)作为雷达指标，考虑数据符号的随机性和确定性导频符号；推导考虑OTFS信道估计误差的信道容量下界作为通信指标；通过交替优化框架最大化感知和通信指标的加权和。

Result: 仿真结果表明，所提出的信号设计相比传统信号方案显著改善了感知-通信性能区域，在感知方面至少获得9.44 dB的ISL抑制增益，在通信方面获得4.82 dB的SINR增益。

Conclusion: 该研究为DFRC-OTFS系统提供了一种有效的信号设计方法，能够同时优化感知和通信性能，证明了OTFS在双功能系统中的巨大潜力。

Abstract: Orthogonal time frequency space (OTFS) offers significant advantages in
managing mobility for both wireless sensing and communication systems, making
it a promising candidate for dual-functional radar-communication (DFRC).
However, the optimal signal design that fully exploits OTFS's potential in DFRC
has not been sufficiently explored. This paper addresses this gap by
formulating an optimization problem for signal design in DFRC-OTFS,
incorporating both pilot-symbol design for channel estimation and data-power
allocation. Specifically, we employ the integrated sidelobe level (ISL) of the
ambiguity function as a radar metric, accounting for the randomness of the data
symbols alongside the deterministic pilot symbols. For communication, we derive
a channel capacity lower bound metric that considers channel estimation errors
in OTFS. We maximize the weighted sum of sensing and communication metrics and
solve the optimization problem via an alternating optimization framework.
Simulations indicate that the proposed signal significantly improves the
sensing-communication performance region compared with conventional signal
schemes, achieving at least a 9.44 dB gain in ISL suppression for sensing, and
a 4.82 dB gain in the signal-to-interference-plus-noise ratio (SINR) for
communication.

</details>


### [19] [Active Localization of Close-range Adversarial Acoustic Sources for Underwater Data Center Surveillance](https://arxiv.org/abs/2510.20122)
*Adnan Abdullah,David Blow,Sara Rampazzi,Md Jahidul Islam*

Main category: eess.SP

TL;DR: 提出了一种用于水下数据中心声学攻击源定位的实时监控框架，结合固定和移动水听器，通过LC-MAP方案和UKF滤波实现高精度3D定位。


<details>
  <summary>Details</summary>
Motivation: 水下数据中心虽然具有自然冷却和物理安全优势，但容易受到声学注入攻击威胁，现有基于TDOA和FDOA的静态方法无法适应动态配置需求。

Method: 采用异构接收器配置（固定水听器+移动水听器），提出LC-MAP方案生成声学信息和几何一致性先验，集成到UKF滤波管道中进行联合TDOA-FDOA滤波。

Result: 通过蒙特卡洛分析、Gazebo物理仿真和现场试验验证，能够实时估计攻击源的3D位置和速度，实现亚米级定位精度和超过90%的成功率，收敛时间比基线方法减少近一半。

Conclusion: 该研究建立了几何感知的实时声学威胁定位方法，提升了水下基础设施的自主监控能力。

Abstract: Underwater data infrastructures offer natural cooling and enhanced physical
security compared to terrestrial facilities, but are susceptible to acoustic
injection attacks that can disrupt data integrity and availability. This work
presents a comprehensive surveillance framework for localizing and tracking
close-range adversarial acoustic sources targeting offshore infrastructures,
particularly underwater data centers (UDCs). We propose a heterogeneous
receiver configuration comprising a fixed hydrophone mounted on the facility
and a mobile hydrophone deployed on a dedicated surveillance robot. While using
enough arrays of static hydrophones covering large infrastructures is not
feasible in practice, off-the-shelf approaches based on time difference of
arrival (TDOA) and frequency difference of arrival (FDOA) filtering fail to
generalize for this dynamic configuration. To address this, we formulate a
Locus-Conditioned Maximum A-Posteriori (LC-MAP) scheme to generate acoustically
informed and geometrically consistent priors, ensuring a physically plausible
initial state for a joint TDOA-FDOA filtering. We integrate this into an
unscented Kalman filtering (UKF) pipeline, which provides reliable convergence
under nonlinearity and measurement noise. Extensive Monte Carlo analyses,
Gazebo-based physics simulations, and field trials demonstrate that the
proposed framework can reliably estimate the 3D position and velocity of an
adversarial acoustic attack source in real time. It achieves sub-meter
localization accuracy and over 90% success rates, with convergence times nearly
halved compared to baseline methods. Overall, this study establishes a
geometry-aware, real-time approach for acoustic threat localization, advancing
autonomous surveillance capabilities of underwater infrastructures.

</details>


### [20] [Sensing Security in Near-Field ISAC: Exploiting Scatterers for Eavesdropper Deception](https://arxiv.org/abs/2510.20140)
*Jiangong Chen,Xia Lei,Kaitao Meng,Kawon Han,Yuchen Zhang,Christos Masouros,Athina P. Petropulu*

Main category: eess.SP

TL;DR: 提出了一种在近场ISAC场景中利用已知散射体进行位置欺骗的方案，通过向散射体分配更多探测功率来误导窃听者，使其将散射体误认为目标。


<details>
  <summary>Details</summary>
Motivation: 在近场集成感知与通信场景中，需要保护感知安全，防止具有感知能力的窃听者正确识别目标位置。

Method: 使用分数规划和半定松弛方法优化波束成形策略，在合法感知SINR约束下最大化加权和速率和散射体分配功率，实现通信、感知和感知安全的三方权衡。

Result: 仿真结果表明该方案能灵活调整波束成形策略，显著增强窃听者端的杂波信号强度，导致实际目标的混淆甚至漏检。

Conclusion: 所提出的位置欺骗方案能有效保护感知安全，无需窃听者特征或位置信息即可实现目标混淆，实现了通信、感知和安全的灵活权衡。

Abstract: In this paper, we explore sensing security in near-field (NF) integrated
sensing and communication (ISAC) scenarios by exploiting known scatterers in
the sensing scene. We propose a location deception (LD) scheme where scatterers
are deliberately illuminated with probing power that is higher than that
directed toward targets of interest, with the goal of deceiving potential
eavesdroppers (Eves) with sensing capability into misidentifying scatterers as
targets. While the known scatterers can be removed at the legitimate sensing
receiver, our LD approach causes Eves to misdetect targets. Notably, this
deception is achieved without requiring any prior information about the Eves'
characteristics or locations. To strike a flexible three-way tradeoff among
communication, sensing, and sensing-security performance, the sum rate and
power allocated to scatterers are weighted and maximized under a legitimate
radar signal-to-interference-plus-noise ratio (SINR) constraint. We employ the
fractional programming (FP) framework and semidefinite relaxation (SDR) to
solve this problem. To evaluate the security of the proposed LD scheme, the
Cramer-Rao Bound (CRB) and mean squared error (MSE) metrics are employed.
Additionally, we introduce the Kullback-Leibler Divergence (KLD) gap between
targets and scatterers at Eve to quantify the impact of the proposed LD
framework on Eve's sensing performance from an information-theoretical
perspective. Simulation results demonstrate that the proposed LD scheme can
flexibly adjust the beamforming strategy according to performance requirements,
thereby achieving the desired three-way tradeoff. In particular, in terms of
sensing security, the proposed scheme significantly enhances the clutter signal
strength at Eve's side, leading to confusion or even missed detection of the
actual target.

</details>


### [21] [Time-series Random Process Complexity Ranking Using a Bound on Conditional Differential Entropy](https://arxiv.org/abs/2510.20551)
*Jacob Ayers,Richard Hahnloser,Julia Ulrich,Lothar Sebastian Krapp,Remo Nitschke,Sabine Stoll,Balthasar Bickel,Reinhard Furrer*

Main category: eess.SP

TL;DR: 本文提出了一种基于预测误差协方差矩阵的时间序列复杂度排序方法，通过信息论预测误差边界理论框架，利用Hadamard不等式和协方差矩阵的半正定性来上界条件微分熵。


<details>
  <summary>Details</summary>
Motivation: 条件微分熵可以直观地衡量时间序列复杂度，但直接计算高维未知分布过程的条件微分熵往往不可行。本文旨在建立计算可行的复杂度排序方法。

Method: 基于Fang等人的信息论预测误差边界理论，进一步利用Hadamard不等式和协方差矩阵的半正定性来增加边界。通过两个合成实验验证：控制线性自回归过程和生物启发合成音频数据的复杂度排序。

Result: 实验表明，该方法能够有效恢复已知的复杂度排序，使用普通最小二乘预测误差熵代理和神经网络预测误差都能成功完成复杂度排序任务。

Conclusion: 该框架提供了一种计算可行的基于预测误差的时间序列复杂度排序方法，保持了信息论的理论基础。

Abstract: Conditional differential entropy provides an intuitive measure for relatively
ranking time-series complexity by quantifying uncertainty in future
observations given past context. However, its direct computation for
high-dimensional processes from unknown distributions is often intractable.
This paper builds on the information theoretic prediction error bounds
established by Fang et al. \cite{fang2019generic}, which demonstrate that the
conditional differential entropy \textbf{$h(X_k \mid X_{k-1},...,X_{k-m})$} is
upper bounded by a function of the determinant of the covariance matrix of
next-step prediction errors for any next step prediction model. We add to this
theoretical framework by further increasing this bound by leveraging Hadamard's
inequality and the positive semi-definite property of covariance matrices.
  To see if these bounds can be used to rank the complexity of time series, we
conducted two synthetic experiments: (1) controlled linear autoregressive
processes with additive Gaussian noise, where we compare ordinary least squares
prediction error entropy proxies to the true entropies of various additive
noises, and (2) a complexity ranking task of bio-inspired synthetic audio data
with unknown entropy, where neural network prediction errors are used to
recover the known complexity ordering.
  This framework provides a computationally tractable method for time-series
complexity ranking using prediction errors from next-step prediction models,
that maintains a theoretical foundation in information theory.

</details>


### [22] [Deep Learning Based Joint Space-Time-Frequency Domain Channel Prediction for Cell-Free Massive MIMO Systems](https://arxiv.org/abs/2510.20146)
*Yongning Qi,Tao Zhou,Zuowei Xiang,Liu Liu,Bo Ai*

Main category: eess.SP

TL;DR: 本文提出了一种基于深度学习的无蜂窝大规模MIMO系统联合空时频域信道预测方法，通过在Transformer编码器中添加频域卷积和空间卷积层来利用空时频相关性，在高速列车LTE网络中验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 无蜂窝大规模MIMO是6G通信系统的关键技术，准确的信道状态信息获取对系统性能至关重要。传统信道预测方法存在局限性，需要开发更有效的预测技术。

Method: 提出新颖的信道预测模型，在Transformer编码器中添加频域卷积(FreqConv)和空间卷积(SpaceConv)层，能够利用空时频相关性并在不规则AP部署中提取空间相关性。使用模拟数据集进行超参数优化，并在高速列车LTE网络中验证。

Result: 所提模型的预测精度高于传统模型，计算复杂度低于传统Transformer模型。在高速列车LTE网络中的验证结果表明，相比传统模型具有更高的预测精度。

Conclusion: 提出的基于深度学习的联合空时频域信道预测方法在无蜂窝大规模MIMO系统中表现出优越性能，为6G通信系统的信道预测提供了有效解决方案。

Abstract: The cell-free massive multi-input multi-output (CF-mMIMO) is a promising
technology for the six generation (6G) communication systems. Channel
prediction will play an important role in obtaining the accurate CSI to improve
the performance of CF-mMIMO systems. This paper studies a deep learning (DL)
based joint space-time-frequency domain channel prediction for CF-mMIMO.
Firstly, the prediction problems are formulated, which can output the
multi-step prediction results in parallel without error propagation. Then, a
novel channel prediction model is proposed, which adds frequency convolution
(FreqConv) and space convolution (SpaceConv) layers to Transformer-encoder. It
is able to utilize the space-time-frequency correlations and extract the space
correlation in the irregular AP deployment. Next, simulated datasets with
different sizes of service areas, UE velocities and scenarios are generated,
and correlation analysis and cross-validation are used to determine the optimal
hyper-parameters. According to the optimized hyper-parameters, the prediction
accuracy and computational complexity are evaluated based on simulated
datasets. It is indicated that the prediction accuracy of the proposed model is
higher than traditional model, and its computational complexity is lower than
traditional Transformer model. After that, the impacts of space-time-frequency
correlations on prediction accuracy are studied. Finally, realistic datasets in
a high-speed train (HST) long-term evolution (LTE) network are collected to
verify the prediction accuracy. The verification results demonstrate that it
also achieves higher prediction accuracy compared with traditional models in
the HST LTE network.

</details>


### [23] [NOMA for Visible Light Communications: Recent Advances and Future Directions](https://arxiv.org/abs/2510.20215)
*Xuesong Wang*

Main category: eess.SP

TL;DR: 本文综述了可见光通信(VLC)在6G网络中的潜力，重点探讨了非正交多址接入(NOMA)技术在VLC系统中的应用前景和优化方向。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络对高速数据传输需求的增长，VLC作为射频系统的补充技术具有重要价值。现有标准未充分利用光链路的特性，且VLC链路的非对称性使得传统TDMA协议效率低下，需要重新设计MAC层协议。

Method: 通过综述VLC和基于NOMA的VLC研究进展，分析关键优化约束和目标，调查适合NOMA的VLC场景，并指出未来研究方向。

Result: 发现NOMA技术允许多个用户共享相同时频资源，同时容忍可控干扰，在VLC系统中具有应用潜力。CSMA/CA等方法在VLC中仍可使用，但需要设计调整。

Conclusion: NOMA技术为6G VLC系统提供了有前景的解决方案，特别是在MAC层需要全新设计的背景下，未来需要在多个方向进行深入研究。

Abstract: Rapidly increasing demand for high speed data is pushing 6G wireless networks
to support larger link scales, lower latency, and higher spectral efficiency.
Visible light communications (VLC) is a strong complement to radio frequency
(RF) systems within 6G. The latest ITU G.9991 and IEEE 802.11bb standards are
adapted from cable and RF wireless technologies for use in VLC, so they do not
fully exploit the optical nature of light links. VLC links are often asymmetric
between uplink and downlink, which makes TDMA style protocols inefficient when
many users generate bursty and asymmetric traffic. Compared with RF, the strong
directionality and frequent line of sight in VLC can mitigate hidden and
exposed terminals, yet these effects can still appear under limited field of
view, blockage, or reflections. CSMA/CA and related methods remain usable in
VLC and in RF plus VLC networks, but they usually need design tweaks such as
RTS/CTS or directional sensing to perform well. Although the optical spectrum
is vast, the bandwidth of practical LEDs and of common PIN or APD receivers is
limited, so efficient multiple access can yield large gains. This motivates a
clean slate design for VLC, especially at the MAC layer. NOMA, first explored
in 5G RF systems, is also promising for 6G VLC. It lets multiple users share
the same time and frequency resources while tolerating controlled interference.
This paper reviews progress in VLC and in NOMA based VLC, outlines key
optimization constraints and objectives, surveys scenarios that fit NOMA in
VLC, and points to several directions for future work.

</details>


### [24] [A Survey of OTFS-Based Index Modulation Techniques: Challenges, Benefits, and Future Directions for 6G and Beyond](https://arxiv.org/abs/2510.20265)
*Burak Ahmet Ozden,Erdogan Aydin,Emir Aslandogan,Haci Ilhan,Ertugrul Basar,Miaowen Wen,Marco Di Renzo,Vincent Poor*

Main category: eess.SP

TL;DR: 本文综述了基于正交时频空间(OTFS)的索引调制(IM)无线通信系统，系统性地分类了现有OTFS-IM方案，比较了各种变体的性能，并讨论了挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: OTFS是一种在延迟多普勒域进行二维调制的技术，能够充分利用信道多样性并将快速时变信道转换为近乎静态信道。索引调制通过在选择通信资源索引中编码数据位来提高性能。结合两者可为6G及未来网络提供鲁棒、高容量的无线通信。

Method: 对现有OTFS-IM方案进行系统性综述和分类，包括系统架构、检测方法、性能分析等方面。描述了OTFS-IM变体的工作原理和系统模型，如基于OTFS的空间移位键控、空间调制、正交空间调制等。

Result: 提供了OTFS-IM系统的全面性能比较分析，包括计算复杂度、误码性能、容量、节能、频谱效率和吞吐量等方面。

Conclusion: 讨论了OTFS-IM系统面临的挑战、优势及未来发展方向，涵盖复杂度、效率、延迟、信道估计、硬件约束、同步、安全性等关键方面，以及与其它先进无线通信技术的潜在集成。

Abstract: Orthogonal time frequency space (OTFS) is a two-dimensional modulation
technique that uses the delay-Doppler (DD) domain and is a candidate for
providing robust, high-capacity wireless communications for envisioned 6G and
beyond networks. The OTFS technique maps data to the DD domain instead of the
traditional time-frequency domain, enabling it to fully utilize channel
diversity and transform fast time-varying channels into nearly static channels.
Index modulation (IM) is a communication paradigm that conveys information not
only through conventional modulation symbols but also by encoding data bits in
the indices of the selected communication resources to improve error
performance, spectral efficiency, and energy efficiency. In this survey, a
comprehensive review of work on OTFS-based wireless communication systems is
presented. In particular, the existing OTFS-IM schemes are reviewed and
systematically categorized according to their system architectures, detection
methods, and performance aspects such as capacity, peak-to-average power ratio,
diversity, complexity, imperfect channel state information, spectral
efficiency, and outage probability. Furthermore, the operating principles and
system models of OTFS-IM variants-including OTFS-based space shift keying,
OTFS-based spatial modulation, OTFS-based quadrature spatial modulation,
OTFS-based media-based modulation, and OTFS-based code index modulation-are
described, followed by a comparative performance analysis in terms of
computational complexity, error performance, capacity, energy saving, spectral
efficiency, and throughput. Finally, the challenges, benefits, and future
directions for OTFS-IM systems are discussed, covering key aspects such as
complexity, efficiency, latency, channel estimation, hardware constraints,
synchronization, security, and potential integration with other advanced
wireless communication techniques.

</details>


### [25] [Near-Field 3D Localization and MIMO Channel Estimation with Sub-Connected Planar Arrays](https://arxiv.org/abs/2510.20274)
*Kangda Zhi,Tianyu Yang,Songyan Xue,Giuseppe Caire*

Main category: eess.SP

TL;DR: 提出一种基于OMP和SBL的三阶段算法，用于近场XL-MIMO系统的信道估计和3D定位，显著降低了导频开销并提高了估计精度。


<details>
  <summary>Details</summary>
Motivation: 在近场XL-MIMO系统中，上行MIMO信道具有满列秩，现有针对远场或单天线用户的码本无法有效估计信道，需要新的解决方案。

Method: 三阶段算法：1) 将XL-MIMO划分为子阵列，使用OMP和DFT字典估计子阵列信道；2) 利用估计的子阵列信道，通过一维MUSIC和LS准则估计用户阵列中心位置；3) 使用估计的中心位置构建位置辅助字典，通过SBL获得MIMO信道估计。

Result: 与多个基准方法相比，所提算法在导频开销和估计精度方面均表现出显著优势。

Conclusion: 该三阶段算法有效解决了近场XL-MIMO系统的信道估计和3D定位问题，为大规模MIMO系统提供了实用的解决方案。

Abstract: This paper investigates the design of channel estimation and 3D localization
algorithms in a challenging scenario, where a sub-connected planar extremely
large-scale multiple-input multiple-output (XL-MIMO) communicates with
multi-antenna users. In the near field, the uplink MIMO channel is of full
column rank and therefore can not be estimated effectively by applying existing
codebooks that are designed for the far-field case or for the near-field case
but limited to single antenna users. To solve this problem, we propose a
three-stage algorithm aided by orthogonal matching pursuit (OMP) and sparse
Bayesian learning (SBL). Specifically, we firstly partition the XL-MIMO into
subarrays and use OMP to solve the compressed sensing (CS) problem about
subarray channel estimation with the Discrete Fourier Transform (DFT)-based
dictionary matrix. Secondly, exploiting the estimated subarray channels and
employing one-dimensional multiple signal classification (MUSIC), we estimate
the central location of the user array under the Least Squares (LS) criterion.
Finally, we utilize the estimated central location to construct a refined
location-aided dictionary matrix and obtain the MIMO channel estimation using
SBL. Results exhibit the significant superiority of the proposed algorithm
compared with several benchmarks, in terms of both the pilot overhead and
estimation accuracy.

</details>


### [26] [Channel Estimation and Passive Beamforming for Pixel-based Reconfigurable Intelligent Surfaces with Non-Separable State Response](https://arxiv.org/abs/2510.20354)
*Huayan Guo,Junhui Rao,Alex M. H. Wong,Ross Murch,Vincent K. N. Lau*

Main category: eess.SP

TL;DR: 提出针对像素型可重构智能表面(RIS)的完整解决方案，包括RIS响应函数近似、简化级联信道建模和低复杂度波束赋形算法，显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 像素型RIS通过消除传统RIS中的移相器降低硬件成本，但其不可分离状态响应特性给信道估计和波束赋形带来挑战，现有解决方案无法有效处理。

Method: 1) 使用核方法和深度神经网络近似RIS响应函数；2) 提出简化级联信道模型，关注主导散射路径；3) 分别估计短期和长期参数的自定义算法；4) 低复杂度被动波束赋形算法配置离散RIS状态向量。

Result: 仿真结果表明，所提出的解决方案在广泛的SNR范围内显著优于各种基线方法。

Conclusion: 该研究为像素型RIS系统提供了有效的信道估计和波束赋形解决方案，在保持低硬件成本的同时实现了高性能。

Abstract: Pixel-based reconfigurable intelligent surfaces (RISs) employ a novel design
to achieve high reflection gain at a lower hardware cost by eliminating the
phase shifters used in traditional RIS. However, this design presents
challenges for channel estimation and passive beamforming due to its
non-separable state response, rendering existing solutions ineffective. To
address this, we first approximate the non-separable RIS response functions
using a kernel-based method and a deep neural network, achieving high accuracy
while reducing computational and memory complexity. Next, we propose a
simplified cascaded channel model that focuses on dominated scattering paths
with limited unknown parameters, along with customized algorithms to estimate
short-term and long-term parameters separately. Finally, we introduce a
low-complexity passive beamforming algorithm to configure the discrete RIS
state vector, maximizing the achievable rate. Our simulation results
demonstrate that the proposed solution significantly outperforms various
baselines across a wide SNR range.

</details>


### [27] [A Transformer Inspired AI-based MIMO receiver](https://arxiv.org/abs/2510.20363)
*András Rácz,Tamás Borsos,András Veres,Benedek Csala*

Main category: eess.SP

TL;DR: AttDet是一种基于Transformer的MIMO检测方法，将每个传输层视为token，通过轻量级自注意力机制学习流间干扰，结合模型可解释性和数据驱动灵活性。


<details>
  <summary>Details</summary>
Motivation: 解决MIMO系统中传统检测方法在高阶调制和复杂信道条件下性能不足的问题，同时保持计算复杂度可控。

Method: 将传输层作为token，直接从估计的信道矩阵生成query和key，注意力分数量化信道相关性，值由匹配滤波器输出初始化并迭代优化。

Result: 在5G信道模型和高阶混合QAM调制下，AttDet能够接近最优的BER/BLER性能，同时保持多项式复杂度。

Conclusion: AttDet成功结合了模型可解释性和数据驱动方法的灵活性，为MIMO检测提供了高效且性能优越的解决方案。

Abstract: We present AttDet, a Transformer-inspired MIMO (Multiple Input Multiple
Output) detection method that treats each transmit layer as a token and learns
inter-stream interference via a lightweight self-attention mechanism. Queries
and keys are derived directly from the estimated channel matrix, so attention
scores quantify channel correlation. Values are initialized by matched-filter
outputs and iteratively refined. The AttDet design combines model-based
interpretability with data-driven flexibility. We demonstrate through
link-level simulations under realistic 5G channel models and high-order, mixed
QAM modulation and coding schemes, that AttDet can approach near-optimal
BER/BLER (Bit Error Rate/Block Error Rate) performance while maintaining
predictable, polynomial complexity.

</details>


### [28] [Efficient Medium Access Control for Low-Latency Industrial M2M Communications](https://arxiv.org/abs/2510.20380)
*Anwar Ahmed Khan,Indrakshi Dey*

Main category: eess.SP

TL;DR: 本文比较了两种工业M2M网络MAC协议：基于竞争窗口的BoP-MAC和基于分片的FROG-MAC。FROG-MAC通过分片低优先级流量实现高优先级数据早期传输，在多优先级异构数据环境中表现更优。


<details>
  <summary>Details</summary>
Motivation: 工业M2M网络中需要低延迟可靠通信，多优先级数据增加了挑战。过去十年开发了众多MAC方案，需要进行全面比较以了解各协议的相对优势和局限。

Method: 在Contiki平台上进行仿真，通过改变节点数量来比较BoP-MAC和FROG-MAC两种协议。BoP-MAC为多优先级流量分配差异化退避值，FROG-MAC通过分片低优先级流量实现高优先级数据早期传输。

Result: 在工业环境的多优先级异构数据处理中，FROG-MAC在延迟和吞吐量方面表现更优。

Conclusion: FROG-MAC协议在工业M2M网络的多优先级数据环境中具有更好的性能表现，特别是在延迟和吞吐量方面优于BoP-MAC。

Abstract: Efficient medium access control (MAC) is critical for enabling low-latency
and reliable communication in industrial Machine-to-Machine (M2M) net-works,
where timely data delivery is essential for seamless operation. The presence of
multi-priority data in high-risk industrial environments further adds to the
challenges. The development of tens of MAC schemes over the past decade often
makes it a tough choice to deploy the most efficient solu-tion. Therefore, a
comprehensive cross-comparison of major MAC protocols across a range of
performance parameters appears necessary to gain deeper insights into their
relative strengths and limitations. This paper presents a comparison of
Contention window-based MAC scheme BoP-MAC with a fragmentation based,
FROG-MAC; both protocols focus on reducing the delay for higher priority
traffic, while taking a diverse approach. BoP-MAC assigns a differentiated
back-off value to the multi-priority traffic, whereas FROG-MAC enables early
transmission of higher-priority packets by fragmenting lower-priority traffic.
Simulations were performed on Contiki by varying the number of nodes for two
traffic priorities. It has been shown that when work-ing with multi-priority
heterogenous data in the industrial environment, FROG-MAC results better both
in terms of delay and throughput.

</details>


### [29] [Inference-Optimal ISAC via Task-Oriented Feature Transmission and Power Allocation](https://arxiv.org/abs/2510.20429)
*Biao Dong,Bin Cao,Qinyu Zhang*

Main category: eess.SP

TL;DR: 该论文研究集成感知与通信系统中基于压缩估计框架的协调增益，以推断性能为关键指标，通过判别增益最大化而非均方误差最小化来优化收发器设计。


<details>
  <summary>Details</summary>
Motivation: 探索在集成感知与通信系统中，通过最大化判别增益而非传统的最小化均方误差是否能获得更好的推断性能，并实现更高效的功率分配。

Method: 提出基于判别增益的收发器优化设计，推导出闭式解，采用注水型功率分配结构，明确感知与通信的权衡关系。

Result: 数值实验表明，判别增益最优设计在低信噪比下实现更节能的传输，通过选择性分配功率到信息特征来节省感知发射功率。

Conclusion: 判别增益最大化策略在集成感知与通信系统中优于传统均方误差最小化方法，特别是在低信噪比条件下能实现更高效的功率利用。

Abstract: This work is concerned with the coordination gain in integrated sensing and
communication (ISAC) systems under a compress-and-estimate (CE) framework,
wherein inference performance is leveraged as the key metric. To enable
tractable transceiver design and resource optimization, we characterize
inference performance via an error probability bound as a monotonic function of
the discriminant gain (DG). This raises the natural question of whether
maximizing DG, rather than minimizing mean squared error (MSE), can yield
better inference performance. Closed-form solutions for DG-optimal and
MSE-optimal transceiver designs are derived, revealing water-filling-type
structures and explicit sensing and communication (S\&C) tradeoff. Numerical
experiments confirm that DG-optimal design achieves more power-efficient
transmission, especially in the low signal-to-noise ratio (SNR) regime, by
selectively allocating power to informative features and thus saving transmit
power for sensing.

</details>


### [30] [Analysis of Frequency-Diverse and Dispersion Effects in Dynamic Metasurface Antenna for Holographic Sensing and Imaging](https://arxiv.org/abs/2510.20447)
*Abdul Jabbar,Aakash Bansal,William Whittow*

Main category: eess.SP

TL;DR: 本文展示了毫米波动态超表面天线(DMA)的频率多样性和色散操作，通过动态全息可重构性实现灵活的色散操控，在不同频率产生不同辐射模式，为下一代近场和远场全息传感应用提供新方法。


<details>
  <summary>Details</summary>
Motivation: 当前DMA设计和模型通常是准窄带的，忽略了频率多样性表现及其利用。本文旨在探索DMA的频率多样性和色散操作潜力。

Method: 通过动态全息可重构性操控DMA中元原子的色散特性，在不同工作频率产生不同的辐射模式。

Result: 实现了灵活的色散操控，在紧凑可重构平台上增强了扫描范围，无需宽带系统或复杂移相网络。

Conclusion: 研究结果为下一代近场和远场全息传感及计算全息成像应用中DMA色散效应的建模和利用提供了基础见解。

Abstract: Dynamic metasurface antennas (DMAs) represent a novel approach to
programmable and affordable electromagnetic wave manipulation for enhanced
wireless communications, sensing, and imaging applications. Nevertheless,
current DMA designs and models are usually quasi-narrowband, neglecting the
versatile frequency-diverse manifestation and its utilization. This work
demonstrates the frequency-diversity and dispersion operations of a
representative DMA structure at the millimeter-wave band. We demonstrate
flexible dispersion manipulation through dynamic holographic reconfigurability
of the meta-atoms in a DMA. This effect can create distinct radiation patterns
across the operating frequency band, achieving flexible frequency diversity
with enhanced scanning range within a compact, reconfigurable platform. It
eliminates the need for wideband systems or complex phase-shifting networks
while offering an alternative to frequency-scanned static beams of traditional
leaky-wave antennas. The results establish fundamental insights into modelling
and utilization of dispersive effects of DMAs in next-generation near-field and
far-field holographic sensing and computational holographic imaging
applications.

</details>


### [31] [An Accelerated Mixed Weighted-Unweighted MMSE Approach for MU-MIMO Beamforming](https://arxiv.org/abs/2510.20507)
*Xi Gao,Akang Wang,Junkai Zhang,Qihong Duan,Jiang Xue*

Main category: eess.SP

TL;DR: 提出了一种基于块坐标下降框架的高并行算法A-MMMSE，用于多用户MIMO系统的预编码设计，避免了矩阵求逆，仅使用矩阵乘法，适合GPU加速，性能与WMMSE相当但计算时间显著减少。


<details>
  <summary>Details</summary>
Motivation: 传统WMMSE算法由于矩阵求逆导致计算复杂度高（基站天线数的三次方），在延迟敏感场景中应用受限。

Method: 采用块坐标梯度下降更新预编码矩阵，避免矩阵求逆，仅依赖矩阵乘法；引入基于和均方误差最小化问题的两阶段热启动策略加速收敛。

Result: 仿真结果表明A-MMMSE在加权和速率性能上与WMMSE及其增强变体reduced-WMMSE相当，同时在各种系统配置下显著减少计算时间。

Conclusion: A-MMMSE算法通过避免矩阵求逆和利用GPU并行性，在保持性能的同时大幅降低了计算复杂度，适用于延迟敏感的多用户MIMO系统。

Abstract: Precoding design based on weighted sum-rate (WSR) maximization is a
fundamental problem in downlink multi-user multiple-input multiple-output
(MU-MIMO) systems. While the weighted minimum mean-square error (WMMSE)
algorithm is a standard solution, its high computational complexity--cubic in
the number of base station antennas due to matrix inversions--hinders its
application in latency-sensitive scenarios. To address this limitation, we
propose a highly parallel algorithm based on a block coordinate descent
framework. Our key innovation lies in updating the precoding matrix via block
coordinate gradient descent, which avoids matrix inversions and relies solely
on matrix multiplications, making it exceptionally amenable to GPU
acceleration. We prove that the proposed algorithm converges to a stationary
point of the WSR maximization problem. Furthermore, we introduce a two-stage
warm-start strategy grounded in the sum mean-square error (MSE) minimization
problem to accelerate convergence. We refer to our method as the Accelerated
Mixed weighted-unweighted sum-MSE minimization (A-MMMSE) algorithm. Simulation
results demonstrate that A-MMMSE matches the WSR performance of both
conventional WMMSE and its enhanced variant, reduced-WMMSE, while achieving a
substantial reduction in computational time across diverse system
configurations.

</details>


### [32] [Performance Analysis of End-to-End LEO Satellite-Aided Shore-to-Ship Communications: A Stochastic Geometry Approach](https://arxiv.org/abs/2510.20515)
*Xu Hu,Bin Lin,Xiao Lu,Ping Wang,Nan Cheng,Zhisheng Yin,Weihua Zhuang*

Main category: eess.SP

TL;DR: 提出了一种用于低地球轨道卫星辅助岸到船通信网络的理论框架，使用二项点过程建模卫星分布，通过随机几何方法推导端到端传输性能的解析表达式。


<details>
  <summary>Details</summary>
Motivation: 传统基于多圆轨道的性能建模难以表征大规模LEO卫星星座，需要一种可处理的方法来准确评估网络性能。

Method: 将LEO卫星建模为特定球面上的二项点过程，考虑海洋链路和空间链路的信号传输，提出距离近似方法，结合阈值通信方案，利用随机几何推导性能指标。

Result: 广泛的数值结果验证了分析的准确性，并展示了关键参数对LEO-SSCN性能的影响。

Conclusion: 所提出的理论框架能够准确评估LEO卫星辅助岸到船通信网络的性能，为大规模卫星星座的性能分析提供了有效工具。

Abstract: Low Earth orbit (LEO) satellite networks have shown strategic superiority in
maritime communications, assisting in establishing signal transmissions from
shore to ship through space-based links. Traditional performance modeling based
on multiple circular orbits is challenging to characterize large-scale LEO
satellite constellations, thus requiring a tractable approach to accurately
evaluate the network performance. In this paper, we propose a theoretical
framework for an LEO satellite-aided shore-to-ship communication network
(LEO-SSCN), where LEO satellites are distributed as a binomial point process
(BPP) on a specific spherical surface. The framework aims to obtain the
end-to-end transmission performance by considering signal transmissions through
either a marine link or a space link subject to Rician or Shadowed Rician
fading, respectively. Due to the indeterminate position of the serving
satellite, accurately modeling the distance from the serving satellite to the
destination ship becomes intractable. To address this issue, we propose a
distance approximation approach. Then, by approximation and incorporating a
threshold-based communication scheme, we leverage stochastic geometry to derive
analytical expressions of end-to-end transmission success probability and
average transmission rate capacity. Extensive numerical results verify the
accuracy of the analysis and demonstrate the effect of key parameters on the
performance of LEO-SSCN.

</details>
