<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 12]
- [cs.IT](#cs.IT) [Total: 9]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Distributed Detection and Bandwidth Allocation with Hybrid Quantized and Full-Precision Observations over Multiplicative Fading Channels](https://arxiv.org/abs/2510.06429)
*Linlin Mao,Zeping Sui,Michail Matthaiou,Hongbin Li*

Main category: eess.SP

TL;DR: 提出了一种融合量化和全精度观测的混合检测器，用于加性和乘性高斯噪声下的弱信号检测。通过局部最优检验、量化阈值优化和带宽分配策略，在误码信道条件下表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 解决在加性和乘性高斯噪声环境下，传统检测器对弱信号检测性能不足的问题，特别是在带宽受限和误码信道条件下的检测挑战。

Method: 1. 基于复合观测概率分布推导局部最优检验混合检测器；2. 优化传感器级量化阈值；3. 提出混合整数线性规划方法解决带宽分配优化问题。

Result: 仿真结果表明，所提出的混合检测器和带宽分配策略在具有挑战性的误码信道条件下表现出优越性能。

Conclusion: 该混合检测器通过融合不同精度观测和优化带宽分配，有效提升了弱信号检测性能，特别适用于误码信道环境。

Abstract: A hybrid detector that fuses both quantized and full-precision observations
is proposed for weak signal detection under additive and multiplicative
Gaussian noise. We first derive a locally most powerful test (LMPT)--based
hybrid detector from the composite probability distribution of the compound
observations received by the fusion center, and then analyze its asymptotic
detection performance. Subsequently, we optimize the sensor-wise quantization
thresholds to achieve near-optimal asymptotic performance at the local sensor
level. Moreover, we propose a mixed-integer linear programming approach to
solve the optimization problem of transmission bandwidth allocation accounting
for bandwidth constraints and error-prone channels. Finally, simulation results
demonstrate the superiority of the proposed hybrid detector and the bandwidth
allocation strategy, especially in challenging error-prone channel conditions.

</details>


### [2] [Optimized SVR Framework for Electric Load Forecasting](https://arxiv.org/abs/2510.06476)
*Nishant Gadde,Yoshua Alexander,Sarvesh Parthasarthy,Arman Allidina*

Main category: eess.SP

TL;DR: 本文提出了一种基于支持向量回归(SVR)的电力负荷预测框架，相比行业标准方法在各项评估指标上表现更优，特别是在MSE和MAE方面有显著提升。


<details>
  <summary>Details</summary>
Motivation: 由于电力系统日益复杂、极端天气增多以及用户能源需求变化，传统负荷预测方法有时会失效，需要更准确的预测工具来支持电网运营。

Method: 采用支持向量回归(SVR)框架进行电力负荷预测，该方法在机器学习中具有良好的泛化能力和非线性处理能力。

Result: SVR模型在所有重要评估指标上都优于行业标准：MSE降低54.2%(31.91 vs 69.63)，MAE改善33.5%，其他指标也有性能提升。

Conclusion: 该SVR方法为电力系统规划和资源分配提供了额外的准确性检查工具，在与电力预测工具集成时显示出显著优势。

Abstract: Load forecasting has always been a challenge for grid operators due to the
growing complexity of power systems. The increase in extreme weather and the
need for energy from customers has led to load forecasting sometimes failing.
This research presents a Support Vector Regression (SVR) framework for electric
load forecasting that outperforms the industry standard. The SVR model
demonstrates better accuracy across all evaluation metrics that are important
for power system operations. The model has a 54.2\% reduction in Mean Squared
Error (31.91 vs. 69.63), a 33.5\% improvement in Mean Absolute Error, and
performance benefits across other metrics. These improvements show significant
benefits when integrated with power forecasting tools and show that the
approach provides an additional tool for accuracy checking for system planning
and resource allocation in times of need for resource allocation in electric
power systems.

</details>


### [3] [Cooperative Multi-Static ISAC Networks: A Unified Design Framework for Active and Passive Sensing](https://arxiv.org/abs/2510.06654)
*Yan Yang,Zhendong Li,Jianwei Zhao,Qingqing Wu,Zhiqing Wei,Wen Chen,Weimin Jia*

Main category: eess.SP

TL;DR: 提出了一个联合主动和被动感知(JAPS)的统一设计框架，用于多静态协作ISAC系统，通过交替优化算法最大化DL和UL传输的和速率，同时满足感知要求和功率约束。


<details>
  <summary>Details</summary>
Motivation: 多静态协作感知是推进集成感知与通信(ISAC)的有前景技术，能够提高感知精度和范围。

Method: 采用交替优化(AO)架构，使用基于逐次凸逼近(SCA)和惩罚的算法解决波束赋形子问题，以及基于分数规划(FP)的算法解决接收滤波器和UL功率优化子问题。

Result: 广泛的数值结果验证了所提JAPS方案的性能提升，并证明了所提算法的有效性。

Conclusion: 所提出的JAPS框架和算法能够有效解决多静态ISAC系统中的联合优化问题，实现通信和感知性能的平衡。

Abstract: Multi-static cooperative sensing emerges as a promising technology for
advancing integrated sensing and communication (ISAC), enhancing sensing
accuracy and range. In this paper, we develop a unified design framework for
joint active and passive sensing (JAPS). In particular, we consider a JAPSbased
cooperative multi-static ISAC system for coexisting downlink (DL) and uplink
(UL) communications. An optimization problem is formulated for maximizing the
sum rate of both the DL and UL transmissions via jointly optimizing
beamforming, receive filters and power allocation, while guaranteeing the
sensing requirements and transmission power constraints. However, the
formulated problem is a non-convex optimization problem that is challenging to
solve directly due to the tight coupling among optimization variables. To
tackle this complicated issue, we employ an efficient algorithm architecture
leveraging alternating optimization (AO). Specifically, with the given receive
filters and transmission power for UL communication, the transmit beamforming
subproblem is addressed by successive convex approximation (SCA)-based and
penalty-based algorithms. A fractional programming (FP)-based algorithm is
developed to tackle the receive filters and transmission power for UL
communication optimization subproblem. Extensive numerical results validate the
performance improvement of our proposed JAPS scheme and demonstrate the
effectiveness of our proposed algorithms.

</details>


### [4] [Personalized Federated Learning-Driven Beamforming Optimization for Integrated Sensing and Communication Systems](https://arxiv.org/abs/2510.06709)
*Zhou Ni,Sravan Reddy Chintareddy,Peiyuan Guan,Morteza Hashemi*

Main category: eess.SP

TL;DR: 提出基于期望最大化算法的个性化联邦学习框架，用于ISAC系统中的多目标优化，通过自适应权重聚合提升通信与感知任务的性能。


<details>
  <summary>Details</summary>
Motivation: 标准联邦学习方法对所有客户端统一处理，无法适应ISAC系统中通信与感知目标的竞争性需求，需要个性化方法处理应用特定的权衡。

Method: 使用EM算法让每个基站自适应确定聚合权重，计算EM后验概率来量化全局模型与局部模型的相对适用性，基于模型在各自数据集上的损失。

Result: 在目标同质和异质条件下进行仿真，结果显示该方法优于FedPer和pFedMe等现有PFL基线，收敛更快且多目标性能更好。

Conclusion: 所提出的EM-PFL框架能有效处理ISAC系统中的多目标优化问题，使基站能够动态适应应用特定的权衡需求。

Abstract: In this paper, we propose an Expectation-Maximization-based (EM) Personalized
Federated Learning (PFL) framework for multi-objective optimization (MOO) in
Integrated Sensing and Communication (ISAC) systems. In contrast to standard
federated learning (FL) methods that handle all clients uniformly, the proposed
approach enables each base station (BS) to adaptively determine its aggregation
weight with the EM algorithm. Specifically, an EM posterior is computed at each
BS to quantify the relative suitability between the global and each local
model, based on the losses of models on their respective datasets. The proposed
method is especially valuable in scenarios with competing communication and
sensing objectives, as it enables BSs to dynamically adapt to
application-specific trade-offs. To assess the effectiveness of the proposed
approach, we conduct simulation studies under both objective-wise homogeneous
and heterogeneous conditions. The results demonstrate that our approach
outperforms existing PFL baselines, such as FedPer and pFedMe, achieving faster
convergence and better multi-objective performance.

</details>


### [5] [Low Complexity Weight Flexible Decoding Schemes of Linear Block Code for 6G xURLLC](https://arxiv.org/abs/2510.06768)
*Di Zhang,Yinglei Yang,Zhilong Liu,Shaobo Jia,Kyungchun Lee,Zhirong Zhang*

Main category: eess.SP

TL;DR: 提出基于对偶码字特性的线性分组码解码方案，利用灵活权重的对偶码字提供错误位置和幅度的解码信息，实现更高可靠性性能。


<details>
  <summary>Details</summary>
Motivation: 低复杂度纠错码是6G时代超可靠低延迟通信(xURLLC)的关键使能技术，需要开发高效解码方案。

Method: 提出两种解码方案：一种直接利用内在信息进行迭代解码，另一种将先验信道信息与内在信息结合进行解码。两种方案都使用向量乘法和实数比较实现，便于硬件实现。

Result: 仿真结果验证了所提方案的有效性。

Conclusion: 利用对偶码字的灵活权重特性可以提供有用的错误位置和幅度信息，从而提高解码可靠性，且方案易于硬件实现。

Abstract: Low complexity error correction code is a key enabler for next generation
ultra-reliable low-latency communications (xURLLC) in six generation (6G).
Against this background, this paper proposes a decoding scheme for linear block
code by leveraging certain interesting properties of dual codewords. It is
found that dual codewords with flexible weights can provide useful decoding
information for the locations and magnitudes of error bits, which yielding
higher reliability performance. In addition, two decoding schemes are proposed,
in which one directly utilizes intrinsic information for iterative decoding,
and the other combines prior channel information with intrinsic information for
decoding. Both schemes are implemented using vector multiplication and
real-number comparisons, making them easy to implement in hardware. Simulation
results demonstrate the validness of our study.

</details>


### [6] [Mobility-Aware Localization in mmWave Channel: Adaptive Hybrid Filtering Approach](https://arxiv.org/abs/2510.06861)
*Abidemi Orimogunje,Kyeong-Ju Cha,Hyunwoo Park,Abdulahi A. Badrudeen,Sunwoo Kim,Dejan Vukobratovic*

Main category: eess.SP

TL;DR: 提出了一种混合移动感知自适应框架，在行人速度下使用扩展卡尔曼滤波器，在车辆速度下使用无迹卡尔曼滤波器，通过自适应噪声缩放、卡方门控和Rauch-Tung-Striebel平滑来改善用户定位精度。


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络中精确的用户定位和跟踪对于能效和超可靠低延迟应用至关重要。传统卡尔曼滤波定位技术存在计算复杂度高、数据关联问题，且随着用户轨迹速度增加，估计误差会增大。

Method: 利用毫米波信号进行联合感知和通信，无需额外传感器。采用混合移动感知自适应框架，根据速度选择扩展卡尔曼滤波器（行人速度）或无迹卡尔曼滤波器（车辆速度），结合自适应噪声缩放、卡方门控和Rauch-Tung-Striebel平滑技术。

Result: 使用绝对轨迹误差、相对位姿误差、归一化估计误差平方和均方根误差等指标评估，在各自场景下显示出约30-60%的改进，明显优于现有针对室内或静态场景的方法。

Conclusion: 该方法能够有效缓解数据关联问题和估计误差，在不同速度场景下都表现出优越的定位性能，为下一代无线网络的精确定位提供了有效解决方案。

Abstract: Precise user localization and tracking enhances energy-efficient and
ultra-reliable low latency applications in the next generation wireless
networks. In addition to computational complexity and data association
challenges with Kalman-filter localization techniques, estimation errors tend
to grow as the user's trajectory speed increases. By exploiting mmWave signals
for joint sensing and communication, our approach dispenses with additional
sensors adopted in most techniques while retaining high resolution spatial
cues. We present a hybrid mobility-aware adaptive framework that selects the
Extended Kalman filter at pedestrian speed and the Unscented Kalman filter at
vehicular speed. The scheme mitigates data-association problem and estimation
errors through adaptive noise scaling, chi-square gating, Rauch-Tung-Striebel
smoothing. Evaluations using Absolute Trajectory Error, Relative Pose Error,
Normalized Estimated Error Squared and Root Mean Square Error metrics
demonstrate roughly 30-60% improvement in their respective regimes indicating a
clear advantage over existing approaches tailored to either indoor or static
settings.

</details>


### [7] [Memory-Augmented Generative AI for Real-time Wireless Prediction in Dynamic Industrial Environments](https://arxiv.org/abs/2510.06884)
*Rahul Gulia,Amlan Ganguly,Michael E. Kuhl,Ehsan Rashedi,Clark Hochgraf*

Main category: eess.SP

TL;DR: Evo-WISVA是一种用于工业4.0环境下无线信道预测的深度学习架构，通过结合变分自编码器和卷积LSTM网络，实现了对信号干扰噪声比(SINR)的准确实时预测，在复杂动态环境中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统物理或统计模型无法应对智能仓库中移动障碍物和瞬时干扰带来的时空复杂性，而超可靠低延迟通信(URLLC)需要准确实时的无线信道条件预测。

Method: 提出Evo-WISVA架构，集成带有注意力驱动潜在记忆模块的变分自编码器进行空间特征提取，以及卷积LSTM网络进行时间预测和序列优化，通过端到端的联合损失函数优化整个流程。

Result: 在高保真ns-3生成的工业仓库数据集上，Evo-WISVA显著超越现有基准方法，平均重建误差降低达47.6%，在未见环境中表现出优异的泛化能力，同时保持实时部署所需的计算效率。

Conclusion: Evo-WISVA为主动无线资源管理建立了基础技术，实现了自主优化，推动了工业通信网络中预测性数字孪生的发展。

Abstract: Accurate and real-time prediction of wireless channel conditions,
particularly the Signal-to-Interference-plus-Noise Ratio (SINR), is a
foundational requirement for enabling Ultra-Reliable Low-Latency Communication
(URLLC) in highly dynamic Industry 4.0 environments. Traditional physics-based
or statistical models fail to cope with the spatio-temporal complexities
introduced by mobile obstacles and transient interference inherent to smart
warehouses. To address this, we introduce Evo-WISVA (Evolutionary Wireless
Infrastructure for Smart Warehouse using VAE), a novel synergistic deep
learning architecture that functions as a lightweight 2D predictive digital
twin of the radio environment. Evo-WISVA integrates a memory-augmented
Variational Autoencoder (VAE) featuring an Attention-driven Latent Memory
Module (LMM) for robust, context-aware spatial feature extraction, with a
Convolutional Long Short-Term Memory (ConvLSTM) network for precise temporal
forecasting and sequential refinement. The entire pipeline is optimized
end-to-end via a joint loss function, ensuring optimal feature alignment
between the generative and predictive components. Rigorous experimental
evaluation conducted on a high-fidelity ns-3-generated industrial warehouse
dataset demonstrates that Evo-WISVA significantly surpasses state-of-the-art
baselines, achieving up to a 47.6\% reduction in average reconstruction error.
Crucially, the model exhibits exceptional generalization capacity to unseen
environments with vastly increased dynamic complexity (up to ten simultaneously
moving obstacles) while maintaining amortized computational efficiency
essential for real-time deployment. Evo-WISVA establishes a foundational
technology for proactive wireless resource management, enabling autonomous
optimization and advancing the realization of predictive digital twins in
industrial communication networks.

</details>


### [8] [Sensing Management for Pilot-Free Predictive Beamforming in Cell-Free Massive MIMO Systems](https://arxiv.org/abs/2510.06936)
*Eren Berk Kama,Murat Babek Salman,Isaac Skog,Emil Björnson*

Main category: eess.SP

TL;DR: 提出了一种用于无蜂窝大规模MIMO系统中集成感知与通信的感知管理方法，通过基于状态的跟踪和预测波束成形来减少信道估计开销。


<details>
  <summary>Details</summary>
Motivation: 传统通信系统的信道估计过程在数据传输期间产生显著开销，消耗了本可用于数据的资源。

Method: 采用基于状态的方法，利用感知能力在没有通信请求时跟踪用户；当收到通信请求时，基于跟踪的用户位置进行预测波束成形；结合扩展卡尔曼滤波跟踪算法和自适应感知管理。

Result: 仿真结果表明，所提出的感知管理方法通过实现无开销的预测波束成形，提供了比现有方法更高的均匀下行链路通信速率。

Conclusion: 该框架有效减少了信道估计开销，提高了系统性能。

Abstract: This paper introduces a sensing management method for integrated sensing and
communications (ISAC) in cell-free massive multiple-input multiple-output
(MIMO) systems. Conventional communication systems employ channel estimation
procedures that impose significant overhead during data transmission, consuming
resources that could otherwise be utilized for data. To address this challenge,
we propose a state-based approach that leverages sensing capabilities to track
the user when there is no communication request. Upon receiving a communication
request, predictive beamforming is employed based on the tracked user position,
thereby reducing the need for channel estimation. Our framework incorporates an
extended Kalman filter (EKF) based tracking algorithm with adaptive sensing
management to perform sensing operations only when necessary to maintain high
tracking accuracy. The simulation results demonstrate that our proposed sensing
management approach provides uniform downlink communication rates that are
higher than with existing methods by achieving overhead-free predictive
beamforming.

</details>


### [9] [Optimal Real-time Communication in 6G Ultra-Massive V2X Mobile Networks](https://arxiv.org/abs/2510.06937)
*He Huang,Zilong Liu,Zeping Sui,Wei Huang,Md. Noor-A-Rahim,Haishi Wang,Zhiheng Hu*

Main category: eess.SP

TL;DR: 提出了一种针对6G超大规模V2X网络的协同车辆通信算法，通过集成空间-空中-地面通信系统解决快速移动车辆间的实时信息交换问题。


<details>
  <summary>Details</summary>
Motivation: 解决未来6G网络中快速移动车辆间实时信息交换的挑战，利用集成空间-空中-地面通信系统提升通信性能。

Method: 证明了在固定中继数量下信道容量存在上界，并提出了一种低复杂度的中继选择启发式算法。

Result: 仿真结果表明，所提算法相比现有协同车辆通信方法获得了更优的信道容量。

Conclusion: 该算法为6G超大规模V2X网络提供了一种有效的协同通信解决方案，在保持低复杂度的同时提升了信道容量性能。

Abstract: This paper introduces a novel cooperative vehicular communication algorithm
tailored for future 6G ultra-massive vehicle-to-everything (V2X) networks
leveraging integrated space-air-ground communication systems. Specifically, we
address the challenge of real-time information exchange among rapidly moving
vehicles. We demonstrate the existence of an upper bound on channel capacity
given a fixed number of relays, and propose a low-complexity relay selection
heuristic algorithm. Simulation results verify that our proposed algorithm
achieves superior channel capacities compared to existing cooperative vehicular
communication approaches.

</details>


### [10] [Maritime Communication in Evaporation Duct Environment with Ship Trajectory Optimization](https://arxiv.org/abs/2510.06946)
*Ruifeng Gao,Hao Zhang,Jue Wang,Ye Li,Yingdong Hu,Qiuming Zhu,Shu Sun,Meixia Tao*

Main category: eess.SP

TL;DR: 提出了一种利用蒸发波导信道增益先验信息来优化船舶轨迹的框架，以减少数据传输时间和航行时间


<details>
  <summary>Details</summary>
Motivation: 在海上无线网络中，蒸发波导效应有利于长距离传输，但如何有效利用这种效应进行高效通信设计仍有待研究

Method: 采用动态种群PSO集成的NSGA-II算法求解多目标优化问题，优化船舶轨迹以最小化数据传输时间和航行时间

Result: 仿真表明，与忽略蒸发波导有用信息的基准方案相比，所提方案能有效减少数据传输时间和航行时间

Conclusion: 利用蒸发波导信道增益先验信息进行轨迹优化能显著提升海上船对岸数据传输效率

Abstract: In maritime wireless networks, the evaporation duct effect has been known as
a preferable condition for long-range transmissions. However, how to
effectively utilize the duct effect for efficient communication design is still
open for investigation. In this paper, we consider a typical scenario of
ship-to-shore data transmission, where a ship collects data from multiple
oceanographic buoys, sails from one to another, and transmits the collected
data back to a terrestrial base station during its voyage. A novel framework,
which exploits priori information of the channel gain map in the presence of
evaporation duct, is proposed to minimize the data transmission time and the
sailing time by optimizing the ship's trajectory. To this end, a
multi-objective optimization problem is formulated and is further solved by a
dynamic population PSO-integrated NSGA-II algorithm. Through simulations, it is
demonstrated that, compared to the benchmark scheme which ignores useful
information of the evaporation duct, the proposed scheme can effectively reduce
both the data transmission time and the sailing time.

</details>


### [11] [Towards Reliable Emergency Wireless Communications over SAGINs: A Composite Fading and QoS-Centric Perspective](https://arxiv.org/abs/2510.07120)
*Yinong Chen,Wenchi Cheng,Jingqing Wang,Xiao Zheng,Jiangzhou Wang*

Main category: eess.SP

TL;DR: 提出了一种基于Fisher-Snedecor F复合衰落模型的卫星-空中-地面综合网络性能建模框架，准确描述恶劣地面环境中的多径衰落和阴影效应，并分析了QoS约束下的有效容量、中断概率和ε中断容量。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视了复杂地形变化导致的信道特性，或在缺乏QoS约束下分析性能，导致理论分析与实际性能不匹配。需要建立更准确的性能建模框架来满足紧急无线通信场景的可靠、灵活、高速传输需求。

Method: 采用Fisher-Snedecor F复合衰落模型来表征空-地链路，开发了端到端信噪比统计的精确分布，分析了固定增益放大转发和解码转发中继协议的级联信道，并提供了渐近表达式。

Result: 通过现场测量和蒙特卡洛仿真验证了所提框架的有效性，渐近表达式在高信噪比区域与理论预测高度一致，提供了具有QoS保障的有效容量、中断概率和ε中断容量的闭式和渐近表达式。

Conclusion: 所建立的性能建模框架能够准确描述SAGIN在复杂信道条件下的性能，为紧急无线通信场景提供了可靠的理论分析工具，解决了现有研究理论与实际性能不匹配的问题。

Abstract: In emergency wireless communications (EWC) scenarios, ensuring reliable,
flexible, and high-rate transmission while simultaneously maintaining seamless
coverage and rapid response capabilities presents a critical technical
challenge. To this end, satellite-aerial-ground integrated network (SAGIN) has
emerged as a promising solution due to its comprehensive three-dimensional
coverage and capability to meet stringent, multi-faceted quality-of-service
(QoS) requirements. Nevertheless, most existing studies either neglected the
inherent characteristics of the complex channel conditions due to the terrain
changes or analyzed the performance in the absence of QoS constraints,
resulting in a mismatch between theoretical analysis and practical performance.
To remedy such deficiencies, in this paper we establish a performance modeling
framework for SAGIN employing the Fisher-Snedecor $\mathcal{F}$ composite
fading model to characterize the air-ground link. In specific, the proposed
$\mathcal{F}$ composite fading channel is adopted to accurately describe both
multipath fading and shadowing in harsh ground environments. The exact
distribution of end-to-end signal-to-noise (SNR) statistics for space-air and
air-ground links is developed, enabling theoretical analysis of cascaded
channels with fixed-gain amplify-and-forward (AF) and decode-and-forward (DF)
relaying protocols, respectively. Furthermore, asymptotic expressions of the
derived results are provided to offer concise representations and demonstrate
close alignment with theoretical predictions in the high-SNR regime. Finally,
the insightful closed-form and asymptotic expressions of effective capacity
with QoS provisioning, outage probability, and $\epsilon$-outage capacity are
investigated, respectively, followed by both field measurements and Monte Carlo
simulations to verify the effectiveness.

</details>


### [12] [Moments Matter: Posterior Recovery in Poisson Denoising via Log-Networks](https://arxiv.org/abs/2510.07199)
*Shirin Shoushtari,Edward P. Chandler,Ulugbek S. Kamilov*

Main category: eess.SP

TL;DR: 提出了一种基于对数网络的新策略用于泊松去噪，通过预测后验对数期望而非后验均值，能够恢复高阶后验矩并支持后验分布近似。


<details>
  <summary>Details</summary>
Motivation: 传统使用MSE损失训练的深度学习方法只能预测后验均值，无法捕捉泊松去噪中的后验不确定性，而Tweedie公式在泊松噪声下不再适用。

Method: 训练一个对数网络来学习后验对数期望E[log x|y]，利用对数作为泊松分布的便捷参数化方式。

Result: 在模拟数据上的实验表明，该方法在去噪性能上与标准MMSE模型相当，同时能够提供后验分布信息。

Conclusion: 所提出的对数网络方法既能保持去噪性能，又能恢复高阶后验矩，为泊松去噪提供了后验不确定性估计的能力。

Abstract: Poisson denoising plays a central role in photon-limited imaging applications
such as microscopy, astronomy, and medical imaging. It is common to train deep
learning models for denoising using the mean-squared error (MSE) loss, which
corresponds to computing the posterior mean $\mathbb{E}[x \mid y]$. When the
noise is Gaussian, Tweedie's formula enables approximation of the posterior
distribution through its higher-order moments. However, this connection no
longer holds for Poisson denoising: while $ \mathbb{E}[x \mid y] $ still
minimizes MSE, it fails to capture posterior uncertainty. We propose a new
strategy for Poisson denoising based on training a log-network. Instead of
predicting the posterior mean $ \mathbb{E}[x \mid y] $, the log-network is
trained to learn $\mathbb{E}[\log x \mid y]$, leveraging the logarithm as a
convenient parameterization for the Poisson distribution. We provide a
theoretical proof that the proposed log-network enables recovery of
higher-order posterior moments and thus supports posterior approximation.
Experiments on simulated data show that our method matches the denoising
performance of standard MMSE models while providing access to the posterior.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [13] [A doubly composite Chernoff-Stein lemma and its applications](https://arxiv.org/abs/2510.06342)
*Ludovico Lami*

Main category: cs.IT

TL;DR: 本文建立了适用于复合假设和真正相关分布的通用Chernoff-Stein引理，严格包含了大多数先前工作，并应用于零假设与复合i.i.d.或任意变化备择假设的区分问题。


<details>
  <summary>Details</summary>
Motivation: 现有Chernoff-Stein引理主要适用于简单假设或非真正相关的复合假设，缺乏对复合且真正相关分布的通用分析框架。

Method: 使用在广义量子Stein引理背景下开发的模糊技术的精细化版本，逐符号应用模糊处理，使其更强且适用于无置换对称性的情况。

Result: 建立了适用于复合假设和真正相关分布的通用Chernoff-Stein引理，提供了Stein指数的单字母公式，并建立了约束de Finetti约简陈述。

Conclusion: 新方法严格包含了大多数先前工作，能够处理更一般的假设检验问题，为量子假设检验等应用提供了理论基础。

Abstract: Given a sequence of random variables $X^n=X_1,\ldots, X_n$, discriminating
between two hypotheses on the underlying probability distribution is a key task
in statistics and information theory. Of interest here is the Stein exponent,
i.e. the largest rate of decay (in $n$) of the type II error probability for a
vanishingly small type I error probability. When the hypotheses are simple and
i.i.d., the Chernoff-Stein lemma states that this is given by the relative
entropy between the single-copy probability distributions. Generalisations of
this result exist in the case of composite hypotheses, but mostly to settings
where the probability distribution of $X^n$ is not genuinely correlated, but
rather, e.g., a convex combination of product distributions with components
taken from a base set. Here, we establish a general Chernoff-Stein lemma that
applies to the setting where both hypotheses are composite and genuinely
correlated, satisfying only generic assumptions such as convexity (on both
hypotheses) and some weak form of permutational symmetry (on either
hypothesis). Our result, which strictly subsumes most prior work, is proved
using a refinement of the blurring technique developed in the context of the
generalised quantum Stein's lemma [Lami, IEEE Trans. Inf. Theory 2025]. In this
refined form, blurring is applied symbol by symbol, which makes it both
stronger and applicable also in the absence of permutational symmetry. The
second part of the work is devoted to applications: we provide a single-letter
formula for the Stein exponent characterising the discrimination of broad
families of null hypotheses vs a composite i.i.d. or an arbitrarily varying
alternative hypothesis, and establish a 'constrained de Finetti reduction'
statement that covers a wide family of convex constraints. Applications to
quantum hypothesis testing are explored in a related paper [Lami, arXiv:today].

</details>


### [14] [$α$-leakage Interpretation of Rényi Capacity](https://arxiv.org/abs/2510.06622)
*Ni Ding,Farhad Farokhi,Tao Guo,Yinfei Xu,Xiang Zhang*

Main category: cs.IT

TL;DR: 本文提出了Y-基本α-泄漏的概念，将点式最大泄漏扩展到整个Rényi阶范围α∈[0,∞)，并给出了实现δ-近似ε-上界α-泄漏的充分条件。


<details>
  <summary>Details</summary>
Motivation: 研究Sibson互信息与α-泄漏之间的关系，扩展现有泄漏度量到更广泛的Rényi阶范围，为信息泄漏分析提供更全面的理论框架。

Method: 通过定义Y-基本α-泄漏，并将其在所有信道输入X的属性U上最大化得到Rényi散度，同时提出交替最大-最大实现方法来计算Rényi容量。

Result: 证明了Sibson互信息是α-泄漏在对手的f-均值相对信息增益上的平均值，Rényi容量可解释为在对手恶意推断决策和信道输入X上的最大f-均值信息泄漏。

Conclusion: 提出的Y-基本α-泄漏扩展了现有泄漏度量，为信息泄漏分析提供了更完整的理论工具，并给出了实现近似泄漏控制的充分条件和计算方法。

Abstract: For $\tilde{f}(t) = \exp(\frac{\alpha-1}{\alpha}t)$, this paper shows that
the Sibson mutual information is an $\alpha$-leakage averaged over the
adversary's $\tilde{f}$-mean relative information gain (on the secret) at
elementary event of channel output $Y$ as well as the joint occurrence of
elementary channel input $X$ and output $Y$. This interpretation is used to
derive a sufficient condition that achieves a $\delta$-approximation of
$\epsilon$-upper bounded $\alpha$-leakage. A $Y$-elementary $\alpha$-leakage is
proposed, extending the existing pointwise maximal leakage to the overall
R\'{e}nyi order range $\alpha \in [0,\infty)$. Maximizing this $Y$-elementary
leakage over all attributes $U$ of channel input $X$ gives the R\'{e}nyi
divergence. Further, the R\'{e}nyi capacity is interpreted as the maximal
$\tilde{f}$-mean information leakage over both the adversary's malicious
inference decision and the channel input $X$ (represents the adversary's prior
belief). This suggests an alternating max-max implementation of the existing
generalized Blahut-Arimoto method.

</details>


### [15] [Optimizing Fronthaul Quantization for Flexible User Load in Cell-Free Massive MIMO](https://arxiv.org/abs/2510.06734)
*Fabian Göttsch,Max Franke,Arash Pourdamghani,Giuseppe Caire,Stefan Schmid*

Main category: cs.IT

TL;DR: 研究可扩展用户中心无蜂窝大规模MIMO系统的物理层频谱效率和前传网络负载，通过优化量化率和前传路由来平衡系统性能。


<details>
  <summary>Details</summary>
Motivation: 解决用户中心无蜂窝大规模MIMO系统中前传链路容量有限的问题，需要量化数据传输，同时保持物理层性能。

Method: 使用混合整数线性规划联合优化簇处理器放置和前传流量路由，并基于率失真理论计算量化率。

Result: 优化量化率后，前传负载在广泛用户负载范围内保持稳定，且物理层性能损失不显著。

Conclusion: 无蜂窝大规模MIMO系统和前传网络对变化的用户密度具有弹性，可通过优化量化实现稳定性能。

Abstract: We investigate the physical layer (PHY) spectral efficiency and fronthaul
network load of a scalable user-centric cell-free massive MIMO system. Each
user-centric cluster processor responsible for cluster-level signal processing
is located at one of multiple decentralized units (DUs). Thus, the radio units
in the cluster must exchange data with the corresponding DU over the fronthaul.
Because the fronthaul links have limited capacity, this data must be quantized
before it is sent over the fronthaul. We consider a routed fronthaul network,
where the cluster processor placement and fronthaul traffic routing are jointly
optimized with a mixed-integer linear program. For different numbers of users
in the network, we investigate the effect of fronthaul quantization rates, a
system parameter computed based on rate-distortion theory. Our results show
that with optimized quantization rates, the fronthaul load is quite stable for
a wide range of user loads without significant PHY performance loss. This
demonstrates that the cell-free massive MIMO PHY and fronthaul network are
resilient to varying user densities.

</details>


### [16] [Multi-hop Deep Joint Source-Channel Coding with Deep Hash Distillation for Semantically Aligned Image Retrieval](https://arxiv.org/abs/2510.06868)
*Didrik Bergström,Deniz Gündüz,Onur Günlü*

Main category: cs.IT

TL;DR: 该论文提出了一种结合深度哈希蒸馏的深度联合源信道编码方法，用于多跳AWGN信道中的图像传输，通过语义聚类提升安全应用中的语义一致性和重建质量。


<details>
  <summary>Details</summary>
Motivation: 传统DeepJSCC在多跳信道中可能遭受噪声累积问题，需要提升语义一致性和感知重建质量，特别是在安全导向的应用场景中。

Method: 训练DeepJSCC编码器-解码器对，结合预训练的深度哈希蒸馏模块进行语义聚类，同时最小化MSE和源图像与重建图像DHD哈希的余弦距离。

Result: 在不同多跳设置下，语义对齐显著改善了感知质量，通过LPIPS指标验证了改进效果。

Conclusion: 结合深度哈希蒸馏的DeepJSCC方法能有效提升多跳信道中图像传输的语义一致性和感知重建质量。

Abstract: We consider image transmission via deep joint source-channel coding
(DeepJSCC) over multi-hop additive white Gaussian noise (AWGN) channels by
training a DeepJSCC encoder-decoder pair with a pre-trained deep hash
distillation (DHD) module to semantically cluster images, facilitating
security-oriented applications through enhanced semantic consistency and
improving the perceptual reconstruction quality. We train the DeepJSCC module
to both reduce mean square error (MSE) and minimize cosine distance between DHD
hashes of source and reconstructed images. Significantly improved perceptual
quality as a result of semantic alignment is illustrated for different
multi-hop settings, for which classical DeepJSCC may suffer from noise
accumulation, measured by the learned perceptual image patch similarity (LPIPS)
metric.

</details>


### [17] [A Stochastic Geometric Analysis on Multi-cell Pinching-antenna Systems under Blockage Effect](https://arxiv.org/abs/2510.06972)
*Yanshi Sun,Zhiguo Ding,George K. Karagiannidis*

Main category: cs.IT

TL;DR: 本文提出了一个多细胞夹捏天线系统的分析框架，考虑了连接到不同基站的分布式波导，使用随机几何工具进行建模，获得了中断概率表达式，并验证了夹捏天线系统优于固定天线系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有夹捏天线技术研究大多关注单细胞场景，忽略了连接到空间分布式基站的干扰夹捏天线对波导的影响，本文旨在填补这一知识空白。

Method: 应用随机几何工具进行系统建模，考虑连接到不同基站的分布式波导，推导出中断概率的解析表达式。

Result: 仿真结果验证了分析的准确性，并证明夹捏天线系统相比固定天线系统具有更优越的性能。

Conclusion: 本文为多细胞夹捏天线系统提供了一个有效的分析框架，证明了该技术在考虑干扰情况下的性能优势。

Abstract: Recently, the study on pinching-antenna technique has attracted significant
attention. However, most relevant literature focuses on a single-cell scenario,
where the effect from the interfering pinching-antennas on waveguides connected
to spatially distributed base stations (BSs) was ignored. To fulfill this
knowledge gap, this letter aims to provide an analytical framework on
performance evaluation for multi-cell pinching-antenna systems where spatially
distributed waveguides which are connected to different BSs are considered. In
particular, tools from stochastic geometry is applied for system modeling. The
expression for the outage probability is obtained. Simulation results are
provided to verify the accuracy of the analysis and demonstrate the superior
performance of pinching-antenna system compared to fixed-antenna systems.

</details>


### [18] [Lossless Compression of Time Series Data: A Comparative Study](https://arxiv.org/abs/2510.07015)
*Jonas G. Matt,Pengcheng Huang,Balz Maag*

Main category: cs.IT

TL;DR: 该研究对时间序列数据的无损压缩方法进行了大规模比较分析，提出了包含数据转换和熵编码两阶段的统一框架，通过消融实验揭示了不同算法面对各种时间序列特性时的优缺点。


<details>
  <summary>Details</summary>
Motivation: 数字世界中产生了前所未有的数据量，需要高效管理、传输和存储这些数据以节省资源并实现可扩展性。数据压缩在其中一直是关键技术，但目前缺乏对时间序列数据压缩方法的系统性比较研究。

Method: 构建包含数据转换和熵编码两阶段的统一压缩框架，在具有不同特性的合成和真实数据集上评估各种压缩算法，通过每个压缩阶段的消融实验来分离各组件对整体压缩性能的影响。

Result: 揭示了不同算法在面对多样化时间序列特性时的优势和弱点，强调了配置良好且完整的压缩管道的重要性，而不仅仅是单个组件或算法。

Conclusion: 研究为针对特定数据集选择和组合最合适的压缩算法提供了全面指南，证明了完整压缩管道配置的重要性。

Abstract: Our increasingly digital and connected world has led to the generation of
unprecedented amounts of data. This data must be efficiently managed,
transmitted, and stored to preserve resources and allow scalability. Data
compression has therein been a key technology for a long time, resulting in a
vast landscape of available techniques. This largest-to-date study analyzes and
compares various lossless data compression methods for time series data. We
present a unified framework encompassing two stages: data transformation and
entropy encoding. We evaluate compression algorithms across both synthetic and
real-world datasets with varying characteristics. Through ablation studies at
each compression stage, we isolate the impact of individual components on
overall compression performance -- revealing the strengths and weaknesses of
different algorithms when facing diverse time series properties. Our study
underscores the importance of well-configured and complete compression
pipelines beyond individual components or algorithms; it offers a comprehensive
guide for selecting and composing the most appropriate compression algorithms
tailored to specific datasets.

</details>


### [19] [Robustness of Covariance Estimators with Application in Activity Detection](https://arxiv.org/abs/2510.07044)
*Hendrik Bernd Zarucha,Peter Jung,Giuseppe Caire*

Main category: cs.IT

TL;DR: 该论文提出了一类通用的协方差估计器，证明了其在温和条件下的鲁棒性，并将其应用于多天线随机接入中的活动检测问题，提出了基于带符号核条件的码本设计。


<details>
  <summary>Details</summary>
Motivation: 研究通用协方差估计器的鲁棒性，并将其应用于解决多天线随机接入系统中活动检测的稀疏恢复问题。

Method: 定义由实值函数g和模型协方差矩阵集合H生成的协方差估计器类，通过最小化W^(1/2)Z^(-1)W^(1/2)的特征值的g函数和来估计协方差矩阵。在活动检测中，将大尺度衰落系数恢复问题转化为结构化协方差估计问题。

Result: 证明了在温和条件下，这类估计器具有鲁棒性；在活动检测中，当接收天线数足够多且S≤⌈1/2M^2⌉-1时，两种估计器都能恢复大尺度衰落系数。

Conclusion: 提出的通用协方差估计器具有鲁棒性，且能有效解决多天线随机接入系统中的活动检测问题，通过合适的码本设计可以实现对大尺度衰落系数的可靠恢复。

Abstract: The first part of this work considers a general class of covariance
estimators. Each estimator of that class is generated by a real-valued function
$g$ and a set of model covariance matrices $H$. If $\bf{W}$ is a potentially
perturbed observation of a searched covariance matrix, then the estimator is
the minimizer of the sum of $g$ applied to each eigenvalue of
$\bf{W}^\frac{1}{2}\bf{Z}^{-1}\bf{W}^\frac{1}{2}$ under the constraint that
$\bf{Z}$ is from $H$. It is shown that under mild conditions on $g$ and $H$
such estimators are robust, meaning the estimation error can be made
arbitrarily small if the perturbation of $\bf{W}$ gets small enough. \par In
the second part of this work the previous results are applied to activity
detection in random access with multiple receive antennas. In activity
detection recovering the large scale fading coefficients is a sparse recovery
problem which can be reduced to a structured covariance estimation problem. The
recovery can be done with a non-negative least squares estimator or with a
relaxed maximum likelihood estimator. It is shown that under suitable
assumptions on the distributions of the noise and the channel coefficients, the
relaxed maximum likelihood estimator is from the general class of covariance
estimators considered in the first part of this work. Then, codebooks based
upon a signed kernel condition are proposed. It is shown that with the proposed
codebooks both estimators can recover the large-scale fading coefficients if
the number of receive antennas is high enough and
$S\leq\left\lceil\frac{1}{2}M^2\right\rceil-1$ where $S$ is the number of
active users and $M$ is number of pilot symbols per user.

</details>


### [20] [A Theoretically-Grounded Codebook for Digital Semantic Communications](https://arxiv.org/abs/2510.07108)
*Lingyi Wang,Rashed Shelim,Walid Saad,Naren Ramakrishnan*

Main category: cs.IT

TL;DR: 提出了一种基于信息理论的可学习码本设计方法，用于数字语义通信中的量化映射，通过最大化语义信息和减少信道失真，在图像重建任务中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决语义通信中将高维语义特征映射到离散符号表示的问题，从信息理论角度优化码本设计，平衡量化效率、传输效率和鲁棒性能。

Method: 建立语义信息理论中的同义映射与码本Voronoi分区量化映射的等价关系，推导语义特征与量化索引的互信息，提出基于经验估计的熵正则化量化损失和信道感知语义失真损失进行端到端码本训练。

Result: 在图像重建任务中，当信噪比为10dB时，相比现有码本设计，峰值信噪比提升24.1%，学习感知图像块相似度提升46.5%。

Conclusion: 理论驱动的码本设计能有效提升语义通信性能，通过最大化语义信息和减少信道失真实现更好的量化效率和鲁棒性。

Abstract: The use of a learnable codebook provides an efficient way for semantic
communications to map vector-based high-dimensional semantic features onto
discrete symbol representations required in digital communication systems. In
this paper, the problem of codebook-enabled quantization mapping for digital
semantic communications is studied from the perspective of information theory.
Particularly, a novel theoretically-grounded codebook design is proposed for
jointly optimizing quantization efficiency, transmission efficiency, and robust
performance. First, a formal equivalence is established between the one-to-many
synonymous mapping defined in semantic information theory and the many-to-one
quantization mapping based on the codebook's Voronoi partitions. Then, the
mutual information between semantic features and their quantized indices is
derived in order to maximize semantic information carried by discrete indices.
To realize the semantic maximum in practice, an entropy-regularized
quantization loss based on empirical estimation is introduced for end-to-end
codebook training. Next, the physical channel-induced semantic distortion and
the optimal codebook size for semantic communications are characterized under
bit-flip errors and semantic distortion. To mitigate the semantic distortion
caused by physical channel noise, a novel channel-aware semantic distortion
loss is proposed. Simulation results on image reconstruction tasks demonstrate
the superior performance of the proposed theoretically-grounded codebook that
achieves a 24.1% improvement in peak signal-to-noise ratio (PSNR) and a 46.5%
improvement in learned perceptual image patch similarity (LPIPS) compared to
the existing codebook designs when the signal-to-noise ratio (SNR) is 10 dB.

</details>


### [21] [Spectral Graph Clustering under Differential Privacy: Balancing Privacy, Accuracy, and Efficiency](https://arxiv.org/abs/2510.07136)
*Mohamed Seif,Antti Koskela,H. Vincent Poor,Andrea J. Goldsmith*

Main category: cs.IT

TL;DR: 本文提出了三种在边差分隐私保护下的谱图聚类机制：边翻转加邻接矩阵洗牌、低维空间投影加高斯噪声、以及带噪声的幂迭代方法，实现了严格的隐私保护并分析了误分类误差率。


<details>
  <summary>Details</summary>
Motivation: 研究在边差分隐私约束下进行谱图聚类的问题，需要在保护图结构隐私的同时保持聚类的有效性。

Method: 开发了三种机制：(1) 边翻转加邻接矩阵洗牌；(2) 低维空间投影加高斯噪声；(3) 带噪声的幂迭代方法，将高斯噪声分布在迭代过程中。

Result: 理论分析提供了严格的隐私保证和误分类误差率的精确刻画，在合成和真实网络上的实验验证了理论分析并展示了隐私-效用的权衡。

Conclusion: 提出的三种机制在边差分隐私下有效实现了谱图聚类，洗牌机制显著增强了隐私保证，噪声分布策略保持了算法收敛性。

Abstract: We study the problem of spectral graph clustering under edge differential
privacy (DP). Specifically, we develop three mechanisms: (i) graph perturbation
via randomized edge flipping combined with adjacency matrix shuffling, which
enforces edge privacy while preserving key spectral properties of the graph.
Importantly, shuffling considerably amplifies the guarantees: whereas flipping
edges with a fixed probability alone provides only a constant epsilon edge DP
guarantee as the number of nodes grows, the shuffled mechanism achieves
(epsilon, delta) edge DP with parameters that tend to zero as the number of
nodes increase; (ii) private graph projection with additive Gaussian noise in a
lower-dimensional space to reduce dimensionality and computational complexity;
and (iii) a noisy power iteration method that distributes Gaussian noise across
iterations to ensure edge DP while maintaining convergence. Our analysis
provides rigorous privacy guarantees and a precise characterization of the
misclassification error rate. Experiments on synthetic and real-world networks
validate our theoretical analysis and illustrate the practical privacy-utility
trade-offs.

</details>
