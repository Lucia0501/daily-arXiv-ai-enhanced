<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 4]
- [eess.SP](#eess.SP) [Total: 25]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Semantic Rate Distortion and Posterior Design: Compute Constraints, Multimodality, and Strategic Inference](https://arxiv.org/abs/2602.03949)
*Emrah Akyol*

Main category: cs.IT

TL;DR: 该论文研究在速率和计算约束下的战略高斯语义压缩，其中编码器和解码器优化不同的二次目标，推导出战略率失真函数，并证明架构计算限制作为隐式速率约束，为数据高效AI提供信息理论基础。


<details>
  <summary>Details</summary>
Motivation: 研究在编码器和解码器具有不同目标函数的战略压缩场景，为现代多模态语言模型提供理论基础，理解资源约束下的语义通信机制。

Method: 采用高斯状态模型，编码器设计后验协方差，解码器通过MMSE估计进行最优响应，分析直接、远程和完全信息三种机制，推导语义注水算法和速率约束高斯劝说解。

Result: 建立了战略率失真函数的完整刻画，证明了目标不一致时的高斯最优性，发现计算限制作为隐式速率约束，模型深度和推理时间计算带来语义准确性的指数级改进，多模态观测消除了远程编码的几何平均惩罚。

Conclusion: 该研究为数据高效和能量高效AI提供了信息理论基础，将现代多模态语言模型解释为资源约束下的后验设计机制，揭示了战略语义压缩的基本原理。

Abstract: We study strategic Gaussian semantic compression under rate and compute constraints, where an encoder and decoder optimize distinct quadratic objectives. A latent Gaussian state generates a task dependent semantic variable, and the decoder best responds via MMSE estimation, reducing the encoder's problem to posterior covariance design under an information rate constraint. We characterize the strategic rate distortion function in direct, remote, and full information regimes, derive semantic waterfilling and rate constrained Gaussian persuasion solutions, and establish Gaussian optimality under misaligned objectives. We further show that architectural compute limits act as implicit rate constraints, yielding exponential improvements in semantic accuracy with model depth and inference time compute, while multimodal observation eliminates the geometric mean penalty inherent to remote encoding. These results provide information theoretic foundations for data and energy efficient AI and offer a principled interpretation of modern multimodal language models as posterior design mechanisms under resource constraints.

</details>


### [2] [Joint Sleep Mode Activation and Load Balancing with Dynamic Cell Load: A Combinatorial Bandit Approach](https://arxiv.org/abs/2602.04808)
*Wajahat Bashir Gilkar,Gourab Ghatak*

Main category: cs.IT

TL;DR: 提出组合多臂老虎机方法，通过触发小基站睡眠模式和负载均衡来优化5G网络能效，同时保证服务质量


<details>
  <summary>Details</summary>
Motivation: 5G网络中大量小基站的能耗问题显著，需要智能节能方案。但关闭小基站会转移负载到相邻基站，可能影响整体能效，需要平衡节能与服务质量

Method: 采用组合上置信界算法选择要关闭的小基站，结合小区范围扩展负载均衡技术，确保5G服务质量标识要求得到满足。通过建模动态小区负载，考虑用户位置、相对基站位置和数据需求

Result: 提出的CUCB+负载均衡算法优于保持所有小基站开启的朴素策略和其他先进强化学习方案，可在O-RAN近实时RAN智能控制器中实现

Conclusion: 组合多臂老虎机方法能有效优化5G网络能效，在保证服务质量的同时实现智能节能，适合在O-RAN架构中部署

Abstract: We propose a combinatorial bandit formulation to opportunistically trigger sleep modes in gNode-B (gNB) small cells (SCs), followed by a cell range expansion (CRE)-based load balancing procedure. This is implemented by ensuring that the fifth generation (5G) quality of service identifier (5QI)-requirements of user equipments (UEs) are maintained. The key challenge is the fact that while deactivating a given SC gNB reduces its own consumption, it may increase the load on neighboring gNBs and the macro gNB (coverage cell), impacting the overall energy efficiency. This phenomenon is accurately characterized by modeling the dynamic cell load that jointly takes into account the location of the UEs, their relative locations to all the SCs, and their data demands. We experimentally show that the proposed combinatorial upper confidence bound (CUCB) followed by the load balancer outperforms not only the naive strategies like arbitrarily keeping all the SCs on, but also other state-of-the-art reinforcement learning solutions. The proposed algorithm can be implemented as open-radio access network (O-RAN) near-real-time (NRT) RAN intelligent controller (RIC) xApps.

</details>


### [3] [Game of Coding for Vector-Valued Computations](https://arxiv.org/abs/2602.04810)
*Hanzaleh Akbari Nodehi,Parsa Moradi,Soheil Mohajer,Mohammad Ali Maddah-Ali*

Main category: cs.IT

TL;DR: 将编码博弈从标量扩展到N维欧几里得空间，为高维数据计算提供理论基础，即使在对抗性多数情况下也能保证正确解码


<details>
  <summary>Details</summary>
Motivation: 传统编码理论需要诚实节点占多数才能保证正确解码，而编码博弈利用经济理性来保证正确性，即使对抗节点占多数。然而现有研究仅限于标量计算，无法处理现实世界中的高维数据，因此需要扩展到向量空间。

Method: 将编码博弈框架扩展到N维欧几里得空间，为向量值计算提供严格的问题表述，并完全表征高维博弈的均衡策略。

Result: 分析表明标量设置中建立的弹性特性在向量机制中得以保留，为无需诚实多数假设的安全大规模去中心化计算奠定了理论基础。

Conclusion: 成功将编码博弈扩展到高维空间，为去中心化机器学习等应用提供了处理向量数据的理论基础，突破了传统编码理论的信任限制。

Abstract: The game of coding is a new framework at the intersection of game theory and coding theory; designed to transcend the fundamental limitations of classical coding theory. While traditional coding theoretic schemes rely on a strict trust assumption, that honest nodes must outnumber adversarial ones to guarantee valid decoding, the game of coding leverages the economic rationality of actors to guarantee correctness and reliable decodability, even in the presence of an adversarial majority. This capability is paramount for emerging permissionless applications, particularly decentralized machine learning (DeML). However, prior investigations into the game of coding have been strictly confined to scalar computations, limiting their applicability to real world tasks where high dimensional data is the norm. In this paper, we bridge this gap by extending the framework to the general $N$-dimensional Euclidean space. We provide a rigorous problem formulation for vector valued computations and fully characterize the equilibrium strategies of the resulting high dimensional game. Our analysis demonstrates that the resilience properties established in the scalar setting are preserved in the vector regime, establishing a theoretical foundation for secure, large scale decentralized computing without honest majority assumptions.

</details>


### [4] [Capacity Bounds on Doppler OFDM Channels](https://arxiv.org/abs/2602.04862)
*Pablo Orellana,Zheng Li,Jean-Marc Kelif,Sheng Yang,Shlomo Shamai*

Main category: cs.IT

TL;DR: 论文研究LEO卫星系统中多普勒效应引起的信道不确定性，提出了一种基于子空间对齐的叠加编码方案，在低复杂度下实现接近最优的速率。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道卫星系统由于高速移动会产生显著的多普勒效应。虽然多普勒频移可以大部分补偿，但残余频率不确定性会导致结构化的信道不确定性，这会限制可实现的速率。

Method: 采用块衰落信道模型 H = F + sG，其中s是未知的标量随机参数。首先在一般N×N MIMO设置下研究该模型，推导基于显式传输方案的可实现速率下界和使用对偶方法的容量上界。提出具有子空间对齐和连续干扰消除的实用叠加方案，其中粗层流作为解码细层数据的隐式导频。

Result: 在近相干和高信噪比区域表征了渐近容量，通过多普勒-OFDM仿真表明所提出的SN方案以低复杂度实现了接近最优的速率。

Conclusion: 提出的子空间对齐叠加编码方案能有效处理LEO卫星系统中的多普勒残余不确定性，在低复杂度下实现接近最优的性能，为实际系统设计提供了实用解决方案。

Abstract: Low Earth orbit (LEO) satellite systems experience significant Doppler effects due to high mobility. While Doppler shifts can be largely compensated, residual frequency uncertainty induces a structured form of channel uncertainty that can limit achievable rates. We model this effect using a block-fading channel of the form $ \mathbf{H} = \mathbf{F} + s \mathbf{G} $, where $s$ is an unknown scalar random parameter. We first study this model in a general $N\times N$ MIMO setting. For this channel, we derive achievable rate lower bounds based on explicit transmission schemes and capacity upper bounds using a duality approach. We study Gaussian signaling and propose a practical superposition scheme with subspace alignment (SN) and successive interference cancellation, where a coarse-layer stream serves as an implicit pilot for decoding refined-layer data. We characterize asymptotic capacity in the near-coherent and high-SNR regimes, and show via Doppler-OFDM simulations that the proposed SN scheme achieves near-optimal rates with low complexity.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [5] [Majorization-Minimization Networks for Inverse Problems: An Application to EEG Imaging](https://arxiv.org/abs/2602.03855)
*Le Minh Triet Tran,Sarah Reynaud,Ronan Fablet,Adrien Merlini,François Rousseau,Mai Quyen Pham*

Main category: eess.SP

TL;DR: 提出一种基于双层优化的学习型Majorization-Minimization框架，通过轻量级RNN学习结构化曲率上界，在保持经典MM下降保证的同时提升逆问题的求解性能。


<details>
  <summary>Details</summary>
Motivation: 逆问题通常是不适定的，需要具有强稳定性和收敛保证的优化方案。现有的基于学习的方法（如深度展开和元学习）虽然取得了良好的经验性能，但缺乏对下降和曲率的显式控制，限制了鲁棒性。

Method: 提出学习型Majorization-Minimization框架，在双层优化设置中学习结构化曲率上界而非完整优化器。曲率上界由轻量级循环神经网络参数化，并显式约束以满足有效的MM条件。对于余弦相似度损失，推导出显式曲率边界得到对角上界；当解析边界不可用时，使用基于Hessian-向量积的谱估计自动上界局部曲率。

Result: 在EEG源成像实验中，相比深度展开和元学习基线方法，该方法在准确性、稳定性和跨数据集泛化能力方面都有显著提升。

Conclusion: 提出的学习型MM框架通过结合学习能力和经典优化理论保证，为逆问题提供了既具有强大经验性能又保持理论鲁棒性的解决方案。

Abstract: Inverse problems are often ill-posed and require optimization schemes with strong stability and convergence guarantees. While learning-based approaches such as deep unrolling and meta-learning achieve strong empirical performance, they typically lack explicit control over descent and curvature, limiting robustness. We propose a learned Majorization-Minimization (MM) framework for inverse problems within a bilevel optimization setting. Instead of learning a full optimizer, we learn a structured curvature majorant that governs each MM step while preserving classical MM descent guarantees. The majorant is parameterized by a lightweight recurrent neural network and explicitly constrained to satisfy valid MM conditions. For cosine-similarity losses, we derive explicit curvature bounds yielding diagonal majorants. When analytic bounds are unavailable, we rely on efficient Hessian-vector product-based spectral estimation to automatically upper-bound local curvature without forming the Hessian explicitly. Experiments on EEG source imaging demonstrate improved accuracy, stability, and cross-dataset generalization over deep-unrolled and meta-learning baselines.

</details>


### [6] [An Enhanced Polar-Domain Dictionary Design for Elevated BSs in Near-Field U-MIMO](https://arxiv.org/abs/2602.04331)
*Luca Antonelli,Antonio Alberto D'Amico,Luca Sanguinetti*

Main category: eess.SP

TL;DR: 提出了一种考虑基站高度的广义网格设计框架，用于近场U-MIMO通信，相比传统方法提高了信道估计精度和频谱效率


<details>
  <summary>Details</summary>
Motivation: 现有近场U-MIMO通信的网格设计方法大多忽略基站高度的影响，假设基站位于地面水平，这与实际部署情况不符，需要一种能适应任意基站位置的通用网格设计方法

Method: 提出广义网格设计框架，基于最优归一化均方误差最小化来优化网格设计，而非传统的基于相关性的方法，适用于任意基站位置，并在亚太赫兹频段的混合U-MIMO系统中使用P-SOMP算法进行信道估计

Result: 分析和数值结果表明，所提出的设计相比现有方案，在信道估计精度和频谱效率方面都有显著提升

Conclusion: 考虑基站高度的广义网格设计框架能够更准确地表示近场U-MIMO信道，在实际部署中具有更好的性能表现

Abstract: Near-field U-MIMO communications require carefully optimized sampling grids in both angular and distance domains. However, most existing grid design methods neglect the influence of base station height, assuming instead that the base station is positioned at ground level - a simplification that rarely reflects real-world deployments. To overcome this limitation, we propose a generalized grid design framework that accommodates arbitrary base station locations. Unlike conventional correlation-based approaches, our method optimizes the grid based on the minimization of the optimal normalized mean squared error, leading to more accurate channel representation. We evaluate the performance of a hybrid U-MIMO system operating at sub-THz frequencies, considering the P-SOMP algorithm for channel estimation. Analytical and numerical results show that the proposed design enhances both channel estimation accuracy and spectral efficiency compared to existing alternatives.

</details>


### [7] [The Turing Synthetic Radar Dataset: A dataset for pulse deinterleaving](https://arxiv.org/abs/2602.03856)
*Edward Gunn,Adam Hosford,Robert Jones,Leo Zeitler,Ian Groves,Victoria Nockles*

Main category: eess.SP

TL;DR: 提出Turing合成雷达数据集，包含6000个脉冲序列、近30亿个脉冲，用于雷达脉冲去交织研究基准和挑战赛


<details>
  <summary>Details</summary>
Motivation: 解决电子战和信号情报中多未知发射源交织雷达脉冲分离的关键问题，为电子战社区提供首个公开的综合性脉冲序列数据集

Method: 创建包含6000个脉冲序列的综合数据集，涵盖两种接收器配置，模拟多达110个发射器的真实场景，并启动Turing去交织挑战赛

Result: 建立了包含近30亿个脉冲的数据集，具有显著参数空间重叠的真实场景，为雷达脉冲去交织研究提供了标准化评估基准

Conclusion: Turing合成雷达数据集是首个公开的综合性脉冲序列数据集，旨在促进电子战社区复杂模型开发，通过挑战赛推动标准化评估

Abstract: We present the Turing Synthetic Radar Dataset, a comprehensive dataset to serve both as a benchmark for radar pulse deinterleaving research and as an enabler of new research methods. The dataset addresses the critical problem of separating interleaved radar pulses from multiple unknown emitters for electronic warfare applications and signal intelligence. Our dataset contains a total of 6000 pulse trains over two receiver configurations, totalling to almost 3 billion pulses, featuring realistic scenarios with up to 110 emitters and significant parameter space overlap. To encourage dataset adoption and establish standardised evaluation procedures, we have launched an accompanying Turing Deinterleaving Challenge, for which models need to associate pulses in interleaved pulse trains to the correct emitter by clustering and maximising metrics such as the V-measure. The Turing Synthetic Radar Dataset is one of the first publicly available, comprehensively simulated pulse train datasets aimed to facilitate sophisticated model development in the electronic warfare community

</details>


### [8] [Cross-Attention Transformer for Joint Multi-Receiver Uplink Neural Decoding](https://arxiv.org/abs/2602.04728)
*Xavier Tardy,Grégoire Lefebvre,Apostolos Kountouris,Haïfa Fares,Amor Nafkha*

Main category: eess.SP

TL;DR: 提出一种跨注意力Transformer，用于联合解码多个协调接入点接收的上行OFDM信号，无需显式信道估计，通过比特度量目标训练，在Wi-Fi信道中优于传统方法


<details>
  <summary>Details</summary>
Motivation: 传统Wi-Fi接收器需要显式的每接收器信道估计，这在稀疏导频或链路退化情况下性能受限。需要一种能够自适应融合多个接入点信号、容忍链路缺失或退化、且无需显式信道估计的联合解码方法

Method: 使用跨注意力Transformer架构：1) 共享的每接收器编码器学习每个接收网格的时频结构；2) 令牌级跨注意力模块融合多个接收器信息；3) 生成软对数似然比供标准信道解码器使用；4) 通过比特度量目标训练，使模型自适应融合策略

Result: 在真实Wi-Fi信道中，该方法持续优于传统流水线和强卷积基线，经常匹配（某些情况下超越）假设完美信道知识的强大基线。模型紧凑、计算成本低（低GFLOPs），在GPU上实现低延迟

Conclusion: 提出的跨注意力Transformer是一种实用的下一代Wi-Fi接收器构建块，无需显式信道估计，能自适应融合多接收器信号，容忍链路问题，在稀疏导频下保持鲁棒性，同时保持高效计算性能

Abstract: We propose a cross-attention Transformer for joint decoding of uplink OFDM signals received by multiple coordinated access points. A shared per-receiver encoder learns time-frequency structure within each received grid, and a token-wise cross-attention module fuses the receivers to produce soft log-likelihood ratios for a standard channel decoder, without requiring explicit per-receiver channel estimates. Trained with a bit-metric objective, the model adapts its fusion to per-receiver reliability, tolerates missing or degraded links, and remains robust when pilots are sparse. Across realistic Wi-Fi channels, it consistently outperforms classical pipelines and strong convolutional baselines, frequently matching (and in some cases surpassing) a powerful baseline that assumes perfect channel knowledge per access point. Despite its expressiveness, the architecture is compact, has low computational cost (low GFLOPs), and achieves low latency on GPUs, making it a practical building block for next-generation Wi-Fi receivers.

</details>


### [9] [PENGUIN: General Vital Sign Reconstruction from PPG with Flow Matching State Space Model](https://arxiv.org/abs/2602.03858)
*Shuntaro Suzuki,Shuitsu Koyama,Shinnosuke Hirano,Shunya Nagashima*

Main category: eess.SP

TL;DR: PENGUIN：一种基于生成流匹配的通用框架，可从PPG信号中重建多种生命体征的连续波形，克服现有方法在泛化性和形态特征保留方面的限制。


<details>
  <summary>Details</summary>
Motivation: PPG信号易受运动伪影和噪声影响，现有生命体征估计方法通常局限于单一任务或环境，缺乏跨场景的泛化能力。此外，当前通用方法依赖多秒间隔预测，丢弃了生命体征的形态特征。

Method: 提出PENGUIN框架，结合生成流匹配技术和深度状态空间模型，实现对PPG信号的细粒度条件化，重建多种生命体征的连续波形。

Result: 在6个真实世界PPG数据集上评估了3种生命体征重建任务（心电图重建、呼吸监测、动脉血压监测），PENGUIN在各项任务中均优于任务专用和通用基线方法。

Conclusion: PENGUIN作为一个通用框架，能够从PPG信号中稳健地重建多种生命体征，解决了现有方法的泛化性和形态特征保留问题。

Abstract: Photoplethysmography (PPG) plays a crucial role in continuous cardiovascular health monitoring as a non-invasive and cost-effective modality. However, PPG signals are susceptible to motion artifacts and noise, making accurate estimation of vital signs such as arterial blood pressure (ABP) challenging. Existing estimation methods are often restricted to a single-task or environment, limiting their generalizability across diverse PPG decoding scenarios. Moreover, recent general-purpose approaches typically rely on predictions over multi-second intervals, discarding the morphological characteristics of vital signs. To address these challenges, we propose PENGUIN, a generative flow-matching framework that extends deep state space models, enabling fine-grained conditioning on PPG for reconstructing multiple vital signs as continuous waveforms. We evaluate PENGUIN using six real-world PPG datasets across three distinct vital sign reconstruction tasks (electrocardiogram reconstruction, respiratory monitoring, and ABP monitoring). Our method consistently outperformed both task-specific and general-purpose baselines, demonstrating PENGUIN as a general framework for robust vital sign reconstruction from PPG.

</details>


### [10] [Polynomial Closed-Form Model for Evaluating Nonlinear Interference in Any Island](https://arxiv.org/abs/2602.03860)
*Yanchao Jiang,Pierluigi Poggiolini*

Main category: eess.SP

TL;DR: 提出多项式闭合形式GN模型，通过将每个信道沿跨度的空间功率剖面表示为多项式，推导出所有自干扰、交叉干扰和多信道干扰贡献的通用闭合表达式


<details>
  <summary>Details</summary>
Motivation: 传统GN模型计算复杂，需要数值积分，本文旨在开发更高效、解析的闭合形式模型来准确评估光纤通信系统中的非线性干扰

Method: 将每个信道沿光纤跨度的空间功率剖面表示为多项式，推导出所有非线性干扰贡献（自干扰、交叉干扰、多信道干扰）的通用闭合形式表达式

Result: 提供了完整的推导过程，得到了多项式闭合形式的GN模型，能够以闭合形式准确计算所有类型的非线性干扰贡献

Conclusion: 提出的多项式闭合形式GN模型为光纤通信系统中的非线性干扰评估提供了高效、准确的解析工具，简化了系统性能分析

Abstract: Polynomial closed-form GN model is proposed by expressing the spatial power profile of each channel along a span as a polynomial. In this paper, we present the generic closed-form expression for all contributions of self-, cross-, and multi-channel interference. The full derivation is provided.

</details>


### [11] [A Multi-Modal Foundational Model for Wireless Communication and Sensing](https://arxiv.org/abs/2602.04016)
*Vahid Yazdnian,Yasaman Ghasempour*

Main category: eess.SP

TL;DR: 提出一种任务无关、多模态的无线系统物理层基础模型，通过物理引导的自监督预训练学习可迁移的物理感知表示，实现跨任务和环境的鲁棒泛化。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的无线技术泛化能力差：大多数模型是任务特定、环境依赖且限于狭窄的感知模态，在新场景部署时需要昂贵的重新训练。

Method: 采用物理引导的自监督预训练策略，引入专门的物理令牌来捕捉由电磁传播支配的跨模态物理对应关系，学习可迁移的物理感知表示。

Result: 学习到的表示能够高效适应多种下游任务（大规模多天线优化、无线信道估计、设备定位等），相比任务特定基线表现出优越的泛化能力、对部署变化的鲁棒性以及减少的数据需求。

Conclusion: 该任务无关、多模态的基础模型为下一代无线通信和感知系统提供了可泛化的解决方案，通过物理感知表示学习实现了跨任务和环境的鲁棒性能。

Abstract: Artificial intelligence is a key enabler for next-generation wireless communication and sensing. Yet, today's learning-based wireless techniques do not generalize well: most models are task-specific, environment-dependent, and limited to narrow sensing modalities, requiring costly retraining when deployed in new scenarios. This work introduces a task-agnostic, multi-modal foundational model for physical-layer wireless systems that learns transferable, physics-aware representations across heterogeneous modalities, enabling robust generalization across tasks and environments. Our framework employs a physics-guided self-supervised pretraining strategy incorporating a dedicated physical token to capture cross-modal physical correspondences governed by electromagnetic propagation. The learned representations enable efficient adaptation to diverse downstream tasks, including massive multi-antenna optimization, wireless channel estimation, and device localization, using limited labeled data. Our extensive evaluations demonstrate superior generalization, robustness to deployment shifts, and reduced data requirements compared to task-specific baselines.

</details>


### [12] [Cross-Frequency Bispectral EEG Analysis of Reach-to-Grasp Planning and Execution](https://arxiv.org/abs/2602.04018)
*Sima Ghafoori,Anna Cetera,Ali Rabiee,MH Farhadi,Rahul Singh,Mariusz Furmanek,Yalda Shahriari,Reza Abiri*

Main category: eess.SP

TL;DR: EEG研究发现高阶交叉频率耦合能区分运动规划与执行阶段，为脑机接口提供新特征


<details>
  <summary>Details</summary>
Motivation: 传统EEG运动解码主要依赖线性二阶谱特征，但神经控制涉及多脑节律的非线性交互，需要探索高阶交叉频率动态是否能更好区分自然抓握行为中的规划与执行阶段

Method: 采用基于线索的范式记录执行精确抓握和力量抓握时的EEG，使用交叉频率双谱分析计算典型频率带对的双相干矩阵，提取幅度和相位特征，进行分类、基于置换的特征选择和受试者内统计测试

Result: 执行阶段比规划阶段表现出更强、更具区分性的非线性耦合，主要由β和γ频段驱动；精确抓握与力量抓握的解码在规划和执行阶段表现相当，表明抓握类型表征在规划阶段形成并持续到执行；信息性双谱特征反映前额叶、中央区和枕叶区域的协调活动

Conclusion: 非线性交叉频率耦合为运动规划和执行提供了可解释且稳健的标记，将双谱EEG分析扩展到生态有效的抓握行为，支持其在脑机接口和神经假肢控制中的应用价值

Abstract: Neural control of grasping arises from nonlinear interactions across multiple brain rhythms, yet EEG-based motor decoding has largely relied on linear, second-order spectral features. Here, we examine whether higher-order cross-frequency dynamics distinguish motor planning from execution during natural reach-to-grasp behavior. EEG was recorded in a cue-based paradigm during executed precision and power grips, enabling stage-resolved analysis of preparatory and execution-related neural activity.
  Cross-frequency bispectral analysis was used to compute bicoherence matrices across canonical frequency band pairs, from which magnitude- and phase-based features were extracted. Classification, permutation-based feature selection, and within-subject statistical testing showed that execution is characterized by substantially stronger and more discriminative nonlinear coupling than planning, with dominant contributions from beta- and gamma-driven interactions. In contrast, decoding of precision versus power grips achieved comparable performance during planning and execution, indicating that grasp-type representations emerge during planning and persist into execution.
  Spatial and spectral analyses further revealed that informative bispectral features reflect coordinated activity across prefrontal, central, and occipital regions. Despite substantial feature redundancy, effective dimensionality reduction preserved decoding performance. Together, these findings demonstrate that nonlinear cross-frequency coupling provides an interpretable and robust marker of motor planning and execution, extending bispectral EEG analysis to ecologically valid grasping and supporting its relevance for brain-computer interfaces and neuroprosthetic control.

</details>


### [13] [Ultra-Fast Device-Free Visible Light Sensing and Localization via Reflection-Based ΔRSS and Deep Learning](https://arxiv.org/abs/2602.04062)
*Helena Serpi,Christina,Politi*

Main category: eess.SP

TL;DR: 提出超快速、无设备的可见光传感与定位系统，利用天花板安装的光电探测器捕获单LED VLC信道响应的时空变化，通过光学信号反射建模非侵入式推断人员存在与位置


<details>
  <summary>Details</summary>
Motivation: 开发一种无需用户携带设备、非侵入式的室内人员感知与定位系统，利用现有可见光通信基础设施实现高精度、实时的环境感知

Method: 使用天花板安装的光电探测器捕获单LED可见光通信信道的时空变化，通过光学信号反射建模分析信号特征，采用多架构深度神经网络集成库中的机器学习模型进行人员存在与位置推断

Result: 系统能够准确、非侵入式地推断人员存在和位置，具有高度适应性，可服务于不同真实世界传感和定位场景

Conclusion: 该系统展示了利用可见光通信基础设施实现无设备、非侵入式室内人员感知与定位的可行性，为智能环境感知提供了新的解决方案

Abstract: We propose an Ultra-Fast, Device-Free Visible Light Sensing and Positioning system that captures spatiotemporal variations in single-LED VLC channel responses, using ceiling-mounted photodetectors, to accurately and non-intrusively infer human presence and position through optical signal reflection modeling. The system is highly adaptive and ready to serve different real-world sensing and positioning scenarios using one or more ML based models from the library of multi-architecture deep neural network ensembles we have developed.

</details>


### [14] [Structure-Informed Estimation for Pilot-Limited MIMO Channels via Tensor Decomposition](https://arxiv.org/abs/2602.04083)
*Alexandre Barbosa de Lima*

Main category: eess.SP

TL;DR: 提出混合张量-神经网络架构，用于宽带MIMO系统的导频受限信道估计，将问题建模为稀疏观测下的低秩张量补全，相比传统方法显著降低导频开销。


<details>
  <summary>Details</summary>
Motivation: 宽带MIMO系统在B5G/6G高维场景下面临导频开销的根本性限制，现有张量方法通常假设完全观测接收信号张量，而实际导频受限场景需要处理稀疏观测下的信道估计问题。

Method: 提出混合架构：比较CP（规范多线性）和Tucker分解在不同SNR和散射条件下的性能；使用轻量级3D U-Net学习低秩结构之外的残差分量；将信道估计建模为稀疏观测下的低秩张量补全问题。

Result: 样本复杂度约与内在模型维度L(Nr+Nt+Nf)成正比，而非环境张量大小NrNtNf；在合成信道上比LS和OMP基线提升10-20dB NMSE（5-10%导频密度）；在DeepMIMO射线追踪信道上比纯张量方法额外降低24-44% NMSE。

Conclusion: 混合张量-神经网络架构能有效解决导频受限宽带MIMO信道估计问题，结合代数模型和实际传播效应，在低导频密度下显著提升估计精度，为B5G/6G系统提供可行方案。

Abstract: Channel estimation in wideband multiple-input multiple-output (MIMO) systems faces fundamental pilot overhead limitations in high-dimensional beyond-5G and sixth-generation (6G) scenarios. This paper presents a hybrid tensor-neural architecture that formulates pilot-limited channel estimation as low-rank tensor completion from sparse observations -- a fundamentally different setting from prior tensor methods that assume fully observed received signal tensors. A canonical polyadic (CP) baseline implemented via a projection-based scheme (Tucker completion under partial observations) and Tucker decompositions are compared under varying signal-to-noise ratio (SNR) and scattering conditions: CP performs well for specular channels matching the multipath model, while Tucker provides greater robustness under model mismatch. A lightweight three-dimensional (3D) U-Net learns residual components beyond the low-rank structure, bridging algebraic models and realistic propagation effects. Empirical recovery threshold analysis shows that sample complexity scales approximately with intrinsic model dimensionality $L(N_r + N_t + N_f)$ rather than ambient tensor size $N_r N_t N_f$, where $L$ denotes the number of dominant propagation paths. Experiments on synthetic channels demonstrate 10-20\,dB normalized mean-square error (NMSE) improvement over least-squares (LS) and orthogonal matching pursuit (OMP) baselines at 5-10\% pilot density, while evaluations on DeepMIMO ray-tracing channels show 24-44\% additional NMSE reduction over pure tensor-based methods.

</details>


### [15] [Uncertainty Principle for Vertex-Time Graph Signal Processing](https://arxiv.org/abs/2602.04084)
*Yanan Zhao,Xingchao Jian,Feng Ji,Wee Peng Tay,Antonio Ortega*

Main category: eess.SP

TL;DR: 提出图信号的顶点-时间不确定性原理，统一经典时频与图不确定性原理，定义顶点-时间与谱-频率扩展度量信号定位，识别出在空间和时间域同时达到最大集中的信号类，构建新的顶点-时间字典用于信号重建，并基于不确定性原理提出新的图拓扑推断方法。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性原理主要关注时频域或图域，缺乏统一框架处理顶点-时间联合域的信号分析。传感器网络和社交网络中常遇到间歇性数据等实际约束，需要更有效的信号重建和图学习方法。

Method: 定义顶点-时间扩展和谱-频率扩展来量化信号在不同域的定位程度；识别在空间和时间域同时达到最大集中的信号类；构建基于这些信号的顶点-时间字典；提出基于不确定性原理的图拓扑推断方法。

Result: 在合成和真实数据集上的数值实验验证了方法的有效性：相比现有方法，在信号重建精度、噪声鲁棒性和图学习性能方面均有提升。

Conclusion: 提出的顶点-时间不确定性原理为图信号分析提供了统一框架，识别的最优集中信号类可用于构建高效字典，基于不确定性原理的图拓扑推断方法在多种应用中表现出优越性能。

Abstract: We present an uncertainty principle for graph signals in the vertex-time domain, unifying the classical time-frequency and graph uncertainty principles within a single framework. By defining vertex-time and spectral-frequency spreads, we quantify signal localization across these domains. Our framework identifies a class of signals that achieve maximum concentration in both the spatial and temporal domains. These signals serve as fundamental atoms for a new vertex-time dictionary, enhancing signal reconstruction under practical constraints, such as intermittent data commonly encountered in sensor and social networks. Furthermore, we introduce a novel graph topology inference method leveraging the uncertainty principle. Numerical experiments on synthetic and real datasets validate the effectiveness of our approach, demonstrating improved reconstruction accuracy, greater robustness to noise, and enhanced graph learning performance compared to existing methods.

</details>


### [16] [Semantic Pilot Design for Data-Aided Channel Estimation Using a Large Language Model](https://arxiv.org/abs/2602.04126)
*Sojeong Park,Hyun Jong Yang*

Main category: eess.SP

TL;DR: 提出一种基于大语言模型的语义导频设计，用于文本数据传输中的信道估计，通过LLM纠正解码文本中的错误来识别可靠符号作为额外导频


<details>
  <summary>Details</summary>
Motivation: 传统导频估计在信道条件差时性能受限，而文本传输中信道损伤常表现为解码文本的拼写错误，这些错误可通过LLM纠正，从而识别出可靠符号用于改进信道估计

Method: 使用LLM纠正初始解码文本中的错误，比较原始解码文本与纠正后版本，识别可靠解码符号，将这些可靠符号作为语义导频用于数据辅助的信道估计

Result: 仿真结果表明，所提方案优于传统仅使用导频的估计方法，在估计信道的归一化均方误差、相位误差以及误码率方面均有显著降低

Conclusion: 首次利用语义信息进行可靠符号选择，提出的语义导频设计能有效提升文本数据传输中的信道估计性能，为数据辅助信道估计提供了新思路

Abstract: This paper proposes a semantic pilot design for data-aided channel estimation in text-inclusive data transmission, using a large language model (LLM). In this scenario, channel impairments often appear as typographical errors in the decoded text, which can be corrected using an LLM. The proposed method compares the initially decoded text with the LLM-corrected version to identify reliable decoded symbols. A set of selected symbols, referred to as a semantic pilot, is used as an additional pilot for data-aided channel estimation. To the best of our knowledge, this work is the first to leverage semantic information for reliable symbol selection. Simulation results demonstrate that the proposed scheme outperforms conventional pilot-only estimation, achieving lower normalized mean squared error and phase error of the estimated channel, as well as reduced bit error rate.

</details>


### [17] [Spatial Angular Pseudo-Derivative Searching: A Single Snapshot Super-resolution Sparse DOA Scheme with Potential for Practical Application](https://arxiv.org/abs/2602.04169)
*Longxin Bai,Jingchao Zhang,Liyan Qiao*

Main category: eess.SP

TL;DR: 提出了一种基于空间角度伪导数约束的稀疏DOA估计算法SAPD，专门针对汽车雷达的计算资源有限、阵列孔径受限和单快照场景，实现了实时高效、高精度和超分辨率的平衡。


<details>
  <summary>Details</summary>
Motivation: 汽车雷达系统需要准确、高分辨率、实时的DOA估计，但现有稀疏信号恢复方法计算复杂度太高，难以在实际部署中应用。需要针对汽车雷达的特定限制（计算资源有限、阵列孔径受限、单快照）设计高效的DOA估计算法。

Method: 提出空间角度伪导数概念，将其作为约束引入标准的L0范数最小化问题，构建更符合DOA物理特性的目标函数。相应的求解器SAPD搜索算法将高维优化任务转化为高效的网格搜索方案，避免了高阶矩阵求逆和计算密集的迭代。

Result: SAPD算法在计算复杂度和收敛性方面表现优异，数值仿真表明该方法在实时效率、高精度和超分辨率方面达到了优越的平衡，非常适合下一代汽车雷达应用。

Conclusion: 提出的SAPD方法通过引入空间角度伪导数约束，成功解决了汽车雷达DOA估计中计算复杂度高的问题，实现了实时高效、高精度和超分辨率的平衡，为下一代汽车雷达系统提供了可行的解决方案。

Abstract: Accurate, high-resolution, and real-time DOA estimation is a cornerstone of environmental perception in automotive radar systems. While sparse signal recovery techniques offer super-resolution and high-precision estimation, their prohibitive computational complexity remains a primary bottleneck for practical deployment. This paper proposes a sparse DOA estimation scheme specifically tailored for the stringent requirements of automotive radar such as limited computational resources, restricted array apertures, and a single snapshot. By introducing the concept of the spatial angular pseudo-derivative and incorporating this property as a constraint into a standard L0-norm minimization problem, we formulate an objective function that more faithfully characterizes the physical properties of the DOA problem. The associated solver, designated as the SAPD search algorithm, naturally transforms the high-dimensional optimization task into an efficient grid-search scheme. The SAPD algorithm circumvents high-order matrix inversions and computationally intensive iterations. We provide an analysis of the computational complexity and convergence properties of the proposed algorithm. Extensive numerical simulations demonstrate that the SAPD method achieves a superior balance of real-time efficiency, high precision, and super-resolution, making it highly suitable for next-generation automotive radar applications.

</details>


### [18] [GPINND: A deep-learning-based state of health estimation for Lithium-ion battery](https://arxiv.org/abs/2602.04187)
*Yuzhu Lei,Guanding Yu*

Main category: eess.SP

TL;DR: 提出一种结合深度学习与电化学机理的电池健康状态估计方法，通过构建混合驱动代理模型、自监督参数识别网络和数据驱动残差修正，实现非迭代参数识别和高精度SOH估计。


<details>
  <summary>Details</summary>
Motivation: 电化学模型在电池退化诊断中具有优越的可解释性和可靠性，但迭代参数识别的高计算成本严重阻碍了电化学信息健康状态估计在实际实时系统中的实现。

Method: 1. 构建混合驱动代理模型，融合高保真仿真数据和物理约束学习内部电化学动力学；2. 开发自监督框架训练参数识别网络，最小化电压重构误差；3. 利用识别参数作为物理化学健康指标，建立高精度SOH估计网络，采用数据驱动残差修正补偿识别偏差；4. 采用顺序训练策略解决收敛问题。

Result: 实验结果表明，该方法平均电压重构均方根误差为0.0198V，SOH估计均方根误差为0.0014。

Conclusion: 该方法成功解决了电化学模型实时应用的挑战，通过深度学习与电化学机理的融合，实现了高效准确的非迭代参数识别和SOH估计。

Abstract: Electrochemical models offer superior interpretability and reliability for battery degradation diagnosis. However, the high computational cost of iterative parameter identification severely hinders the practical implementation of electrochemically informed state of health (SOH) estimation in real-time systems. To address this challenge, this paper proposes an SOH estimation method that integrates deep learning with electrochemical mechanisms and adopts a sequential training strategy. First, we construct a hybrid-driven surrogate model to learn internal electrochemical dynamics by fusing high-fidelity simulation data with physical constraints. This model subsequently serves as an accurate and differentiable physical kernel for voltage reconstruction. Then, we develop a self-supervised framework to train a parameter identification network by minimizing the voltage reconstruction error. The resulting model enables the non-iterative identification of aging parameters from external measurements. Finally, utilizing the identified parameters as physicochemical health indicators, we establish a high-precision SOH estimation network that leverages data-driven residual correction to compensate for identification deviations. Crucially, a sequential training strategy is applied across these modules to effectively mitigate convergence issues and improve the accuracy of each module. Experimental results demonstrate that the proposed method achieves an average voltage reconstruction root mean square error (RMSE) of 0.0198 V and an SOH estimation RMSE of 0.0014.

</details>


### [19] [Maneuverable-Jamming-Aided Secure Communication and Sensing in A2G-ISAC Systems](https://arxiv.org/abs/2602.04209)
*Libiao Lou,Yuan Liu,Fotis Foukalas,Hongjiang Lei,Gaofeng Pan,Theodoros A. Tsiftsis,Hongwu Liu*

Main category: eess.SP

TL;DR: 提出了一种用于空对地集成感知与通信系统的机动干扰辅助安全通信与感知方案，通过双无人机协作在混合单基地-双基地雷达配置下，联合优化轨迹和波束成形以最大化平均保密率。


<details>
  <summary>Details</summary>
Motivation: 在空对地集成感知与通信系统中，安全通信和感知在资源分配上存在根本冲突，难以同时达到最优性能。此外，不完美的连续干扰消除会产生残余干扰，降低系统性能。需要一种能够协调这两种功能并应对干扰影响的方案。

Method: 采用两阶段设计：安全通信阶段使用基于信任域连续凸近似和半定松弛的块坐标下降算法迭代优化双无人机轨迹和波束成形；安全通信与感知阶段通过贪婪算法确定合适的双无人机感知位置，然后联合优化源波束成形和干扰波束成形。

Result: 仿真结果表明，所提方案在基准方法中实现了最高的平均保密率，同时保持了稳健的感知性能，并证实了连续干扰消除残余干扰对安全通信和感知的影响。

Conclusion: 提出的机动干扰辅助安全通信与感知方案通过两阶段设计和联合优化策略，有效解决了空对地集成感知与通信系统中安全通信与感知的资源冲突问题，在保证感知性能的同时显著提升了通信安全性。

Abstract: In this paper, we propose a maneuverablejamming-aided secure communication and sensing (SCS) scheme for an air-to-ground integrated sensing and communication (A2G-ISAC) system, where a dual-functional source UAV and a maneuverable jamming UAV operate collaboratively in a hybrid monostatic-bistatic radar configuration. The maneuverable jamming UAV emits artificial noise to assist the source UAV in detecting multiple ground targets while interfering with an eavesdropper. The effects of residual interference caused by imperfect successive interference cancellation on the received signal-to-interference-plus-noise ratio are considered, which degrades the system performance. To maximize the average secrecy rate (ASR) under transmit power budget, UAV maneuvering constraints, and sensing requirements, the dual-UAV trajectory and beamforming are jointly optimized. Given that secure communication and sensing fundamentally conflict in terms of resource allocation, making it difficult to achieve optimal performance for both simultaneously, we adopt a two-phase design to address this challenge. By dividing the mission into the secure communication (SC) phase and the SCS phase, the A2G-ISAC system can focus on optimizing distinct objectives separately. In the SC phase, a block coordinate descent algorithm employing the trust-region successive convex approximation and semidefinite relaxation iteratively optimizes dual-UAV trajectory and beamforming. For the SCS phase, a weighted distance minimization problem determines the suitable dual-UAV sensing positions by a greedy algorithm, followed by the joint optimization of source beamforming and jamming beamforming. Simulation results demonstrate that the proposed scheme achieves the highest ASR among benchmarks while maintaining robust sensing performance, and confirm the impact of the SIC residual interference on both secure communication and sensing.

</details>


### [20] [Aortic Valve Disease Detection from PPG via Physiology-Informed Self-Supervised Learning](https://arxiv.org/abs/2602.04266)
*Jiaze Wang,Qinghao Zhao,Zizheng Chen,Zhejun Sun,Deyun Zhang,Yuxi Zhou,Shenda Hong*

Main category: eess.SP

TL;DR: 提出生理学引导的自监督学习框架(PG-SSL)，利用大规模未标记PPG数据解决主动脉瓣疾病筛查中的标签稀缺问题，显著提升主动脉狭窄和主动脉反流的筛查性能。


<details>
  <summary>Details</summary>
Motivation: 传统超声心动图诊断主动脉瓣疾病成本高且需要专业知识，限制了大规模早期筛查。PPG作为穿戴设备广泛可用的筛查方式具有潜力，但金标准标记数据极度稀缺限制了数据驱动方法的有效性。

Method: 提出生理学引导的自监督学习(PG-SSL)框架：1) 将临床知识形式化为PPG形态表型；2) 构建脉搏模式识别代理任务进行自监督预训练；3) 使用双分支门控融合架构在小标记子集上进行高效微调。

Result: PG-SSL框架在主动脉狭窄(AS)和主动脉反流(AR)筛查中分别达到0.765和0.776的AUC，显著优于在有限标记数据上训练的监督基线。多变量分析验证模型输出作为独立的数字生物标志物，在调整标准临床风险因素后仍具有持续预后价值。

Conclusion: PG-SSL为医学人工智能中的标签稀缺问题提供了有效的领域知识驱动解决方案，显示出实现低成本、大规模主动脉瓣疾病早期筛查的强大潜力。

Abstract: Traditional diagnosis of aortic valve disease relies on echocardiography, but its cost and required expertise limit its use in large-scale early screening. Photoplethysmography (PPG) has emerged as a promising screening modality due to its widespread availability in wearable devices and its ability to reflect underlying hemodynamic dynamics. However, the extreme scarcity of gold-standard labeled PPG data severely constrains the effectiveness of data-driven approaches. To address this challenge, we propose and validate a new paradigm, Physiology-Guided Self-Supervised Learning (PG-SSL), aimed at unlocking the value of large-scale unlabeled PPG data for efficient screening of Aortic Stenosis (AS) and Aortic Regurgitation (AR). Using over 170,000 unlabeled PPG samples from the UK Biobank, we formalize clinical knowledge into a set of PPG morphological phenotypes and construct a pulse pattern recognition proxy task for self-supervised pre-training. A dual-branch, gated-fusion architecture is then employed for efficient fine-tuning on a small labeled subset. The proposed PG-SSL framework achieves AUCs of 0.765 and 0.776 for AS and AR screening, respectively, significantly outperforming supervised baselines trained on limited labeled data. Multivariable analysis further validates the model output as an independent digital biomarker with sustained prognostic value after adjustment for standard clinical risk factors. This study demonstrates that PG-SSL provides an effective, domain knowledge-driven solution to label scarcity in medical artificial intelligence and shows strong potential for enabling low-cost, large-scale early screening of aortic valve disease.

</details>


### [21] [Joint Fractional Delay and Doppler Frequency Estimator Under Spectrum Wrapping Phenomenon for LEO-ICAN AFDM Signals](https://arxiv.org/abs/2602.04316)
*Zhenyu Chen,Ke Xiao,Xiaomei Tang,Jing Lei,Muzi Yuan,Guangfu Sun*

Main category: eess.SP

TL;DR: 本文针对LEO卫星ICAN信号中的AFDM波形，提出了分数时延和多普勒频率联合估计算法，解决了现有方法忽略频谱折叠现象导致的模型偏差问题。


<details>
  <summary>Details</summary>
Motivation: 随着低地球轨道卫星的快速发展，集成通信导航信号设计在车联网领域受到关注。AFDM作为新一代波形具有抗多普勒效应强、调制结构简单、导频开销低等优点，适合高动态LEO卫星场景。但LEO-ICAN AFDM信号面临分数时延和多普勒频率估计的挑战，现有研究忽略其固有的频谱折叠现象可能导致不同程度的模型偏差。

Method: 深入推导了AFDM在分数情况下的输入输出关系，揭示了其等效信道的包络特性，提出了基于峰值旁瓣功率比检测和早晚门联合估计算法来估计分数多普勒频率和时延。

Result: 仿真结果表明，与传统方法相比，该算法具有低复杂度、低保护间隔开销和高精度的优势。

Conclusion: 本文提出的联合估计算法有效解决了AFDM在LEO卫星ICAN信号中的分数时延和多普勒频率估计问题，为高动态场景下的信号处理提供了更准确的解决方案。

Abstract: With the rapid development of low earth orbit (LEO) satellites, the design of integrated communication and navigation (ICAN) signals has attracted increasing attention, especially in the field of vehicle-to-everything (V2X). As a new-generation waveform, Affine Frequency Division Multiplexing (AFDM) features high robustness against Doppler effects, a simple modulation structure, and low pilot overhead, making it a promising candidate for high-dynamic LEO satellite scenarios. However, LEO-ICAN AFDM signals face challenges in fractional delay and Doppler frequency estimation. Existing studies that ignore its inherent spectrum wrapping phenomenon may lead to deviations of varying degrees in model construction. This paper conducts an in-depth derivation of AFDM's input-output relationship under fractional cases, reveals the envelope characteristics of its equivalent channel, and proposes a joint estimation algorithm based on peak-to-sidelobe power ratio (PSPR) detection and early-late gate (ELG) to estimate fractional Doppler frequency and delay. Simulations show that the algorithm has low complexity, low guard interval overhead, and high precision compared with traditional methods.

</details>


### [22] [Rigid Body Localization via Gaussian Belief Propagation with Quadratic Angle Approximation](https://arxiv.org/abs/2602.04410)
*Niclas Führling,Hyeon Seok Rou,Giuseppe Abreu,David González G.,Osvaldo Gonsa*

Main category: eess.SP

TL;DR: 提出一种基于高斯置信传播的刚性体定位新方法，通过二次角度近似线性化相对方向，无需精确先验方向信息，实现高精度旋转角度估计


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯置信传播的刚性体定位方法需要精确的先验方向信息，这在实际应用中是一个限制。本文旨在消除这一限制，开发一种无需精确先验方向信息的定位方案

Method: 采用二次角度近似来线性化先验与目标刚性体之间的相对方向，即使在大偏差情况下也能实现高精度旋转角度估计。基于线性化模型，推导出相应的消息传递规则，用于估计目标刚性体相对于先验参考系的平移向量和旋转矩阵

Result: 数值结果表明，所提出的角度近似本身具有良好的性能，并且在均方根误差方面优于现有最先进方法，同时保持了较低的计算复杂度

Conclusion: 本文成功开发了一种无需精确先验方向信息的基于高斯置信传播的刚性体定位方法，通过二次角度近似实现了高精度估计，在性能和计算效率方面均表现出色

Abstract: Gaussian belief propagation (GaBP) is a technique that relies on linearized error and input-output models to yield low-complexity solutions to complex estimation problems, which has been recently shown to be effective in the design of range-based GaBP schemes for stationary and moving rigid body localization (RBL) in three-dimensional (3D) space, as long as an accurate prior on the orientation of the target rigid body is available. In this article we present a novel range-based RBL scheme via GaBP that removes the latter limitation. To this end, the proposed method incorporates a quadratic angle approximation to linearize the relative orientation between the prior and the target rigid body, enabling high precision estimates of corresponding rotation angles even for large deviations. Leveraging the resulting linearized model, we derive the corresponding message-passing (MP) rules to obtain estimates of the translation vector and rotation matrix of the target rigid body, relative to a prior reference frame. Numerical results corroborate the good performance of the proposed angle approximation itself, as well as the consequent RBL performance in terms of root mean square errors (RMSEs) in comparison to the state-of-the-art (SotA), while maintaining a low computational complexity

</details>


### [23] [An Information-Theoretic Detector for Multiple Scatterers in SAR Tomography](https://arxiv.org/abs/2602.04465)
*Pia Addabbo,Diego Reale,Antonio Pauciullo,Gianfranco Fornaro,Danilo Orlando*

Main category: eess.SP

TL;DR: 提出一种基于信息理论和压缩感知的SAR层析成像单阶段自适应多假设检验架构，用于城市区域叠掩情况下的多散射体检测和参数估计


<details>
  <summary>Details</summary>
Motivation: 城市区域SAR成像中，叠掩现象导致同一像素包含不同高度的多个散射体，传统方法难以有效检测和分离这些多散射体，需要更有效的多假设检验方法

Method: 结合信息理论工具设计单阶段自适应多假设检验架构，采用压缩感知方法估计各假设下的未知参数，在模拟和真实数据上进行验证

Result: 所提架构在模拟和真实数据上均得到验证，并与合适的对比方法进行比较，显示出良好的性能

Conclusion: 基于信息理论和压缩感知的单阶段自适应多假设检验架构能有效解决SAR层析成像中的多散射体检测问题，适用于城市区域叠掩情况

Abstract: Persistent scatterer interferometry and Synthetic Aperture Radar (SAR) Tomography are powerful tools for the detection and time monitoring of persistent scatterers. They have been proven to be effective in urban scenarios, especially for buildings and infrastructures 3-D reconstruction and monitoring of deformation. In urban areas, occurrence of layover leads to the presence of multiple contributions within the same image pixel from scatterers located at different heights. In the context of SAR Tomography, this problem can be addressed by considering a multiple hypothesis test to detect the presence of feasible multiple scatterers [1][2]. In the present paper, we consider this problem in the framework of the information theory and exploit the theoretical tool, developed in [3], to design a one-stage adaptive architecture for multiple hypothesis testing problems in the context of SAR Tomography. Moreover, we resort to the compressive sensing approach for the estimation of the unknown parameters under each hypothesis. This architecture has been verified on both simulated as well as real data also in comparison with suitable counterparts.

</details>


### [24] [Total Variation Sparse Bayesian Learning for Block Sparsity via Majorization-Minimization](https://arxiv.org/abs/2602.04623)
*Yanbin He,Geethu Joseph*

Main category: eess.SP

TL;DR: 本文提出了一种新的优化框架，用于解决基于差异对数总变分（DoL-TV）正则化的稀疏贝叶斯学习（SBL）问题，通过指数重参数化技术简化了复杂优化过程，并在稀疏恢复任务中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 块稀疏性在稀疏恢复中被广泛应用，但实际信号往往具有未知的块边界和孤立的非零元素，这给传统方法带来了挑战。DoL-TV正则化的SBL方法虽然能处理这种复杂稀疏模式，但由于DoL-TV项的复杂形式，优化问题难以求解。

Method: 通过引入SBL超参数的指数重参数化，揭示了新的结构特性，建立了主化-最小化（majorization-minimization）优化框架，并自然地扩展到未知噪声方差估计。

Result: 在合成数据和扩展源方向到达估计任务上的稀疏恢复结果表明，相比基准方法，该方法在准确性和运行时间性能方面都有所改进。

Conclusion: 提出的新优化框架有效解决了DoL-TV SBL成本函数的优化难题，为处理复杂稀疏模式提供了一种高效解决方案，在稀疏恢复应用中展现出优越性能。

Abstract: Block sparsity is a widely exploited structure in sparse recovery, offering significant gains when signal blocks are known. Yet, practical signals often exhibit unknown block boundaries and isolated non-zero entries, which challenge traditional approaches. A promising method to handle such complex sparsity patterns is the difference-of-logs total variation (DoL-TV) regularized sparse Bayesian learning (SBL). However, due to the complex form of DoL-TV term, the resulting optimization problem is hard to solve. This paper develops a new optimization framework for the DoL-TV SBL cost function. By introducing an exponential reparameterization of the SBL hyperparameters, we reveal a novel structure that admits a majorization-minimization formulation and naturally extends to unknown noise variance estimation. Sparse recovery results on both synthetic data and extended source direction-of-arrival estimation demonstrate improved accuracy and runtime performance compared to benchmark methods.

</details>


### [25] [Learning to Separate RF Signals Under Uncertainty: Detect-Then-Separate vs. Unified Joint Models](https://arxiv.org/abs/2602.04650)
*Ariel Rodrigez,Alejandro Lancho,Amir Weiss*

Main category: eess.SP

TL;DR: 提出统一联合模型（UJM）用于单通道射频信号处理，通过单一神经网络架构同时实现干扰检测与分离，相比传统的检测-分离策略具有更好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 射频频谱日益拥挤导致通信信号共存，产生非高斯结构的异构干扰。现有数据驱动方法通常假设干扰类型已知，导致专用模型集合难以扩展到多种干扰类型。

Method: 提出统一联合模型（UJM），使用单一深度神经网络架构直接对接收信号进行联合检测和分离。采用针对基带（复值）射频信号定制的UNet架构，并与传统的检测-分离策略进行比较。

Result: 容量匹配的UJM能够在不同信干噪比、干扰类型和星座阶数下，匹配甚至达到基于先验知识的检测-分离策略性能，包括训练和测试中类型不确定性比例不匹配的情况。

Conclusion: UJM作为检测-分离策略的可扩展且实用的替代方案，为更广泛机制下的统一分离开辟了新方向。

Abstract: The increasingly crowded radio frequency (RF) spectrum forces communication signals to coexist, creating heterogeneous interferers whose structure often departs from Gaussian models. Recovering the interference-contaminated signal of interest in such settings is a central challenge, especially in single-channel RF processing. Existing data-driven methods often assume that the interference type is known, yielding ensembles of specialized models that scale poorly with the number of interferers. We show that detect-then-separate (DTS) strategies admit an analytical justification: within a Gaussian mixture framework, a plug-in maximum a posteriori detector followed by type-conditioned optimal estimation achieves asymptotic minimum mean-square error optimality under a mild temporal-diversity condition. This makes DTS a principled benchmark, but its reliance on multiple type-specific models limits scalability. Motivated by this, we propose a unified joint model (UJM), in which a single deep neural architecture learns to jointly detect and separate when applied directly to the received signal. Using tailored UNet architectures for baseband (complex-valued) RF signals, we compare DTS and UJM on synthetic and recorded interference types, showing that a capacity-matched UJM can match oracle-aided DTS performance across diverse signal-to-interference-and-noise ratios, interference types, and constellation orders, including mismatched training and testing type-uncertainty proportions. These findings highlight UJM as a scalable and practical alternative to DTS, while opening new directions for unified separation under broader regimes.

</details>


### [26] [HFMCA: Orthonormal Feature Learning for EEG-based Brain Decoding](https://arxiv.org/abs/2602.04681)
*Yinghao Wang,Lintao Xu,Shujian Yu,Enzo Tartaglione,Van-Tam Nguyen*

Main category: eess.SP

TL;DR: 提出基于分层功能最大相关算法（HFMCA）的自监督框架，通过特征去相关和冗余减少学习正交EEG表示，在SEED和BCIC-2A数据集上超越现有自监督方法，显著提升分类准确率。


<details>
  <summary>Details</summary>
Motivation: EEG信号分析对脑机接口和神经科学至关重要，但EEG信号固有的噪声和高维度特性阻碍了有效的特征学习，需要开发能够捕获本质脑动力学并减少冗余的表示学习方法。

Method: 提出分层功能最大相关算法（HFMCA）自监督框架，通过强制特征去相关和减少冗余来学习正交EEG表示，从而鲁棒地捕获各种EEG识别任务中的基本脑动力学。

Result: 在SEED和BCIC-2A基准数据集上验证，HFMCA预训练始终优于竞争的自监督基线，在SEED情绪识别上提升2.71%，在BCIC-2A运动想象分类上提升2.57%，在跨被试泛化方面表现出色。

Conclusion: HFMCA框架通过特征去相关和冗余减少有效学习EEG表示，在多个EEG任务中实现了最先进的性能，显著提升了分类准确率和跨被试泛化能力，为EEG分析提供了有效的自监督学习方法。

Abstract: Electroencephalography (EEG) analysis is critical for brain-computer interfaces and neuroscience, but the intrinsic noise and high dimensionality of EEG signals hinder effective feature learning. We propose a self-supervised framework based on the Hierarchical Functional Maximal Correlation Algorithm (HFMCA), which learns orthonormal EEG representations by enforcing feature decorrelation and reducing redundancy. This design enables robust capture of essential brain dynamics for various EEG recognition tasks. We validate HFMCA on two benchmark datasets, SEED and BCIC-2A, where pretraining with HFMCA consistently outperforms competitive self-supervised baselines, achieving notable gains in classification accuracy. Across diverse EEG tasks, our method demonstrates superior cross-subject generalization under leave-one-subject-out validation, advancing state-of-the-art by 2.71\% on SEED emotion recognition and 2.57\% on BCIC-2A motor imagery classification.

</details>


### [27] [Knowledge Distillation for mmWave Beam Prediction Using Sub-6 GHz Channels](https://arxiv.org/abs/2602.04703)
*Sina Tavakolian,Nhan Thanh Nguyen,Ahmed Alkhateeb,Markku Juntti*

Main category: eess.SP

TL;DR: 提出基于知识蒸馏的轻量级毫米波波束预测框架，用小型学生模型替代大型教师模型，在保持性能的同时降低99%的计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 毫米波高移动性环境中的波束成形需要大量训练开销，现有利用sub-6 GHz信道预测毫米波波束的方法依赖大型深度学习模型，计算和内存需求过高。

Method: 基于知识蒸馏技术，开发两种紧凑的学生DL架构：个体蒸馏策略和关系蒸馏策略，仅保留少量隐藏层但能模拟大型教师模型的性能。

Result: 广泛仿真表明，提出的学生模型在波束预测准确性和频谱效率方面达到教师模型水平，同时将可训练参数和计算复杂度降低99%。

Conclusion: 知识蒸馏技术能有效构建轻量级sub-6 GHz信道-毫米波波束映射框架，在保持高性能的同时大幅降低计算需求，适用于实际部署。

Abstract: Beamforming in millimeter-wave (mmWave) high-mobility environments typically incurs substantial training overhead. While prior studies suggest that sub-6 GHz channels can be exploited to predict optimal mmWave beams, existing methods depend on large deep learning (DL) models with prohibitive computational and memory requirements. In this paper, we propose a computationally efficient framework for sub-6 GHz channel-mmWave beam mapping based on the knowledge distillation (KD) technique. We develop two compact student DL architectures based on individual and relational distillation strategies, which retain only a few hidden layers yet closely mimic the performance of large teacher DL models. Extensive simulations demonstrate that the proposed student models achieve the teacher's beam prediction accuracy and spectral efficiency while reducing trainable parameters and computational complexity by 99%.

</details>


### [28] [Resilient Channel Charting Under Varying Radio Link Availability](https://arxiv.org/abs/2602.04704)
*Jonas Pirkl,Jonathan Ott,Maximilian Stahlke,George Yammine,Tobias Feigl,Christopher Mutschler*

Main category: eess.SP

TL;DR: AdaPos是一种自适应定位架构，通过结合卷积特征提取和基于transformer的编码器，能够原生处理可变数量的信道测量输入，解决天线故障或配置变化问题。


<details>
  <summary>Details</summary>
Motivation: 现有信道制图模型通常假设固定大小的输入（如恒定天线数量），但在实际系统中天线可能故障、信号可能被阻挡或天线配置可能变化，导致固定输入架构脆弱。现有方法需要为每种天线配置训练单独模型，训练成本随阵列规模指数增长。

Method: AdaPos结合卷积特征提取和基于transformer的编码器，使用可学习的天线标识符和自注意力机制来融合任意子集的CSI输入。提出新颖的训练策略，使模型能够处理单个天线故障和整阵列中断。

Result: 在两个公开真实世界数据集（SISO和MIMO）上的实验表明，AdaPos在缺失天线条件下保持最先进的准确性，用一个统一模型替代了大约57个配置特定模型。模型对单个天线故障和整阵列中断都具有弹性。

Conclusion: AdaPos提供了一种能够原生处理可变数量信道测量的信道制图架构，解决了实际系统中天线配置变化的挑战，显著减少了模型训练和维护成本，提高了系统的鲁棒性。

Abstract: Channel charting (CC) has become a key technology for RF-based localization, enabling unsupervised radio fingerprinting, even in non line of sight scenarios, with a minimum of reference position labels. However, most CC models assume fixed-size inputs, such as a constant number of antennas or channel measurements. In practical systems, antennas may fail, signals may be blocked, or antenna sets may change during handovers, making fixed-input architectures fragile. Existing radio-fingerprinting approaches address this by training separate models for each antenna configuration, but the resulting training effort scales prohibitively with the array size. We propose Adaptive Positioning (AdaPos), a CC architecture that natively handles variable numbers of channel measurements. AdaPos combines convolutional feature extraction with a transformer-based encoder using learnable antenna identifiers and self-attention to fuse arbitrary subsets of CSI inputs. Experiments on two public real-world datasets (SISO and MIMO) show that AdaPos maintains state-of-the-art accuracy under missing-antenna conditions and replaces roughly 57 configuration-specific models with a single unified model. With AdaPos and our novel training strategies, we provide resilience to both individual antenna failures and full-array outages.

</details>


### [29] [Safe-NEureka: a Hybrid Modular Redundant DNN Accelerator for On-board Satellite AI Processing](https://arxiv.org/abs/2602.04803)
*Riccardo Tedeschi,Luigi Ghionda,Alessandro Nadalini,Yvan Tortorella,Arpan Suravi Prasad,Luca Benini,Davide Rossi,Francesco Conti*

Main category: eess.SP

TL;DR: Safe-NEureka是一个用于卫星的混合模块冗余DNN加速器，支持冗余模式（DMR硬件恢复）和性能模式（最大化并行吞吐），在12nm工艺下实现96倍故障执行减少和15%面积开销。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道卫星星座需要AI加速器来处理安全关键功能（如自主GNC）和性能关键功能（如高带宽传感器数据处理），这些加速器必须同时具备抗辐射故障的鲁棒性和高吞吐能力。

Method: 提出Safe-NEureka混合模块冗余DNN加速器，采用两种工作模式：冗余模式使用双模块冗余（DMR）配合硬件恢复机制；性能模式重新利用冗余数据路径最大化并行吞吐。内存接口采用ECC保护，控制器采用三模块冗余（TMR）。

Result: 在GlobalFoundries 12nm工艺下实现：冗余模式下故障执行减少96倍，面积开销15%；性能模式下3x3密集卷积接近基线速度，吞吐量下降5%，效率下降11%（相比冗余模式的48%和53%下降）。

Conclusion: Safe-NEureka通过灵活的混合冗余架构，为空间应用提供了既能保证关键任务可靠性，又能维持高性能的DNN加速解决方案，将高开销限制在必要任务上。

Abstract: Low Earth Orbit (LEO) constellations are revolutionizing the space sector, with on-board Artificial Intelligence (AI) becoming pivotal for next-generation satellites. AI acceleration is essential for safety-critical functions such as autonomous Guidance, Navigation, and Control (GNC), where errors cannot be tolerated, and performance-critical processing of high-bandwidth sensor data, where occasional errors are tolerable. Consequently, AI accelerators for satellites must combine robust protection against radiation-induced faults with high throughput. This paper presents Safe-NEureka, a Hybrid Modular Redundant Deep Neural Network (DNN) accelerator for heterogeneous RISC-V systems. It operates in two modes: a redundancy mode utilizing Dual Modular Redundancy (DMR) with hardware-based recovery, and a performance mode repurposing redundant datapaths to maximize parallel throughput. Furthermore, its memory interface is protected by Error Correction Codes (ECCs), and the controller by Triple Modular Redundancy (TMR). Implementation in GlobalFoundries 12nm technology shows a 96 reduction in faulty executions in redundancy mode, with a manageable 15 area overhead. In performance mode, the architecture achieves near-baseline speeds on 3x3 dense convolutions with a 5 throughput and 11 efficiency reduction, compared to 48 and 53 in redundancy mode. This flexibility ensures high overheads are limited to critical tasks, establishing Safe-NEureka as a versatile solution for space applications.

</details>
