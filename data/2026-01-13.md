<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 22]
- [cs.IT](#cs.IT) [Total: 50]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Dual radar-guided glide path error correction based on the Izhikevich neuron model](https://arxiv.org/abs/2601.06068)
*Yuan Gao,Xinyu Wang,Yifan Ren,Yuning Zhou,Ziwei Wang*

Main category: eess.SP

TL;DR: 提出基于Izhikevich神经模型的双雷达航迹误差校正方法，通过脉冲神经网络动态补偿雷达测量误差


<details>
  <summary>Details</summary>
Motivation: 针对双雷达跟踪中目标反射特性和系统噪声导致的测距测角误差问题，需要一种有效的误差校正方法

Method: 使用Izhikevich神经模型的动态微分方程模拟生物神经元放电特性，输入层集成双雷达坐标测量数据，输出层通过脉冲发射频率表示误差补偿量，采用STDP机制动态调整神经元连接权重

Result: 能够有效抑制系统噪声和雷达测距测角误差引起的轨迹失真

Conclusion: 基于Izhikevich神经模型的双雷达航迹误差校正方法可以有效提高雷达跟踪精度

Abstract: Aiming at the ranging and angle measurement errors caused by target reflection characteristics and system noise in dual radar tracking, this paper proposes a dual radar track error correction method based on the Izhikevich neural model. The network uses the dynamic differential equation of the Izhikevich model to simulate the discharge characteristics of biological neurons. Its input layer integrates the coordinate measurement data of the dual radar, and the output layer represents the error compensation amount through the pulse emission frequency. The spike-timing-dependent plasticity (STDP) is used to adjust the neuron connection weights dynamically, and the trajectory distortion caused by system noise and radar ranging and angle measurement errors can be effectively suppressed.

</details>


### [2] [Optimizing the 4G--5G Migration: A Simulation-Driven Roadmap for Emerging Markets](https://arxiv.org/abs/2601.06076)
*Desire Guel,Justin Pegd-Windé Kouraogo,Kouka Kouakou Nakoulma*

Main category: eess.SP

TL;DR: 该研究通过MATLAB仿真分析了5G网络在新兴市场部署的关键技术杠杆，包括MIMO、载波聚合、频谱重耕、毫米波传播和网络架构选择，提出了从NSA起步、优先载波聚合、选择性密集化、最终向SA迁移的实用路线图。


<details>
  <summary>Details</summary>
Motivation: 在新兴市场部署5G网络需要在性能目标与预算、频谱和基础设施限制之间取得平衡。研究旨在量化各种无线和架构杠杆对容量、覆盖、延迟和干扰鲁棒性的影响，为实际部署提供指导。

Method: 使用MATLAB仿真分析多种技术：MIMO（波束赋形、分集、空间复用）、载波聚合（CA）、向新空口（NR）的频谱重耕、毫米波传播（考虑遮挡/雨衰）、非独立组网（NSA）与独立组网（SA）核心网，以及D2D和M2M作为广域接入的补充。

Result: 波束赋形提升小区边缘SNR约3-6 dB；空间复用在中等/高SNR下通过多流增益占主导；载波聚合显著提升吞吐量（1到5个20-MHz载波使峰值速率从200 Mb/s提升至1 Gb/s）；中频段向NR重耕使城市中位吞吐量提升60-90%，农村提升40-70%；28 GHz毫米波受雨衰和人体遮挡影响增加8-30 dB额外损耗；NSA比SA提供更广的初始覆盖。

Conclusion: 提出实用部署路线图：从NSA开始部署NR，优先采用以CA为中心的频谱策略并聚焦频谱重耕，在需求热点区域选择性密集化，随着回传和设备生态成熟逐步迁移到SA架构。

Abstract: Deploying fifth-generation (5G) networks in emerging markets demands a balance between performance targets and constraints in budget, spectrum, and infrastructure. We use MATLAB simulations to quantify how radio and architectural levers - MIMO (beamforming, diversity, spatial multiplexing), carrier aggregation (CA), targeted spectrum refarming to New Radio (NR), mmWave propagation with blockage/rain, and Non-Standalone (NSA) versus Standalone (SA) cores - affect capacity, coverage, latency, and interference robustness, with D2D and M2M as complements to wide-area access. Beamforming improves cell-edge SNR by about 3-6 dB, while spatial multiplexing dominates at moderate/high SNR via multi-stream gains. Throughput scales strongly with CA: increasing from 1 to 5x20-MHz carriers raises peak rate from about 200 Mb/s to about 1 Gb/s at 30 dB SNR; water-filling adds 5-12% over equal power at mid-SNR. Targeted mid-band refarming to NR increases median throughput by 60-90% in urban and 40-70% in rural scenarios when sub-1-GHz layers preserve coverage. At 28 GHz, rain and human blockage add about 8-30 dB excess loss, so viable mmWave deployment concentrates in LOS hot zones with narrow-beam arrays and short inter-site distances. NSA delivers broader initial coverage than SA by reusing LTE/EPC, while SA becomes attractive as transport improves (e.g., >= 10 Gb/s and < 5 ms RTT) and site density grows. We synthesize these results into a practical roadmap: start NR on NSA, prioritize CA-centric spectrum strategies with focused refarming, densify selectively in demand hotspots, and migrate to SA as backhaul and device ecosystems mature.

</details>


### [3] [Timing Fragility Aware Selective Hardening of RISCV Soft Processors on SRAM Based FPGAs](https://arxiv.org/abs/2601.06308)
*Mostafa Darvishi*

Main category: eess.SP

TL;DR: 提出一种基于时序脆弱性感知的选择性加固方法，用于SRAM FPGA上的RISC-V软处理器，通过量化流水线组件在路由扰动下的时序敏感性来指导加固决策，在保持与完全加固相当可靠性的同时显著减少面积和时序开销。


<details>
  <summary>Details</summary>
Motivation: 现有选择性加固方法主要依赖架构关键性或功能故障分析，忽略了路由相关的时序敏感性对处理器鲁棒性的影响。需要一种考虑时序脆弱性的方法来优化FPGA软处理器的可靠性设计。

Method: 基于原位时序可观测性技术，量化流水线组件在受控路由扰动下的统计时序敏感性，利用这些信息指导选择性加固决策。该方法针对SRAM FPGA上的RISC-V软处理器实现。

Result: 实验结果显示，时序脆弱性较高的组件对路由引起的延迟效应也更敏感。利用这种相关性，提出的选择性加固策略在实现与完全加固相当的鲁棒性的同时，显著减少了面积和时序开销。

Conclusion: 时序脆弱性为FPGA处理器架构的可靠性感知设计优化提供了一个实用有效的度量指标，能够指导选择性加固决策，在可靠性和开销之间取得良好平衡。

Abstract: Selective hardening is widely employed to improve the reliability of FPGA based soft processors while limiting the overhead of full redundancy. However, existing approaches primarily rely on architectural criticality or functional fault analysis, overlooking the impact of routing dependent timing sensitivity on processor robustness. This paper introduces a timing fragility aware selective hardening methodology for RISCV soft processors implemented on SRAM based FPGAs. Building on recent advances in in situ timing observability, the proposed approach quantifies the statistical timing sensitivity of pipeline components under controlled routing perturbations and uses this information to guide hardening decisions. Experimental results on a RISCV processor implemented on a commercial FPGA platform show that components exhibiting higher timing fragility also demonstrate increased vulnerability to routing induced delay effects. Leveraging this correlation, the proposed selective hardening strategy achieves robustness comparable to full hardening while significantly reducing area and timing overhead. These results demonstrate that timing fragility provides a practical and effective metric for reliability aware design optimization in FPGA based processor architectures.

</details>


### [4] [Building Envelope Inversion by Data-driven Interpretation of Ground Penetrating Radar](https://arxiv.org/abs/2601.06333)
*Ahmed Nirjhar Alam,Wesley Reinhart,Rebecca Napolitano*

Main category: eess.SP

TL;DR: 开发基于GPR的墙体诊断框架，将墙体反演分解为垂直（立柱存在）和水平（墙体类型）分类任务，使用稀疏神经网络实现高精度且物理可解释的特征提取。


<details>
  <summary>Details</summary>
Motivation: 探地雷达（GPR）具有深度分辨率、非破坏性操作和广泛材料敏感性等优点，但在建筑围护结构诊断中应用有限。墙体组件的紧凑几何结构导致来自紧密排列的立柱、护板和覆层的反射强烈重叠，使得系统反演困难。数据驱动解释的最新进展为重新审视这一挑战提供了机会。

Method: 开发GPR反演框架，将墙体诊断分解为垂直（立柱存在）和水平（墙体类型）分类任务。实施多种特征最小化策略，包括递归消除、凝聚聚类和基于L0的稀疏性，以提高保真度和可解释性。其中基于L0的稀疏神经网络（SparseNN）表现尤为出色。

Result: 基于L0的稀疏神经网络（SparseNN）表现最佳：在仅依赖一小部分输入特征的情况下超越了随机森林的准确性，每个特征都与可识别的介电界面相关联。SHAP分析进一步证实SparseNN学习的反射模式与物理层边界一致。

Conclusion: 该框架为使用GPR雷达图进行物理可解释和数据高效的墙体组件反演奠定了基础。虽然未涉及缺陷检测，但重建完整围护结构并隔离与关键元素相关特征的能力为未来的反演和异常分析任务提供了必要的基线。

Abstract: Ground-penetrating radar (GPR) combines depth resolution, non-destructive operation, and broad material sensitivity, yet it has seen limited use in diagnosing building envelopes. The compact geometry of wall assemblies, where reflections from closely spaced studs, sheathing, and cladding strongly overlap, has made systematic inversion difficult. Recent advances in data-driven interpretation provide an opportunity to revisit this challenge and assess whether machine learning can reliably extract structural information from such complex signals. Here, we develop a GPR-based inversion framework that decomposes wall diagnostics into classification tasks addressing vertical (stud presence) and lateral (wall-type) variations. Alongside model development, we implement multiple feature minimization strategies - including recursive elimination, agglomerative clustering, and L0-based sparsity - to promote fidelity and interpretability. Among these approaches, the L0-based sparse neural network (SparseNN) emerges as particularly effective: it exceeds Random Forest accuracy while relying on only a fraction of the input features, each linked to identifiable dielectric interfaces. SHAP analysis further confirms that the SparseNN learns reflection patterns consistent with physical layer boundaries. In summary, this framework establishes a foundation for physically interpretable and data-efficient inversion of wall assemblies using GPR radargrams. Although defect detection is not addressed here, the ability to reconstruct intact envelope structure and isolate features tied to key elements provides a necessary baseline for future inversion and anomaly-analysis tasks.

</details>


### [5] [Performance Analysis for Wireless Localization with Random Sensor Network](https://arxiv.org/abs/2601.06396)
*Mengqi Ma,Aihua Xia*

Main category: eess.SP

TL;DR: 论文研究了无线定位中基于RSS和AOA融合估计器的性能分析，证明了在噪声较大时，任意平稳各向同性传感器网络与泊松点过程网络在分布上不可区分，并推导了泊松网络下的MSE和CMSE上界。


<details>
  <summary>Details</summary>
Motivation: 准确的无线定位对自动驾驶系统和智能基础设施至关重要。现有研究需要理解传感器网络部署参数（如密度、观测半径）与定位精度之间的定量关系，为下一代位置感知无线网络提供设计指导。

Method: 1. 建立近似定理：证明在测量噪声足够大时，任意平稳各向同性传感器网络与齐次泊松点过程网络在RSS和AOA观测的联合分布上不可区分；2. 针对泊松网络，提出基于RSS和AOA融合的估计器，推导MSE和条件MSE的解析上界，建立与传感器密度、观测半径和噪声方差的显式缩放规律。

Result: 1. 证明了近似定理的有效性；2. 推导了泊松网络下融合估计器MSE和CMSE的易处理解析上界；3. 建立了定位精度与传感器密度、观测半径和噪声方差之间的明确缩放关系；4. 验证了泊松网络结果可作为非泊松部署在噪声较大时的合理代理。

Conclusion: 该研究提供了将部署参数和感知参数转化为可实现精度目标的定量框架，为下一代位置感知无线网络的鲁棒、成本感知设计提供了理论指导。泊松近似定理使得复杂网络部署下的性能分析变得可行，为实际系统设计提供了实用工具。

Abstract: Accurate wireless localization underpins applications from autonomous systems to smart infrastructure. We study the mean-squared error (MSE) and conditional MSE (CMSE) of a practical fusion-based estimator in d-dimensional, stationary isotropic (translation- and rotation-invariant) random sensor networks, where a central processor combines received-signal-strength (RSS) and angle-of-arrival (AOA) measurements to infer a target's position. Our contributions are twofold. First, we establish an approximation theorem: when measurement noise is sufficiently large, the joint law of RSS and AOA observations under a broad class of stationary isotropic deployments is, in distribution, indistinguishable from that induced by a homogeneous Poisson point process (PPP). Second, leveraging this equivalence, we investigate a homogeneous PPP-based sensor network. We propose a fusion-based estimator in which a central processor aggregates RSS and AOA measurements from a set of spatially distributed sensors to infer the target position. For this PPP deployment within a finite observation region, we derive tractable analytical upper bounds for both the MSE and CMSE, establishing explicit scaling laws with respect to sensor density, observation radius, and noise variance. The approximation theorem then certifies these PPP-based bounds as reasonable proxies for non-Poisson deployments in noisy regimes. Overall, the results translate deployment and sensing parameters into achievable accuracy targets and provide robust, cost-aware guidance for the design of next-generation location-aware wireless networks.

</details>


### [6] [Neuro-Wideband WiFi Sensing via Self-Conditioned CSI Extrapolation](https://arxiv.org/abs/2601.06467)
*Sijie Ji,Weiying Hou,Chenshu Wu*

Main category: eess.SP

TL;DR: 提出Neuro-Wideband (NWB)新范式，通过深度学习将有限带宽的CSI转换为近似宽带的eCSI，无需额外硬件或信道测量，实现商品WiFi的宽带感知能力。


<details>
  <summary>Details</summary>
Motivation: 商用WiFi的有限带宽限制了多径分辨率和多用户感知能力，而获取大带宽在实际中不可行（频谱有限、网络拥挤）。需要一种无需额外硬件或测量的宽带WiFi感知方案。

Method: 提出NWB范式，核心洞察：CSI测量天然包含多径参数，可转换为近似宽带的eCSI。开发WUKONG框架，将NWB建模为自条件学习问题，使用现有CSI数据作为自标记样本训练。结合Transformer和Diffusion模型，捕获样本特定多径参数并转移到eCSI。

Result: 在不同协议和带宽的WiFi信号上进行真实世界实验，验证了NWB的有效性。通过定位和多人员呼吸监测案例研究进一步展示了eCSI的实用性。

Conclusion: NWB为在商品硬件上实现宽带WiFi感知提供了实用途径，扩展了无线感知系统的设计空间。

Abstract: WiFi sensing has suffered from the limited bandwidths designated for its original communication purpose, leading to fundamental limits in multipath resolution and thus multi-user sensing. Unfortunately, it is practically prohibitive to obtain large bandwidths on commercial WiFi, considering the conflict between the limited spectrum and the crowded networks. In this paper, we present Neuro-Wideband (NWB), a completely different paradigm that enables wideband WiFi sensing without specialized hardware or extra channel measurements. Our key insight is that any physical measurement of channel state information (CSI) inherently encapsulates multipath parameters, which, while unsolvable in isolation, can be transformed into an expanded form of CSI (eCSI) approximating measurements over a broader bandwidth. To ground this insight, we propose WUKONG to address NWB as a unique self-conditioned learning problem that can be trained by using any existing CSI data as self-labeled samples. WUKONG introduces a novel deep learning framework by integrating Transformer and Diffusion models, which captures sample-specific multipath parameters and transfers this sample-level knowledge to the outcome eCSI. We conduct real-world experiments to evaluate WUKONG on diverse WiFi signals across protocols and bandwidths. The results show the promising effectiveness of NWB, which is further demonstrated through case studies on localization and multi-person breathing monitoring using eCSI. Overall, the proposed NWB promises a practical pathway toward realizing wideband WiFi sensing on commodity hardware, expanding the design space of wireless sensing systems.

</details>


### [7] [Joint Impact of ADC and Fronthaul Quantization in Cell-Free Massive MIMO-OFDM Uplink](https://arxiv.org/abs/2601.06483)
*Özlem Tuğfe Demir,Emil Björnson*

Main category: eess.SP

TL;DR: 论文研究了宽带OFDM无蜂窝大规模MIMO系统中，ADC量化与fronthaul量化的联合影响，提出了一种在fronthaul传输前处理接收信号以减少量化失真的策略。


<details>
  <summary>Details</summary>
Motivation: 在无蜂窝大规模MIMO系统的上行链路中，量化在ADC和fronthaul两个关键域影响性能。虽然窄带系统中这两种量化效应已被广泛研究，但在实际的宽带OFDM系统中，它们的联合影响尚未得到充分探索。

Method: 论文对联合失真进行建模，提出了一种fronthaul策略：每个接入点在传输前处理接收信号以减少量化伪影。开发了一种有效的估计算法，在fronthaul传输前重建未量化的时域信号。

Result: 提出的设计为在宽带无蜂窝架构中实现高效、量化感知的上行传输提供了新的见解。通过仅在活动子载波上应用量化，减少了fronthaul负载并避免了不必要的失真。

Conclusion: 该研究填补了宽带OFDM无蜂窝大规模MIMO系统中ADC和fronthaul量化联合影响的空白，提出的信号处理策略能够有效减少量化失真，为实际系统实现提供了有价值的指导。

Abstract: In the uplink of a cell-free massive MIMO system, quantization affects performance in two key domains: the time-domain distortion introduced by finite-resolution analog-to-digital converters (ADCs) at the access points (APs), and the fronthaul quantization of signals sent to the central processing unit (CPU). Although quantizing twice may seem redundant, the ADC quantization in orthogonal frequency-division duplex (OFDM) systems appears in the time domain, and one must then convert to the frequency domain, where quantization can be applied only to the signals at active subcarriers. This reduces fronthaul load and avoids unnecessary distortion, since the ADC output spans all OFDM samples while only a subset of subcarriers carries useful information.
  While both quantization effects have been extensively studied in narrowband systems, their joint impact in practical wideband OFDM-based cell-free massive MIMO remains largely unexplored. This paper addresses the gap by modeling the joint distortion and proposing a fronthaul strategy in which each AP processes the received signal to reduce quantization artifacts before transmission. We develop an efficient estimation algorithm that reconstructs the unquantized time-domain signal prior to fronthaul transmission and evaluate its effectiveness. The proposed design offers new insights for implementing efficient, quantization-aware uplink transmission in wideband cell-free architectures.

</details>


### [8] [Cell-Free Massive MIMO with Hardware-Impaired Wireless Fronthaul](https://arxiv.org/abs/2601.06486)
*Özlem Tuğfe Demir,Emil Björnson*

Main category: eess.SP

TL;DR: 该论文提出了一种针对无蜂窝大规模MIMO的新型放大转发无线前传方案，联合建模了接入点和前传收发器的硬件损伤，并设计了损伤感知的线性组合器来优化性能。


<details>
  <summary>Details</summary>
Motivation: 无蜂窝大规模MIMO通过分布式接入点实现联合传输和接收，提高了频谱和能量效率。然而，低成本密集部署的接入点不可避免存在射频链路的硬件损伤。现有研究主要关注接入侧的硬件损伤，而前传链路的硬件损伤影响尚未得到充分探索。

Method: 提出了一种基于放大转发的新型无线前传方案，专门针对无蜂窝大规模MIMO设计。开发了一个分析框架，联合建模接入点和前传收发器的硬件损伤，推导端到端失真信号表达式，量化各损伤对频谱效率的贡献，并设计了损伤感知的线性组合器来优化缓解这些影响。

Result: 数值结果表明，损伤感知处理带来了显著的性能增益，证明了所提出的放大转发前传方案作为未来无蜂窝架构成本效益使能器的潜力。

Conclusion: 该研究填补了无蜂窝大规模MIMO系统中前传链路硬件损伤建模的重要空白，提出的损伤感知处理方案能够有效提升系统性能，为未来低成本无蜂窝架构提供了可行的解决方案。

Abstract: Cell-free massive MIMO (multiple-input multiple-output) enhances spectral and energy efficiency compared to conventional cellular networks by enabling joint transmission and reception across a large number of distributed access points (APs). Since these APs are envisioned to be low-cost and densely deployed, hardware impairments, stemming from non-ideal radio-frequency (RF) chains, are unavoidable. While existing studies primarily address hardware impairments on the access side, the impact of hardware impairments on the wireless fronthaul link has remained largely unexplored. In this work, we fill this important gap by introducing a novel amplify-and-forward (AF) based wireless fronthauling scheme tailored for cell-free massive MIMO. Focusing on the uplink, we develop an analytical framework that jointly models the hardware impairments at both the APs and the fronthaul transceivers, derives the resulting end-to-end distorted signal expression, and quantifies the individual contribution of each impairment to the spectral efficiency. Furthermore, we design distortion-aware linear combiners that optimally mitigate these effects. Numerical results demonstrate significant performance gains from distortion-aware processing and illustrate the potential of the proposed AF fronthauling scheme as a cost-effective enabler for future cell-free architectures.

</details>


### [9] [A Multimodal Deep Learning Framework for Predicting ICU Deterioration: Integrating ECG Waveforms with Clinical Data and Clinician Benchmarking](https://arxiv.org/abs/2601.06645)
*Juan Miguel López Alcaraz,Xicoténcatl López Moran,Erick Dávila Zaragoza,Claas Händel,Richard Koebe,Wilhelm Haverkamp,Nils Strodthoff*

Main category: eess.SP

TL;DR: MDS ICU是一个统一的多模态机器学习框架，融合人口统计学、生命体征、实验室数据、ECG波形等多种ICU常规数据，使用S4编码器和RealMLP编码器联合预测33种临床结局，在MIMIC IV数据集上表现出色，能增强临床决策支持。


<details>
  <summary>Details</summary>
Motivation: 现有ICU风险预测模型通常只关注单一结局或有限数据类型，而临床医生需要整合纵向历史、实时生理数据和异质临床信息。为填补这一空白，需要开发能融合多模态数据的统一预测框架。

Method: 开发MDS ICU多模态机器学习框架，融合人口统计学、生物特征、生命体征、实验室值、ECG波形、手术过程和医疗设备使用等常规数据。使用MIMIC IV中27062名患者的63001个样本，采用结构化状态空间S4编码器处理ECG波形，多层感知器RealMLP编码器处理表格数据，联合预测33种临床相关结局。

Result: 模型表现出强大的区分能力：24小时死亡率AUROC 0.90，镇静药物使用0.92，有创机械通气0.97，凝血功能障碍0.93。校准分析显示预测风险与实际风险高度一致，ECG波形整合带来持续增益。模型预测单独优于临床医生和大型语言模型，提供模型输出作为决策支持能进一步提升临床医生表现。

Conclusion: 多模态AI能在ICU中提供有临床意义的跨结局风险分层，增强而非替代临床专业知识，为精准重症监护决策支持建立了可扩展的基础。

Abstract: Artificial intelligence holds strong potential to support clinical decision making in intensive care units where timely and accurate risk assessment is critical. However, many existing models focus on isolated outcomes or limited data types, while clinicians integrate longitudinal history, real time physiology, and heterogeneous clinical information. To address this gap, we developed MDS ICU, a unified multimodal machine learning framework that fuses routinely collected data including demographics, biometrics, vital signs, laboratory values, ECG waveforms, surgical procedures, and medical device usage to provide continuous predictive support during ICU stays. Using 63001 samples from 27062 patients in MIMIC IV, we trained a deep learning architecture that combines structured state space S4 encoders for ECG waveforms with multilayer perceptron RealMLP encoders for tabular data to jointly predict 33 clinically relevant outcomes spanning mortality, organ dysfunction, medication needs, and acute deterioration. The model achieved strong discrimination with AUROCs of 0.90 for 24 hour mortality, 0.92 for sedative administration, 0.97 for invasive mechanical ventilation, and 0.93 for coagulation dysfunction. Calibration analysis showed close agreement between predicted and observed risks, with consistent gains from ECG waveform integration. Comparisons with clinicians and large language models showed that model predictions alone outperformed both, and that providing model outputs as decision support further improved their performance. These results demonstrate that multimodal AI can deliver clinically meaningful risk stratification across diverse ICU outcomes while augmenting rather than replacing clinical expertise, establishing a scalable foundation for precision critical care decision support.

</details>


### [10] [Artificial Intelligence Driven Channel Coding and Resource Optimization for Wireless Networks](https://arxiv.org/abs/2601.06796)
*Yasir Ali,Tayyab Manzoor,Huan Yang,Chenhang Yan,Yuanqing Xia*

Main category: eess.SP

TL;DR: AI在5G/5G+网络中的关键作用：通过深度学习、强化学习等AI技术解决干扰缓解、动态资源分配等挑战，特别是在编码理论方面的创新显著提升了纠错性能和传输效率。


<details>
  <summary>Details</summary>
Motivation: 5G/5G+网络对超高速数据传输、超低延迟和弹性连接的需求急剧增长，这些能力对于物联网、自动驾驶汽车和智慧城市等关键应用至关重要。传统技术在应对网络挑战方面存在局限，需要AI提供更先进的解决方案。

Method: 采用深度学习、强化学习和神经网络方法，研究AI在编码理论中的创新应用，包括纠错码、调制技术改进，并探讨AI与大规模MIMO、智能反射面、隐私增强机制等新兴技术的集成。

Result: AI驱动的方法在纠错性能、解码效率和自适应传输策略方面取得了显著进展，能够更好地应对5G/5G+网络的动态挑战，为下一代无线网络奠定基础。

Conclusion: AI对现代无线通信具有变革性影响，通过AI与新兴技术的融合，可以构建更可扩展、自适应和高效的网络架构，推动5G/5G+网络向更高性能发展。

Abstract: The ongoing evolution of 5G and its enhanced version, 5G+, has significantly transformed the telecommunications landscape, driving an unprecedented demand for ultra-high-speed data transmission, ultra-low latency, and resilient connectivity. These capabilities are essential for enabling mission-critical applications such as the Internet of Things, autonomous vehicles, and smart city infrastructures. This paper investigates the important role of Artificial Intelligence (AI) in addressing the key challenges faced by 5G/5G+ networks, including interference mitigation, dynamic resource allocation, and maintaining seamless network operation. The study particularly focuses on AI-driven innovations in coding theory, which offer advanced solutions to the limitations of conventional error correction and modulation techniques. By employing deep learning, reinforcement learning, and neural network-based approaches, this research demonstrates significant advancements in error correction performance, decoding efficiency, and adaptive transmission strategies. Additionally, the integration of AI with emerging technologies, such as massive multiple-input and multiple-output, intelligent reflecting surfaces, and privacy-enhancing mechanisms, is discussed, highlighting their potential to propel the next generation of wireless networks. This paper also provides insights into the transformative impact of AI on modern wireless communication, establishing a foundation for scalable, adaptive, and more efficient network architectures.

</details>


### [11] [RIS-aided ISAC with $K$-Rydberg Atomic Receivers](https://arxiv.org/abs/2601.06809)
*Hong-Bae Jeon,Chan-Byoung Chae*

Main category: eess.SP

TL;DR: 该论文提出了一种基于可重构智能表面(RIS)辅助的集成感知与通信(ISAC)框架，配备多个里德堡原子接收器(RAR)用户，通过联合优化通信性能和感知精度，为6G网络开发了创新的信号处理方案。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络的发展，需要同时支持通信和感知功能。里德堡原子接收器(RAR)具有高灵敏度和参考辅助接收机制，为集成感知与通信提供了新机遇。然而，如何在RIS辅助的ISAC系统中平衡多用户通信性能和雷达感知精度仍是一个挑战。

Method: 1. 开发了统一的信号模型，联合捕获下行多用户通信和单基地雷达感知；2. 提出了CRB约束的效用最大化问题来平衡通信性能和感知精度；3. 设计了结合分数规划(FP)、主化-最小化(MM)和交替方向乘子法(ADMM)的联合优化框架。

Result: 仿真结果表明，所提出的框架在各种系统环境下始终优于传统方法，显著提升了通信性能和感知精度，验证了RAR在6G网络中的潜力。

Conclusion: 该研究成功开发了一个RIS辅助的ISAC框架，通过创新的优化算法有效平衡了通信和感知性能，为6G网络中RAR技术的应用提供了重要理论基础和实践指导。

Abstract: In this paper, we investigate a reconfigurable intelligent surface (RIS)-assisted integrated sensing and communications (ISAC) framework equipped with multiple Rydberg atomic receiver (RAR)-aided users. By leveraging the reference-assisted reception mechanism of RARs, we develop a unified signal model that jointly captures downlink multi-user communication with RARs and monostatic radar sensing. To explicitly balance communication performance and sensing accuracy, we formulate a Cramer-Rao bound (CRB)-constrained utility maximization problem. To address these challenges, we propose a joint optimization framework that combines fractional programming (FP), majorization-minimization (MM), and the alternating direction method of multipliers (ADMM). Simulation results demonstrate that the proposed framework consistently outperforms the conventional approach over a wide range of system environments, thereby highlighting the importance of the proposed framework in unlocking the potential of RARs for 6G.

</details>


### [12] [Radar-Based Identification of Individuals Using Heartbeat Features Extracted from Signal Amplitude and Phase](https://arxiv.org/abs/2601.06824)
*Haruto Kobayashi,Takuya Sakamoto*

Main category: eess.SP

TL;DR: 提出基于毫米波雷达心跳特征的非接触式身份识别方法，通过分析幅度、相位和复数信号的贡献，并融合三者特征提升识别准确率至97.67%


<details>
  <summary>Details</summary>
Motivation: 现有基于毫米波雷达的心跳身份识别主要使用复数信号频谱图，但幅度、相位和复数信号各自对识别准确率的贡献不明确，需要系统分析不同信号分量的作用

Method: 首先分别评估幅度、相位和复数信号频谱图的识别性能，然后提出特征融合方法整合这三种表示，使用79GHz雷达系统进行实验

Result: 在6名参与者的实验中，提出的特征融合方法实现了97.67%的身份识别准确率，证明了分量分析和集成方法的有效性

Conclusion: 通过系统分析幅度、相位和复数信号分量对身份识别的贡献，并融合这些特征，可以显著提升毫米波雷达心跳识别的准确率，为非接触式生物识别提供了有效方法

Abstract: This study proposes a non-contact method for identifying individuals through the use of heartbeat features measured with millimeter-wave radar. Although complex-valued radar signal spectrograms are commonly used for this task, little attention has been paid to the choice of signal components, namely, whether to use amplitude, phase, or the complex signal itself. Although spectrograms can be constructed independently from amplitude or phase information, their respective contributions to identification accuracy remain unclear. To address this issue, we first evaluate identification performance using spectrograms derived separately from amplitude, phase, and complex signals. We then propose a feature fusion method that integrates these three representations to enhance identification accuracy. Experiments conducted with a 79-GHz radar system and involving six participants achieved an identification accuracy of 97.67%, demonstrating the effectiveness of the proposed component-wise analysis and integration approach.

</details>


### [13] [Movable Beyond-Diagonal Reconfigurable Intelligent Surfaces: Moving, Interconnecting, or Both?](https://arxiv.org/abs/2601.06837)
*Shuyue Xu,Matteo Nerini,Bruno Clerckx*

Main category: eess.SP

TL;DR: 提出可移动超对角线可重构智能表面设计，结合单元间连接性和可移动性增强信道，通过联合优化波束成形、RIS配置和单元位置最大化系统和速率


<details>
  <summary>Details</summary>
Motivation: 传统RIS存在性能限制，需要结合单元间连接性和可移动性来进一步提升信道增强能力，特别是在不同场景下需要灵活适应不同系统配置

Method: 开发高效算法：闭式波束成形、低复杂度部分近端交替方向乘子法用于BD-RIS设计、连续凸近似用于单元位置优化，联合优化波束成形、BD-RIS配置和单元位置

Result: 仿真显示：高移动性结构在小规模RIS和丰富散射场景中表现优越，而高连接性结构在大规模RIS和大规模发射阵列配置中占主导地位

Conclusion: MA-BD-RIS设计通过结合单元间连接性和可移动性，能够根据场景需求灵活调整，在不同系统配置下实现最优性能，为RIS技术发展提供新方向

Abstract: This letter proposes a movable beyond-diagonal reconfigurable intelligent surfaces (MA-BD-RIS) design, combining inter-element connectivity and movability for channel enhancement. We study a MA-BD-RIS assisted multi-user multiple input single output system where beamforming, BD-RIS configuration, and elements positions are jointly optimized to maximize the sum-rate. An efficient algorithm is developed, incorporating closed-form beamforming, a low-complexity partially proximal alternating direction method of multipliers for BD-RIS design, and successive convex approximation for element placement. Simulations show that the high-movability structure yields superior performance in small-scale RIS and rich scattering scenarios, while the high-connectivity structure dominates in large-scale RIS and massive transmit array configurations.

</details>


### [14] [Deep Learning Based Channel Extrapolation for Dual-Band Massive MIMO Systems](https://arxiv.org/abs/2601.06858)
*Qikai Xiao,Kehui Li,Binggui Zhou,Shaodan Ma*

Main category: eess.SP

TL;DR: 提出MDFCE方法，通过融合多域特征将sub-6 GHz CSI外推到mmWave CSI，减少毫米波信道估计的导频开销


<details>
  <summary>Details</summary>
Motivation: 毫米波大规模MIMO系统需要高精度CSI，但直接估计毫米波信道需要大量导频开销，因为CSI维度大且信噪比低。双频段系统需要有效利用sub-6 GHz频段信息来减少毫米波频段的导频需求。

Method: 提出多域融合信道外推器(MDFCE)，结合混合专家框架和多头自注意力机制，融合sub-6 GHz CSI的多域特征，有效表征从sub-6 GHz CSI到mmWave CSI的映射关系。

Result: 仿真结果表明，MDFCE在不同天线阵列规模和信噪比水平下，相比现有方法能以更少的训练导频获得更优性能，同时计算效率更高。

Conclusion: MDFCE为双频段大规模MIMO系统提供了一种高效的毫米波CSI获取方案，通过智能融合sub-6 GHz频段信息显著减少了毫米波信道的导频开销。

Abstract: Future wireless communication systems will increasingly rely on the integration of millimeter wave (mmWave) and sub-6 GHz bands to meet heterogeneous demands on high-speed data transmission and extensive coverage. To fully exploit the benefits of mmWave bands in massive multiple-input multiple-output (MIMO) systems, highly accurate channel state information (CSI) is required. However, directly estimating the mmWave channel demands substantial pilot overhead due to the large CSI dimension and low signal-to-noise ratio (SNR) led by severe path loss and blockage attenuation. In this paper, we propose an efficient \textbf{M}ulti-\textbf{D}omain \textbf{F}usion \textbf{C}hannel \textbf{E}xtrapolator (MDFCE) to extrapolate sub-6 GHz band CSI to mmWave band CSI, so as to reduce the pilot overhead for mmWave CSI acquisition in dual band massive MIMO systems. Unlike traditional channel extrapolation methods based on mathematical modeling, the proposed MDFCE combines the mixture-of-experts framework and the multi-head self-attention mechanism to fuse multi-domain features of sub-6 GHz CSI, aiming to characterize the mapping from sub-6 GHz CSI to mmWave CSI effectively and efficiently. The simulation results demonstrate that MDFCE can achieve superior performance with less training pilots compared with existing methods across various antenna array scales and signal-to-noise ratio levels while showing a much higher computational efficiency.

</details>


### [15] [Continuous Energy Landscape Model for Analyzing Brain State Transitions](https://arxiv.org/abs/2601.06991)
*Triet M. Tran,Seyed Majid Razavi,Dee H. Wu,Sina Khanmohammadi*

Main category: eess.SP

TL;DR: 提出连续能量景观框架，使用图神经网络从fMRI信号学习连续精度矩阵，避免二值化信息损失，在合成和真实fMRI数据上优于传统二值能量景观模型。


<details>
  <summary>Details</summary>
Motivation: 传统能量景观模型依赖二值脑状态表示，导致信息损失和状态数量指数增长，难以计算大量脑区的能量值。

Method: 提出连续能量景观框架，使用图神经网络直接从fMRI信号学习连续精度矩阵，保留信号完整范围进行能量景观计算。

Result: 在合成数据上获得更高似然度、更准确的盆地几何、状态占据和转移动态恢复；在真实fMRI数据上，工作记忆和执行功能预测AUC提高0.27，反应时间预测R2提高0.35。

Conclusion: 利用完整信号值的连续能量景观模型能更好捕捉神经元动态，对神经疾病诊断和监测有重要意义。

Abstract: Energy landscape models characterize neural dynamics by assigning energy values to each brain state that reflect their stability or probability of occurrence. The conventional energy landscape models rely on binary brain state representation, where each region is considered either active or inactive based on some signal threshold. However, this binarization leads to significant information loss and an exponential increase in the number of possible brain states, making the calculation of energy values infeasible for large numbers of brain regions. To overcome these limitations, we propose a novel continuous energy landscape framework that employs Graph Neural Networks (GNNs) to learn a continuous precision matrix directly from functional MRI (fMRI) signals, preserving the full range of signal values during energy landscape computation. We validated our approach using both synthetic data and real-world fMRI datasets from brain tumor patients. Our results on synthetic data generated from a switching linear dynamical system (SLDS) and a Kuramoto model show that the continuous energy model achieved higher likelihood and more accurate recovery of basin geometry, state occupancy, and transition dynamics than conventional binary energy landscape models. In addition, results from the fMRI dataset indicate a 0.27 increase in AUC for predicting working memory and executive function, along with a 0.35 improvement in explained variance (R2) for predicting reaction time. These findings highlight the advantages of utilizing the full signal values in energy landscape models for capturing neuronal dynamics, with strong implications for diagnosing and monitoring neurological disorders.

</details>


### [16] [Autofocus Method for Human-Body Imaging under Respiratory Motion Using Synthetic Aperture Radar](https://arxiv.org/abs/2601.07099)
*Masaya Kato,Takuya Sakamoto*

Main category: eess.SP

TL;DR: 提出一种针对人体呼吸运动条件下合成孔径雷达成像的有效自动聚焦方法，通过分离空间-时间频率域中的雷达回波并分别估计相位误差，改善图像质量。


<details>
  <summary>Details</summary>
Motivation: 人体呼吸运动会导致合成孔径雷达成像中的相位误差，传统方法难以处理多个身体部位因呼吸产生的不同运动，影响图像聚焦质量。

Method: 通过分离空间-时间频率域中的雷达回波，分别估计每个分离回波的相位误差，然后补偿这些误差，生成所有散射点都聚焦的合成孔径雷达图像。

Result: 实验显示，与传统方法相比，Muller-Buffington锐度指标改善5.1倍，相对于参考点云的均方根误差从34mm降低到20mm。

Conclusion: 该方法能有效抑制呼吸运动引起的相位误差，显著提高人体合成孔径雷达成像质量，特别是在多个身体部位有不同运动的情况下。

Abstract: This study presents an effective autofocusing approach for synthetic aperture radar imaging of the human body under conditions of respiratory motion. The proposed method suppresses respiratory-motion-induced phase errors by separating radar echoes in the spatial- and time-frequency domains and estimating phase errors individually for each separated echo. By compensating for the estimated phase errors, synthetic aperture radar images focused on all scattering points are generated, even when multiple body parts exhibit different motions due to respiration. The performance of the proposed method is evaluated through experiments with four participants in the supine position. Compared with a conventional method, the proposed approach improves image quality by a factor of 5.1 in terms of Muller-Buffington sharpness, and reduces the root-mean-square error with respect to a reference point cloud from 34 mm to 20 mm.

</details>


### [17] [Antenna Coding Optimization for Pixel Antenna Empowered MIMO Wireless Power Transfer](https://arxiv.org/abs/2601.07324)
*Yijun Chen,Shanpu Shen,Tianrui Qiao,Hongyu Li,Kai-Kit Wong,Ross Murch*

Main category: eess.SP

TL;DR: 提出利用像素天线进行天线编码，增强MIMO无线功率传输系统的输出直流功率，通过联合优化天线编码、波束成形和整流器非线性特性，实现超过15dB的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统MIMO WPT系统使用固定天线配置，性能受限。像素天线提供了一种新的自由度（天线编码），可以联合利用天线编码、波束成形和整流器非线性特性来显著提升输出直流功率。

Method: 1. 提出基于波束空间信道模型的MIMO WPT系统模型，支持二进制和连续天线编码；2. 建立联合天线编码和波束成形优化问题，采用非线性整流器模型；3. 提出两种高效的闭式逐次凸逼近算法优化波束成形；4. 为降低计算复杂度，提出基于K-means聚类的码本天线编码设计。

Result: 1. 二进制天线编码相比传统固定天线配置系统提升输出直流功率超过15dB；2. 连续天线编码进一步提升6dB性能；3. 提出的码本设计比先前设计性能提升达40%，同时降低计算复杂度。

Conclusion: 天线编码利用像素天线显著提升了MIMO WPT系统的输出直流功率，验证了这种新自由度在增强无线功率传输系统中的巨大潜力。

Abstract: We investigate antenna coding utilizing pixel antennas as a new degree of freedom for enhancing multiple-input multiple-output (MIMO) wireless power transfer (WPT) systems. The objective is to enhance the output direct current (DC) power under RF combining and DC combining schemes by jointly exploiting gains from antenna coding, beamforming, and rectenna nonlinearity. We first propose the MIMO WPT system model with binary and continuous antenna coding using the beamspace channel model and formulate the joint antenna coding and beamforming optimization using a nonlinear rectenna model. We propose two efficient closed-form successive convex approximation algorithms to efficiently optimize the beamforming. To further reduce the computational complexity, we propose codebook-based antenna coding designs for output DC power maximization based on K-means clustering. Results show that the proposed pixel antenna empowered MIMO WPT system with binary antenna coding increases output DC power by more than 15 dB compared with conventional systems with fixed antenna configuration. With continuous antenna coding, the performance improves another 6 dB. Moreover, the proposed codebook design outperforms previous designs by up to 40% and shows good performance with reduced computational complexity. Overall, the significant improvement in output DC power verifies the potential of leveraging antenna coding utilizing pixel antennas to enhance WPT systems.

</details>


### [18] [PIDT: Physics-Informed Digital Twin for Optical Fiber Parameter Estimation](https://arxiv.org/abs/2601.07436)
*Zicong Jiang,Magnus Karlsson,Erik Agrell,Christian Häger*

Main category: eess.SP

TL;DR: 提出物理信息数字孪生(PIDT)：一种结合参数化分步方法和物理信息损失的光纤参数估计方法，相比先前神经算子具有更高精度、更快收敛速度和更低复杂度


<details>
  <summary>Details</summary>
Motivation: 传统光纤参数估计方法存在精度不足或计算复杂度高的问题，需要一种既能准确估计光纤参数又能保持计算效率的方法

Method: 结合参数化分步方法和物理信息损失函数，通过数字孪生框架实现光纤参数估计

Result: PIDT相比先前神经算子方法在精度、收敛速度和计算复杂度方面均有显著提升

Conclusion: PIDT为光纤参数估计提供了一种高效准确的新方法，在精度和计算效率之间取得了良好平衡

Abstract: We propose physics-informed digital twin (PIDT): a fiber parameter estimation approach that combines a parameterized split-step method with a physics-informed loss. PIDT improves accuracy and convergence speed with lower complexity compared to previous neural operators.

</details>


### [19] [Vector Quantized-Aided XL-MIMO CSI Feedback with Channel Adaptive Transmission](https://arxiv.org/abs/2601.07584)
*Yuhang Ma,Nan Ma,Jianqiao Chen,Wenkai Liu*

Main category: eess.SP

TL;DR: 提出VQ-DJSCC-F方案，利用向量量化和深度联合信源信道编码框架，解决6G XL-MIMO系统中CSI反馈的高开销问题，同时考虑近场效应。


<details>
  <summary>Details</summary>
Motivation: 6G XL-MIMO系统的大规模天线阵列导致CSI反馈开销巨大，现有量化反馈方法面临量化精度有限和信道鲁棒性不足的双重挑战，特别是在压缩高维信道特征为离散符号时。

Method: 1) 利用近场信道在极坐标-延迟域的稀疏性提取能量集中特征以降低维度；2) 同时设计Transformer和CNN架构作为骨干网络分层提取CSI特征；3) 使用VQ模块将特征投影到离散潜在空间；4) 引入熵损失正则化和EMA更新策略最大化量化精度；5) 开发注意力机制驱动的信道自适应模块减轻无线信道衰落对索引序列传输的影响。

Result: 仿真结果表明，所提方案在不同信道条件下实现了优越的CSI重建精度，同时具有更低的反馈开销。

Conclusion: VQ-DJSCC-F方案有效解决了XL-MIMO系统中CSI反馈的高开销问题，通过结合近场信道特性、混合网络架构和先进的量化技术，在保证重建精度的同时显著降低了反馈开销。

Abstract: Efficient channel state information (CSI) feedback is critical for 6G extremely large-scale multiple-input multiple-output (XL-MIMO) systems to mitigate channel interference. However, the massive antenna scale imposes a severe burden on feedback overhead. Meanwhile, existing quantized feedback methods face dual challenges of limited quantization precision and insufficient channel robustness when compressing high-dimensional channel features into discrete symbols. To reduce these gaps, guided by the deep joint source-channel coding (DJSCC) framework, we propose a vector quantized (VQ)-aided scheme for CSI feedback in XL-MIMO systems considering the near-field effect, named VQ-DJSCC-F. Firstly, taking advantage of the sparsity of near-field channels in the polar-delay domain, we extract energy-concentrated features to reduce dimensionality. Then, we simultaneously design the Transformer and CNN (convolutional neural network) architectures as the backbones to hierarchically extract CSI features, followed by VQ modules projecting features into a discrete latent space. The entropy loss regularization in synergy with an exponential moving average (EMA) update strategy is introduced to maximize quantization precision. Furthermore, we develop an attention mechanism-driven channel adaptation module to mitigate the impact of wireless channel fading on the transmission of index sequences. Simulation results demonstrate that the proposed scheme achieves superior CSI reconstruction accuracy with lower feedback overheads under varying channel conditions.

</details>


### [20] [Learning to Unfold Fractional Programming for Multi-Cell MU-MIMO Beamforming with Graph Neural Networks](https://arxiv.org/abs/2601.07630)
*Zihan Jiao,Xinping Yi,Shi Jin*

Main category: eess.SP

TL;DR: 论文提出通过展开FastFP算法来加速多小区MU-MIMO系统中波束成形优化的方法，解决传统FP算法计算复杂度高的问题


<details>
  <summary>Details</summary>
Motivation: 在多小区多用户MIMO系统中，分数规划(FP)在优化波束成形向量方面效果显著，但存在计算复杂度高的问题。需要找到既能保持FP效果又能降低复杂度的解决方案。

Method: 采用深度学习展开FastFP算法的方法(DeepFP)。FastFP通过避免大维度矩阵求逆来降低复杂度，而DeepFP通过学习展开FastFP算法来进一步加速收敛。

Result: DeepFP方法相比传统FP算法具有更快的收敛速度，同时保持了优化性能。通过避免大矩阵求逆和算法展开学习，显著降低了计算复杂度。

Conclusion: 通过将深度学习与优化算法结合，DeepFP为多小区MU-MIMO系统中的波束成形优化提供了一种高效且低复杂度的解决方案，平衡了性能与计算效率。

Abstract: In the multi-cell multiuser multi-input multi-output (MU-MIMO) systems, fractional programming (FP) has demonstrated considerable effectiveness in optimizing beamforming vectors, yet it suffers from high computational complexity. Recent improvements demonstrate reduced complexity by avoiding large-dimension matrix inversions (i.e., FastFP) and faster convergence by learning to unfold the FastFP algorithm (i.e., DeepFP).

</details>


### [21] [Lagrangian Grid-based Estimation of Nonlinear Systems with Invertible Dynamics](https://arxiv.org/abs/2601.07721)
*Jindřich Duník,Jan Krejčí,Jakub Matoušek,Marek Brandner,Yeongkwon Choe*

Main category: eess.SP

TL;DR: 提出一种非线性拉格朗日网格滤波器，将计算复杂度从二次降低到对数线性，同时保持原网格滤波器的鲁棒性、准确性和确定性行为。


<details>
  <summary>Details</summary>
Motivation: 针对非线性非高斯系统的状态估计问题，需要解决贝叶斯递归关系的数值解。现有网格滤波器（GbF）计算复杂度高（二次），需要开发更高效的非线性系统滤波方法。

Method: 基于线性系统的拉格朗日网格滤波器，扩展到具有可逆非线性动态的系统。通过拉格朗日方法将计算复杂度从二次降低到对数线性，同时保持原网格滤波器的优点。

Result: 提出的非线性拉格朗日网格滤波器在多个数值研究中与粒子滤波器进行比较，展示了其计算效率优势。提供了公开的MATLAB实现。

Conclusion: 成功开发了一种高效的非线性拉格朗日网格滤波器，显著降低了计算复杂度，同时保持了网格滤波器的鲁棒性和准确性，为非线性非高斯系统状态估计提供了有效解决方案。

Abstract: This paper deals with the state estimation of non-linear and non-Gaussian systems with an emphasis on the numerical solution to the Bayesian recursive relations. In particular, this paper builds upon the Lagrangian grid-based filter (GbF) recently-developed for linear systems and extends it for systems with nonlinear dynamics that are invertible. The proposed nonlinear Lagrangian GbF reduces the computational complexity of the standard GbFs from quadratic to log-linear, while preserving all the strengths of the original GbF such as robustness, accuracy, and deterministic behaviour. The proposed filter is compared with the particle filter in several numerical studies using the publicly available MATLAB\textregistered\ implementation\footnote{https://github.com/pesslovany/Matlab-LagrangianPMF}.

</details>


### [22] [Tensor Decompositions for Online Grid-Based Terrain-Aided Navigation](https://arxiv.org/abs/2601.07728)
*J. Matoušek,J. Krejčí,J. Duník,R. Zanetti*

Main category: eess.SP

TL;DR: 提出一种实用的网格化状态估计方法，适用于具有可逆线性动力学和高度非线性测量的高维模型，通过利用可分解的模型结构实现实时估计。


<details>
  <summary>Details</summary>
Motivation: 传统基于张量分解的方法大多停留在概念验证阶段，无法实际应用于高维状态估计。需要一种能够处理高维模型（如地形辅助导航）的实用网格化滤波方法。

Method: 利用可分解的模型结构（块对角动力学和稀疏耦合测量维度），采用拉格朗日公式进行时间更新，并利用低秩张量分解紧凑表示和有效传播状态密度。

Result: 该方法能够实现大状态维度模型的实时估计，显著扩展了网格化滤波器的实际应用范围，超越了传统的低维使用场景。计算复杂度和估计精度取决于模型的具体结构。

Conclusion: 该方法为具有可分解结构的高维模型提供了实用且可扩展的网格化状态估计解决方案，虽然在地形辅助导航中演示，但适用于更广泛的模型类型。

Abstract: This paper presents a practical and scalable grid-based state estimation method for high-dimensional models with invertible linear dynamics and with highly non-linear measurements, such as the nearly constant velocity model with measurements of e.g. altitude, bearing, and/or range. Unlike previous tensor decomposition-based approaches, which have largely remained at the proof-of-concept stage, the proposed method delivers an efficient and practical solution by exploiting decomposable model structure-specifically, block-diagonal dynamics and sparsely coupled measurement dimensions. The algorithm integrates a Lagrangian formulation for the time update and leverages low-rank tensor decompositions to compactly represent and effectively propagate state densities. This enables real-time estimation for models with large state dimension, significantly extending the practical reach of grid-based filters beyond their traditional low-dimensional use. Although demonstrated in the context of terrain-aided navigation, the method is applicable to a wide range of models with decomposable structure. The computational complexity and estimation accuracy depend on the specific structure of the model. All experiments are fully reproducible, with source code provided alongside this paper (GitHub link: https://github.com/pesslovany/Matlab-LagrangianPMF).

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [23] [Context Video Semantic Transmission with Variable Length and Rate Coding over MIMO Channels](https://arxiv.org/abs/2601.06059)
*Bingyan Xie,Yongpeng Wu,Wenjun Zhang,Derrick Wing Kwan Ng,Merouane Debbah*

Main category: cs.IT

TL;DR: CVST框架在MIMO信道下实现视频语义传输，通过上下文-信道关联图学习特征组与MIMO子信道关系，采用多参考熵编码和棋盘特征调制实现可变长度和速率编码，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信方案主要针对简单AWGN或Rayleigh衰落信道优化，忽略了普遍存在的MIMO环境，这严重阻碍了实际部署。需要填补MIMO信道下视频语义传输的研究空白。

Method: 提出CVST框架：1) 基于高效上下文视频传输骨干网络；2) 学习上下文-信道关联图，显式建模特征组与MIMO子信道关系；3) 设计多参考熵编码机制，实现信道状态感知的变长编码；4) 采用棋盘式特征调制策略，在单一训练模型中实现多速率点。

Result: CVST在MIMO信道下相比各种标准化分离编码方法和最近的无线视频语义通信方法，表现出显著的性能提升。

Conclusion: CVST框架成功解决了MIMO信道下视频语义传输的挑战，通过上下文-信道关联学习和MR-VLRC方案，实现了高性能、灵活部署的视频传输系统，代码已开源。

Abstract: The evolution of semantic communications has profoundly impacted wireless video transmission, whose applications dominate driver of modern bandwidth consumption. However, most existing schemes are predominantly optimized for simple additive white Gaussian noise or Rayleigh fading channels, neglecting the ubiquitous multiple-input multiple-output (MIMO) environments that critically hinder practical deployment. To bridge this gap, we propose the context video semantic transmission (CVST) framework under MIMO channels. Building upon an efficient contextual video transmission backbone, CVST effectively learns a context-channel correlation map to explicitly formulate the relationships between feature groups and MIMO subchannels. Leveraging these channel-aware features, we design a multi-reference entropy coding mechanism, enabling channel state-aware variable length coding. Furthermore, CVST incorporates a checkerboard-based feature modulation strategy to achieve multiple rate points within a single trained model, thereby enhancing deployment flexibility. These innovations constitute our multi-reference variable length and rate coding (MR-VLRC) scheme. By integrating contextual transmission with MR-VLRC, CVST demonstrates substantial performance gains over various standardized separated coding methods and recent wireless video semantic communication approaches. The code is available at https://github.com/xie233333/CVST.

</details>


### [24] [Jamming Detection in Cell-Free MIMO with Dynamic Graphs](https://arxiv.org/abs/2601.06075)
*Ali Hossary,Laura Crosara,Stefano Tomasin*

Main category: cs.IT

TL;DR: 提出基于动态图和图卷积神经网络的干扰检测框架，用于无蜂窝大规模MIMO系统中的干扰攻击检测


<details>
  <summary>Details</summary>
Motivation: 干扰攻击对无线网络构成严重威胁，特别是在无蜂窝大规模MIMO系统中，分布式接入点和用户设备的复杂时变拓扑结构使得干扰检测更具挑战性

Method: 将网络建模为动态图以捕捉通信链路的演化，采用GCN-Transformer模型通过监督学习学习图嵌入，将干扰攻击检测为图演化中的异常

Result: 在模拟场景中评估性能，包括移动用户设备、变化的干扰条件和信道衰落，通过准确率和F1分数指标展示了方法的有效性

Conclusion: 提出的基于动态图和GCN的干扰检测框架在无蜂窝大规模MIMO系统中表现出良好的干扰检测性能

Abstract: Jamming attacks pose a critical threat to wireless networks, particularly in cell-free massive MIMO systems, where distributed access points and user equipment (UE) create complex, time-varying topologies. This paper proposes a novel jamming detection framework leveraging dynamic graphs and graph convolutional neural networks (GCN) to address this challenge. By modeling the network as a dynamic graph, we capture evolving communication links and detect jamming attacks as anomalies in the graph evolution. A GCN-Transformer-based model, trained with supervised learning, learns graph embeddings to identify malicious interference. Performance evaluation in simulated scenarios with moving UEs, varying jamming conditions and channel fadings, demonstrates the method's effectiveness, which is assessed through accuracy and F1 score metrics, achieving promising results for effective jamming detection.

</details>


### [25] [One if by Land, Two if by Sea, Three if by Four Seas, and More to Come -- Values of Perception, Prediction, Communication, and Common Sense in Decision Making](https://arxiv.org/abs/2601.06077)
*Aolin Xu*

Main category: cs.IT

TL;DR: 该论文从决策理论角度严格定义了感知、预测、通信和常识的价值，这些量具有信息论类似物，并揭示了感知无预测时可能产生负价值的重要观察。


<details>
  <summary>Details</summary>
Motivation: 为自主决策系统设计提供理论指导，解决实际工程问题，如：是否需要观察和预测特定智能体行为、其重要性如何、观察和预测的最佳顺序是什么。同时为认知科学和神经科学提供理解自然决策者如何利用不同来源信息运作的洞见。

Method: 采用决策理论框架严格定义感知、预测、通信和常识的价值，建立这些量与信息论量（如香农熵和互信息）的数学联系，证明它们共享关键数学性质，并在特定设置下可简化为这些信息论量。

Result: 发现感知无预测时可能产生负价值，而感知与预测结合或单独预测的价值总是非负。这些定义量能为自主系统设计提供具体答案，并为理解自然决策过程提供理论工具。

Conclusion: 该研究建立了决策理论与信息论之间的桥梁，为自主决策系统设计提供了量化评估工具，同时为理解自然智能的信息处理机制提供了新的理论视角。

Abstract: This work aims to rigorously define the values of perception, prediction, communication, and common sense in decision making. The defined quantities are decision-theoretic, but have information-theoretic analogues, e.g., they share some simple but key mathematical properties with Shannon entropy and mutual information, and can reduce to these quantities in particular settings. One interesting observation is that, the value of perception without prediction can be negative, while the value of perception together with prediction and the value of prediction alone are always nonnegative. The defined quantities suggest answers to practical questions arising in the design of autonomous decision-making systems. Example questions include: Do we need to observe and predict the behavior of a particular agent? How important is it? What is the best order to observe and predict the agents? The defined quantities may also provide insights to cognitive science and neural science, toward the understanding of how natural decision makers make use of information gained from different sources and operations.

</details>


### [26] [Deep Q-Network Based Resilient Drone Communication:Neutralizing First-Order Markov Jammers](https://arxiv.org/abs/2601.06095)
*Andrii Grekhov,Volodymyr Kharchenko,Vasyl Kondratiuk*

Main category: cs.IT

TL;DR: 基于深度强化学习的跳频抗干扰通信解决方案，在16信道环境中对抗一阶反应式干扰，通过自学习实现均匀随机跳频策略，有效抵消干扰的预测优势。


<details>
  <summary>Details</summary>
Motivation: 现代电子战场景中，通信系统面临智能干扰威胁，传统跳频技术可能被预测和中断。需要自主、智能的抗干扰通信框架来应对反应式干扰。

Method: 采用深度Q网络（DQN）作为发射机，在16信道环境中连续选择跳频信道，对抗基于观测统计预测的一阶反应式干扰。通过自训练学习策略，结合BCH前向纠错码，在瑞利衰落和加性噪声环境下评估性能。

Result: 智能体成功学习到均匀随机跳频策略，有效抵消干扰的预测优势。即使中等冗余的BCH纠错码也能显著降低丢包率。学习动态、信道利用率分布、累积奖励等可视化结果证实收敛到接近最优的抗干扰策略。

Conclusion: 该研究为现代电子战场景中的自主弹性通信提供了实用框架，证明了深度强化学习在智能抗干扰通信中的有效性，结合前向纠错码可显著提升系统鲁棒性。

Abstract: Deep Reinforcement Learning based solution for jamming communications using Frequency Hopping Spread Spectrum technology in a 16 channel radio environment is presented. Deep Q Network based transmitter continuously selects the next frequency hopping channel while facing first order reactive jamming, which uses observed transition statistics to predict and interrupt transmissions. Through self training, the proposed agent learns a uniform random frequency hopping policy that effectively neutralizes the predictive advantage of the jamming. In the presence of Rayleigh fading and additive noise, the impact of forward error correction Bose Chaudhuri Hocquenghem type codes is systematically evaluated, demonstrating that even moderate redundancy significantly reduces packet loss. Extensive visualization of the learning dynamics, channel utilization distribution, epsilon greedy decay, cumulative reward, BER and SNR evolution, and detailed packet loss tables confirms convergence to a near optimal jamming strategy. The results provide a practical framework for autonomous resilient communications in modern electronic warfare scenarios.

</details>


### [27] [Optimal Beamforming for Uplink Covert Communication in MIMO GEO Satellite-Terrestrial Systems](https://arxiv.org/abs/2601.06110)
*Zewei Guo,Ranran Sun,Yulong Shen,Xiaohong Jiang*

Main category: cs.IT

TL;DR: 该论文研究了MIMO卫星-地面系统中的上行隐蔽通信，提出了波束成形和天线方向设计方案，在完美和不完美信道估计场景下优化隐蔽率。


<details>
  <summary>Details</summary>
Motivation: 随着卫星通信的快速发展，确保卫星-地面系统通信的隐蔽性变得日益重要。现有的隐蔽通信研究主要集中在地面网络，而卫星通信由于其独特的信道特性和天线配置，需要专门的研究。特别是在存在多个卫星监视器的情况下，如何设计有效的隐蔽通信方案是一个重要挑战。

Method: 1. 基于波束成形和默认天线方向设置，提出了Alice-Bob上行隐蔽传输方案
2. 在完美信道估计场景下，建立了检测错误概率、传输中断概率和隐蔽率的理论模型
3. 设计了最优波束成形以及联合最优波束成形和天线方向方案来最大化隐蔽率
4. 将研究扩展到不完美信道估计场景，并进行相关性能建模和优化设计
5. 应用半定松弛、交替优化、罗德里格斯旋转公式和一维搜索算法来解决优化问题

Result: 1. 建立了MIMO卫星-地面系统上行隐蔽通信的理论性能模型
2. 开发了有效的优化算法来解决波束成形和天线方向设计问题
3. 数值结果验证了理论分析的正确性
4. 证明了波束成形和天线方向设计对支持MIMO GEO卫星-地面系统上行隐蔽通信的有效性

Conclusion: 该论文成功解决了MIMO卫星-地面系统中的上行隐蔽通信问题。通过波束成形和天线方向设计的联合优化，能够有效提高隐蔽率并降低被检测的风险。提出的算法在实际系统中具有可行性，为卫星隐蔽通信提供了理论和技术支持。

Abstract: This paper investigates the uplink covert communication in a multiple-input multiple-output (MIMO) satellite-terrestrial system consisting of an Earth station transmitter Alice, a geosynchronous Earth orbit (GEO) satellite receiver Bob, and multiple GEO satellite wardens around Bob, where each node in the system is equipped with an array of directional antennas. Based on beamforming and the default antenna orientation setting, we first propose a scheme for covert Alice-Bob uplink transmission. Under the perfect channel estimation scenario, we provide theoretical modeling for the system performance in terms of detection error probability (DEP), transmission outage probability (TOP) and covert rate (CR), and then explore the optimal beamforming (OB) design as well as the joint optimal beamforming and antenna orientation (JO-BA) design for CR maximization. We then extend our study to the imperfect channel estimation scenario, and conduct related performance modeling and OB/JO-BA designs for CR maximization. We also apply the techniques of semidefinite relaxation, alternating optimization, Rodrigues' rotation formula and 1-D search algorithm to develop efficient algorithms to solve the above optimization problems. Finally, extensive numerical results are presented to verify our theoretical results and to illustrate the efficiency of beamforming and antenna orientation design for supporting the uplink covert communication in MIMO GEO satellite-terrestrial systems.

</details>


### [28] [Range-Coder with fast Adaptation and Table-Based Decoding](https://arxiv.org/abs/2601.06120)
*Tilo Strutz,Roman Rischke*

Main category: cs.IT

TL;DR: 提出一种基于环形缓冲区的自适应表解码方法，通过位运算替代除法，显著加速区间编码过程


<details>
  <summary>Details</summary>
Motivation: 传统区间编码方法中，解码器的符号确定需要搜索过程，虽然可以用O(1)复杂度的表方法替代，但符号统计的自适应更新会因表更新耗时过长而不可行

Method: 使用环形缓冲区技术实现自适应表解码过程，同时在编码器和解码器核心例程中用位运算替代除法操作

Result: 静态模式下编码时间减少约40%；自适应模式下，在12-64符号的字母表范围内，整体编码+解码时间快于其他方法

Conclusion: 提出的环形缓冲区自适应表解码技术有效解决了传统表方法无法自适应更新的问题，显著提升了区间编码的效率

Abstract: The transmission or storage of signals typically involves data compression. The final processing step in compression systems is generally an entropy coding stage, which converts symbols into a bit stream based on their probability distribution. A distinct class of entropy coding methods operates not by mapping input symbols to discrete codewords but by operating on intervals or ranges. This approach enables a more accurate approximation of the source entropy, particularly for sources with highly skewed or varying symbol distributions. Representative techniques in this category include traditional arithmetic coding, range coding, and methods based on asymmetric numeral systems (ANS). The complexity of these methods depends mainly on three processing steps: the core routines of encoding and decoding doing the calculations, the interval-based determination of the correct symbol at decoder, and the efforts of keeping updated with respect to the varying symbol distribution.
  The interval-based symbol determination at decoder typically demands for a searching procedure. In previous literature, it could be shown that the search can be replaced by a table-based approach with only O(1)-complexity but having the side-effect that the adaptation of the symbols statistic becomes infeasible because of the high time-consumption of adapting the table.
  We propose an adaptation process using a ring-buffer technique enabling the adaptive table-based decoding procedure as well as the replacement of a division by a bit-shift operation at encoder and decoder core routines. This accelerates the coding process significantly. In static (non-adaptive) mode, the coding time can be reduced by about 40 percent. In adaptive mode, the proposed technique is faster than alternative approaches for alphabets from about 12 to 64 different symbol when comparing the overall encoder+decoder time.

</details>


### [29] [Extended Target Adaptive Beamforming for ISAC:A Perspective of Predictive Error Ellipse](https://arxiv.org/abs/2601.06125)
*Shengcai Zhou,Luping Xiang,Yi Wang,Kun Yang,Kai Kit Wong,Chan-Byoung Chae*

Main category: cs.IT

TL;DR: 该论文为V2X网络中的通信感知一体化系统，推导了OFDM波形和UPA配置下的雷达参数估计CRB，并提出了两种NR-V2X兼容的波束成形方案，分别针对初始波束建立和调整阶段，显著提升了系统性能。


<details>
  <summary>Details</summary>
Motivation: 在V2X网络中，利用通信信号提取运动参数已成为重要方向。现有研究主要依赖定性分析，缺乏对通信信号与感知性能关系的准确建模，这限制了系统的发展。特别是车辆作为扩展目标的情况需要专门的处理方法。

Method: 1. 推导OFDM波形和UPA配置下的雷达参数估计CRB；2. 提出两种NR-V2X兼容的波束成形方案：初始阶段基于预测误差椭圆并集的波束成形，增强散射体定位；调整阶段基于散射体和通信接收机位置的自适应最窄波束策略；3. 使用最小包围椭圆算法和定制天线控制方法解决波束设计问题。

Result: 仿真验证表明，与传统的波束扫描相比，在相同SNR条件下，32*32发射天线阵列可实现32.4%的速率提升，8*8阵列可实现5.2%的增益。提出的方法有效提升了系统性能。

Conclusion: 该研究为V2X网络中的通信感知一体化系统提供了理论分析和实用解决方案，通过精确建模和智能波束成形设计，显著提升了系统性能，为未来智能交通系统的发展提供了重要技术支持。

Abstract: Utilizing communication signals to extract motion parameters has emerged as a key direction in Vehicle-to- Everything (V2X) networks. Accurately modeling the relationship between communication signals and sensing performance is critical for the advancement of such systems. Unlike prior work that relies primarily on qualitative analysis, this paper derives the Cramér-Rao Bound (CRB) for radar parameter estimation in the context of Orthogonal Frequency Division Multiplexing (OFDM) waveforms and Uniform Planar Array (UPA) configurations. Recognizing that vehicles may act as extended targets, we propose two New Radio (NR)-V2X-compatible beamforming schemes tailored to different phases of the communication process. During the initial beam establishment phase, we develop a beamforming approach based on the union of predictive error ellipses, which enhances scatterer localization through temporally assisted beam training. In the beam adjustment phase, we introduce an adaptive narrowest-beam strategy that leverages the positions of scatterers and the communication receiver (CR), enabling effective tracking with reduced complexity. The beam design problem is addressed using the minimum enclosing ellipse algorithm and tailored antenna control methods. Simulation results validate the proposed approach, showing up to a 32.4% improvement in achievable rate with a 32*32 transmit antenna array and a 5.2% gain with an 8*8 array, compared to conventional beam sweeping under identical SNR conditions.

</details>


### [30] [Channel Knowledge Map Construction via Guided Flow Matching](https://arxiv.org/abs/2601.06156)
*Ziyu Huang,Yong Zeng,Shen Fu,Xiaoli Xu,Hongyang Du*

Main category: cs.IT

TL;DR: 提出基于线性传输引导流匹配(LT-GFM)的CKM构建新框架，相比扩散模型大幅提升推理速度25倍，同时保持高保真度


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型(如DDPM)的CKM构建方法依赖迭代随机采样，推理速度过慢，无法满足无线网络实时应用需求

Method: 采用线性传输引导流匹配(LT-GFM)框架，将CKM生成建模为确定性ODE，沿线性最优传输路径演化；提出统一架构支持CGM和SCM构建，集成环境语义和Hermitian对称性约束

Result: LT-GFM在FID指标上表现更优，推理速度比DDPM快25倍，能有效构建高保真的信道增益图和空间相关图

Conclusion: LT-GFM成功解决了CKM构建中高保真度与高效率之间的权衡问题，为环境感知无线网络的实时应用提供了可行方案

Abstract: The efficient construction of accurate channel knowledge maps (CKMs) is crucial for unleashing the full potential of environment-aware wireless networks, yet it remains a difficult ill-posed problem due to the sparsity of available location-specific channel knowledge data. Although diffusion-based methods such as denoising diffusion probabilistic models (DDPMs) have been exploited for CKM construction, they rely on iterative stochastic sampling, rendering them too slow for real-time wireless applications. To bridge the gap between high fidelity and efficient CKM construction, this letter introduces a novel framework based on linear transport guided flow matching (LT-GFM). Deviating from the noise-removal paradigm of diffusion models, our approach models the CKM generation process as a deterministic ordinary differential equation (ODE) that follows linear optimal transport paths, thereby drastically reducing the number of required inference steps. We propose a unified architecture that is applicable to not only the conventional channel gain map (CGM) construction, but also the more challenging spatial correlation map (SCM) construction. To achieve physics-informed CKM constructions, we integrate environmental semantics (e.g., building masks) for edge recovery and enforce Hermitian symmetry for property of the SCM. Simulation results verify that LT-GFM achieves superior distributional fidelity with significantly lower Fréchet Inception Distance (FID) and accelerates inference speed by a factor of 25 compared to DDPMs.

</details>


### [31] [Large Multimodal Model-Aided Scheduling for 6G Autonomous Communications](https://arxiv.org/abs/2601.06211)
*Sunwoo Kim,Byonghyo Shim*

Main category: cs.IT

TL;DR: 提出基于大型多模态模型（LMM）的调度技术，通过视觉感知信息和导频信号预测未来信道参数，实现预判性调度决策，在6G环境中提升吞吐量。


<details>
  <summary>Details</summary>
Motivation: 随着AI功能在自主设备中的指数增长，中央单元需要处理LMM来有效控制设备。在6G环境中，用户微小移动可能导致信道突变，传统调度技术难以应对这种挑战。

Method: 利用LMM分析视觉感知信息和导频信号，预测未来信道参数（距离、角度、路径增益）。通过LMM预测可靠路径的存在和用户的几何信息，结合过去信道状态，准确预测未来信道参数，从而做出预判性的信道感知调度决策。

Result: 数值评估显示，所提出的技术相比传统调度技术实现了超过30%的吞吐量增益。

Conclusion: 基于LMM的调度技术能够有效应对6G环境中信道突变的挑战，通过预测未来信道参数实现预判性调度，显著提升系统性能。

Abstract: Recently, large language models (LLMs) have gained significant attention for their ability to generate fast and accurate answer to the given query. These models have evolved into large multimodal models (LMMs), which can interpret and analyze multimodal inputs such as images and text. With the exponential growth of AI functionalities in autonomous devices, the central unit (CU), a digital processing unit performing AI inference, needs to handle LMMs to effectively control these devices. To ensure seamless command delivery to devices, the CU must perform the scheduling, which involves resource block (RB) allocation for data transmission and modulation and coding scheme (MCS) index selection based on the channel conditions. This task is challenging in many practical environments in 6G, where even small user movement can cause abrupt channel changes. In this paper, we propose a novel LMM-based scheduling technique to address this challenge. Our key idea is to leverage LMM to predict future channel parameters (e.g., distance, angles, and path gain) by analyzing the visual sensing information as well as pilot signals. By exploiting LMMs to predict the presence of reliable path and geometric information of users from the visual sensing information, and then combining these with past channel states from pilot signals, we can accurately predict future channel parameters. Using these predictions, we can preemptively make channel-aware scheduling decisions. From the numerical evaluations, we show that the proposed technique achieves more than 30% throughput gain over the conventional scheduling techniques.

</details>


### [32] [Robust and Secure Blockage-Aware Pinching Antenna-assisted Wireless Communication](https://arxiv.org/abs/2601.06430)
*Ruotong Zhao,Shaokang Hu,Deepak Mishra,Derrick Wing Kwan Ng*

Main category: cs.IT

TL;DR: 提出一种阻塞感知的捏合天线系统，用于存在多天线窃听者的不完美CSI环境下安全无线通信，通过几何感知不确定性集和联合优化算法，系统性能比传统固定天线系统提升4.7dB。


<details>
  <summary>Details</summary>
Motivation: 传统线性CSI误差界对于空间分布的天线架构过于保守，且现有系统未充分考虑阻塞效应，导致安全性能不足。需要开发能同时考虑窃听者位置和阵列方向误差的几何感知方法。

Method: 1) 开发几何感知不确定性集，联合表征窃听者位置和阵列方向误差；2) 构建鲁棒联合优化问题，优化波导波束成形、人工噪声协方差、单个PA功率比分配和PA位置；3) 采用块坐标下降、惩罚方法、MM算法、S-过程和Lipschitz代理函数的低复杂度迭代算法。

Result: 所提算法比传统固定天线系统性能提升4.7dB，自适应PA定位能保持与合法用户的视距连接，同时利用波导几何结构破坏窃听者信道。忽略阻塞效应会导致性能下降和安全保证不足。

Conclusion: 阻塞感知PA系统通过几何感知不确定性集和联合优化设计，能显著提升安全无线通信的性能和保密性，自适应天线定位和阻塞效应考虑对系统设计至关重要。

Abstract: In this work, we investigate a blockage-aware pinching antenna (PA) system designed for secure and robust wireless communication. The considered system comprises a base station equipped with multiple waveguides, each hosting multiple PAs, and serves multiple single-antenna legitimate users in the presence of multi-antenna eavesdroppers under imperfect channel state information (CSI). To safeguard confidential transmissions, artificial noise (AN) is deliberately injected to degrade the eavesdropping channels. Recognizing that conventional linear CSI-error bounds become overly conservative for spatially distributed PA architectures, we develop new geometry-aware uncertainty sets that jointly characterize eavesdroppers position and array-orientation errors. Building upon these sets, we formulate a robust joint optimization problem that determines per-waveguide beamforming and AN covariance, individual PA power-ratio allocation, and PA positions to maximize the system sum rate subject to secrecy constraints. The highly non-convex design problem is efficiently addressed via a low computational complexity iterative algorithm that capitalizes on block coordinate descent, penalty-based methods, majorization-minimization, the S-procedure, and Lipschitz-based surrogate functions. Simulation results demonstrate that sum rates for the proposed algorithm outperforms conventional fixed antenna systems by 4.7 dB, offering substantially improved rate and secrecy performance. In particular, (i) adaptive PA positioning preserves LoS to legitimate users while effectively exploiting waveguide geometry to disrupt eavesdropper channels, and (ii) neglecting blockage effects in the PA system significantly impacts the system design, leading to performance degradation and inadequate secrecy guarantees.

</details>


### [33] [Error correction methods based on two-faced processes](https://arxiv.org/abs/2601.06447)
*Boris Ryabko*

Main category: cs.IT

TL;DR: 提出一种新的信道纠错方法，通过增加符号间相互依赖性来显著降低误码率，编解码复杂度为线性


<details>
  <summary>Details</summary>
Motivation: 解决通信信道中的纠错问题，传统方法可能无法充分利用符号间的相互依赖性，需要更高效的纠错方案

Method: 对输入序列进行变换，显著增加符号间的相互依赖性，传输后利用这一特性进行纠错

Result: 剩余误码率显著降低，编码和解码复杂度均为线性

Conclusion: 该方法通过增强符号间相互依赖性实现了高效的线性复杂度纠错，显著提升了信道纠错性能

Abstract: A new approach to the problem of error correction in communication channels is proposed, in which the input sequence is transformed in such a way that the interdependence of symbols is significantly increased. Then, after the sequence is transmitted over the channel, this property is used for error correction so that the remaining error rate is significantly reduced. The complexity of encoding and decoding is linear.

</details>


### [34] [Function-Correcting Partition codes](https://arxiv.org/abs/2601.06450)
*Charul Rajput,B. Sundar Rajan,Ragnar Freij-Hollanti,Camilla Hollanti*

Main category: cs.IT

TL;DR: 本文引入了函数校正划分码(FCPCs)，作为函数校正码(FCCs)的自然推广，用于同时保护多个函数并节省带宽。


<details>
  <summary>Details</summary>
Motivation: 现有的函数校正码(FCCs)只能保护单个函数，当需要同时保护多个函数时，需要为每个函数单独构建编码，导致带宽效率低下。本文旨在开发一种能够同时保护多个函数的编码方案，提高带宽利用率。

Method: 1. 定义函数校正划分码(FCPCs)，直接在域划分上构建编码；2. 使用划分的连接构造同时保护多个函数的单一编码；3. 引入划分冗余增益和划分率增益来量化带宽节省；4. 针对线性函数，通过核的交集的陪集划分进行专门化；5. 为划分构建划分图，通过寻找合适团来获得最优冗余；6. 引入块保持收缩概念来简化寻找最优冗余的问题。

Result: 1. 证明了任何t-误差函数校正码((f,t)-FCC)恰好是相对于由f诱导的域划分的FCPC；2. 展示了在权重划分和支持划分的划分图中存在满尺寸团；3. 发现FCPCs自然地提供了一种部分隐私形式，因为只需要向发送方揭示函数的域划分。

Conclusion: FCPCs是FCCs的自然推广，能够同时保护多个函数，显著节省带宽，并提供部分隐私保护。通过划分图分析和块保持收缩技术，可以有效地寻找最优编码方案。

Abstract: We introduce function-correcting partition codes (FCPCs) that are a natural generalization of function-correcting codes (FCCs). A $t$-error function-correcting partition code is an $(\mathcal{P},t)$-encoding defined directly on a partition $\mathcal{P}$ of $\mathbb{F}_q^k$. For a partition $\mathcal{P}=\{P_1,P_2,\ldots,P_E\}$ a systematic mapping $\mathcal{C}_{\mathcal{P}} : \mathbb{F}_q^k \rightarrow \mathbb{F}_q^{k+r}$ is called a \emph{$(\mathcal{P},t)$-encoding} if for all $u\in P_i$ and $v\in P_j$ with $i\neq j$, $d\big(\mathcal{C}_{\mathcal{P}}(u), \mathcal{C}_{\mathcal{P}}(v)\big)\ge 2t+1.$ We show that any $t$-error correcting code for a function $f$, denoted by $(f,t)$-FCC is exactly an FCPC with respect to the domain partition induced by $f$, which makes these codes a natural generalization of FCCs. We use the join of domain partitions to construct a single code that protects multiple functions simultaneously. We define the notion of partition redundancy gain and partition rate gain to measure the bandwidth saved by using a single FCPC for multiple functions instead of constructing separate FCCs for each function. We specialize this to linear functions via coset partition of the intersection of their kernels. Then, we associate a partition graph to any given partition of $\mathbb{F}_q^k$, and show that the existence of a suitable clique in this graph yields a set of representative information vectors that achieves the optimal redundancy. We showed the existence of a full-size clique in the partition graphs of weight partition and support partition. Finally, we introduce the notion of a block-preserving contraction for a partition, which helps reduce the problem of finding optimal redundancy for an FCPC. We observe that FCPCs naturally provide a form of partial privacy, in the sense that only the domain partition of the function needs to be revealed to the transmitter.

</details>


### [35] [Algorithms for Computing the Petz-Augustin Capacity](https://arxiv.org/abs/2601.06492)
*Chun-Neng Chu,Wei-Fu Tseng,Yen-Huan Li*

Main category: cs.IT

TL;DR: 提出了首个具有非渐近收敛保证的算法来计算Petz-Augustin容量，该容量推广了信道容量并刻画了经典-量子信道编码中的最优错误指数。


<details>
  <summary>Details</summary>
Motivation: Petz-Augustin容量是信道容量的推广，描述了经典-量子信道编码中的最优错误指数，但之前缺乏具有非渐近收敛保证的高效计算方法。

Method: 1. 对于Petz-Rényi信息最大化：利用凸Hölder-光滑优化问题特性，采用Nesterov(2015)的通用快速梯度法；2. 对于Petz-Augustin信息最大化：采用双层方法，通过相对负Shannon熵的平滑性使用熵镜像下降法，并设计新的固定点算法计算Petz-Augustin信息。

Result: 提出了首个具有非渐近收敛保证的算法来计算Petz-Augustin容量，建立了Petz-Rényi信息的凸优化框架和Petz-Augustin信息的双层优化方法，并证明了固定点算法的收缩性。

Conclusion: 该工作为计算Petz-Augustin容量提供了首个具有理论保证的高效算法，将Blahut-Arimoto算法的镜像下降解释推广到量子信息论领域。

Abstract: We propose the first algorithms with non-asymptotic convergence guarantees for computing the Petz-Augustin capacity, which generalizes the channel capacity and characterizes the optimal error exponent in classical-quantum channel coding. This capacity can be equivalently expressed as the maximization of two generalizations of mutual information: the Petz-Rényi information and the Petz-Augustin information. To maximize the Petz-Rényi information, we show that it corresponds to a convex Hölder-smooth optimization problem, and hence the universal fast gradient method of Nesterov (2015), along with its convergence guarantees, readily applies. Regarding the maximization of the Petz-Augustin information, we adopt a two-layered approach: we show that the objective function is smooth relative to the negative Shannon entropy and can be efficiently optimized by entropic mirror descent; each iteration of entropic mirror descent requires computing the Petz-Augustin information, for which we propose a novel fixed-point algorithm and establish its contractivity with respect to the Thompson metric. Notably, this two-layered approach can be viewed as a generalization of the mirror-descent interpretation of the Blahut-Arimoto algorithm due to He et al. (2024).

</details>


### [36] [On the Number of Subsequences in the Nonbinary Deletion Channel](https://arxiv.org/abs/2601.06493)
*Han Li,Xiang Wang,Fang-Wei Fu*

Main category: cs.IT

TL;DR: 研究非二进制字符串在删除信道中经过t次删除后的子序列数量，给出了r-run非二进制字符串子序列数量的改进上界，并找到了具有最大子序列数量的字符串族。


<details>
  <summary>Details</summary>
Motivation: 在删除信道中，确定字符串经过t次删除后产生的子序列数量是一个重要问题。已知子序列数量与字符串的"run"数（连续相同字符的最大子串）密切相关。本文旨在研究非二进制字符串在此场景下的子序列数量。

Method: 研究非二进制字符串在t次删除后的子序列数量，提出r-run非二进制字符串子序列数量的改进上界。通过理论分析，刻画了一类具有最大子序列数量的r-run非二进制字符串族。

Result: 找到了在任何t次删除下具有最大子序列数量的r-run非二进制字符串族，并证明该数量可以在多项式时间内计算。给出了比现有结果更优的改进上界。

Conclusion: 本文对非二进制字符串在删除信道中的子序列数量问题做出了理论贡献，提供了更精确的上界和高效的计算方法，深化了对删除信道中字符串组合性质的理解。

Abstract: In the deletion channel, an important problem is to determine the number of subsequences derived from a string $U$ of length $n$ when subjected to $t$ deletions. It is well-known that the number of subsequences in the setting exhibits a strong dependence on the number of runs in the string $U$, where a run is defined as a maximal substring of identical characters. In this paper we study the number of subsequences of a non-binary string in this scenario, and propose some improved bounds on the number of subsequences of $r$-run non-binary strings. Specifically, we characterize a family of $r$-run non-binary strings with the maximum number of subsequences under any $t$ deletions, and show that this number can be computed in polynomial time.

</details>


### [37] [Coding for Fading Channels with Imperfect CSI at the Transmitter and Quantized Feedback](https://arxiv.org/abs/2601.06501)
*Yuhan Yang,Haoheng Yuan,Chao Qi,Fan Cheng,Bin Dai*

Main category: cs.IT

TL;DR: 本文研究了具有无噪声反馈的多径衰落信道中的Schalkwijk-Kailath (SK)方案扩展，提出了针对2路径准静态衰落信道和任意多径衰落信道的SK型方案设计。


<details>
  <summary>Details</summary>
Motivation: 经典的SK方案在高斯加性噪声信道中具有极低的编码复杂度和双指数衰减的译码错误率，但如何将其扩展到具有记忆性的信道模型尚未解决。本文旨在解决多径衰落信道中的SK方案扩展问题。

Method: 1. 针对2路径准静态衰落信道：将第二路径信号视为中继，采用放大转发(AF)中继策略，利用干扰路径信号增强传输速率。
2. 针对任意多径衰落信道：将时域信道转换为频域MIMO信道，设计相应的SK型方案。

Result: 研究表明，对于2路径准静态衰落信道，通过AF中继策略可以利用干扰路径信号提高传输速率。对于任意多径衰落信道，成功设计了将时域信道转换为频域MIMO信道的SK型方案。

Conclusion: 本文成功将经典的SK方案扩展到多径衰落信道模型，为具有反馈的多径衰落信道提供了有效的编码方案设计思路，证明了干扰路径信号可以用于增强传输性能。

Abstract: The classical Schalkwijk-Kailath (SK) scheme for the additive Gaussian noise channel with noiseless feedback is highly efficient since its coding complexity is extremely low and the decoding error doubly exponentially decays as the coding blocklength tends to infinity. However, how to extend the SK scheme to channel models with memory has yet to be solved. In this paper, we first investigate how to design SK-type scheme for the 2-path quasi-static fading channel with noiseless feedback. By viewing the signal of the second path as a relay and adopting an amplify-and-forward (AF) relay strategy, we show that the interference path signal can help to enhance the transmission rate. Besides this, for arbitrary multi-path fading channel with feedback, we also present an SK-type scheme for such a model, which
  transforms the time domain channel into a frequency domain MIMO channel.

</details>


### [38] [Some New Results on Sequence Reconstruction Problem for Deletion Channels](https://arxiv.org/abs/2601.06503)
*Xiang Wang,Weijun Fang,Han Li,Fang-Wei Fu*

Main category: cs.IT

TL;DR: 该论文解决了序列重构问题中的一个开放性问题，确定了当序列长度n≥13、距离d=3、半径t=4时，两个度量球交集的最大规模N(n,3,4)=20n-166。


<details>
  <summary>Details</summary>
Motivation: 解决Pham、Goyal和Kiah提出的开放性问题，确定N(n,3,4)的确切值，这是序列重构问题在组合数学中的一个重要参数。

Method: 提出了N(n,3,t)的下界，特别针对t=4的情况，证明该下界是紧的，从而确定了N(n,3,4)的精确表达式。

Result: 证明了对于n≥13和t≥4，N(n,3,t)的下界；特别地，对于t=4，证明该下界是紧的，得到N(n,3,4)=20n-166。

Conclusion: 完全解决了Pham等人提出的开放性问题，确定了N(n,3,4)的精确值，为序列重构问题的研究提供了重要进展。

Abstract: Levenshtein first introduced the sequence reconstruction problem in $2001$. In the realm of combinatorics, the sequence reconstruction problem is equivalent to determining the value of $N(n,d,t)$, which represents the maximum size of the intersection of two metric balls of radius $t$, given that the distance between their centers is at least $d$ and the sequence length is $n$. In this paper, We present a lower bound on $N(n,3,t)$ for $n\geq 13$ and $t \geq 4$. For $t=4$, we prove that this lower bound is tight. This settles an open question posed by Pham, Goyal, and Kiah, confirming that $N(n,3,4)=20n-166$ for all $n \geq 13$.

</details>


### [39] [Visible Light Communication using Led-Based AR Markers for Robot Localization](https://arxiv.org/abs/2601.06527)
*Wataru Uemura,Shogo Kawasaki*

Main category: cs.IT

TL;DR: 提出一种将ArUco标记实现为照明形式的方法，通过LED阵列按标记网格排列，利用人眼无法察觉的闪烁频率差异编码黑白图案，实现自然外观的同时保持标记识别功能。


<details>
  <summary>Details</summary>
Motivation: 在移动机器人日益普及的日常环境中，特别是在人机协作场景（如工厂单元制造系统、家庭伴侣机器人），需要设计既自然不突兀又能用于机器人定位的视觉标记。传统黑白图案标记在人类环境中显得突兀，需要更自然的实现方式。

Method: 将ArUco标记实现为照明形式：LED按标记网格图案排列，每个LED的闪烁频率根据对应单元格的黑白状态确定。人眼看到的是均匀亮光，而相机可以捕捉闪烁频率差异，从而重建黑白图案并识别标记信息。

Result: 开发了原型系统，并通过实验评估了在不同距离和视角下对ArUco标记的识别准确性。实验结果表明该方法在保持自然外观的同时能够有效识别标记。

Conclusion: 提出的照明式ArUco标记方法成功实现了在人类环境中自然不突兀的视觉标记，同时保持了机器人定位所需的功能性，为人机协作环境中的标记设计提供了新思路。

Abstract: A method of information transmission using visual markers has been widely studied. In this approach, information or identifiers (IDs) are encoded in the black-and-white pattern of each marker. By analyzing the geometric properties of the marker frame - such as its size, distortion, and coordinates - the relative position and orientation between the camera and the marker can be estimated. Furthermore, by associating the positional information of each marker with its corresponding ID, the position of the camera that takes the image picture can be calculated. In the field of mobile robotics, such markers are commonly utilized for robot localization. As mobile robots become more widely used in everyday environments, such visual markers are expected to be utilized across various contexts. In environments where robots collaborate with humans - such as in cell-based manufacturing systems in factories or in domestic settings with partner robots - it is desirable for such markers to be designed in a manner that appears natural and unobtrusive to humans. In this paper, we propose a method for implementing an ArUco marker in the form of illumination. In the proposed method, LEDs are arranged in accordance with the grid pattern of the marker, and the blinking frequency of each LED is determined based on the corresponding black or white cell. As a result, the illumination appears uniformly bright to the human eye, while the camera can capture variations in the blinking frequency. From these differences, the black-and-white pattern can be reconstructed, enabling the identification of the marker's tag information. We develop a prototype system, and conduct experiments which are conducted to evaluate its performance in terms of recognition accuracy under varying distances and viewing angles with respect to the ArUco marker.

</details>


### [40] [Hard Thresholding Pursuit Algorithms for Least Absolute Deviations Problem](https://arxiv.org/abs/2601.06558)
*Jiao Xu,Peng Li,Bing Zheng*

Main category: cs.IT

TL;DR: GFHTP₁算法在LAD准则下对异常值具有鲁棒性，无需信号稀疏度先验信息且无参数设计，在鲁棒性和计算效率上优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 研究自适应迭代硬阈值算法的鲁棒性，特别是在存在异常值污染的场景中。传统算法通常需要信号稀疏度先验信息且涉及参数优化，而GFHTP₁算法旨在解决这些问题。

Method: 采用基于最小绝对偏差（LAD）准则的graded fast hard thresholding pursuit（GFHTP₁）算法。该算法是自适应迭代硬阈值算法的变体，无需信号稀疏度先验信息，且设计为无参数算法。

Result: 数值实验表明，GFHTP₁算法在鲁棒性和计算效率方面持续优于竞争算法。该算法对异常值具有强鲁棒性，即使少数测量值被任意幅度的异常值污染也能有效工作。

Conclusion: GFHTP₁算法在LAD准则下表现出优越的鲁棒性和计算效率，其无参数设计和无需稀疏度先验信息的特点简化了实现过程，使其在实际应用中具有优势。

Abstract: Least absolute deviations (LAD) is a statistical optimality criterion widely utilized in scenarios where a minority of measurements are contaminated by outliers of arbitrary magnitudes. In this paper, we delve into the robustness of the variant of adaptive iterative hard thresholding to outliers, known as graded fast hard thresholding pursuit (GFHTP$_1$) algorithm. Unlike the majority of the state-of-the-art algorithms in this field, GFHTP$_1$ does not require prior information about the signal's sparsity. Moreover, its design is parameterless, which not only simplifies the implementation process but also removes the intricacies of parameter optimization. Numerical experiments reveal that the GFHTP$_1$ algorithm consistently outperforms competing algorithms in terms of both robustness and computational efficiency.

</details>


### [41] [TCLNet: A Hybrid Transformer-CNN Framework Leveraging Language Models as Lossless Compressors for CSI Feedback](https://arxiv.org/abs/2601.06588)
*Zijiu Yang,Qianqian Yang,Shunpu Tang,Tingting Yang,Zhiguo Shi*

Main category: cs.IT

TL;DR: TCLNet是一个用于FDD大规模MIMO系统CSI压缩的统一框架，结合了Transformer-CNN架构进行有损压缩和混合语言模型-分解模型进行无损压缩，显著提升了压缩效率和重建精度。


<details>
  <summary>Details</summary>
Motivation: 在FDD大规模MIMO系统中，下行CSI反馈开销随着天线数量增加成为主要瓶颈。现有深度学习方法在捕获CSI的局部和全局特征方面存在局限，限制了压缩效率。

Method: 提出TCLNet统一框架：1) 有损压缩模块采用混合Transformer-CNN架构，联合利用局部特征和全局上下文；2) 无损压缩模块采用混合语言模型和分解模型设计，自适应切换上下文感知编码和并行编码以优化率失真复杂度权衡。

Result: 在真实世界和模拟数据集上的实验表明，TCLNet在重建精度和传输效率方面优于现有方法，在不同场景下实现了高达5dB的性能增益。此外，研究还展示了大型语言模型可以通过精心设计的提示作为零样本CSI无损压缩器。

Conclusion: TCLNet通过创新的混合架构有效解决了CSI压缩中的局部-全局特征平衡问题，显著提升了压缩性能，并为利用LLMs进行CSI压缩开辟了新途径。

Abstract: In frequency division duplexing (FDD) massive multiple-input multiple-output (MIMO) systems, downlink channel state information (CSI) plays a crucial role in achieving high spectrum and energy efficiency. However, the CSI feedback overhead becomes a major bottleneck as the number of antennas increases. Although existing deep learning-based CSI compression methods have shown great potential, they still face limitations in capturing both local and global features of CSI, thereby limiting achievable compression efficiency. To address these issues, we propose TCLNet, a unified CSI compression framework that integrates a hybrid Transformer-CNN architecture for lossy compression with a hybrid language model (LM) and factorized model (FM) design for lossless compression. The lossy module jointly exploits local features and global context, while the lossless module adaptively switches between context-aware coding and parallel coding to optimize the rate-distortion-complexity (RDC) trade-off. Extensive experiments on both real-world and simulated datasets demonstrate that the proposed TCLNet outperforms existing approaches in terms of reconstruction accuracy and transmission efficiency, achieving up to a 5 dB performance gain across diverse scenarios. Moreover, we show that large language models (LLMs) can be leveraged as zero-shot CSI lossless compressors via carefully designed prompts.

</details>


### [42] [Symplectic Hulls over a Non-Unital Ring](https://arxiv.org/abs/2601.06609)
*Anup Kushwaha,Om Prakash*

Main category: cs.IT

TL;DR: 研究非单位环E上辛壳的结构与性质，包括自由E线性码的辛壳生成矩阵、辛壳秩扩展技术、置换等价性，并应用于小长度最优码分类


<details>
  <summary>Details</summary>
Motivation: 研究非单位环E上辛壳的性质，该环具有特殊代数结构（κ,τ满足特定关系），旨在理解自由E线性码的辛壳结构及其在编码理论中的应用

Method: 1. 识别左右及双边辛壳的剩余码和挠码；2. 刻画自由E线性码双边辛壳的生成矩阵；3. 探索两个自由E线性码和的辛壳；4. 提出两种扩展技术，从小长度低辛壳秩扩展到更大长度更高辛壳秩；5. 研究置换等价性和辛壳变化问题

Result: 建立了非单位环E上辛壳的完整理论框架，包括生成矩阵刻画、扩展技术、置换等价性分析，并成功应用于小长度自由E线性最优码的分类

Conclusion: 该研究为非单位环E上的辛壳理论提供了系统分析，发展了有效的扩展技术，解决了辛壳变化问题，并将理论应用于最优码分类，为代数编码理论提供了新工具

Abstract: This paper presents the study of the symplectic hulls over a non-unital ring $ E= \langle κ,τ\mid 2 κ=2 τ=0,~ κ^2=κ,~ τ^2=τ,~ κτ=κ,~ τκ=τ\rangle$. We first identify the residue and torsion codes of the left, right, and two-sided symplectic hulls, and characterize the generator matrix of the two-sided symplectic hull of a free $E$-linear code. Then, we explore the symplectic hull of the sum of two free $E$-linear codes. Subsequently, we provide two build-up techniques that extend a free $E$-linear code of smaller length and symplectic hull-rank to one of larger length and symplectic hull-rank. Further, for free $E$-linear codes, we discuss the permutation equivalence and investigate the symplectic hull-variation problem. An application of this study is given by classifying the free $E$-linear optimal codes for smaller lengths.

</details>


### [43] [Large Artificial Intelligence Models for Future Wireless Communications](https://arxiv.org/abs/2601.06906)
*Chong Huang,Gaojie Chen,Pei Xiao,Zhu Han,Rahim Tafazolli*

Main category: cs.IT

TL;DR: 本文探讨了大型AI模型与无线通信的融合潜力，分析了其在数据管理、资源分配和实时适应方面的优势，同时讨论了能源、架构设计、隐私安全等挑战及解决方案，并展望了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着无线网络日益复杂，传统优化管理方法面临挑战，而大型AI模型凭借其广泛的参数空间和增强的学习能力，能够为这些挑战提供创新解决方案，并具备实时学习、适应和优化的能力。

Method: 提出面向未来无线通信的大型AI模型架构，分析其在数据分析和资源分配方面的优势，探讨能源、架构设计、隐私安全、伦理监管等方面的挑战及相应解决方案。

Result: 建立了大型AI模型在无线通信中的架构框架，明确了其在数据管理、资源优化和实时适应方面的应用潜力，同时识别了实施过程中需要解决的关键技术和社会挑战。

Conclusion: 大型AI模型与无线通信的融合将带来变革性影响，虽然面临能源、隐私、安全等多重挑战，但通过适当的架构设计和解决方案，有望推动无线通信技术进入新的发展阶段，为未来研究奠定基础。

Abstract: The anticipated integration of large artificial intelligence (AI) models with wireless communications is estimated to usher a transformative wave in the forthcoming information age. As wireless networks grow in complexity, the traditional methodologies employed for optimization and management face increasingly challenges. Large AI models have extensive parameter spaces and enhanced learning capabilities and can offer innovative solutions to these challenges. They are also capable of learning, adapting and optimizing in real-time. We introduce the potential and challenges of integrating large AI models into wireless communications, highlighting existing AIdriven applications and inherent challenges for future large AI models. In this paper, we propose the architecture of large AI models for future wireless communications, introduce their advantages in data analysis, resource allocation and real-time adaptation, discuss the potential challenges and corresponding solutions of energy, architecture design, privacy, security, ethical and regulatory. In addition, we explore the potential future directions of large AI models in wireless communications, laying the groundwork for forthcoming research in this area.

</details>


### [44] [The Sample Complexity of Lossless Data Compression](https://arxiv.org/abs/2601.06688)
*Terence Viaud,Ioannis Kontoyiannis*

Main category: cs.IT

TL;DR: 该论文提出了一个用于分析无损数据压缩基本极限的新框架，强调真正非渐近的结果，定义了压缩样本复杂度，并建立了与Rényi熵的紧密联系。


<details>
  <summary>Details</summary>
Motivation: 传统压缩理论主要关注渐近性能，缺乏对有限块长下压缩性能的精确分析。作者希望建立一个非渐近框架，类似于统计学和计算机科学中的样本复杂度概念，以更精确地评估实际压缩系统的性能极限。

Method: 引入"样本复杂度"作为核心度量，定义为在给定压缩率和超出率概率下所需的最小块长。通过将压缩问题与假设检验问题联系起来，利用现有假设检验的样本复杂度结果。分析不同类型压缩器（变长、前缀自由、定长）的等价性，并针对不同信源类型（无记忆、马尔可夫、通用压缩）建立精确的样本复杂度界限。

Result: 1. 对于任意信源，变长压缩器、前缀自由码和定长码的样本复杂度紧密耦合；2. 对于无记忆信源，样本复杂度由Rényi熵（阶数1/2）而非香农熵决定；3. 获得了具有显式常数的非渐近界限；4. 对于马尔可夫信源，样本复杂度由Rényi熵率（阶数1/2）决定；5. 对于通用压缩，样本复杂度由信源族与均匀分布之间的最小Rényi散度（阶数1/2）表征。

Conclusion: 该论文建立了一个统一框架来分析无损压缩的非渐近极限，揭示了Rényi熵（特别是阶数1/2）在确定压缩样本复杂度中的核心作用。这一框架不仅连接了压缩理论与假设检验理论，还为实际压缩系统的设计和分析提供了理论基础。

Abstract: A new framework is introduced for examining and evaluating the fundamental limits of lossless data compression, that emphasizes genuinely non-asymptotic results. The {\em sample complexity} of compressing a given source is defined as the smallest blocklength at which it is possible to compress that source at a specified rate and to within a specified excess-rate probability. This formulation parallels corresponding developments in statistics and computer science, and it facilitates the use of existing results on the sample complexity of various hypothesis testing problems. For arbitrary sources, the sample complexity of general variable-length compressors is shown to be tightly coupled with the sample complexity of prefix-free codes and fixed-length codes. For memoryless sources, it is shown that the sample complexity is characterized not by the source entropy, but by its Rényi entropy of order~$1/2$. Nonasymptotic bounds on the sample complexity are obtained, with explicit constants. Generalizations to Markov sources are established, showing that the sample complexity is determined by the source's Rényi entropy rate of order~$1/2$. Finally, bounds on the sample complexity of universal data compression are developed for arbitrary families of memoryless sources. There, the sample complexity is characterized by the minimum Rényi divergence of order~$1/2$ between elements of the family and the uniform distribution. The connection of this problem with identity testing and with the associated separation rates is explored and discussed.

</details>


### [45] [Study of Adaptive Reliability-Driven Conditional Innovation Decoding for LDPC Codes](https://arxiv.org/abs/2601.06732)
*Hassan Touati,Rodrigo C. de Lamare*

Main category: cs.IT

TL;DR: 提出一种自适应可靠性驱动的条件创新(AR-CID)解码算法用于LDPC码，通过消息质量检查和消息传递精炼两阶段，在残差置信传播框架下实现快速收敛和优越性能


<details>
  <summary>Details</summary>
Motivation: 现有的LDPC解码算法在收敛速度和性能之间存在权衡，特别是在低延迟应用中需要快速收敛的解码算法。本文旨在开发一种既能提供优越解码性能又能实现极快收敛速度的算法

Method: 提出AR-CID解码算法，包含两个阶段：1)消息质量检查阶段，评估消息可靠性；2)消息传递精炼阶段，在残差置信传播框架下进行优化。算法还分析了计算复杂度和延迟特性

Result: 仿真结果表明，AR-CID算法在短码和中长码的各种信道条件下均优于竞争解码技术，具有极快的收敛速度，特别适合低延迟应用

Conclusion: AR-CID解码算法为LDPC码提供了一种高效可靠的解码解决方案，在性能和收敛速度方面均表现出色，特别适用于对延迟敏感的应用场景

Abstract: In this work, we present an adaptive reliability-driven conditional innovation (AR-CID) decoding algorithm for low-density parity check (LDPC) codes. The proposed AR-CID decoding algorithm consists of one stage of message quality checking and another stage of message passing refinement, which are incorporated into a residual belief propagation decoding strategy. An analysis of the AR-CID decoding algorithm is carried out along with a study of its computational complexity and latency characteristics. Simulation results for several examples of LDPC codes, including short and medium-length codes over an extended range of channel conditions, indicate that the proposed AR-CID decoding algorithm outperforms competing decoding techniques and has an extremely fast convergence, making it particularly suitable for low-delay applications.

</details>


### [46] [Optimal Rate Region for Multi-server Secure Aggregation with User Collusion](https://arxiv.org/abs/2601.06836)
*Zhou Li,Xiang Zhang,Kai Wan,Hua Sun,Mingyue Ji,Giuseppe Caire*

Main category: cs.IT

TL;DR: 该论文研究了多服务器安全聚合问题，在存在用户合谋的情况下，完全刻画了最优速率区域，发现最小通信和个体密钥速率均为每输入符号1个符号，最优源密钥速率为min{U+V+T-2, UV-1}。


<details>
  <summary>Details</summary>
Motivation: 研究多服务器架构下的安全聚合问题，在存在用户合谋的情况下，探索如何降低密钥随机性需求，相比单服务器架构提供更好的安全性和效率。

Method: 采用信息论安全框架，通过线性密钥构造实现可达性证明，利用正确性和安全性约束推导紧熵界进行逆证明。

Result: 完全刻画了最优速率区域：最小通信和个体密钥速率均为每输入符号1个符号，最优源密钥速率为min{U+V+T-2, UV-1}，其中U为服务器数，V为每服务器用户数，T为合谋用户数。

Conclusion: 多服务器架构能显著降低所需密钥随机性，揭示了安全性与密钥效率之间的基本权衡，为存在用户合谋的多服务器安全聚合提供了完整的信息论表征。

Abstract: Secure aggregation is a fundamental primitive in privacy-preserving distributed learning systems, where an aggregator aims to compute the sum of users' inputs without revealing individual data. In this paper, we study a multi-server secure aggregation problem in a two-hop network consisting of multiple aggregation servers and multiple users per server, under the presence of user collusion. Each user communicates only with its associated server, while the servers exchange messages to jointly recover the global sum. We adopt an information-theoretic security framework, allowing up to $T$ users to collude with any server.
  We characterize the complete optimal rate region in terms of user-to-server communication rate, server-to-server communication rate, individual key rate, and source key rate. Our main result shows that the minimum communication and individual key rates are all one symbol per input symbol, while the optimal source key rate is given by $\min\{U+V+T-2,\, UV-1\}$, where $U$ denotes the number of servers and $V$ the number of users per server. The achievability is established via a linear key construction that ensures correctness and security against colluding users, while the converse proof relies on tight entropy bounds derived from correctness and security constraints.
  The results reveal a fundamental tradeoff between security and key efficiency and demonstrate that the multi-server architecture can significantly reduce the required key randomness compared to single-server secure aggregation. Our findings provide a complete information-theoretic characterization of secure aggregation in multi-server systems with user collusion.

</details>


### [47] [Caching Yields up to 5x Spectral Efficiency in Multi-Beam Satellite Communications](https://arxiv.org/abs/2601.06925)
*Hui Zhao,Dirk Slock,Petros Elia*

Main category: cs.IT

TL;DR: 将向量编码缓存(VCC)集成到多波束卫星通信系统中，即使有限的接收端缓存也能显著提升频谱效率，实现300-550%的性能增益


<details>
  <summary>Details</summary>
Motivation: 卫星通信系统需要提高频谱效率以缩小与有线网络的性能差距，传统方法如多播、预取等存在局限性，需要纯粹的物理层解决方案

Method: 将向量编码缓存(VCC)集成到多波束卫星通信系统，利用缓存内容抑制干扰，实现多个预编码信号向量的并发传输，建立Rician-shadowed衰落信道模型，考虑匹配滤波预编码、CSI获取开销和CSI不完美等实际因素

Result: 推导出VCC在SATCOM中的平均和速率和频谱效率增益的闭式表达式，数值仿真验证显示VCC相比传统多用户MISO SATCOM可实现300-550%的频谱效率增益

Conclusion: VCC作为一种纯粹的物理层解决方案，能显著提升卫星通信系统的频谱效率，缩小卫星网络与有线网络的性能差距，为未来高吞吐量SATCOM系统提供有效途径

Abstract: This paper examines the integration of vector coded caching (VCC) into multi-beam satellite communications (SATCOM) systems and demonstrates that even limited receiver-side caching can substantially enhance spectral efficiency. By leveraging cached content to suppress interference, VCC enables the concurrent transmission of multiple precoded signal vectors that would otherwise require separate transmission resources. This leads to a multiplicative improvement in resource utilization in SATCOM. To characterize this performance, we model the satellite-to-ground channel using Rician-shadowed fading and after incorporating practical considerations such as matched-filter precoding, channel state information (CSI) acquisition overhead as well as CSI imperfections at the transmitter, we here derive closed-form expressions for the average sum rate and spectral efficiency gain of VCC in SATCOM. Our analysis, tightly validated through numerical simulations, reveals that VCC can yield spectral efficiency gains of 300% to 550% over traditional multi-user MISO SATCOM with the same resources. These gains -- which have nothing to do with multicasting, prefetching gains nor file popularity -- highlight VCC as a pure physical-layer solution for future high-throughput SATCOM systems, significantly narrowing the performance gap between satellite and wired networks.

</details>


### [48] [Generalization Bounds for Transformer Channel Decoders](https://arxiv.org/abs/2601.06969)
*Qinshan Zhang,Bin Chen,Yong Jiang,Shu-Tao Xia*

Main category: cs.IT

TL;DR: 本文首次为Transformer信道解码器（ECCT）提供了理论泛化保证，通过比特级Rademacher复杂度推导了泛化误差上界，并证明基于奇偶校验的掩码注意力能通过稀疏性获得更紧的泛化界。


<details>
  <summary>Details</summary>
Motivation: Transformer信道解码器（如ECCT）在信道解码中表现出强大的经验性能，但其泛化行为缺乏理论理解。本文旨在从学习理论角度研究ECCT的泛化性能，填补这一理论空白。

Method: 通过建立乘性噪声估计误差与比特错误率（BER）之间的连接，使用比特级Rademacher复杂度推导泛化误差上界。进一步分析基于奇偶校验的掩码注意力如何通过诱导稀疏性降低覆盖数，从而获得更紧的泛化界。

Result: 推导出依赖于码长、模型参数和训练集大小的泛化误差上界，适用于单层和多层ECCT。证明基于奇偶校验的掩码注意力能通过稀疏性获得更紧的泛化界。

Conclusion: 本文首次为Transformer信道解码器提供了理论泛化保证，建立了学习理论与信道解码性能之间的理论联系，为这类解码器的设计和分析提供了理论基础。

Abstract: Transformer channel decoders, such as the Error Correction Code Transformer (ECCT), have shown strong empirical performance in channel decoding, yet their generalization behavior remains theoretically unclear. This paper studies the generalization performance of ECCT from a learning-theoretic perspective. By establishing a connection between multiplicative noise estimation errors and bit-error-rate (BER), we derive an upper bound on the generalization gap via bit-wise Rademacher complexity. The resulting bound characterizes the dependence on code length, model parameters, and training set size, and applies to both single-layer and multi-layer ECCTs. We further show that parity-check-based masked attention induces sparsity that reduces the covering number, leading to a tighter generalization bound. To the best of our knowledge, this work provides the first theoretical generalization guarantees for this class of decoders.

</details>


### [49] [Quantum Optical Integrated Sensing and Communication with Homodyne BPSK Detection](https://arxiv.org/abs/2601.07034)
*Ioannis Krikidis*

Main category: cs.IT

TL;DR: 提出一种量子集成传感与通信方案，使用BPSK调制和零差检测，在未知相位旋转的高斯信道中实现联合符号检测和相位估计


<details>
  <summary>Details</summary>
Motivation: 在量子光学链路中，需要在未知确定性相位旋转的信道上同时实现可靠通信和精确传感，传统方法难以兼顾两者性能

Method: 采用BPSK调制和零差检测，设计迭代算法：内层使用期望最大化进行联合检测和估计，外层自适应调整本地振荡器相位，最小化误码率同时满足费舍尔信息约束

Result: 数值结果验证了方法的有效性，并揭示了通信可靠性和传感精度之间的基本权衡关系

Conclusion: 提出的量子集成传感通信方案能够有效处理未知相位旋转，在通信和传感性能之间实现优化平衡

Abstract: In this letter, we propose a quantum integrated sensing and communication scheme for a quantum optical link using binary phase-shift keying modulation and homodyne detection. The link operates over a phase-insensitive Gaussian channel with an unknown deterministic phase rotation, where the homodyne receiver jointly carries out symbol detection and phase estimation. We formulate a design problem that minimizes the bit-error rate subject to a Fisher information-based constraint on estimation accuracy. To solve it, we develop an iterative algorithm composed of an inner expectation-maximization loop for joint detection and estimation and an outer loop that adaptively retunes the local oscillator phase. Numerical results confirm the effectiveness of the proposed approach and demonstrate a fundamental trade-off between communication reliability and sensing accuracy.

</details>


### [50] [Random Access in DNA Storage: Algorithms, Constructions, and Bounds](https://arxiv.org/abs/2601.07053)
*Chen Wang,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 提出计算DNA存储随机访问问题中期望读取次数的O(n)算法，推导显式公式，改进码构造，将k=3时的上界从0.8815k降至0.8811k，并建立更紧的理论下界。


<details>
  <summary>Details</summary>
Motivation: DNA数据存储迈向实际应用，需要最小化测序覆盖深度以降低操作成本和检索延迟。随机访问问题评估从n个编码链中恢复特定信息链所需的期望读取次数。

Method: 提出计算期望读取次数精确值的新算法，复杂度为O(n)；推导平均和最大期望读取次数的显式公式；搜索最优生成矩阵；提出新的码构造方法。

Result: 算法复杂度为O(n)；k=3时上界从0.8815k改进到0.8811k；k=4时上界为0.8629k；建立更紧的理论下界；证明n=k+1时简单奇偶校验码的最优性。

Conclusion: 本文在DNA存储随机访问问题上取得理论和实践进展，提出高效算法、改进码构造、建立更紧边界，为实际DNA存储系统设计提供理论支持。

Abstract: As DNA data storage moves closer to practical deployment, minimizing sequencing coverage depth is essential to reduce both operational costs and retrieval latency. This paper addresses the recently studied Random Access Problem, which evaluates the expected number of read samples required to recover a specific information strand from $n$ encoded strands. We propose a novel algorithm to compute the exact expected number of reads, achieving a computational complexity of $O(n)$ for fixed field size $q$ and information length $k$. Furthermore, we derive explicit formulas for the average and maximum expected number of reads, enabling an efficient search for optimal generator matrices under small parameters. Beyond theoretical analysis, we present new code constructions that improve the best-known upper bound from $0.8815k$ to $0.8811k$ for $k=3$, and achieve an upper bound of $0.8629k$ for $k=4$ for sufficiently large $q$. We also establish a tighter theoretical lower bound on the expected number of reads that improves upon state-of-the-art bounds. In particular, this bound establishes the optimality of the simple parity code for the case of $n=k+1$ across any alphabet $q$.

</details>


### [51] [Score-Based VAMP with Fisher-Information-Based Onsager Correction](https://arxiv.org/abs/2601.07095)
*Tadashi Wadayama,Takumi Takahashi*

Main category: cs.IT

TL;DR: SC-VAMP是一种基于分数的向量近似消息传递变体，通过条件Fisher信息计算Onsager校正，实现无需雅可比矩阵的非线性MMSE估计，适用于复杂黑盒推理问题。


<details>
  <summary>Details</summary>
Motivation: 传统VAMP方法需要显式建模和解析导数，限制了其在复杂黑盒推理问题中的应用。本文旨在扩展VAMP到非线性、结构化或相关感知设置中，避免对先验或似然函数的解析导数需求。

Method: 提出基于分数的VAMP变体（SC-VAMP）：1）通过条件Fisher信息表达和计算Onsager校正；2）使用学习到的分数函数通过Tweedie公式构建非线性MMSE估计器；3）从分数-范数统计中推导相应的Onsager项；4）结合随机正交/酉混合处理结构化感知设置。

Result: SC-VAMP实现了无需雅可比矩阵的VAMP实现，能够处理复杂黑盒推理问题，其中显式建模不可行。通过信息论视角分析高斯近似，提供了超越理想i.i.d.设置的解耦原理见解。

Conclusion: SC-VAMP成功扩展了VAMP框架到非线性黑盒推理问题，通过分数函数和条件Fisher信息避免了传统方法对解析导数的依赖，为复杂感知设置提供了实用的消息传递算法。

Abstract: We propose score-based VAMP (SC-VAMP), a variant of vector approximate message passing (VAMP) in which the Onsager correction is expressed and computed via conditional Fisher information, thereby enabling a Jacobian-free implementation. Using learned score functions, SC-VAMP constructs nonlinear MMSE estimators through Tweedie's formula and derives the corresponding Onsager terms from the score-norm statistics, avoiding the need for analytical derivatives of the prior or likelihood. When combined with random orthogonal/unitary mixing to mitigate non-ideal, structured or correlated sensing settings, the proposed framework extends VAMP to complex black-box inference problems where explicit modeling is intractable. Finally, by leveraging the entropic CLT, we provide an information-theoretic perspective on the Gaussian approximation underlying SE, offering insight into the decoupling principle beyond idealized i.i.d. settings, including nonlinear regimes.

</details>


### [52] [PASS-Enabled Covert Communications With Distributed Cooperative Wardens](https://arxiv.org/abs/2601.07147)
*Ji He*

Main category: cs.IT

TL;DR: 研究PASS技术支持的隐蔽通信系统，在多监视器分布式监测环境下，通过双波导架构同时传输隐蔽信息和随机干扰，分析系统级检测错误概率，优化隐蔽速率。


<details>
  <summary>Details</summary>
Motivation: 在分布式监视环境下，多个监视器通过多数投票规则融合本地检测结果，对隐蔽通信构成严重威胁。需要设计能够有效隐藏传输足迹的隐蔽通信系统。

Method: 采用双波导架构同时传输隐蔽信息和随机干扰，考虑三种PASS功率辐射定律（通用、比例、相等）。推导本地虚警和漏检概率闭式解，利用PGF-ESP框架和基于断点的阈值域划分，获得系统级检测错误概率的显式闭式表征。提出MM-BCD-SCA算法优化隐蔽速率。

Result: 获得了系统级检测错误概率的闭式表达式，验证了理论分析的正确性。数值结果表明合作监测和PASS辐射定律对隐蔽性-速率权衡有显著影响。

Conclusion: 提出的PASS-enabled双波导隐蔽通信系统能有效对抗分布式监视，通过理论分析和优化算法实现了隐蔽性与传输速率的良好平衡。

Abstract: This paper investigates PASS-enabled downlink covert communication in the presence of distributed surveillance, where multiple wardens perform signal detection and fuse their local binary decisions via majority-voting rule. We consider a dual-waveguide architecture that simultaneously delivers covert information and randomized jamming to hide the transmission footprint, incorporating three representative PASS power-radiation laws-general, proportional, and equal. To characterize the system-level detectability, we derive closed-form expressions for local false-alarm and miss-detection probabilities. By leveraging a probability-generating-function (PGF) and elementary-symmetric-polynomial (ESP) framework, combined with a breakpoint-based partition of the threshold domain, we obtain explicit closed-form characterizations of the system-level detection error probability (DEP) under non-i.i.d. majority-voting fusion. Building on this analytical framework, we formulate a robust optimization problem to maximize the average covert rate subject to covertness constraint. To solve the resulting nonconvex design, we develop an MM-BCD-SCA algorithm that produces tractable alternating updates for power/radiation variables and PA positions via convex surrogates and inner approximations of the DEP value function. Numerical results validate the theoretical analysis and demonstrate the impact of cooperative monitoring and PASS radiation laws on the covertness-rate tradeoff.

</details>


### [53] [Sentiment Analysis on Movie Reviews: A Deep Dive into Modern Techniques and Open Challenges](https://arxiv.org/abs/2601.07235)
*Agnivo Gosai,Shuvodeep De,Karun Thankachan*

Main category: cs.IT

TL;DR: 本文对电影评论情感分析方法进行了全面综述，涵盖了从早期词典方法到现代深度学习和大语言模型的技术演进，重点关注领域特定挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 电影评论情感分析作为NLP基准任务在推动领域发展中发挥了核心作用。现有综述多关注文本流水线，缺乏对领域特定问题（如讽刺、否定、上下文歧义）和新兴关注点（可解释性、公平性、鲁棒性）的系统分析。

Method: 采用比较性、挑战驱动的分析方法，回顾技术演进：从词典方法和经典机器学习（朴素贝叶斯、SVM）到深度学习（LSTM、BERT、Transformer）和多模态方法（文本、音频、视觉融合）。涵盖IMDb、Rotten Tomatoes、SST-2等数据集。

Result: 系统梳理了不同建模范式如何应对领域特定挑战，包括讽刺、否定、上下文歧义和领域迁移等开放问题。总结了多模态情感分析的最新进展，并识别了现有文献中常被忽视的可解释性、公平性和鲁棒性等新兴关注点。

Conclusion: 本文提供了领域聚焦的研究路线图，既总结了成熟解决方案，也指出了未解决的挑战，为构建更准确、可泛化、可解释的电影评论情感分析系统指明了方向，包括零样本/少样本学习、混合符号-神经模型和实时部署等未来研究方向。

Abstract: This paper presents a comprehensive survey of sentiment analysis methods for movie reviews, a benchmark task that has played a central role in advancing natural language processing. We review the evolution of techniques from early lexicon-based and classical machine learning approaches to modern deep learning architectures and large language models, covering widely used datasets such as IMDb, Rotten Tomatoes, and SST-2, and models ranging from Naive Bayes and support vector machines to LSTM networks, BERT, and attention-based transformers. Beyond summarizing prior work, this survey differentiates itself by offering a comparative, challenge-driven analysis of how these modeling paradigms address domain-specific issues such as sarcasm, negation, contextual ambiguity, and domain shift, which remain open problems in existing literature. Unlike earlier reviews that focus primarily on text-only pipelines, we also synthesize recent advances in multimodal sentiment analysis that integrate textual, audio, and visual cues from movie trailers and clips. In addition, we examine emerging concerns related to interpretability, fairness, and robustness that are often underexplored in prior surveys, and we outline future research directions including zero-shot and few-shot learning, hybrid symbolic--neural models, and real-time deployment considerations. Overall, this abstract provides a domain-focused roadmap that highlights both established solutions and unresolved challenges toward building more accurate, generalizable, and explainable sentiment analysis systems for movie review data.

</details>


### [54] [Bias-Aware BP Decoding of Quantum Codes via Directional Degeneracy](https://arxiv.org/abs/2601.07240)
*Mohammad Rowshan*

Main category: cs.IT

TL;DR: 提出方向性信念传播解码方法，通过分析量子CSS码的Tanner图各向异性结构和偏置噪声，利用方向权重改进BP→OSD解码器，显著降低逻辑错误率


<details>
  <summary>Details</summary>
Motivation: 量子CSS码的Tanner图具有各向异性结构，噪声分布存在方向性偏差，传统解码方法未充分利用这些方向性信息，导致解码性能受限

Method: 在Tanner图边上定义方向权重，聚合为每个量子位的方向权重，定义方向简并枚举器，通过偏置参数β将权重转换为位置相关的对数似然比，作为各向异性先验直接集成到标准BP→OSD解码器中

Result: 推导了方向距离与汉明距离的关系界限，给出了简并错误类数量的上界，提供了方向枚举器的MacWilliams型表达式，仿真显示在中等物理错误率下逻辑错误率显著降低（通常一个数量级）

Conclusion: 适度的各向异性是获得硬件感知解码增益的简单有效途径，方向性BP解码能显著提升量子CSS码的解码性能

Abstract: We study directionally informed belief propagation (BP) decoding for quantum CSS codes, where anisotropic Tanner-graph structure and biased noise concentrate degeneracy along preferred directions. We formalize this by placing orientation weights on Tanner-graph edges, aggregating them into per-qubit directional weights, and defining a \emph{directional degeneracy enumerator} that summarizes how degeneracy concentrates along those directions. A single bias parameter~$β$ maps these weights into site-dependent log-likelihood ratios (LLRs), yielding anisotropic priors that plug directly into standard BP$\rightarrow$OSD decoders without changing the code construction. We derive bounds relating directional and Hamming distances, upper bound the number of degenerate error classes per syndrome as a function of distance, rate, and directional bias, and give a MacWilliams-type expression for the directional enumerator. Finite-length simulations under code-capacity noise show significant logical error-rate reductions -- often an order of magnitude at moderate physical error rates -- confirming that modest anisotropy is a simple and effective route to hardware-aware decoding gains.

</details>


### [55] [Rate-distortion Theory on Non-compact Spaces: A Concentration-compactness Approach](https://arxiv.org/abs/2601.07246)
*Jiayang Zou,Luyao Fan,Jiayang Gao,Jia Wang*

Main category: cs.IT

TL;DR: 本文通过引入集中紧致原理，在非紧致空间中建立了率失真理论最优重建分布的存在性定理


<details>
  <summary>Details</summary>
Motivation: 经典率失真理论的存在性结果依赖于紧致性假设，这在非紧致空间中经常被违反。本文旨在解决非紧致空间中最优重建分布的存在性问题。

Method: 将集中紧致原理引入率失真泛函分析，在失真函数的温和强制性条件下建立存在性结果

Result: 在非紧致空间上建立了统一的、透明的率失真问题存在性定理，放宽了对紧致性的要求

Conclusion: 通过集中紧致原理，可以在非紧致空间中建立率失真最优重建分布的存在性，为一般源提供更广泛的理论基础

Abstract: In this paper, we study rate-distortion theory for general sources with an emphasis on the existence of optimal reconstruction distributions. Classical existence results rely on compactness assumptions that are often violated in non-compact settings. By introducing the concentration-compactness principle into the analysis of the rate-distortion functional, we establish the existence of optimal reconstructions under mild coercivity conditions on the distortion function. Our results provide a unified and transparent existence theorem for rate-distortion problems on general non-compact spaces.

</details>


### [56] [Engineering Favorable Propagation: Near-Field IRS Deployment for Spatial Multiplexing](https://arxiv.org/abs/2601.07317)
*Yuxuan Chen,Qingqing Wu,Guangji Chen,Qiaoyan Peng,Wen Chen*

Main category: cs.IT

TL;DR: 利用稀疏阵列大孔径获取近场球面波，通过IRS近场部署解决MIMO系统级联信道秩不足问题，提升空间复用能力


<details>
  <summary>Details</summary>
Motivation: IRS辅助MIMO系统中，强视距链路会导致级联信道高度秩不足，限制空间复用能力。传统远场部署无法解决此根本问题。

Method: 提出确定性部署准则：将IRS战略性地部署在基站近场区域，利用稀疏阵列大孔径产生的球面波前，设计解相关信道。建立物理信道模型，分析级联信道秩特性和用户间相关性，推导闭式有利传播度量。

Result: 部署准则能有效降低用户间信道相关性，增强有效自由度。基于统计CSI的低复杂度MRT预编码方案和联合优化算法在仿真中显著优于基准方案。

Conclusion: IRS近场部署利用球面波前能从根本上解决远场级联信道秩不足问题，为创建有利传播环境提供简单有效的几何驱动部署规则。

Abstract: In intelligent reflecting surface IRS assisted multiple input multiple output MIMO systems, a strong line of sight LoS link is required to compensate for the severe cascaded path loss. However, such a link renders the effective channel highly rank deficient and fundamentally limits spatial multiplexing. To overcome this limitation, this paper leverages the large aperture of sparse arrays to harness near field spherical wavefronts, and establishes a deterministic deployment criterion that strategically positions the IRS in the near field of a base station BS. This placement exploits the spherical wavefronts of the BS IRS link to engineer decorrelated channels, thereby fundamentally overcoming the rank deficiency issue in far field cascaded channels. Based on a physical channel model for the sparse BS array and the IRS, we characterize the rank properties and inter user correlation of the cascaded BS IRS user channel. We further derive a closed form favorable propagation metric that reveals how the sparse array geometry and the IRS position can be tuned to reduce inter user channel correlation. The resulting geometry driven deployment rule provides a simple guideline for creating a favorable propagation environment with enhanced effective degrees of freedom. The favorable channel statistics induced by our deployment criterion enable a low complexity maximum ratio transmission MRT precoding scheme. This serves as the foundation for an efficient algorithm that jointly optimizes the IRS phase shifts and power allocation based solely on long term statistical channel state information CSI. Simulation results validate the effectiveness of our deployment criterion and demonstrate that our optimization framework achieves significant performance gains over benchmark schemes.

</details>


### [57] [Performance Bounds of Joint Detection with Kalman Filtering and Channel Decoding for Wireless Networked Control Systems](https://arxiv.org/abs/2601.07322)
*Jinnan Piao,Dong Li,Zhibo Li,Ming Yang,Xueting Yu,Jincheng Dai*

Main category: cs.IT

TL;DR: 该论文将联合检测视为最大后验解码，推导了考虑系统干扰、量化间隔和权重分布的成对错误概率上下界，并通过无限状态马尔可夫链分析控制系统的连续丢包，最终获得MAP性能界限。


<details>
  <summary>Details</summary>
Motivation: 传统联合检测使用卡尔曼滤波估计控制输出的先验概率来辅助信道解码，但需要更精确的性能界限分析。本文旨在为控制系统的联合检测建立理论性能界限，特别是在考虑系统干扰、量化效应和连续丢包模式的情况下。

Method: 1. 将联合检测建模为最大后验解码问题；2. 基于成对错误概率推导考虑系统干扰、量化间隔和权重分布的性能上下界；3. 分析SNR趋于无穷大和系统干扰趋于零时的极限界限；4. 构建无限状态马尔可夫链描述控制系统的连续丢包模式；5. 将MAP界限近似为从无丢包状态到连续单丢包状态的转移概率界限。

Result: 仿真结果显示：(64,16)极化码和16位CRC的MAP性能随着SNR增加趋近于极限上界；在误块率10^{-3}时，相比有限块长的正态近似有3.0dB的性能增益。

Conclusion: 本文成功为控制系统的联合检测建立了理论性能界限框架，通过马尔可夫链建模连续丢包模式，证明了极化码和CRC组合在实际SNR条件下能够接近理论最优性能，为控制系统通信设计提供了重要理论指导。

Abstract: The joint detection uses Kalman filtering (KF) to estimate the prior probability of control outputs to assist channel decoding. In this paper, we regard the joint detection as maximum a posteriori (MAP) decoding and derive the lower and upper bounds based on the pairwise error probability considering system interference, quantization interval, and weight distribution. We first derive the limiting bounds as the signal-to-noise ratio (SNR) goes to infinity and the system interference goes to zero. Then, we construct an infinite-state Markov chain to describe the consecutive packet losses of the control systems to derive the MAP bounds. Finally, the MAP bounds are approximated as the bounds of the transition probability from the state with no packet loss to the state with consecutive single packet loss. The simulation results show that the MAP performance of $\left(64,16\right)$ polar code and 16-bit CRC coincides with the limiting upper bound as the SNR increases and has $3.0$dB performance gain compared with the normal approximation of the finite block rate at block error rate $10^{-3}$.

</details>


### [58] [On the Extremal Source Key Rates for Secure Storage over Graphs](https://arxiv.org/abs/2601.07340)
*Zhou Li*

Main category: cs.IT

TL;DR: 该论文研究了图上的安全存储编码，其中多个独立源符号根据边级正确性和安全性约束在图的节点上编码存储。对于每条边，必须能从其两个相邻节点恢复指定的源符号子集，同时不泄露其余源符号的任何信息。为了满足安全性要求，可以使用共享源密钥。源符号大小与源密钥大小的比率定义了源密钥率，所有可实现速率的上确界称为源密钥容量。


<details>
  <summary>Details</summary>
Motivation: 研究图上的安全存储系统，其中源符号在节点上编码存储，需要满足边级的正确性（能从相邻节点恢复指定源符号）和安全性（不泄露其他源符号）约束。探索在这种约束下源密钥容量的极值特性，为实际安全存储系统设计提供理论基础。

Method: 采用图论和编码理论相结合的方法，分析不同图结构下的源密钥容量。首先研究每条边关联单个源符号的情况，然后推广到每条边关联多个源符号的情况。通过图特征刻画来确定源密钥容量等于1的图结构，并识别在温和结构条件下达到相应极值容量的图类。

Result: 1. 对于每条边关联单个源符号的情况，完全刻画了源密钥容量等于1的所有图结构。
2. 对于每条边关联多个源符号的情况，识别了一类广泛的图，在温和结构条件下达到相应的极值容量。
3. 刻画了所有无需使用任何源密钥即可实现安全存储的图结构。

Conclusion: 该论文为图上的安全存储系统提供了完整的图特征刻画，揭示了源密钥容量的极值特性。研究结果表明，在某些图结构下可以达到最优的源密钥容量，甚至无需使用源密钥即可实现安全存储，这为设计高效的安全存储系统提供了重要的理论指导。

Abstract: This paper investigates secure storage codes over graphs, where multiple independent source symbols are encoded and stored at graph nodes subject to edge-wise correctness and security constraints. For each edge, a specified subset of source symbols must be recoverable from its two incident nodes, while no information about the remaining sources is revealed. To meet the security requirement, a shared source key may be employed. The ratio between the source symbol size and the source key size defines the source key rate, and the supremum of all achievable rates is referred to as the source key capacity.
  We study extremal values of the source key capacity in secure storage systems and provide complete graph characterizations for several fundamental settings. For the case where each edge is associated with a single source symbol, we characterize all graphs whose source key capacity equals one. We then generalize this result to the case where each edge is associated with multiple source symbols and identify a broad class of graphs that achieve the corresponding extremal capacity under a mild structural condition. In addition, we characterize all graphs for which secure storage can be achieved without using any source key.

</details>


### [59] [Fast and Provable Nonconvex Robust Matrix Completion](https://arxiv.org/abs/2601.07355)
*Yichen Fu,Tianming Wang,Ke Wei*

Main category: cs.IT

TL;DR: ARMC是一种高效的非凸鲁棒矩阵补全方法，通过引入子空间投影改进奇异值阈值法，在理论和实验上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决鲁棒矩阵补全问题，现有方法在同时处理稀疏异常值和随机噪声时存在理论保证不足或计算效率不高的问题。

Method: 提出ARMC方法，在更新低秩部分时引入子空间投影到奇异值阈值法中，形成计算高效的非凸优化方法。

Result: 数值实验表明ARMC优于现有非凸RMC方法；理论分析基于留一法技术，建立了对稀疏异常值和随机噪声的理论保证，样本复杂度和异常值稀疏度边界优于凸方法。

Conclusion: ARMC是一种高效且理论保证强的鲁棒矩阵补全方法，在同时处理异常值和噪声时表现优异。

Abstract: This paper studies the robust matrix completion problem and a computationally efficient non-convex method called ARMC has been proposed. This method is developed by introducing subspace projection to a singular value thresholding based method when updating the low rank part. Numerical experiments on synthetic and real data show that ARMC is superior to existing non-convex RMC methods. Through a refined analysis based on the leave-one-out technique, we have established the theoretical guarantee for ARMC subject to both sparse outliers and stochastic noise. The established bounds for the sample complexity and outlier sparsity are better than those established for a convex approach that also considers both outliers and stochastic noise.

</details>


### [60] [Novel Decoding Algorithm for Noiseless Non-Adaptive Group Testing](https://arxiv.org/abs/2601.07388)
*Manuel Franco-Vivo*

Main category: cs.IT

TL;DR: 提出W-SCOMP算法，在无噪声非自适应群组检测中提升缺陷物品识别成功率并减少测试次数


<details>
  <summary>Details</summary>
Motivation: 群组检测在COVID-19等实际应用中越来越重要，特别是非自适应方法因其时间效率而备受关注。需要提升当前非自适应群组检测的性能，最大化成功识别缺陷物品的概率同时减少测试次数。

Method: 首先回顾现有解码算法和测试设计策略，识别改进机会。提出新的加权顺序组合正交匹配追踪(W-SCOMP)算法，并开发模拟框架进行建模和比较评估。

Result: 理论分析表明W-SCOMP在无噪声非自适应群组检测中优于其他算法。实证结果与理论发现一致，验证了算法的有效性。

Conclusion: W-SCOMP算法扩展了解码算法范围，增进了对无噪声非自适应群组检测的理解，为实际应用提供了更高效的解决方案。

Abstract: Group testing enables the identification of a small subset of defective items within a larger population by performing tests on pools of items rather than on each item individually. Over the years, it has not only attracted attention from the academic community, but has also demonstrated its potential in addressing real-world problems such as infectious disease screening, drug discovery and manufacturing quality control. With the emergence of the COVID-19 pandemic, interest in group testing has grown further, particularly in non-adaptive testing, due to its time efficiency compared to adaptive approaches. This highlights the importance of improving the performance currently achievable in such a scheme. This article focuses on advancing the field of noiseless non-adaptive group testing. The main objective of this work is to study and maximize the probability of successfully identifying the subset of defective items while performing as few tests as possible. To this end, we first note current well-known decoding algorithms, as well as established test design strategies for assigning items to pools. From this review, we identify key opportunities for improvement that inform the development of new decoding algorithms. Specifically, we propose a novel method, Weighted Sequential Combinatorial Orthogonal Matching Pursuit (W-SCOMP), to enhance the efficiency of existing detection procedures. Theoretical results demonstrate that W-SCOMP outperforms other algorithms in noiseless non-adaptive group testing. Furthermore, we develop a simulation framework to model the group testing process and conduct comparative evaluations between the proposed and existing algorithms. The empirical results are consistent with the theoretical findings. Overall, our work expands the range of available decoding algorithms and contributes to the broader understanding of noiseless non-adaptive group testing.

</details>


### [61] [Center-Fed Pinching Antenna System (C-PASS) Aided Wireless Communications](https://arxiv.org/abs/2601.07424)
*Xu Gan,Yuanwei Liu*

Main category: cs.IT

TL;DR: C-PASS天线系统通过可控功率分配实现双自由度，提出PS、DS、TS三种协议，并分别优化波束成形，在不同功率区域各有优势。


<details>
  <summary>Details</summary>
Motivation: 传统PASS天线系统的自由度有限，需要设计新型中心馈电夹持天线系统(C-PASS)来提升性能，通过可控功率分配实现双倍自由度。

Method: 提出C-PASS基本信号模型和三种操作协议：功率分配(PS)、方向切换(DS)、时间切换(TS)。分别建立和速率最大化问题，采用加权最小均方误差重构、交替优化、惩罚算法和迭代技术求解。

Result: 数值结果表明：在低功率区域TS协议表现更优，而在高功率区域PS和DS协议由于增强的自由度能实现显著更高的速率。

Conclusion: C-PASS系统通过三种协议在不同功率条件下都能有效提升性能，为无线通信系统设计提供了灵活高效的解决方案。

Abstract: The novel architecture of the center-fed pinching antenna system (C-PASS) is investigated, where the waveguide-fed signal is divided into two propagation directions through controllable power splitting. By doing so, a doubled degree of freedom (DoF) is achieved compared to conventional PASS. Based on the new designed basic signal model of C-PASS, three practical operating protocols for C-PASS are proposed, namely power splitting (PS), direction switching (DS), and time switching (TS). Then, the sum-rate maximization problem for the joint optimization of transmit and pinching beamforming is formulated for each of the proposed protocols. 1) For PS, the highly coupled non-convex problem is first transformed into a tractable form via the weighted minimum mean square error reformulation and solved using the alternating optimization framework; 2) For DS, the above approach is subsequently extended to solve the mixed-integer constraints inherent for DS via the penalty-based algorithm; 3) For TS, the optimization problem can be decomposed into two subproblems and solved using the similar iterative techniques, while its optimal time allocation ratio is derived in closed form. Finally, numerical results reveal that TS is superior in the low-power regime, while PS and DS achieve significantly higher rates in the high-power regime due to the enhanced DoF.

</details>


### [62] [Secure Joint Source-Channel Coding for the AWGN Channel with Feedback: A Finite Blocklength Analysis](https://arxiv.org/abs/2601.07472)
*Sheng Su,Yuhan Yang,Chao Qi,Xuan He,Bin Dai,Xiaohu Tang*

Main category: cs.IT

TL;DR: 本文研究AWGN窃听信道在有限码长下的反馈方案，发现经典SK方案在有限码长下非最优，提出改进方案并建立有限码长逆定理。


<details>
  <summary>Details</summary>
Motivation: 在无限码长下，AWGN窃听信道带无噪反馈的保密容量等于无保密约束时的容量，且经典SK方案可达保密容量。但在实际有限码长场景中，经典SK方案是否仍然最优尚不清楚，需要研究有限码长下的性能。

Method: 1) 分析经典SK方案在有限码长下的性能，发现其非最优；2) 提出改进的SK方案；3) 建立AWGN窃听信道带反馈的有限码长逆定理，该逆定理也适用于无保密约束的情况。

Result: 1) 证明经典SK方案在有限码长下非最优；2) 提出的改进SK方案性能优于经典方案；3) 建立了首个有限码长逆定理；4) 通过数值算例进一步解释结果。

Conclusion: 在有限码长场景下，经典SK方案并非最优，改进的SK方案能获得更好性能。建立的有限码长逆定理为AWGN窃听信道带反馈系统提供了理论边界，填补了该领域的研究空白。

Abstract: In the literature, it has been shown that the secrecy capacity of the additive white Gaussian noise (AWGN) wiretap channel with noise-free feedback equals the capacity of the same model without secrecy constraint, and the classical Schalkwijk-Kailath (SK) scheme achieves the secrecy capacity. In this paper, we show that in finite blocklength regime, the SK scheme is not optimal, and propose a modified SK scheme which may perform better than the classical one. Besides this, this paper establishes a finite blocklength converse for the AWGN wiretap channel with feedback, which can also be viewed as a converse for the same model without secrecy constraint. To the best of the authors' knowledge, this is the first paper to address such a problem, and the results of this paper are further explained via numerical examples.

</details>


### [63] [Frequency-Adaptive Multi-Band Architecture for Upper Mid-Band MIMO Systems](https://arxiv.org/abs/2601.07489)
*Emiel Vanspranghels,Zhuangzhuang Cui,Sofie Pollin*

Main category: cs.IT

TL;DR: 该论文研究了FR3频段（7-24GHz）在6G中的传播特性和MIMO性能，并提出了一种频率自适应的多频段MIMO架构，通过资源动态重分配在频谱增益和MIMO增益之间进行权衡。


<details>
  <summary>Details</summary>
Motivation: FR3频段（上中频段）作为6G的潜力频谱，但其传播和MIMO特性随频率和环境变化显著，且频谱可用性可能因现有用户而间歇性受限，需要深入研究和适应性解决方案。

Method: 使用Sionna RT射线追踪在典型室内外场景中评估7、10、14、20和24GHz频段下的SISO和MIMO配置，并提出基于ADC/DAC和基带处理资源动态重分配的频率自适应多频段MIMO架构。

Result: FR3表现出介于sub-6GHz和毫米波之间的传播特性，支持有意义的空间复用但具有强烈的场景依赖性；仿真显示利用额外频谱通常是最优的，而自适应资源重分配在子频段不可用或复用增益集中在特定频率时更有益。

Conclusion: FR3频段是6G的有前景频谱，提出的频率自适应多频段MIMO架构能够根据频谱可用性和信道条件，在带宽（频谱增益）和天线整合（MIMO增益）之间实现动态权衡，提高系统性能。

Abstract: FR3 ($\approx$7-24 GHz), also referred to as the upper mid-band, has recently emerged as promising spectrum for 6G; however, its propagation and MIMO characteristics vary significantly with frequency and environment, and spectrum availability may be intermittent due to incumbents. Using site-specific ray tracing (Sionna RT) in representative indoor and outdoor scenarios, we evaluate 7, 10, 14, 20, and 24 GHz under SISO and MIMO configurations. The results show that FR3 exhibits propagation characteristics intermediate between sub-6 GHz and mmWave bands while supporting meaningful spatial multiplexing, albeit with strong site dependence. Motivated by these findings, we propose a fully digital frequency-adaptive multi-band MIMO architecture that repurposes ADCs/DACs and baseband processing resources across FR3 subbands via switching, enabling dynamic trade-offs between bandwidth (spectrum gain) and antenna consolidation (MIMO gain) under availability and channel constraints. Simulation results demonstrate that exploiting additional spectrum is often optimal, while adaptive resource repurposing becomes beneficial when subbands are unavailable or when multiplexing gains are concentrated at specific frequencies.

</details>


### [64] [A Parity-Consistent Decomposition Method for the Weight Distribution of Pre-Transformed Polar Codes](https://arxiv.org/abs/2601.07515)
*Yang Liu,Bolin Wu,Yuxin Han,Kai Niu*

Main category: cs.IT

TL;DR: 提出基于奇偶一致性分解(PCD)的高效算法，用于计算预变换极化码的汉明重量分布，通过构建扩展信息集和等价类理论降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 预变换极化码中预变换矩阵引入了比特依赖性，使得传统的重量分布计算方法复杂度高，需要更高效的算法。

Method: 1) 提出迭代算法构建扩展信息集，通过将信息比特扩展为0和1消除相关性，使用PCD方法递归计算重量分布；2) 建立预变换极化码的等价类理论，选择最小扩展信息集大小的预变换矩阵优化计算。

Result: 数值结果表明，与现有确定性算法相比，所提方法显著降低了计算复杂度。

Conclusion: 提出的基于PCD的算法能高效计算预变换极化码的重量分布，通过扩展信息集和等价类优化有效降低了计算复杂度。

Abstract: This paper introduces an efficient algorithm based on the Parity-Consistent Decomposition (PCD) method to determine the WD of pre-transformed polar codes. First, to address the bit dependencies introduced by the pre-transformation matrix, we propose an iterative algorithm to construct an \emph{Expanded Information Set}. By expanding the information bits within this set into 0s and 1s, we eliminate the correlations among information bits, thereby enabling the recursive calculation of the Hamming weight distribution using the \emph{PCD method}. Second, to further reduce computational complexity, we establish the theory of equivalence classes for pre-transformed polar codes. Codes within the same equivalence class share an identical weight distribution but correspond to different \emph{Expanded Information Set} sizes. By selecting the pre-transformation matrix that minimizes the \emph{Expanded Information Set} size within an equivalence class, we optimize the computation process. Numerical results demonstrate that the proposed method significantly reduces computational complexity compared to existing deterministic algorithms.

</details>


### [65] [Sparse Point-wise Privacy Leakage: Mechanism Design and Fundamental Limits](https://arxiv.org/abs/2601.07523)
*Amirreza Zamani,Sajad Daei,Parastoo Sadeghi,Mikael Skoglund*

Main category: cs.IT

TL;DR: 研究信息论隐私机制设计问题，提出稀疏点式隐私泄露准则，在高隐私机制下将设计问题简化为稀疏二次最大化问题，提出可计算的多项式时间SDP松弛方法。


<details>
  <summary>Details</summary>
Motivation: 研究代理观察有用数据Y（与敏感数据X任意相关）时，如何设计从Y生成的披露数据U，以保护隐私同时保持效用。现有隐私标准可能过于严格或不实用，需要新的隐私泄露度量方法。

Method: 引入稀疏点式隐私泄露准则，包含两个约束：(1)每个披露符号u最多与N个X实现相关，(2)对这些实现的泄露总量有界。在高隐私机制下，使用信息几何概念获得互信息的局部二次近似，将设计问题简化为带ℓ₀约束的稀疏二次最大化（Rayleigh-quotient问题）。提出SDP松弛和舍入过程，提供多项式时间可解方案。

Result: 证明了对于近似问题，可以无损失最优性地限制在具有均匀分布的二元释放变量U上。对于小字母大小，可以通过组合支持枚举计算精确解；对于高维情况，提出SDP松弛方法，并识别出稀疏阈值，超过该阈值稀疏最优解饱和于无约束谱值且SDP松弛变紧。

Conclusion: 提出的稀疏点式隐私泄露准则为隐私机制设计提供了新的理论框架，将复杂的信息论隐私设计问题转化为可计算的稀疏优化问题，为高维隐私保护提供了实用的多项式时间解决方案。

Abstract: We study an information-theoretic privacy mechanism design problem, where an agent observes useful data $Y$ that is arbitrarily correlated with sensitive data $X$, and design disclosed data $U$ generated from $Y$ (the agent has no direct access to $X$). We introduce \emph{sparse point-wise privacy leakage}, a worst-case privacy criterion that enforces two simultaneous constraints for every disclosed symbol $u\in\mathcal{U}$: (i) $u$ may be correlated with at most $N$ realizations of $X$, and (ii) the total leakage toward those realizations is bounded. In the high-privacy regime, we use concepts from information geometry to obtain a local quadratic approximation of mutual information which measures utility between $U$ and $Y$. When the leakage matrix $P_{X|Y}$ is invertible, this approximation reduces the design problem to a sparse quadratic maximization, known as the Rayleigh-quotient problem, with an $\ell_0$ constraint. We further show that, for the approximated problem, one can without loss of optimality restrict attention to a binary released variable $U$ with a uniform distribution. For small alphabet sizes, the exact sparsity-constrained optimum can be computed via combinatorial support enumeration, which quickly becomes intractable as the dimension grows. For general dimensions, the resulting sparse Rayleigh-quotient maximization is NP-hard and closely related to sparse principal component analysis (PCA). We propose a convex semidefinite programming (SDP) relaxation that is solvable in polynomial time and provides a tractable surrogate for the NP-hard design, together with a simple rounding procedure to recover a feasible leakage direction. We also identify a sparsity threshold beyond which the sparse optimum saturates at the unconstrained spectral value and the SDP relaxation becomes tight.

</details>


### [66] [Estimators for Substitution Rates in Genomes from Read Data](https://arxiv.org/abs/2601.07546)
*Shiv Pratap Singh Rathore,Navin Kashyap*

Main category: cs.IT

TL;DR: 该论文研究从噪声测序读数中估计两个序列之间的突变率问题，将现有的无对齐方法扩展到测序框架，提出了多种估计器并提供了理论保证和模拟评估。


<details>
  <summary>Details</summary>
Motivation: 现有无对齐方法通常假设可以直接访问完整序列，但在实际测序场景中只能观察到噪声读数。需要开发适用于测序框架的突变率估计方法。

Method: 使用简单模型（突变和测序错误均为替换），将无对齐方法扩展到测序框架，提出多种估计器，并为其中一个提供理论保证。

Result: 通过模拟评估了提出的估计器性能，为其中一个估计器提供了理论保证，展示了在噪声测序读数下估计突变率的有效性。

Conclusion: 成功将无对齐突变率估计方法扩展到测序框架，为从噪声测序读数中估计突变率提供了可行的解决方案。

Abstract: We study the problem of estimating the mutation rate between two sequences from noisy sequencing reads. Existing alignment-free methods typically assume direct access to the full sequences. We extend these methods to the sequencing framework, where only noisy reads from the sequences are observed. We use a simple model in which both mutations and sequencing errors are substitutions. We propose multiple estimators, provide theoretical guarantees for one of them, and evaluate the others through simulations.

</details>


### [67] [On the Sequence Reconstruction Problem for the Single-Deletion Two-Substitution Channel](https://arxiv.org/abs/2601.07547)
*Wentu Song,Kui Cai,Tony Q. S. Quek*

Main category: cs.IT

TL;DR: 研究了单删除双替换信道下的序列重建问题，证明了当两个q元长度为n的序列汉明距离d≥2时，其错误球交集大小的上界为(q²-1)n²-(3q²+5q-5)n+O_q(1)，且该上界是紧的。


<details>
  <summary>Details</summary>
Motivation: 现有序列重建研究主要关注单一错误类型（如插入、删除或替换），但对于混合错误类型（如同时允许删除和替换）的研究相对较少。本文旨在研究单删除双替换信道下的序列重建问题，确定保证正确重建所需的最小错误副本数。

Method: 研究单删除双替换信道（允许一次删除和最多两次替换）下的序列重建问题。通过分析两个q元长度n序列的错误球交集大小，证明当汉明距离d≥2时，交集大小的上界表达式。

Result: 证明了对于任意固定整数q≥2，当两个q元长度n序列的汉明距离d≥2时，其错误球交集大小的上界为(q²-1)n²-(3q²+5q-5)n+O_q(1)，其中O_q(1)是与n无关但依赖于q的常数。同时证明该上界是紧的（最多相差一个常数项）。

Conclusion: 本文解决了单删除双替换信道下序列重建的关键理论问题，为混合错误类型信道提供了重要的理论界限，对序列重建理论的发展具有重要意义。

Abstract: The Levenshtein sequence reconstruction problem studies the reconstruction of a transmitted sequence from multiple erroneous copies of it. A fundamental question in this field is to determine the minimum number of erroneous copies required to guarantee correct reconstruction of the original sequence. This problem is equivalent to determining the maximum possible intersection size of two error balls associated with the underlying channel. Existing research on the sequence reconstruction problem has largely focused on channels with a single type of error, such as insertions, deletions, or substitutions alone. However, relatively little is known for channels that involve a mixture of error types, for instance, channels allowing both deletions and substitutions. In this work, we study the sequence reconstruction problem for the single-deletion two-substitution channel, which allows one deletion and at most two substitutions applied to the transmitted sequence. Specifically, we prove that if two $q$-ary length-$n$ sequences have the Hamming distance $d\geq 2$, where $q\geq 2$ is any fixed integer, then the intersection size of their error balls under the single-deletion two-substitution channel is upper bounded by $(q^2-1)n^2-(3q^2+5q-5)n+O_q(1)$, where $O_q(1)$ is a constant independent from $n$ but dependent on $q$. Moreover, we show that this upper bound is tight up to an additive constant.

</details>


### [68] [A $q$-Polymatroid Framework for Information Leakage in Secure Linear Network Coding](https://arxiv.org/abs/2601.07567)
*Eimear Byrne,Johan Vester Dinesen,Ragnar Freij-Hollanti,Camilla Hollanti*

Main category: cs.IT

TL;DR: 研究基于嵌套秩度量码的安全线性网络编码方案中的信息泄露问题，建立了信息泄露量与q-多拟阵条件秩函数的关系，并推广了Massey对应到秩度量设置。


<details>
  <summary>Details</summary>
Motivation: 研究安全线性网络编码方案中的信息泄露问题，特别是当攻击者观察到网络链路子集时，需要量化信息泄露量并建立理论框架来分析安全性。

Method: 使用嵌套秩度量码方案，通过q-多拟阵理论分析信息泄露，引入q-多拟阵端口和q-访问结构概念，并推广Massey对应到秩度量设置。

Result: 证明了信息泄露量由底层秩度量码对关联的可表示q-多拟阵的条件秩函数刻画，建立了q-多拟阵端口和q-访问结构的结构性质，证明了秩度量设置下的Brickell-Davenport定理的q-模拟。

Conclusion: 建立了安全线性网络编码中信息泄露的q-多拟阵理论框架，为秩度量码的安全性分析提供了理论基础，并推广了经典编码理论结果到秩度量设置。

Abstract: We study information leakage in secure linear network coding schemes based on nested rank-metric codes. We show that the amount of information leaked to an adversary that observes a subset of network links is characterized by the conditional rank function of a representable $q$-polymatroid associated with the underlying rank-metric code pair. Building on this connection, we introduce the notions of $q$-polymatroid ports and $q$-access structures and describe their structural properties. Moreover, we extend Massey's correspondence between minimal codewords and minimal access sets to the rank-metric setting and prove a $q$-analogue of the Brickell--Davenport theorem.

</details>


### [69] [Clipped Affine Policy: Low-Complexity Near-Optimal Online Power Control for Energy Harvesting Communications over Fading Channels](https://arxiv.org/abs/2601.07622)
*Hao Wu,Shengtian Yang,Huiguo Gao,Diao Wang,Jun Chen,Guanding Yu*

Main category: cs.IT

TL;DR: 本文研究无线衰落信道下能量收集通信的在线功率控制，提出基于线性策略的近似的相对值函数，得到乐观和鲁棒两种截断仿射策略，并开发了领域知识增强的强化学习算法。


<details>
  <summary>Details</summary>
Motivation: 能量收集通信系统需要在时变信道和随机能量到达条件下进行在线功率控制，传统方法在计算复杂度和最优性之间存在权衡，需要开发更高效且接近最优的在线控制策略。

Method: 1) 推导贝尔曼方程中相对值函数的线性策略近似；2) 提出乐观和鲁棒两种截断仿射功率控制策略（电池状态和信道SNR倒数的仿射函数）；3) 开发领域知识增强的强化学习算法；4) 扩展到具有能量/信道预测的场景。

Result: 鲁棒截断仿射策略（结合RL，最多使用5个参数）在各种场景下优于现有方法，相对于最优策略的性能损失小于2%，在计算复杂度和最优性之间取得了良好平衡。

Conclusion: 提出的线性策略近似和领域知识增强RL方法为能量收集通信提供了高效且接近最优的在线功率控制解决方案，特别适用于具有预测能力的实际系统。

Abstract: This paper investigates online power control for point-to-point energy harvesting communications over wireless fading channels. A linear-policy-based approximation is derived for the relative-value function in the Bellman equation of the power control problem. This approximation leads to two fundamental power control policies: optimistic and robust clipped affine policies, both taking the form of a clipped affine function of the battery level and the reciprocal of channel signal-to-noise ratio coefficient. They are essentially battery-limited weighted directional waterfilling policies operating between adjacent time slots. By leveraging the relative-value approximation and derived policies, a domain-knowledge-enhanced reinforcement learning (RL) algorithm is proposed for online power control. The proposed approach is further extended to scenarios with energy and/or channel lookahead. Comprehensive simulation results demonstrate that the proposed methods achieve a good balance between computational complexity and optimality. In particular, the robust clipped affine policy (combined with RL, using at most five parameters) outperforms all existing approaches across various scenarios, with less than 2\% performance loss relative to the optimal policy.

</details>


### [70] [New $X$-Secure $T$-Private Information Retrieval Schemes via Rational Curves and Hermitian Curves](https://arxiv.org/abs/2601.07676)
*Yuan Gao,Weijun Fang,Jingke Xu,Jiejing Wen*

Main category: cs.IT

TL;DR: 本文提出了一种新的XSTPIR方案构建方法，通过提高已有曲线上有理点的利用效率，而不是追求更高亏格的曲线，实现了更高的最大PIR率。


<details>
  <summary>Details</summary>
Motivation: 现有XSTPIR方案主要通过使用更高亏格的曲线（如有理曲线→椭圆曲线→超椭圆曲线→Hermitian曲线）来获得更多有理点，从而提高最大PIR率。本文提出不同思路：不追求更高亏格的曲线，而是提高已有曲线上有理点的利用效率。

Method: 引入多项式空间span{1,x,...,x^{k-1}}的一组新基（替代拉格朗日插值基），基于此开发了两个新的XSTPIR方案家族：一个基于有理曲线，另一个基于Hermitian曲线。

Result: 1. 参数比较显示新方案性能更优；2. 当q²≥14²且X+T≥4q时，基于Hermitian曲线的方案提供已知最大PIR率；3. 当q²≥28²且X+T≥4时，两个方案共同提供已知最大PIR率。

Conclusion: 通过提高有理点利用效率而非追求更高亏格曲线，可以构建具有更高最大PIR率的XSTPIR方案，为XSTPIR方案设计提供了新视角。

Abstract: $X$-secure and $T$-private information retrieval (XSTPIR) is a variant of private information retrieval where data security is guaranteed against collusion among up to $X$ servers and the user's retrieval privacy is guaranteed against collusion among up to $T$ servers. Recently, researchers have constructed XSTPIR schemes through the theory of algebraic geometry codes and algebraic curves, with the aim of obtaining XSTPIR schemes that have higher maximum PIR rates for fixed field size and $X,T$ (the number of servers $N$ is not restricted). The mainstream approach is to employ curves of higher genus that have more rational points, evolving from rational curves to elliptic curves to hyperelliptic curves and, most recently, to Hermitian curves.
  In this paper, we propose a different perspective: with the shared goal of constructing XSTPIR schemes with higher maximum PIR rates, we move beyond the mainstream approach of seeking curves with higher genus and more rational points. Instead, we aim to achieve this goal by enhancing the utilization efficiency of rational points on curves that have already been considered in previous work. By introducing a family of bases for the polynomial space $\text{span}_{\mathbb{F}_q}\{1,x,\dots,x^{k-1}\}$ as an alternative to the Lagrange interpolation basis, we develop two new families of XSTPIR schemes based on rational curves and Hermitian curves, respectively. Parameter comparisons demonstrate that our schemes achieve superior performance. Specifically, our Hermitian-curve-based XSTPIR scheme provides the largest known maximum PIR rates when the field size $q^2\geq 14^2$ and $X+T\geq 4q$. Moreover, for any field size $q^2\geq 28^2$ and $X+T\geq 4$, our two XSTPIR schemes collectively provide the largest known maximum PIR rates.

</details>


### [71] [Weak Composition Lattices and Ring-Linear Anticodes](https://arxiv.org/abs/2601.07725)
*Jessica Bariffi,Drisana Bhatia,Giuseppe Cotardo,Violetta Weger*

Main category: cs.IT

TL;DR: 论文研究环Z/p^sZ上的Lee度量线性码，引入并刻画了最优Lee度量反码，建立了反码格与弱组合格之间的双射，并应用此对应关系通过反码方法引入新的Lee度量码不变量。


<details>
  <summary>Details</summary>
Motivation: 格理论和偏序集在编码理论中日益重要，为研究纠错码的结构和代数性质提供了组合框架。受近期连接格理论、反码和编码理论不变量的研究启发，本文研究具有Lee度量的环线性码。

Method: 引入并刻画了环Z/p^sZ上的最优Lee度量反码，证明这类反码族可按子类型自然划分，并在包含关系下形成格。建立了该格与按支配序排列的弱组合格之间的双射。

Result: 成功建立了Lee度量反码格与弱组合格之间的对应关系，并利用此对应关系通过反码方法引入了新的Lee度量码不变量。

Conclusion: 论文为Lee度量编码理论提供了新的格理论框架，通过反码与弱组合的对应关系，为研究Lee度量码的不变量开辟了新途径。

Abstract: Lattices and partially ordered sets have played an increasingly important role in coding theory, providing combinatorial frameworks for studying structural and algebraic properties of error-correcting codes. Motivated by recent works connecting lattice theory, anticodes, and coding-theoretic invariants, we investigate ring-linear codes endowed with the Lee metric. We introduce and characterize optimal Lee-metric anticodes over the ring $\mathbb{Z}/p^s\mathbb{Z}$. We show that the family of such anticodes admits a natural partition into subtypes and forms a lattice under inclusion. We establish a bijection between this lattice and a lattice of weak compositions ordered by dominance. As an application, we use this correspondence to introduce new invariants for Lee-metric codes via an anticode approach.

</details>


### [72] [Lossy Source Coding with Broadcast Side Information](https://arxiv.org/abs/2601.07797)
*Yiqi Chen,Holger Boche,Marc Geitz*

Main category: cs.IT

TL;DR: 研究带有广播边信息的信源编码问题，边信息通过有噪广播信道发送给两个接收器，给出了速率-失真-带宽四元组的外界和可达界，在二次高斯情况下比较了分离方案和非编码方案。


<details>
  <summary>Details</summary>
Motivation: 研究边信息通过有噪广播信道传输时的信源编码问题，探索如何优化速率、失真和带宽的权衡关系。

Method: 提出速率-失真-带宽四元组的外界，给出分离方案下的可达界，并在二次高斯情况下比较分离方案和非编码方案。

Result: 得到了RDB四元组的外界和可达界，提供了完全表征的特殊情况，在二次高斯情况下比较了两种方案的性能。

Conclusion: 该工作为广播边信息下的信源编码问题提供了理论框架和分析工具，揭示了分离方案和非编码方案在不同场景下的性能差异。

Abstract: This paper considers the source coding problem with broadcast side information. The side information is sent to two receivers through a noisy broadcast channel. We provide an outer bound of the rate--distortion--bandwidth (RDB) quadruples and achievable RDB quadruples when the helper uses a separation-based scheme. Some special cases with full characterization are also provided. We then compare the separation-based scheme with the uncoded scheme in the quadratic Gaussian case.

</details>
