<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 22]
- [cs.IT](#cs.IT) [Total: 3]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Single-Snapshot Gridless 2D-DoA Estimation for UCAs: A Joint Optimization Approach](https://arxiv.org/abs/2510.17818)
*Salar Nouri*

Main category: eess.SP

TL;DR: 提出一种新的网格化二维DOA估计算法，使用非精确增广拉格朗日方法(iALM)解决单快照数据下的均匀圆阵方向估计问题，避免了半定规划的计算负担。


<details>
  <summary>Details</summary>
Motivation: 传统网格化方法在单快照场景下计算成本过高或缺乏鲁棒性，无法有效处理均匀圆阵的二维DOA估计问题。

Method: 通过联合估计流形变换矩阵和源方位-仰角对，构建统一优化问题，并使用iALM高效求解，完全避免半定规划。

Result: 仿真结果表明，提出的iALM框架能够提供鲁棒且高分辨率的网格化2D-DOA估计。

Conclusion: 该方法特别适用于具有挑战性的单快照阵列信号处理应用，在计算效率和估计精度方面表现出色。

Abstract: This paper tackles the challenging problem of gridless two-dimensional (2D)
direction-of-arrival (DOA) estimation for a uniform circular array (UCA) from a
single snapshot of data. Conventional gridless methods often fail in this
scenario due to prohibitive computational costs or a lack of robustness. We
propose a novel framework that overcomes these limitations by jointly
estimating a manifold transformation matrix and the source azimuth-elevation
pairs within a single, unified optimization problem. This problem is solved
efficiently using an inexact Augmented Lagrangian Method (iALM), which
completely circumvents the need for semidefinite programming. By unifying the
objectives of data fidelity and transformation robustness, our approach is
uniquely suited for the demanding single-snapshot case. Simulation results
confirm that the proposed iALM framework provides robust and high-resolution,
gridless 2D-DOA estimates, establishing its efficacy for challenging array
signal processing applications.

</details>


### [2] [Machine Learning-Based Performance Evaluation of a Solar-Powered Hydrogen Fuel Cell Hybrid in a Radio-Controlled Electric Vehicle](https://arxiv.org/abs/2510.17808)
*Amirhesam Aghanouri,Mohamed Sabry,Joshua Cherian Varughese,Cristina Olaverri-Monreal*

Main category: eess.SP

TL;DR: 该论文研究了镍氢电池与质子交换膜燃料电池混合动力系统的性能，通过机器学习技术进行数据分析，提高了电压稳定性和系统可靠性，验证了该系统在小型电动车中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 研究混合动力系统在真实工况下的性能，探索可再生能源在小型电动车中的应用，为大型车辆的扩展提供基础。

Method: 采用实验测试和数据分析方法，结合信号处理和机器学习技术（包括时序卷积网络），在不同负载和环境条件下评估系统性能。

Result: 混合系统相比纯电池系统显著提高了电气性能和可靠性，机器学习技术能高精度识别油门等级，异常检测方法减少了关键故障。

Conclusion: 质子交换膜燃料电池与镍氢电池的集成显著改善了小型电动车的性能，该系统具有扩展到大型车辆的潜力，并验证了离网可再生氢能应用的可行性。

Abstract: This paper presents an experimental investigation and performance evaluation
of a hybrid electric radio-controlled car powered by a Nickel-Metal Hydride
battery combined with a renewable Proton Exchange Membrane Fuel Cell system.
The study evaluates the performance of the system under various load-carrying
scenarios and varying environmental conditions, simulating real-world operating
conditions including throttle operation. In order to build a predictive model,
gather operational insights, and detect anomalies, data-driven analyses using
signal processing and modern machine learning techniques were employed.
Specifically, machine learning techniques were used to distinguish throttle
levels with high precision based on the operational data. Anomaly and change
point detection methods enhanced voltage stability, resulting in fewer critical
faults in the hybrid system compared to battery-only operation. Temporal
Convolutional Networks were effectively employed to predict voltage behavior,
demonstrating potential for use in planning the locations of fueling or
charging stations. Moreover, integration with a solar-powered electrolyzer
confirmed the system's potential for off-grid, renewable hydrogen use. The
results indicate that integrating a Proton Exchange Membrane Fuel Cell with
Nickel-Metal Hydride batteries significantly improves electrical performance
and reliability for small electric vehicles, and these findings can be a
potential baseline for scaling up to larger vehicles.

</details>


### [3] [Covariance Matrix Construction with Preprocessing-Based Spatial Sampling for Robust Adaptive Beamforming](https://arxiv.org/abs/2510.17823)
*Saeed Mohammadzadeh,Rodrigo C. de Lamare,Yuriy Zakharov*

Main category: eess.SP

TL;DR: 提出一种高效鲁棒的自适应波束形成技术，通过方向估计和协方差矩阵重构来处理导向矢量失配和数据协方差矩阵重建问题。


<details>
  <summary>Details</summary>
Motivation: 解决导向矢量估计失配和数据协方差矩阵重建问题，提高自适应波束形成的鲁棒性和效率。

Method: 使用可用快照估计干扰源方向，自适应计算干扰信号角度扇区，利用通用线性组合算法和预处理空间采样重构干扰加噪声协方差矩阵，提出基于预处理矩阵的功率谱采样策略。

Result: 仿真结果表明，与现有方法相比，所提方法在性能上具有显著优势。

Conclusion: 提出的PPBSS技术能够有效处理导向矢量失配和协方差矩阵重建问题，在计算成本和性能方面优于现有方法。

Abstract: This work proposes an efficient, robust adaptive beamforming technique to
deal with steering vector (SV) estimation mismatches and data covariance matrix
reconstruction problems. In particular, the direction-of-arrival(DoA) of
interfering sources is estimated with available snapshots in which the angular
sectors of the interfering signals are computed adaptively. Then, we utilize
the well-known general linear combination algorithm to reconstruct the
interference-plus-noise covariance (IPNC) matrix using preprocessing-based
spatial sampling (PPBSS). We demonstrate that the preprocessing matrix can be
replaced by the sample covariance matrix (SCM) in the shrinkage method. A power
spectrum sampling strategy is then devised based on a preprocessing matrix
computed with the estimated angular sectors' information. Moreover, the
covariance matrix for the signal is formed for the angular sector of the
signal-of-interest (SOI), which allows for calculating an SV for the SOI using
the power method. An analysis of the array beampattern in the proposed PPBSS
technique is carried out, and a study of the computational cost of competing
approaches is conducted. Simulation results show the proposed method's
effectiveness compared to existing approaches.

</details>


### [4] [In-Process Monitoring of Gear Power Honing Using Vibration Signal Analysis and Machine Learning](https://arxiv.org/abs/2510.17809)
*Massimo Capurso,Luciano Afferrante*

Main category: eess.SP

TL;DR: 提出了一种基于振动信号分析和机器学习的齿轮强力珩磨过程监测框架，使用三种子空间学习方法进行特征提取，结合SVM分类器实现齿轮质量分类，在工业环境中达到高精度。


<details>
  <summary>Details</summary>
Motivation: 传统质量控制策略依赖后处理检测和统计过程控制，无法捕捉瞬态加工异常和实现实时缺陷检测。现代齿轮制造对NVH性能有严格要求，需要高精度精加工操作。

Method: 通过加速度计连续采集数据，进行时频信号分析。比较三种子空间学习方法：PCA降维、PCA+LDA两阶段框架、R-UMLDA张量数据分析。提取特征输入SVM分类器预测四个齿轮质量类别。

Result: 在工业环境中收集的实验数据集上，该框架实现了高分类准确率（最高达100%），提供了与过程动力学相关的可解释频谱特征。

Conclusion: 该方法可实现实时监测和预测性维护系统的实际集成，为齿轮制造过程提供有效的在线质量监控解决方案。

Abstract: In modern gear manufacturing, stringent Noise, Vibration, and Harshness (NVH)
requirements demand high-precision finishing operations such as power honing.
Conventional quality control strategies rely on post-process inspections and
Statistical Process Control (SPC), which fail to capture transient machining
anomalies and cannot ensure real-time defect detection. This study proposes a
novel, data-driven framework for in-process monitoring of gear power honing
using vibration signal analysis and machine learning. Our proposed methodology
involves continuous data acquisition via accelerometers, followed by
time-frequency signal analysis. We investigate and compare the efficacy of
three subspace learning methods for features extraction: (1) Principal
Component Analysis (PCA) for dimensionality reduction; (2) a two-stage
framework combining PCA with Linear Discriminant Analysis (LDA) for enhanced
class separation; and (3) Uncorrelated Multilinear Discriminant Analysis with
Regularization (R-UMLDA), adapted for tensor data, which enforces feature
decorrelation and includes regularization for small sample sizes. These
extracted features are then fed into a Support Vector Machine (SVM) classifier
to predict four distinct gear quality categories, established through rigorous
geometrical inspections and test bench results of assembled gearboxes. The
models are trained and validated on an experimental dataset collected in an
industrial context during gear power-honing operations, with gears classified
into four different quality categories. The proposed framework achieves high
classification accuracy (up to 100%) in an industrial setting. The approach
offers interpretable spectral features that correlate with process dynamics,
enabling practical integration into real-time monitoring and predictive
maintenance systems.

</details>


### [5] [Exploring Complexity Changes in Diseased ECG Signals for Enhanced Classification](https://arxiv.org/abs/2510.17810)
*Camilo Quiceno Quintero,Sandip Varkey George*

Main category: eess.SP

TL;DR: 使用非线性时间序列分析研究心电图复杂性如何随心脏病理变化，通过非线性测量和跨通道指标显著区分健康与疾病个体，并提升机器学习分类准确率。


<details>
  <summary>Details</summary>
Motivation: 心脏的复杂动力学反映在心电图中，研究心电图复杂性变化有助于理解心脏病理状态。

Method: 使用PTB-XL数据集，从II导联ECG提取非线性测量，使用Spearman相关性和互信息计算跨通道指标（II、V2、AVL导联）。

Result: 几乎所有测量在健康与疾病类别间以及5个诊断超类间均存在显著差异（p<.001）。将复杂性量化指标加入机器学习模型后，AUC从0.86（基线）提升至0.87（非线性测量）和0.90（包含跨时间序列指标）。

Conclusion: 非线性复杂性测量能有效区分心脏病理状态，并显著提升机器学习模型的分类性能。

Abstract: The complex dynamics of the heart are reflected in its electrical activity,
captured through electrocardiograms (ECGs). In this study we use nonlinear time
series analysis to understand how ECG complexity varies with cardiac pathology.
Using the large PTB-XL dataset, we extracted nonlinear measures from lead II
ECGs, and cross-channel metrics (leads II, V2, AVL) using Spearman correlations
and mutual information. Significant differences between diseased and healthy
individuals were found in almost all measures between healthy and diseased
classes, and between 5 diagnostic superclasses ($p<.001$). Moreover,
incorporating these complexity quantifiers into machine learning models
substantially improved classification accuracy measured using area under the
ROC curve (AUC) from 0.86 (baseline) to 0.87 (nonlinear measures) and 0.90
(including cross-time series metrics).

</details>


### [6] [Channel Modeling of Satellite-to-Underwater Laser Communication Links: An Analytical-Monte Carlo Hybrid Approach](https://arxiv.org/abs/2510.17811)
*Zhixing Wang,Renzhi Yuan,Haifeng Yao,Chuang Yang,Mugen Peng*

Main category: eess.SP

TL;DR: 本文提出了一种综合的卫星到水下激光通信信道模型，采用解析-蒙特卡洛混合方法，同时考虑粒子和湍流效应，分析了不同环境条件下的通信性能。


<details>
  <summary>Details</summary>
Motivation: 卫星到水下激光通信信道建模具有挑战性，因为现有研究要么关注分离的信道，要么忽略了粒子和湍流对激光传播的综合影响。

Method: 采用解析-蒙特卡洛混合方法：基于扩展惠更斯-菲涅耳原理获得大气湍流后的激光强度分布；推导空气-水界面后光子传播方向的闭式概率密度函数；使用蒙特卡洛方法模拟水下链路并获得接收平面功率分布。

Result: 数值结果表明，水下粒子浓度对通信性能的影响远大于大气湍流和水下湍流；增加空气-水界面风速不会显著恶化通信性能。

Conclusion: 提出的综合信道模型能够准确评估卫星到水下激光通信系统的性能，水下粒子浓度是影响通信质量的关键因素。

Abstract: Channel modeling for satellite-to-underwater laser communication (StULC)
links remains challenging due to long distances and the diversity of the
channel constituents. The StULC channel is typically segmented into three
isolated channels: the atmospheric channel, the air-water interface channel,
and the underwater channel. Previous studies involving StULC channel modeling
either focused on separated channels or neglected the combined effects of
particles and turbulence on laser propagation. In this paper, we established a
comprehensive StULC channel model by an analytical-Monte Carlo hybrid approach,
taking into account the effects of both particles and turbulence. We first
obtained the intensity distribution of the transmitted laser beam after passing
through the turbulent atmosphere based on the extended Huygens-Fresnel
principle. Then we derived a closed-form probability density function of the
photon propagating direction after passing through the air-water interface,
which greatly simplified the modeling of StULC links. At last, we employed a
Monte Carlo method to model the underwater links and obtained the power
distribution at the receiving plane. Based on the proposed StULC channel model,
we analyzed the bit error rate and the outage probability under different
environmental conditions. Numerical results demonstrated that, the influence of
underwater particle concentration on the communication performance is much
pronounced than those of both the atmospheric turbulence and the underwater
turbulence. Notably, increasing the wind speed at the air-water interface does
not significantly worsen the communication performance of the StULC links.

</details>


### [7] [Cross-Domain Multi-Person Human Activity Recognition via Near-Field Wi-Fi Sensing](https://arxiv.org/abs/2510.17816)
*Xin Li,Jingzhi Hu,Yinghui He,Hongbo Wang,Jin Gan,Jun Luo*

Main category: eess.SP

TL;DR: WiAnchor是一个用于Wi-Fi多人体活动识别的跨域适应训练框架，通过锚点匹配机制处理活动类别不完整的情况，在缺少某些活动类别时仍能实现90%以上的跨域准确率。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi人体活动识别面临多用户区分困难的问题，利用近场主导效应为每个用户建立专用感知链路是可行方案，但由于近场信号具有用户特定特性和不规则模式，神经网络模型需要跨域微调，这在某些活动类别不可用时特别具有挑战性。

Method: WiAnchor框架分三步处理嵌入不规则时间信息的Wi-Fi信号：预训练阶段扩大类间特征边界增强活动可分性；微调阶段创新锚点匹配机制进行跨域适应，基于不完整活动类别过滤用户特定干扰；最后基于输入样本与锚点的特征相似性进一步改进识别。

Result: 构建了综合数据集进行彻底评估，在活动类别缺失的情况下实现了超过90%的跨域准确率。

Conclusion: WiAnchor框架通过创新的锚点匹配机制有效解决了Wi-Fi多人体活动识别中跨域适应的问题，特别是在活动类别不完整的情况下仍能保持高识别准确率。

Abstract: Wi-Fi-based human activity recognition (HAR) provides substantial convenience
and has emerged as a thriving research field, yet the coarse spatial resolution
inherent to Wi-Fi significantly hinders its ability to distinguish multiple
subjects. By exploiting the near-field domination effect, establishing a
dedicated sensing link for each subject through their personal Wi-Fi device
offers a promising solution for multi-person HAR under native traffic. However,
due to the subject-specific characteristics and irregular patterns of
near-field signals, HAR neural network models require fine-tuning (FT) for
cross-domain adaptation, which becomes particularly challenging with certain
categories unavailable. In this paper, we propose WiAnchor, a novel training
framework for efficient cross-domain adaptation in the presence of incomplete
activity categories. This framework processes Wi-Fi signals embedded with
irregular time information in three steps: during pre-training, we enlarge
inter-class feature margins to enhance the separability of activities; in the
FT stage, we innovate an anchor matching mechanism for cross-domain adaptation,
filtering subject-specific interference informed by incomplete activity
categories, rather than attempting to extract complete features from them;
finally, the recognition of input samples is further improved based on their
feature-level similarity with anchors. We construct a comprehensive dataset to
thoroughly evaluate WiAnchor, achieving over 90% cross-domain accuracy with
absent activity categories.

</details>


### [8] [CLARAE: Clarity Preserving Reconstruction AutoEncoder for Denoising and Rhythm Classification of Intracardiac Electrograms](https://arxiv.org/abs/2510.17821)
*Long Lin,Pablo Peiro-Corbacho,Pablo Ávila,Alejandro Carta-Bergaz,Ángel Arenal,Gonzalo R. Ríos-Muñoz,Carlos Sevilla-Salcedo*

Main category: eess.SP

TL;DR: CLARAE是一种用于心房内电图的自动编码器，通过保留波形形态、减少重建伪影和生成可解释嵌入，实现高保真重建和紧凑的64维潜在表示。


<details>
  <summary>Details</summary>
Motivation: 心房内电图常受噪声污染且维度高，限制了实时分析，需要开发既能降噪又能生成紧凑表示的算法。

Method: 采用一维编码器-解码器架构，基于三个原则：池化下采样、混合插值-卷积上采样路径和有界潜在空间。

Result: 在495,731个心电图段上测试，CLARAE在所有节律类型的分类中F1分数超过0.97，潜在空间显示清晰的节律聚类，在去噪任务中表现优异。

Conclusion: CLARAE结合了稳健的去噪能力和紧凑的判别性表示，为节律鉴别、信号质量评估和实时映射等临床工作流程提供了实用基础。

Abstract: Intracavitary atrial electrograms (EGMs) provide high-resolution insights
into cardiac electrophysiology but are often contaminated by noise and remain
high-dimensional, limiting real-time analysis. We introduce CLARAE
(CLArity-preserving Reconstruction AutoEncoder), a one-dimensional
encoder--decoder designed for atrial EGMs, which achieves both high-fidelity
reconstruction and a compact 64-dimensional latent representation. CLARAE is
designed to preserve waveform morphology, mitigate reconstruction artifacts,
and produce interpretable embeddings through three principles: downsampling
with pooling, a hybrid interpolation--convolution upsampling path, and a
bounded latent space.
  We evaluated CLARAE on 495,731 EGM segments (unipolar and bipolar) from 29
patients across three rhythm types (AF, SR300, SR600). Performance was
benchmarked against six state-of-the-art autoencoders using reconstruction
metrics, rhythm classification, and robustness across signal-to-noise ratios
from -5 to 15 dB. In downstream rhythm classification, CLARAE achieved
F1-scores above 0.97 for all rhythm types, and its latent space showed clear
clustering by rhythm. In denoising tasks, it consistently ranked among the top
performers for both unipolar and bipolar signals.
  In order to promote reproducibility and enhance accessibility, we offer an
interactive web-based application. This platform enables users to explore
pre-trained CLARAE models, visualize the reconstructions, and compute metrics
in real time. Overall, CLARAE combines robust denoising with compact,
discriminative representations, offering a practical foundation for clinical
workflows such as rhythm discrimination, signal quality assessment, and
real-time mapping.

</details>


### [9] [Carbon-Aware Orchestration of Integrated Satellite Aerial Terrestrial Networks via Digital Twin](https://arxiv.org/abs/2510.17825)
*Shumaila Javaid,Nasir Saeed*

Main category: eess.SP

TL;DR: 提出基于数字孪生的碳感知编排框架，用于集成卫星-空中-地面网络，通过多时间尺度PDCA循环和碳感知控制策略，在保证服务质量的同时显著降低碳排放。


<details>
  <summary>Details</summary>
Motivation: 集成卫星-空中-地面网络的大规模部署可能导致不可持续能源使用和碳排放，需要碳感知的编排框架来实现可持续发展目标。

Method: 采用数字孪生技术，建立多时间尺度PDCA循环，结合日前预测和实时自适应优化，利用碳感知切换、无人机占空比控制和可再生能源感知边缘部署等控制策略。

Result: 使用真实碳强度数据的仿真结果显示，相比仅考虑QoS的编排，碳排放降低高达29%，同时提高了可再生能源利用率和恶劣事件下的弹性。

Conclusion: 该碳感知编排框架能有效降低ISATN的碳排放，同时保持服务质量，为实现6G网络的可持续发展提供了可行方案。

Abstract: Integrated Satellite Aerial Terrestrial Networks (ISATNs) are envisioned as
key enablers of 6G, providing global connectivity for applications such as
autonomous transportation, Industrial IoT, and disaster response. Their
large-scale deployment, however, risks unsustainable energy use and carbon
emissions. This work advances prior energy-aware studies by proposing a
carbon-aware orchestration framework for ISATNs that leverages Digital Twin
(DT) technology. The framework adopts grams of CO$_2$-equivalent per bit
(gCO$_2$/bit) as a primary sustainability metric and implements a multi
timescale Plan Do Check Act (PDCA) loop that combines day-ahead forecasting
with real-time adaptive optimization. ISATN-specific control knobs, including
carbon-aware handovers, UAV duty cycling, and renewable-aware edge placement,
are exploited to reduce emissions. Simulation results with real carbon
intensity data show up to 29\% lower gCO$_2$/bit than QoS-only orchestration,
while improving renewable utilization and resilience under adverse events.

</details>


### [10] [Synthetic EEG Generation using Diffusion Models for Motor Imagery Tasks](https://arxiv.org/abs/2510.17832)
*Henrique de Lima Alexandre,Clodoaldo Aparecido de Moraes Lima*

Main category: eess.SP

TL;DR: 该研究提出使用扩散概率模型生成运动想象脑电信号的方法，以解决脑电数据采集困难和数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 脑电信号采集面临传感器成本高、采集时间长和个体间差异大的挑战，限制了脑机接口应用的发展。

Method: 预处理真实脑电数据，训练扩散模型从噪声中重建脑电通道，并通过信号级和任务级指标评估生成信号质量。

Result: 生成数据在分类任务中达到95%以上的准确率，具有低均方误差和高相关性，能有效提升脑机接口分类性能。

Conclusion: 扩散模型生成的合成脑电信号能有效补充数据集，解决数据稀缺问题，改善脑机接口应用的分类性能。

Abstract: Electroencephalography (EEG) is a widely used, non-invasive method for
capturing brain activity, and is particularly relevant for applications in
Brain-Computer Interfaces (BCI). However, collecting high-quality EEG data
remains a major challenge due to sensor costs, acquisition time, and
inter-subject variability. To address these limitations, this study proposes a
methodology for generating synthetic EEG signals associated with motor imagery
brain tasks using Diffusion Probabilistic Models (DDPM). The approach involves
preprocessing real EEG data, training a diffusion model to reconstruct EEG
channels from noise, and evaluating the quality of the generated signals
through both signal-level and task-level metrics. For validation, we employed
classifiers such as K-Nearest Neighbors (KNN), Convolutional Neural Networks
(CNN), and U-Net to compare the performance of synthetic data against real data
in classification tasks. The generated data achieved classification accuracies
above 95%, with low mean squared error and high correlation with real signals.
  Our results demonstrate that synthetic EEG signals produced by diffusion
models can effectively complement datasets, improving classification
performance in EEG-based BCIs and addressing data scarcity.

</details>


### [11] [Two Phases Leakage Detection Strategy Supported by DMAs](https://arxiv.org/abs/2510.17836)
*G. Messa,G. Acconciaioco,S. Ripani,L. Bozzelli,A. Simone,O. Giustolisi*

Main category: eess.SP

TL;DR: 提出了一种基于模型的两阶段泄漏检测策略，包括DMA识别和管道预定位，使用AMSI指标减少误报，并设计了压力计位置优化方法。


<details>
  <summary>Details</summary>
Motivation: 为水务公司提供一种能够识别DMA级别异常并以最小检查成本定位泄漏的实用策略。

Method: 两阶段模型策略：第一阶段识别DMA区域，第二阶段在识别出的DMA内预定位泄漏管道序列；使用AMSI指标检测异常；提出压力计位置设计策略。

Result: 该策略能够有效限制DMA识别阶段的误报，并通过管道序列预定位降低检查成本。

Conclusion: 该两阶段泄漏检测策略为水务公司提供了一种实用且成本效益高的泄漏管理解决方案。

Abstract: The present work proposes a novel two phases model-based strategy for leakage
detection. The two phases are: the identification of the district metering area
(DMA) and the pipe pre-localization into the identified DMA. The strategy is
based on detecting and pre-localizing the punctual leakage as anomaly with
respect to the normal working conditions. A further novelty is the fact that
the pre-localization phase returns the sequence of pipes to inspect, which
makes the strategy attractive for water utilities, whose aim is to identify the
anomaly at DMA level and, successively, to localize it with the minimum
inspection cost. Furthermore, a random database is useful to test the
performance of the strategy with respect to the configuration of DMAs and the
pressure metering system. Consequently, a novel strategy to design the location
of pressure meters is also proposed. It is demonstrated that the entire
strategy limits false positives during the DMA identification phase by using
the recently proposed index named Asset Management Support Indicator (AMSI).
AMSI is invariant with respect to the deterioration, i.e., it is sensitive to
its increase causing punctual leakage. The strategy is studied and discussed
using two real Apulian WDNs managed by Acquedotto Pugliese.

</details>


### [12] [Majority Vote Compressed Sensing](https://arxiv.org/abs/2510.18008)
*Henrik Hellström,Jiwon Jeong,Ayfer Özgür,Viktoria Fodor,Carlo Fischione*

Main category: eess.SP

TL;DR: 提出了一种基于多数投票空中计算的稀疏数据聚合方法，通过随机变换和1位压缩感知技术，在T=O(kn log(d)/ε²)信道使用次数内实现高维稀疏向量的高效聚合。


<details>
  <summary>Details</summary>
Motivation: 现有非相干空中计算需要超过d个信道使用次数来计算函数，而数据向量的稀疏性未被充分利用。本文旨在利用稀疏性显著降低通信成本。

Method: 使用随机变换将高维稀疏数据投影到低维空间，通过多数投票AirComp方案传输投影向量，在接收端利用1位压缩感知技术恢复原始高维聚合结果。

Result: 理论证明MVCS方案能以ℓ₂范数误差ε估计聚合数据向量∑xᵢ，所需信道使用次数为T=O(kn log(d)/ε²)。

Conclusion: MVCS方法相比现有技术具有显著优势，可应用于直方图估计和分布式机器学习等场景。

Abstract: We consider the problem of non-coherent over-the-air computation (AirComp),
where $n$ devices carry high-dimensional data vectors
$\mathbf{x}_i\in\mathbb{R}^d$ of sparsity $\lVert\mathbf{x}_i\rVert_0\leq k$
whose sum has to be computed at a receiver. Previous results on non-coherent
AirComp require more than $d$ channel uses to compute functions of
$\mathbf{x}_i$, where the extra redundancy is used to combat non-coherent
signal aggregation. However, if the data vectors are sparse, sparsity can be
exploited to offer significantly cheaper communication. In this paper, we
propose to use random transforms to transmit lower-dimensional projections
$\mathbf{s}_i\in\mathbb{R}^T$ of the data vectors. These projected vectors are
communicated to the receiver using a majority vote (MV)-AirComp scheme, which
estimates the bit-vector corresponding to the signs of the aggregated
projections, i.e., $\mathbf{y} = \text{sign}(\sum_i\mathbf{s}_i)$. By
leveraging 1-bit compressed sensing (1bCS) at the receiver, the real-valued and
high-dimensional aggregate $\sum_i\mathbf{x}_i$ can be recovered from
$\mathbf{y}$. We prove analytically that the proposed MVCS scheme estimates the
aggregated data vector $\sum_i \mathbf{x}_i$ with $\ell_2$-norm error
$\epsilon$ in $T=\mathcal{O}(kn\log(d)/\epsilon^2)$ channel uses. Moreover, we
specify algorithms that leverage MVCS for histogram estimation and distributed
machine learning. Finally, we provide numerical evaluations that reveal the
advantage of MVCS compared to the state-of-the-art.

</details>


### [13] [MCANet: A Coherent Multimodal Collaborative Attention Network for Advanced Modulation Recognition in Adverse Noisy Environments](https://arxiv.org/abs/2510.18336)
*Wangye Jiang,Haoming Yang,Xinyu Lu,Mingyuan Wang,Huimei Sun,Jingya Zhang*

Main category: eess.SP

TL;DR: MCANet是一个多模态深度学习框架，用于自动调制识别，在低信噪比条件下表现优于主流模型。


<details>
  <summary>Details</summary>
Motivation: 传统自动调制识别方法在复杂噪声环境中，特别是低信噪比条件下面临挑战，需要提高频谱效率。

Method: 使用多模态协作注意力网络，采用精炼特征提取和全局建模来支持融合策略。

Result: 在多个基准数据集上的实验结果表明，MCANet在低信噪比条件下具有更好的鲁棒性。

Conclusion: MCANet框架能够有效解决复杂噪声环境中的自动调制识别问题，特别是在低信噪比条件下表现优异。

Abstract: As wireless communication systems evolve, automatic modulation recognition
(AMR) plays a key role in improving spectrum efficiency, especially in
cognitive radio systems. Traditional AMR methods face challenges in complex,
noisy environments, particularly in low signal-to-noise ratio (SNR) conditions.
This paper introduces MCANet (Multimodal Collaborative Attention Network), a
multimodal deep learning framework designed to address these challenges. MCANet
employs refined feature extraction and global modeling to support its fusion
strategy.Experimental results across multiple benchmark datasets show that
MCANet outperforms mainstream AMR models, offering better robustness in low-SNR
conditions.

</details>


### [14] [AWSPNet: Attention-based Dual-Tree Wavelet Scattering Prototypical Network for MIMO Radar Target Recognition and Jamming Suppression](https://arxiv.org/abs/2510.18422)
*Yizhen Jia,Siyao Xiao,Wenkai Jia,Hui Chen,Wen-Qin Wang*

Main category: eess.SP

TL;DR: 提出基于注意力机制的双树小波散射原型网络(AWSPNet)，用于雷达目标识别和干扰抑制，在低信噪比环境下实现90.45%的准确率。


<details>
  <summary>Details</summary>
Motivation: 数字射频存储器电子对抗技术的威胁日益增加，能够产生大量欺骗性假目标，淹没雷达处理能力并掩盖真实目标，需要在低信噪比环境下稳健区分真实目标和复杂干扰信号。

Method: 使用双树复小波变换提取对噪声和信号平移具有鲁棒性的特征，通过注意力机制和预训练骨干网络进一步精炼特征，采用监督对比学习策略解决标注数据有限问题，原型网络用于分类。

Result: 在-6 dB信噪比下达到90.45%的准确率，通过t-SNE可视化分析特征可分性，结合时域滑动窗口方法有效抑制各类干扰。

Conclusion: AWSPNet在复杂电磁环境中具有实际应用潜力，能够同时识别目标并有效抑制干扰。

Abstract: The increasing of digital radio frequency memory based electronic
countermeasures poses a significant threat to the survivability and
effectiveness of radar systems. These jammers can generate a multitude of
deceptive false targets, overwhelming the radar's processing capabilities and
masking targets. Consequently, the ability to robustly discriminate between
true targets and complex jamming signals, especially in low signal-to-noise
ratio (SNR) environments, is of importance. This paper introduces the
attention-based dual-tree wavelet scattering prototypical network (AWSPNet), a
deep learning framework designed for simultaneous radar target recognition and
jamming suppression. The core of AWSPNet is the encoder that leverages the
dual-tree complex wavelet transform to extract features that are inherently
robust to noise and signal translations. These features are further refined by
an attention mechanism and a pre-trained backbone network. To address the
challenge of limited labeled data and enhance generalization, we employ a
supervised contrastive learning strategy during the training phase. The
classification is performed by a prototypical network, which is particularly
effective in few-shot learning scenarios, enabling rapid adaptation to new
signal types. We demonstrate the efficacy of our approach through extensive
experiments. The results show that AWSPNet achieves 90.45\% accuracy at -6 dB
SNR. Furthermore, we provide a physical interpretation of the network's inner
workings through t-SNE visualizations, which analyze the feature separability
at different stages of the model. Finally, by integrating AWSPNet with a
time-domain sliding window approach, we present a complete algorithm capable of
not only identifying but also effectively suppressing various types of jamming,
thereby validating its potential for practical application in complex
electromagnetic environments.

</details>


### [15] [Microsecond Federated SVD on Grassmann Manifold for Real-time IoT Intrusion Detection](https://arxiv.org/abs/2510.18501)
*Tung-Anh Nguyen,Van-Phuc Bui,Shashi Raj Pandey,Kim Hue Ta,Nguyen H. Tran,Petar Popovski*

Main category: eess.SP

TL;DR: FedSVD是一种基于奇异值分解和Grassmann流形优化的无监督联邦学习框架，用于物联网网络实时异常检测，无需标记数据或集中数据共享，显著降低通信开销和计算成本。


<details>
  <summary>Details</summary>
Motivation: 物联网网络需要实时异常检测，但传统方法依赖标记数据或集中数据共享，不适合资源受限的物联网设备。

Method: 利用奇异值分解和Grassmann流形优化，在低功耗设备上实现无监督联邦学习，避免数据共享。

Result: FedSVD性能与深度学习基线相当，但推理延迟降低10倍以上，适合延迟敏感的物联网应用。

Conclusion: FedSVD为物联网网络提供了一种高效、低延迟的无监督异常检测解决方案。

Abstract: This paper introduces FedSVD, a novel unsupervised federated learning
framework for real-time anomaly detection in IoT networks. By leveraging
Singular Value Decomposition (SVD) and optimization on the Grassmann manifolds,
FedSVD enables accurate detection of both known and unknown intrusions without
relying on labeled data or centralized data sharing. Tailored for deployment on
low-power devices like the NVIDIA Jetson AGX Orin, the proposed method
significantly reduces communication overhead and computational cost.
Experimental results show that FedSVD achieves performance comparable to deep
learning baselines while reducing inference latency by over 10x, making it
suitable for latency-sensitive IoT applications.

</details>


### [16] [Channel-Aware Vector Quantization for Robust Semantic Communication on Discrete Channels](https://arxiv.org/abs/2510.18604)
*Zian Meng,Qiang Li,Wenqian Tang,Mingdie Yan,Xiaohu Ge*

Main category: eess.SP

TL;DR: 提出了一种通道感知向量量化(CAVQ)算法，在联合源信道编码(JSCC)框架下实现离散语义传输，通过整合信道状态信息优化码本，提升数字语义通信的鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的语义通信主要依赖模拟或半数字传输，与现代数字通信基础设施兼容性差；而现有的向量量化方法在码本优化时忽略了信道状态信息，导致鲁棒性不足。

Method: 在离散无记忆信道下建立VQJSCC框架，将语义特征离散化并直接映射到调制星座符号；CAVQ将信道转移概率整合到量化过程中，使易混淆符号与语义相似码字对齐；引入多码本对齐机制处理码本顺序与调制顺序不匹配问题。

Result: 实验结果表明VQJSCC有效缓解了数字悬崖效应，在各种调制方案下实现了优越的重建质量，在鲁棒性和效率方面均优于最先进的数字语义通信基线方法。

Conclusion: 所提出的通道感知向量量化方法能够显著提升数字语义通信的性能，为与现代数字通信基础设施的兼容提供了有效解决方案。

Abstract: Deep learning-based semantic communication has largely relied on analog or
semi-digital transmission, which limits compatibility with modern digital
communication infrastructures. Recent studies have employed vector quantization
(VQ) to enable discrete semantic transmission, yet existing methods neglect
channel state information during codebook optimization, leading to suboptimal
robustness. To bridge this gap, we propose a channel-aware vector quantization
(CAVQ) algorithm within a joint source-channel coding (JSCC) framework, termed
VQJSCC, established on a discrete memoryless channel. In this framework,
semantic features are discretized and directly mapped to modulation
constellation symbols, while CAVQ integrates channel transition probabilities
into the quantization process, aligning easily confused symbols with
semantically similar codewords. A multi-codebook alignment mechanism is further
introduced to handle mismatches between codebook order and modulation order by
decomposing the transmission stream into multiple independently optimized
subchannels. Experimental results demonstrate that VQJSCC effectively mitigates
the digital cliff effect, achieves superior reconstruction quality across
various modulation schemes, and outperforms state-of-the-art digital semantic
communication baselines in both robustness and efficiency.

</details>


### [17] [Delay Management Using Packet Fragmentation in Wireless Industrial Automation Systems](https://arxiv.org/abs/2510.18646)
*Anwar Ahmed Khan,Shama Siddiqui,Indrakshi Dey*

Main category: eess.SP

TL;DR: 比较FROG-MAC和FPS-MAC两种MAC协议在工业自动化环境中的性能，FROG-MAC在能效和延迟方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 工业自动化应用对延迟管理有严格要求，需要高效的MAC协议来保证关键数据的及时传输，特别是在异构数据环境中。

Method: 使用Contiki作为仿真平台，采用单跳星型拓扑模拟工业环境，比较FROG-MAC和FPS-MAC两种协议的性能。

Result: FROG-MAC在能效和延迟方面优于FPS-MAC，这得益于其能够中断信道中正在进行的低优先级传输的特性。

Conclusion: FROG-MAC协议在工业自动化异构无线网络中具有更好的性能表现，特别是在能效和延迟控制方面。

Abstract: Managing delay is one of the core requirements of industrial automation
applications due to the high risk associated for equipment and human lives.
Using efficient Media Access Control (MAC) schemes guarantees the timely
transmission of critical data, particularly in the industrial environments
where heterogeneous data is inherently expected. This paper compares the
performance of Fragmentation based MAC (FROG-MAC) against Fuzzy Priority
Scheduling based MAC (FPS-MAC), both of which have been designed to optimize
the performance of heterogenous wireless networks. Contiki has been used as a
simulation platform and a single hop star topology has been assumed to resemble
the industrial environment. It has been shown that FROG-MAC has the potential
to outperform FPS-MAC in terms of energy efficiency and delay both, due to its
inherent feature of interrupting ongoing lower priority transmission on the
channel.

</details>


### [18] [A Comparative Analysis of High-Level vs. Low-Level Simulations for Dynamic MAC Protocols in Wireless Sensor Networks](https://arxiv.org/abs/2510.18662)
*Shama Siddiqui,Anwar Ahmed Khan,Indrakshi Dey*

Main category: eess.SP

TL;DR: 比较了ADP-MAC协议在高层理论模拟和详细实现模拟中的性能差异，发现两种模拟方法得出的能耗和延迟趋势存在显著不同。


<details>
  <summary>Details</summary>
Motivation: 在无线传感器网络中，数百种MAC协议被提出，需要评估这些协议的性能评估质量，比较高层理论模拟与详细实现结果对于真实场景部署至关重要。

Method: 使用MATLAB进行初始理论模拟，使用TinyOS在Mica2平台上开发协议的详细实现，基于能耗和延迟对ADP-MAC进行性能评估。

Result: 高层实现中，能耗随信道轮询间隔增加而减少，延迟增加；详细实现中，能耗和延迟都随轮询间隔增加而增加。两种模拟方法的趋势显著不同。

Conclusion: 高层理论研究缺乏现实假设，导致与详细实现结果存在显著差异，强调了在实际部署前进行详细实现验证的重要性。

Abstract: Simulation studies are conducted at different levels of details for assessing
the performance of Media Access Control (MAC) protocols in Wireless Sensor
Networks (WSN). In the present-day scenario where hundreds of MAC protocols
have been proposed, it is important to assess the quality of performance
evaluation being conducted for each of the proposed protocols. It therefore
becomes crucial to compare the results of high-level theoretical simulations
with the detailed implementation results before any network protocol could be
deployed for a real-world scenario. In this work, we present a comparison of
high-level theoretical and detailed implementation results for Adaptive and
Dynamic Polling-MAC (ADP-MAC). MATLAB has been used for conducting initial
theoretical simulations and TinyOS has been used to develop the detailed
implementation of protocol for Mica2 platform. Performance evaluation of
ADP-MAC using the two levels of simulation has been conducted based on energy
and delay. In the high-level implementation, energy consumption was found to be
decreasing whereas delay was found to be increasing for increasing channel
polling intervals. On the other hand, when detailed implementation was
developed, it was observed that both energy consumption and delay revealed an
increasing trend with the increasing polling intervals. Therefore, it has been
shown that the trends for high- and low-level simulations for ADP-MAC are
significantly different, due to the lack of realistic assumptions in the
higher-level study.

</details>


### [19] [mSQUID: Model-Based Leanred Modulo Recovery at Low Sampling Rates](https://arxiv.org/abs/2510.18729)
*Yhonatan Kvich,Rotem Arie,Hana Hasan,Shaik Basheeruddin Shah,Yonina C. Eldar*

Main category: eess.SP

TL;DR: 提出了一种基于深度展开网络的模数采样信号恢复方法mSQUID，通过软量化模块在可微分和可学习的方式下编码模数先验，在低采样率和高斯噪声下实现优越的重建性能。


<details>
  <summary>Details</summary>
Motivation: 模数采样通过将输入信号折叠到有界区间来避免信号削波，但非线性失真在噪声和量化条件下带来恢复挑战。需要结合经典压缩感知的可解释性和学习的灵活性来解决这一问题。

Method: 开发了模数软量化展开迭代解码器(mSQUID)，结合模型驱动的深度展开网络和软量化模块，该模块通过引导解趋向折叠范围的离散倍数来编码模数先验。

Result: 在低采样率和高斯噪声下实现优越的重建性能，能够同时恢复幅度差异大且频带不重叠的信号，显著减少运行时间，适合实时资源受限系统。

Conclusion: mSQUID方法有效解决了模数采样中的恢复挑战，结合了经典方法和深度学习的优势，在噪声和量化条件下表现出色，具有实际应用价值。

Abstract: Modulo sampling enables acquisition of signals with unlimited dynamic range
by folding the input into a bounded interval prior to sampling, thus
eliminating the risk of signal clipping and preserving information without
requiring highresolution ADCs. While this enables low-cost hardware, the
nonlinear distortion introduced by folding presents recovery challenges,
particularly under noise and quantization. We propose a model-based deep
unfolding network tailored to this setting, combining the interpretability of
classical compress sensing (CS) solvers with the flexibility of learning. A key
innovation is a soft-quantization module that encodes the modulo prior by
guiding the solution toward discrete multiples of the folding range in a
differentiable and learnable way. Our method, modulo soft-quantized unfolded
iterative decoder (mSQUID), achieves superior reconstruction performance at low
sampling rates under additive Gaussian noise. We further demonstrate its
utility in a challenging case where signals with vastly different amplitudes
and disjoint frequency bands are acquired simultaneously and quantized. In this
scenario, classical sampling often struggles due to weak signal distortion or
strong signal clipping, while our approach is able to recover the input
signals. Our method also offers significantly reduced runtimes, making it
suitable for real-time, resource-limited systems.

</details>


### [20] [Wireless-Fed Pinching-Antenna Systems (Wi-PASS) for NextG Wireless Networks](https://arxiv.org/abs/2510.18743)
*Kasun R. Wijewardhana,Animesh Yadav,Ming Zeng,Mohamed Elsayed,Octavia A. Dobre,Zhiguo Ding*

Main category: eess.SP

TL;DR: 提出无线馈电的夹持天线系统(Wi-PASS)，通过无线方式为波导供电，解决了传统有线馈电PASS系统部署受限的问题，实现了更灵活、成本效益更高的毫米波和太赫兹频段覆盖扩展。


<details>
  <summary>Details</summary>
Motivation: 传统波导夹持天线系统(PASS)依赖有线馈电，限制了部署灵活性，只能部署在基站附近区域，无法有效服务远距离用户，成本效益较低。

Method: 采用无线馈电技术为波导供电，开发无线馈电夹持天线系统(Wi-PASS)，通过室内外多种应用场景验证系统性能。

Result: Wi-PASS相比传统固定天线系统提供更高的数据速率，在覆盖扩展方面展现出优越的可行性和性能表现。

Conclusion: Wi-PASS为毫米波和太赫兹频段提供了一种实用且经济高效的覆盖扩展解决方案，未来研究将进一步推进其实际部署。

Abstract: Waveguide-based pinching-antenna systems (PASS) have recently emerged as a
promising solution to mitigate severe propagation losses in millimeter-wave and
terahertz bands by intelligently and flexibly establishing line-of-sight links.
However, their reliance on wire-based feeding confines deployment to areas near
the base station (BS), limiting installation flexibility and making them
cost-ineffective for serving distant users or regions. To overcome this
challenge, this article proposes wireless-fed pinchingantenna systems
(Wi-PASS), which employ wireless feeding to energize waveguides. Wi-PASS offer
a practical and cost-efficient means to extend coverage beyond the BS vicinity.
Several indoor and outdoor use cases demonstrate Wi-PASS advantages over PASS.
Numerical results further show that Wi-PASS deliver higher data rates than
conventional fixed-antenna systems, confirming the superior feasibility and
performance of Wi-PASS. Key future research directions are also discussed to
advance Wi-PASS deployment.

</details>


### [21] [Analyse comparative d'algorithmes de restauration en architecture dépliée pour des signaux chromatographiques parcimonieux](https://arxiv.org/abs/2510.18760)
*Mouna Gharbi,Silvia Villa,Emilie Chouzenoux,Jean-Christophe Pesquet,Laurent Duval*

Main category: eess.SP

TL;DR: 比较三种展开式架构在参数化色谱信号数据库上的性能，重点评估适用于物理化学峰信号表征的指标。


<details>
  <summary>Details</summary>
Motivation: 稀疏假设下的数据恢复是一个活跃研究领域，传统迭代优化方法现在与深度学习技术互补，展开式方法结合了两者的优势。

Method: 在参数化色谱信号数据库上对三种展开式架构进行对比研究，使用适应物理化学峰信号表征的指标进行评估。

Result: 这些方法表现出良好的性能，特别是在使用适应物理化学峰信号表征的指标时。

Conclusion: 展开式方法结合了传统优化和深度学习的优势，在色谱信号恢复任务中表现优异，特别是当使用适当的物理化学特征指标时。

Abstract: Data restoration from degraded observations, of sparsity hypotheses, is an
active field of study. Traditional iterative optimization methods are now
complemented by deep learning techniques. The development of unfolded methods
benefits from both families. We carry out a comparative study of three
architectures on parameterized chromatographic signal databases, highlighting
the performance of these approaches, especially when employing metrics adapted
to physico-chemical peak signal characterization.

</details>


### [22] [SO(3)-invariant PCA with application to molecular data](https://arxiv.org/abs/2510.18827)
*Michael Fraiman,Paulina Hoyos,Tamir Bendory,Joe Kileel,Oscar Mickelin,Nir Sharon,Amit Singer*

Main category: eess.SP

TL;DR: 提出了一种SO(3)不变的主成分分析方法，用于处理三维体积数据的方向未知问题，无需显式数据增强即可隐式考虑所有旋转，显著降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统PCA在处理具有任意方向的三维数据时面临挑战，需要大量旋转副本的数据增强，导致计算成本过高。

Method: 通过利用底层代数结构，开发了高效的SO(3)不变PCA框架，仅需计算协方差矩阵条目数的平方根，大幅降低复杂度。

Result: 在真实分子数据集上验证了方法的有效性，证明其能够有效处理大规模高维重建问题。

Conclusion: 该方法为三维体积数据的PCA分析提供了高效解决方案，为大规模高维重建问题开辟了新可能性。

Abstract: Principal component analysis (PCA) is a fundamental technique for
dimensionality reduction and denoising; however, its application to
three-dimensional data with arbitrary orientations -- common in structural
biology -- presents significant challenges. A naive approach requires
augmenting the dataset with many rotated copies of each sample, incurring
prohibitive computational costs. In this paper, we extend PCA to 3D volumetric
datasets with unknown orientations by developing an efficient and principled
framework for SO(3)-invariant PCA that implicitly accounts for all rotations
without explicit data augmentation. By exploiting underlying algebraic
structure, we demonstrate that the computation involves only the square root of
the total number of covariance entries, resulting in a substantial reduction in
complexity. We validate the method on real-world molecular datasets,
demonstrating its effectiveness and opening up new possibilities for
large-scale, high-dimensional reconstruction problems.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [23] [Information Capacity of EEG: Theoretical and Computational Limits of Recoverable Neural Information](https://arxiv.org/abs/2510.17841)
*Ishir Rao*

Main category: cs.IT

TL;DR: 通过信息论和合成前向建模估计EEG的信息容量，发现头皮EEG仅能传递数十比特/样本的低维神经活动信息，信息容量在64-128个电极时饱和，且受测量物理限制而非算法复杂性限制。


<details>
  <summary>Details</summary>
Motivation: 量化EEG的信息容量，了解从EEG推断大脑状态或思维内容的内在限制。

Method: 结合信息论和合成前向建模，使用高斯通道理论和经验模拟来估计皮层源与EEG记录之间的互信息。

Result: 头皮EEG仅传递约数十比特/样本的低维神经活动信息；信息在64-128个电极时饱和；线性解码器几乎能捕获所有可线性恢复的方差，但恢复的互信息远低于分析通道容量。

Conclusion: 测量物理是EEG信息容量的主要限制因素，而非算法复杂性，这界定了从EEG推断大脑状态或思维内容的内在上限。

Abstract: Electroencephalography (EEG) is widely used to study human brain dynamics,
yet its quantitative information capacity remains unclear. Here, we combine
information theory and synthetic forward modeling to estimate the mutual
information between latent cortical sources and EEG recordings. Using
Gaussian-channel theory and empirical simulations, we find that scalp EEG
conveys only tens of bits per sample about low-dimensional neural activity.
Information saturates with approximately 64-128 electrodes and scales
logarithmically with signal-to-noise ratio (SNR). Linear decoders capture
nearly all variance that is linearly recoverable, but the mutual information
they recover remains far below the analytic channel capacity, indicating that
measurement physics - not algorithmic complexity - is the dominant limitation.
These results outline the intrinsic ceiling on how much structure about brain
state or thought content can be inferred from EEG.

</details>


### [24] [Performance of Modified Fractional Frequency Reuse Algorithm in Random Ultra Dense Networks](https://arxiv.org/abs/2510.18440)
*Bach Hung Luu,Samuel Harry Gardner,Sinh Cong Lam,Trong Minh Hoang*

Main category: cs.IT

TL;DR: 提出一种改进的分数频率复用算法，使用服务基站与第二最近基站的信号功率比来分类小区边缘用户和中心用户，以减轻5G及超5G网络中的小区间干扰。


<details>
  <summary>Details</summary>
Motivation: 在5G及超5G高密度基站网络中，传统基于下行SINR或距离的用户分类方法存在局限性，需要更有效的干扰管理方案来提升用户性能。

Method: 采用服务基站与第二最近基站的信号功率比作为用户分类标准，当功率比低于预设阈值时，用户被分类为小区边缘用户并获得更高的传输功率。

Result: 仿真结果显示增加传输功率能提升小区边缘用户性能，但会降低普通用户性能；频率复用算法在障碍物密集环境中能有效抑制小区间干扰。

Conclusion: 基于功率比的用户分类方法在特定环境下可行，但需权衡小区边缘用户与普通用户之间的性能平衡。

Abstract: Mitigating intercell interference by employing fractional frequency reuse
algorithms is one of the important approaches to improving user performance in
5G and Beyond 5G cellular network systems, which typically have a high density
of Base Stations (BSs). While most frequency reuse algorithms are based on the
downlink Signal-to-Interference-plus-Noise Ratio (SINR) or the distance between
the user and its serving BS to classify Cell-Edge Users (CEUs) and Cell-Center
Users (CCUs), this paper discusses a modified algorithm that uses the power
ratio between the signal strengths from the serving BS and the second nearest
BS for user classification. Specifically, if the power ratio is below a
predefined threshold, the user is classified as a CEU and is served with higher
transmission power. Simulation results show that increasing transmission power
is necessary to enhance CEU performance, but it also degrades the performance
of typical users. The use of frequency reuse algorithms is particularly
feasible in environments with a high density of obstacles, where intercell
interference can be effectively suppressed.

</details>


### [25] [A Markov-Chain Characterization of Finite-State Dimension and a Generalization of Agafonov's Theorem](https://arxiv.org/abs/2510.18736)
*Laurent Bienvenu,Hugo Gimbert,Subin Pulari*

Main category: cs.IT

TL;DR: 本文扩展了有限状态维度的概念，通过马尔可夫链模拟和Kullback-Leibler散度提供了有限状态维度的新信息论特征，并推广了Agafonov定理。


<details>
  <summary>Details</summary>
Motivation: 有限状态维度量化了有限自动机感知无限序列中信息渐近速率。已有研究表明Borel正规序列具有最大有限状态维度，但需要将其扩展到更一般的序列。

Method: 使用马尔可夫链模拟和条件Kullback-Leibler散度来表征序列的有限状态维度，建立与稳态分布的收敛关系。

Result: 证明了序列的有限状态维度可以通过马尔可夫链模拟产生的极限分布与其稳态分布之间的条件KL散度来刻画，推广了Schnorr-Stimm定理。

Conclusion: 提供了有限状态维度的新信息论特征，并推广了Agafonov定理，建立了序列与其自动子序列有限状态维度之间的定量关系。

Abstract: Finite-state dimension quantifies the asymptotic rate of information in an
infinite sequence as perceived by finite automata. For a fixed alphabet, the
infinite sequences that have maximal finite-state dimension are exactly those
that are Borel normal, i.e., in which all words of any given length appear with
the same frequency. A theorem of Schnorr and Stimm (1972) shows that a real
number is Borel normal if and only if, for every finite-state irreducible
Markov chain with fair transitions, when the chain is simulated using the
binary expansion of the given number, the empirical distribution of states
converges to its stationary distribution. In this paper we extend this
correspondence beyond normal numbers. We show that the finite-state dimension
of a sequence can be characterized in terms of the conditional Kullback-Leibler
divergence between the limiting distributions arising from the simulation of
Markov chains using the given sequence and their stationary distributions. This
provides a new information-theoretic characterization of finite-state dimension
which generalizes the Schnorr-Stimm result.
  As an application, we prove a generalization of Agafonov's theorem for normal
numbers. Agafonov's theorem states that a sequence is normal if and only if
every subsequence selected by a finite automaton is also normal. We extend this
to arbitrary sequences by establishing a tight quantitative relationship
between the finite-state dimension of a sequence and the finite-state
dimensions of its automatic subsequences.

</details>
