<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 5]
- [eess.SP](#eess.SP) [Total: 14]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [VQ-DSC-R: Robust Vector Quantized-Enabled Digital Semantic Communication With OFDM Transmission](https://arxiv.org/abs/2602.15045)
*Jianqiao Chen,Nan Ma,Xiaodong Xu,Tingting Zhu,Huishi Song,Chen Dong,Wenkai Liu,Rui Meng,Ping Zhang*

Main category: cs.IT

TL;DR: 提出基于向量量化的数字语义通信系统VQ-DSC-R，通过Swin Transformer提取语义特征，ANDVQ减少量化误差，条件扩散模型增强信道鲁棒性，实现高效压缩和抗干扰传输。


<details>
  <summary>Details</summary>
Motivation: 当前语义通信研究主要集中于模拟通信和简化信道模型，缺乏与数字基础设施的互操作性。需要开发能够在实际数字传输环境中工作的鲁棒数字语义通信系统。

Method: 1. 基于Swin Transformer的层次语义特征提取，结合VQ模块将特征映射到共享语义量化码本；2. ANDVQ方案使用K近邻统计动态调整量化过程，减少量化误差；3. 条件扩散模型优化信道状态信息，注意力模块自适应信道噪声；4. 采用三阶段训练策略优化整个系统。

Result: 实验表明VQ-DSC-R优于基准方案，实现高压缩比并在实际场景中表现出鲁棒性能。

Conclusion: VQ-DSC-R系统成功弥合了语义通信与数字基础设施之间的鸿沟，为实际应用中的数字语义通信提供了有效的解决方案。

Abstract: Digital mapping of semantic features is essential for achieving interoperability between semantic communication and practical digital infrastructure. However, current research efforts predominantly concentrate on analog semantic communication with simplified channel models. To bridge these gaps, we develop a robust vector quantized-enabled digital semantic communication (VQ-DSC-R) system built upon orthogonal frequency division multiplexing (OFDM) transmission. Our work encompasses the framework design of VQ-DSC-R, followed by a comprehensive optimization study. Firstly, we design a Swin Transformer-based backbone for hierarchical semantic feature extraction, integrated with VQ modules that map the features into a shared semantic quantized codebook (SQC) for efficient index transmission. Secondly, we propose a differentiable vector quantization with adaptive noise-variance (ANDVQ) scheme to mitigate quantization errors in SQC, which dynamically adjusts the quantization process using K-nearest neighbor statistics, while exponential moving average mechanism stabilizes SQC training. Thirdly, for robust index transmission over multipath fading channel and noise, we develop a conditional diffusion model (CDM) to refine channel state information, and design an attention-based module to dynamically adapt to channel noise. The entire VQ-DSC-R system is optimized via a three-stage training strategy. Extensive experiments demonstrate superiority of VQ-DSC-R over benchmark schemes, achieving high compression ratios and robust performance in practical scenarios.

</details>


### [2] [GRAM-DIFF: Gram Matrix Guided Diffusion for MIMO Channel Estimation](https://arxiv.org/abs/2602.15187)
*Xinyuan Wang,Krishna Narayanan*

Main category: cs.IT

TL;DR: GRAM-DIFF：基于Gram矩阵引导的扩散框架，用于半盲MIMO信道估计，通过结合Gram矩阵引导和似然引导，显著提升信道估计性能


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的信道估计方法主要利用学习的生成先验，但未能充分利用从数据符号中估计的Gram矩阵所包含的信道子空间结构信息。在实际系统中，可以从接收符号中估计信道Gram矩阵，这提供了信道子空间结构的实现级信息。

Method: 提出GRAM-DIFF框架，将预训练的角域扩散先验与两种互补的引导机制相结合：1）新颖的Gram矩阵引导项，在反向扩散过程中强制执行二阶一致性；2）来自导频观测的似然引导。采用信噪比匹配初始化和自适应引导缩放确保稳定性和低推理延迟。

Result: 在3GPP和QuaDRiGa信道模型上的仿真表明，相比确定性扩散基线方法，GRAM-DIFF在归一化均方误差方面有持续改进，在NMSE为0.1时比Fest等人（2024）的基线方法获得4-6 dB的信噪比增益。该框架在相干时间约束下表现出优雅退化，当基于数据的Gram估计不可靠时，平滑地恢复到似然引导扩散。

Conclusion: GRAM-DIFF通过有效整合Gram矩阵引导和似然引导，显著提升了半盲MIMO信道估计性能，为实际无线通信系统提供了一种鲁棒且高效的信道估计解决方案。

Abstract: We propose GRAM-DIFF, a Gram-matrix-guided diffusion framework for semi-blind multiple input multiple output (MIMO) channel estimation. Recent diffusion-based estimators leverage learned generative priors to improve pilot-based channel estimation; but they do not exploit second-order structural information estimated from data symbols. In practical systems, the channel Gram matrix can be estimated from received symbols and it provides realization-level information about channel subspace structure. The proposed method integrates a pre-trained angular-domain diffusion prior with two complementary guidance mechanisms: a novel Gram-matrix guidance term that enforces second-order consistency during the reverse diffusion process, and likelihood guidance from pilot observations. Signal-to-noise ratio (SNR)-matched initialization and adaptive guidance scaling ensure stability and low inference latency. Simulations on 3GPP and QuaDRiGa channel models demonstrate consistent normalized mean-squared error (NMSE) improvements over deterministic diffusion baselines, achieving 4 to 6 dB SNR gains at an NMSE of 0.1 over the baseline in Fest et al. (2024). The framework exhibits graceful degradation under coherence-time constraints, smoothly reverting to likelihood-guided diffusion when data-based Gram estimates become unreliable.

</details>


### [3] [On the Entropy of General Mixture Distributions](https://arxiv.org/abs/2602.15303)
*Namyoon Lee*

Main category: cs.IT

TL;DR: 本文开发了一种确定性、闭式的工具包，用于边界计算和准确逼近混合分布的微分熵，通过信息论信道视角将混合熵分解为分量内不确定性的平均值加上重叠项，并使用分量密度间的成对重叠积分来边界和逼近重叠项。


<details>
  <summary>Details</summary>
Motivation: 混合分布是多模态数据建模的重要工具，但即使每个分量密度都很简单，混合分布的微分熵计算仍然非常困难，因为混合将对数与求和耦合在一起。现有方法难以直接计算混合熵，需要开发能够直接从分量参数边界和准确逼近混合熵的方法。

Method: 采用信息论信道视角：将潜在混合标签视为输入，观测视为输出。将混合熵分解为分量内不确定性的平均值加上重叠项。使用分量密度间的成对重叠积分来边界和逼近重叠项，引入简单的族相关偏移来校正Jensen重叠边界的系统偏差，并通过最终裁剪步骤确保估计始终遵循通用信息论边界。

Result: 为高斯、因子化拉普拉斯、均匀和混合混合提供了闭式特化形式。数值实验验证了所得边界和逼近方法在分离度、维度、分量数量和相关性协方差方面的有效性。

Conclusion: 该方法提供了一种确定性、闭式的工具包，能够直接从分量参数边界和准确逼近混合熵，解决了混合熵计算中的关键难题，为信息论、信号处理和机器学习中的多模态数据分析提供了实用工具。

Abstract: Mixture distributions are a workhorse model for multimodal data in information theory, signal processing, and machine learning. Yet even when each component density is simple, the differential entropy of the mixture is notoriously hard to compute because the mixture couples a logarithm with a sum. This paper develops a deterministic, closed-form toolkit for bounding and accurately approximating mixture entropy directly from component parameters. Our starting point is an information-theoretic channel viewpoint: the latent mixture label plays the role of an input, and the observation is the output. This viewpoint separates mixture entropy into an average within-component uncertainty plus an overlap term that quantifies how much the observation reveals about the hidden label. We then bound and approximate this overlap term using pairwise overlap integrals between component densities, yielding explicit expressions whenever these overlaps admit a closed form. A simple, family-dependent offset corrects the systematic bias of the Jensen overlap bound and is calibrated to be exact in the two limiting regimes of complete overlap and near-perfect separation. A final clipping step guarantees that the estimate always respects universal information-theoretic bounds. Closed-form specializations are provided for Gaussian, factorized Laplacian, uniform, and hybrid mixtures, and numerical experiments validate the resulting bounds and approximations across separation, dimension, number of components, and correlated covariances.

</details>


### [4] [Corrected-Inverse-Gaussian First-Hitting-Time Modeling for Molecular Communication Under Time-Varying Drift](https://arxiv.org/abs/2602.15335)
*Yen-Chi Lee*

Main category: cs.IT

TL;DR: 该论文提出了一种针对时变漂移条件下首次命中时间分子通信系统的可处理分析信道模型，通过修正逆高斯分布扩展经典模型以处理强非平稳漂移条件。


<details>
  <summary>Details</summary>
Motivation: 现有非平稳传输研究主要依赖数值解或参数拟合，缺乏对吸收边界轨迹级到达动力学的闭式描述，需要为动态生物和分子通信环境提供物理信息化的计算高效信道模型。

Method: 采用测度变换公式，将首次命中时间密度结构分解为累积漂移位移项和随机边界通量调制因子，推导出修正逆高斯密度的显式解析表达式。

Result: 高精度蒙特卡洛模拟验证了该模型能准确捕捉复杂传输现象，包括相位调制、多脉冲色散和瞬态回流，在平滑脉冲和突变切换漂移剖面下均表现良好。

Conclusion: 该框架提供了物理信息化的计算高效信道模型，适用于动态生物和分子通信环境中的系统级分析和接收器设计，扩展了经典逆高斯模型的应用范围。

Abstract: This paper develops a tractable analytical channel model for first-hitting-time molecular communication systems under time-varying drift. While existing studies of nonstationary transport rely primarily on numerical solutions of advection--diffusion equations or parametric impulse-response fitting, they do not provide a closed-form description of trajectory-level arrival dynamics at absorbing boundaries. By adopting a change-of-measure formulation, we reveal a structural decomposition of the first-hitting-time density into a cumulative-drift displacement term and a stochastic boundary-flux modulation factor. This leads to an explicit analytical expression for the Corrected-Inverse-Gaussian (C-IG) density, extending the classical IG model to strongly nonstationary drift conditions while preserving constant-complexity evaluation. High-precision Monte Carlo simulations under both smooth pulsatile and abrupt switching drift profiles confirm that the proposed model accurately captures complex transport phenomena, including phase modulation, multi-pulse dispersion, and transient backflow. The resulting framework provides a physics-informed, computationally efficient channel model suitable for system-level analysis and receiver design in dynamic biological and molecular communication environments.

</details>


### [5] [A Universal Neural Receiver that Learns at the Speed of Wireless](https://arxiv.org/abs/2602.15458)
*Lingjia Liu,Lizhong Zheng,Yang Yi,Robert Calderbank*

Main category: cs.IT

TL;DR: 提出基于卷积的通用神经接收机架构，无需离线训练即可适应快速变化的无线环境，旨在简化标准讨论并加速无线创新


<details>
  <summary>Details</summary>
Motivation: 传统基于数学模型的无线网络设计方法在复杂网络环境中逐渐失效，运营商希望通过AI提升频谱效率、减少信令开销，但现有AI算法依赖离线训练，无法适应无线干扰环境的毫秒级变化

Method: 设计基于卷积的通用神经接收机架构，将卷积反演问题分离为"反演哪个卷积"和"实际反卷积"两部分。神经网络执行反卷积操作，通过基于领域知识设置权重来配置网络，避免大量离线训练

Result: 提出了一种能够处理任何无线频谱信号的通用接收机架构，该架构简单且不依赖离线训练，能够适应快速变化的无线环境

Conclusion: 通用神经接收机架构可简化国际标准中关于波形选择的讨论，由于接收机架构基本独立于基站引入的技术，有望加速无线领域的创新速度

Abstract: Today we design wireless networks using mathematical models that govern communication in different propagation environments. We rely on measurement campaigns to deliver parametrized propagation models, and on the 3GPP standards process to optimize model-based performance, but as wireless networks become more complex this model-based approach is losing ground. Mobile Network Operators (MNOs) are counting on Artificial Intelligence (AI) to transform wireless by increasing spectral efficiency, reducing signaling overhead, and enabling continuous network innovation through software upgrades. They may also be interested in new use cases like integrated sensing and communications (ISAC). All we need is an AI-native physical layer, so why not simply tailor the offline AI algorithms that have revolutionized image and natural language processing to the wireless domain? We argue that these algorithms rely on off-line training that is precluded by the sub-millisecond speeds at which the wireless interference environment changes. We present an alternative architecture, a universal neural receiver based on convolution, which governs transmit and receive signal processing of any signal in any part of the wireless spectrum. Our neural receiver is designed to invert convolution, and we separate the question of which convolution to invert from the actual deconvolution. The neural network that performs deconvolution is very simple, and we configure this network by setting weights based on domain knowledge. By telling our neural network what we know, we avoid extensive offline training. By developing a universal receiver, we hope to simplify discussions about the proper choice of waveform for different use cases in the international standards. Since the receiver architecture is largely independent of technologies introduced at the base station, we hope to increase the rate of innovation in wireless.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [6] [Transforming Computational Lithography with AC and AI -- Faster, More Accurate, and Energy-efficient](https://arxiv.org/abs/2602.15036)
*Saumyadip Mukhopadhyay,Kiho Yang,Kasyap Thottasserymana Vasudevan,Mounica Jyothi Divvela,Selim Dogru,Dilip Krishnamurthy,Fergo Treska,Werner Gillijns,Ryan Ryoung han Kim,Kumara Sastry,Vivek Singh*

Main category: eess.SP

TL;DR: NVIDIA cuLitho利用加速计算和AI技术，为计算光刻带来57倍端到端加速，实现更好的工艺窗口和边缘放置误差


<details>
  <summary>Details</summary>
Motivation: 科学计算需求激增远超晶体管缩放速度，导致成本、能耗和排放不可持续增长。计算光刻作为半导体制造最大工作负载，在埃米时代变得异常复杂，需要更准确建模和更广泛解决方案探索。

Method: 重新设计软件栈，重构计算光刻核心原语（衍射光学、计算几何、多变量优化、数据处理），结合加速计算和AI作为计算密集型步骤的高保真替代方案。

Result: 实现57倍端到端加速，在IMEC的硅实验显示相比传统方法：工艺窗口提升35%，边缘放置误差改善19%。首次在芯片尺度量化展示加速计算和AI的光刻优势。

Conclusion: 加速计算和AI共同构成科学工作负载的可持续下一代计算平台，cuLitho为计算光刻带来变革性加速，同时支持更严格的解决方案如曲线掩模、高数值孔径EUV光刻和亚原子建模。

Abstract: From climate science to drug discovery, scientific computing demands have surged dramatically in recent years -- driven by larger datasets, more sophisticated models, and higher simulation fidelity. This growth rate far outpaces transistor scaling, leading to unsustainably rising costs, energy consumption, and emissions. Semiconductor manufacturing is no exception. Computational lithography -- involving transferring circuitry to silicon in diffraction-limited conditions -- is the largest workload in semiconductor manufacturing. It has also grown exceptionally complex as miniaturization has advanced in the angstrom-era, requiring more accurate modeling, intricate corrections, and broader solution-space exploration. Accelerated computing (AC) offers a solution by dramatically freeing up the compute and power envelope. AI augments these gains by serving as high-fidelity surrogates for compute-intensive steps. Together, they present a sustainable, next-generation computing platform for scientific workloads. This new paradigm needs a fundamental redesign of the software stack. For computational lithography, NVIDIA cuLitho reinvents the core primitives -- diffractive optics, computational geometry, multi-variant optimization, data processing -- to achieve a transformative 57X end-to-end acceleration. Beyond dramatically faster cycles, this expanded compute envelope enables more rigorous solutions, including curvilinear masks, high-numerical aperture extreme ultraviolet (high-NA EUV) lithography, and subatomic modeling. We reinvest a small fraction of the freed-up compute to include through-focus correction for better process resilience. Silicon experiments at IMEC show significant benefits compared to conventional methods -- 35% better process window and 19% better edge placement error. This is the first quantified chip-scale demonstration of the lithography benefits of AC and AI in silicon.

</details>


### [7] [Combining scEEG and PPG for reliable sleep staging using lightweight wearables](https://arxiv.org/abs/2602.15042)
*Jiawei Wang,Liang Xu,Shuntian Zheng,Yu Guan,Kaichen Wang,Ziqing Zhang,Chen Chen,Laurence T. Yang,Sai Gu*

Main category: eess.SP

TL;DR: 研究单通道脑电图与光电容积描记融合的短窗口睡眠分期方法，通过Mamba增强融合策略显著提升轻睡眠分类性能


<details>
  <summary>Details</summary>
Motivation: 现有轻量可穿戴设备（单通道脑电图或光电容积描记）在睡眠分期上存在局限：单通道脑电图对轻睡眠阶段性能有限，光电容积描记需要整夜记录作为输入，不适用于实时睡眠干预反馈

Method: 1. 评估各模态所需的时间上下文；2. 研究三种融合策略：分数级融合、跨注意力特征级融合、Mamba增强融合（包含时间上下文建模）；3. 在MESA数据集上训练评估，并在CFS和ABC数据集上进行跨数据集验证

Result: Mamba增强融合在MESA数据集上表现最佳（Cohen's Kappa κ = 0.798，准确率86.9%），在轻睡眠分类上提升显著（F1分数：85.63% vs 77.76%，召回率：82.85% vs 69.95%），在CFS和ABC数据集上泛化良好

Conclusion: 单通道脑电图与光电容积描记融合是轻量可穿戴睡眠监测的有前景方法，为更易获得的睡眠健康评估提供了途径

Abstract: Reliable sleep staging remains challenging for lightweight wearable devices such as single-channel electroencephalography (scEEG) or photoplethysmography (PPG). scEEG offers direct measurement of cortical activity and serves as the foundation for sleep staging, yet exhibits limited performance on light sleep stages. PPG provides a low-cost complement that captures autonomic signatures effective for detecting light sleep. However, prior PPG-based methods rely on full night recordings (8 - 10 hours) as input context, which is less practical to provide timely feedback for sleep intervention. In this work, we investigate scEEG-PPG fusion for 4-class sleep staging under short-window (30 s - 30 min) constraints. First, we evaluate the temporal context required for each modality, to better understand the relationship of sleep staging performance with respect to monitoring window. Second, we investigate three fusion strategies: score-level fusion, cross-attention fusion enabling feature-level interactions, and Mamba-enhanced fusion incorporating temporal context modeling. Third, we train and evaluate on the Multi-Ethnic Study of Atherosclerosis (MESA) dataset and perform cross-dataset validation on the Cleveland Family Study (CFS) and the Apnea, Bariatric surgery, and CPAP (ABC) datasets. The Mamba-enhanced fusion achieves the best performance on MESA (Cohen's Kappa $κ$ = 0.798, Acc = 86.9%), with particularly notable improvement in light sleep classification (F1-score: 85.63% vs. 77.76%, recall: 82.85% vs. 69.95% for scEEG alone), and generalizes well to CFS and ABC datasets with different populations. These findings suggest that scEEG-PPG fusion is a promising approach for lightweight wearable based sleep monitoring, offering a pathway toward more accessible sleep health assessment. Source code of this project can be found at: https://github.com/DavyWJW/scEEG-PPGFusion

</details>


### [8] [Secure High-Resolution ISAC via Multi-Layer Intelligent Metasurfaces: A Layered Optimization Framework](https://arxiv.org/abs/2602.15209)
*Amirhossein Taherpour,Abbas Taherpour,Tamer Khattab*

Main category: eess.SP

TL;DR: 本文提出了一种基于堆叠智能超表面(SIM)的集成感知与通信(ISAC)系统，通过分层优化框架同时提升通信安全性和感知精度，相比传统方法在感知精度和保密速率方面均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC系统在实现高分辨率感知的同时，难以兼顾通信安全和频谱效率，存在根本性限制。需要一种新的技术方案来克服这些挑战。

Method: 采用堆叠智能超表面(SIM)辅助的多功能系统，提出分层优化框架，通过多目标优化公式平衡保密速率最大化和感知误差最小化，使用分层块坐标下降算法协调感知配置、安全波束成形、通信超表面优化和资源分配。

Result: 仿真结果显示，相比传统方法，感知精度提升32-61%，保密速率提升15-35%，同时保持计算效率。

Conclusion: 这项工作为安全和精确的多功能无线系统建立了新范式，证明了SIM在提升ISAC系统性能方面的巨大潜力。

Abstract: Integrated sensing and communication (ISAC) has emerged as a pivotal technology for next-generation wireless networks, enabling simultaneous data transmission and environmental sensing. However, existing ISAC systems face fundamental limitations in achieving high-resolution sensing while maintaining robust communication security and spectral efficiency. This paper introduces a transformative approach leveraging stacked intelligent metasurfaces (SIM) to overcome these challenges. We propose a multi-functional SIM-assisted system that jointly optimizes communication secrecy and sensing accuracy through a novel layered optimization framework. Our solution employs a multi-objective optimization formulation that balances secrecy rate maximization with sensing error minimization under practical hardware constraints. The proposed layered block coordinate descent algorithm efficiently coordinates sensing configuration, secure beamforming, communication metasurface optimization, and resource allocation while ensuring robustness to channel uncertainties. Extensive simulations demonstrate significant performance gains over conventional approaches, achieving 32-61\% improvement in sensing accuracy and 15-35\% enhancement in secrecy rates while maintaining computational efficiency. This work establishes a new paradigm for secure and high-precision multi-functional wireless systems.

</details>


### [9] [Large elements and advanced beamformers for increased field of view in 2-D ultrasound matrix arrays](https://arxiv.org/abs/2602.15174)
*Mick Gardner,Michael L. Oelze*

Main category: eess.SP

TL;DR: 通过增大阵元尺寸并使用先进波束形成器，在保持图像质量的同时扩大3D超声矩阵阵列的视野范围，NSI波束形成器表现最佳


<details>
  <summary>Details</summary>
Motivation: 3D超声在腹部、产科和心血管成像中有广泛应用前景，但超声矩阵阵列的阵元数量极高，限制了其视野范围。本研究旨在通过减少阵元数量的阵列设计来扩大视野

Method: 采用增大阵元尺寸并使用先进波束形成器（DAS、NSI、DCF、MV）来保持图像质量。通过K-wave模拟3D点扩散函数，并在Verasonics 256系统上使用多路复用的1024阵元矩阵阵列进行实验，通过电子耦合阵元模拟更大间距和阵元尺寸，并使用定位系统创建虚拟大孔径

Result: 耦合因子为2时获得高质量图像，视野范围翻倍，同时保持与原始矩阵阵列相同的阵元数量。NSI波束形成器在模拟和大孔径实验中表现最佳分辨率，在耦合因子高达4时仍能保持与未耦合DAS相同的分辨率

Conclusion: 研究结果表明，可以通过使用更大阵元构建更大的矩阵阵列，并通过先进波束形成器保持分辨率，为3D超声成像提供更广阔的视野范围

Abstract: Three-dimensional (3D) ultrasound promises various medical applications for abdominal, obstetrics, and cardiovascular imaging. However, ultrasound matrix arrays have extremely high element counts limiting their field of view (FOV). This work seeks to demonstrate an increased field-of-view using a reduced element count array design. The approach is to increase the element size and use advanced beamformers to maintain image quality. The delay and sum (DAS), Null Subtraction Imaging (NSI), directional coherence factor (DCF), and Minimum Variance (MV) beamformers were compared. K-wave simulations of the 3D point-spread functions (PSF) of NSI, DCF, and MV display reduced side lobes and narrowed main lobes compared to DAS. Experiments were conducted using a multiplexed 1024-element matrix array on a Verasonics 256 system. Elements were electronically coupled to imitate a larger pitch and element size. Then, a virtual large aperture was created by using a positioning system to collect data in sections with the matrix array. High-quality images were obtained using a coupling factor of two, doubling the FOV while maintaining the same element count in the virtual large aperture as the original matrix array. The NSI beamformer demonstrated the best resolution performance in simulations and on the large aperture, maintaining the same resolution as uncoupled DAS for coupling factors up to 4. Our results demonstrate how larger matrix arrays could be constructed with larger elements, with resolution maintained by advanced beamformers.

</details>


### [10] [Multiplierless DFT Approximation Based on the Prime Factor Algorithm](https://arxiv.org/abs/2602.15218)
*L. Portella,F. M. Bayer,R. J. Cintra*

Main category: eess.SP

TL;DR: 提出基于小素数点DFT近似的完全无乘法器DFT近似方法，消除了中间乘法步骤和误差传播，设计了1023点DFT近似并优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有DFT近似方法通常在小2的幂次块长度（如8,16,32）或大块长度（如1024）上工作，但基于Cooley-Tukey的近似方法继承了中间旋转因子乘法，这些因子通常不被近似，否则误差传播会影响整体性能。需要一种能够完全消除中间乘法步骤的方法。

Method: 提出基于素数因子算法的DFT近似框架，使用小素数点（3、11、31点）DFT近似来构建完全无乘法器的DFT近似。该方法消除了中间乘法步骤，防止了内部误差传播。具体设计了基于3点、11点和31点DFT近似的1023点DFT近似。

Result: 提出的1023点DFT近似不仅具有显著更低的算术复杂度，而且与竞争方法相比，产生了更小的近似误差测量值。

Conclusion: 素数因子算法为推导完全无乘法器的DFT近似提供了必要框架，基于小素数点DFT近似的方法能够有效消除中间乘法步骤并防止误差传播，在性能和复杂度方面均优于现有方法。

Abstract: Matrix approximation methods have successfully produced efficient, low-complexity approximate transforms for the discrete cosine transforms and the discrete Fourier transforms. For the DFT case, literature archives approximations operating at small power-of-two blocklenghts, such as \{8, 16, 32\}, or at large blocklengths, such as 1024, which are obtained by means of the Cooley-Tukey-based approximation relying on the small-blocklength approximate transforms. Cooley-Tukey-based approximations inherit the intermediate multiplications by twiddled factors which are usually not approximated; otherwise the effected error propagation would prevent the overall good performance of the approximation. In this context, the prime factor algorithm can furnish the necessary framework for deriving fully multiplierless DFT approximations. We introduced an approximation method based on small prime-sized DFT approximations which entirely eliminates intermediate multiplication steps and prevents internal error propagation. To demonstrate the proposed method, we design a fully multiplierless 1023-point DFT approximation based on 3-, 11- and 31-point DFT approximations. The performance evaluation according to popular metrics showed that the proposed approximations not only presented a significantly lower arithmetic complexity but also resulted in smaller approximation error measurements when compared to competing methods.

</details>


### [11] [SCENE OTA-FD: Self-Centering Noncoherent Estimator for Over-the-Air Federated Distillation](https://arxiv.org/abs/2602.15326)
*Hao Chen,Zavareh Bozorgasl*

Main category: eess.SP

TL;DR: SCENE是一种用于空中联邦蒸馏的无导频、相位不变的聚合原语，通过非相干能量估计实现无偏软标签平均，适用于短相干时间和硬件受限场景。


<details>
  <summary>Details</summary>
Motivation: 针对空中联邦蒸馏中需要每轮信道状态信息的问题，特别是在短相干时间和硬件受限场景下，避免导频开销至关重要。现有相干设计需要大量导频，限制了系统效率。

Method: 设备将软标签向量映射到非负发射能量，采用恒定每轮功率和恒定包络信号。服务器使用自中心能量估计器去除噪声能量偏移，获得无偏的加权软标签平均估计。还开发了无导频比率归一化变体来消除未知大尺度增益。

Result: SCENE的估计方差随接收天线数M和重复因子S按1/(SM)衰减。提供了与相干OTA-FD分析一致的收敛边界，并通过开销比较显示在导频开销不可忽略时能超越相干设计。

Conclusion: SCENE以适度的非相干方差常数为代价，实现了零上行导频、无偏聚合和硬件友好传输，特别适用于需要避免每轮CSI的短相干时间和硬件受限场景。

Abstract: We propose SCENE (Self-Centering Noncoherent Estimator), a pilot-free and phase-invariant aggregation primitive for over-the-air federated distillation (OTA-FD). Each device maps its soft-label (class-probability) vector to nonnegative transmit energies under constant per-round power and constant-envelope signaling (PAPR near 1). At the server, a self-centering energy estimator removes the noise-energy offset and yields an unbiased estimate of the weighted soft-label average, with variance decaying on the order of 1/(SM) in the number of receive antennas M and repetition factor S. We also develop a pilot-free ratio-normalized variant that cancels unknown large-scale gains, provide a convergence bound consistent with coherent OTA-FD analyses, and present an overhead-based crossover comparison. SCENE targets short-coherence and hardware-constrained regimes, where avoiding per-round CSI is essential: it trades a modest noncoherent variance constant for zero uplink pilots, unbiased aggregation, and hardware-friendly transmission, and can outperform coherent designs when pilot overhead is non-negligible.

</details>


### [12] [Adaptive Selection of Codebook Using Assistance Information and Artificial Intelligence for 6G Systems](https://arxiv.org/abs/2602.15530)
*Denis Esiunin,Alexei Davydov*

Main category: eess.SP

TL;DR: 提出基于神经网络的自适应码本选择方案，通过UE辅助的统计信道信息来优化下行预编码量化，在保持系统吞吐量的同时减少CSI开销


<details>
  <summary>Details</summary>
Motivation: 预编码量化的准确性依赖于传播条件，需要为每个用户设备独立调整参数。传统方法难以根据信道特性自适应选择最优码本，导致CSI报告开销大或性能下降

Method: 提出基站端UE辅助的码本选择方案：UE报告时域、频域和空域的统计信道特性，作为神经网络输入；神经网络预测不同码本类型的量化精度；综合考虑CSI报告开销和预编码性能选择最优码本

Result: 系统级仿真表明，所提方法在保持目标系统吞吐量性能的同时，显著减少了总CSI开销

Conclusion: 基于神经网络的UE辅助码本选择方案能够有效优化下行预编码量化，实现CSI开销与系统性能的良好平衡，为自适应CSI报告提供了有效解决方案

Abstract: This paper addresses the problem of adaptive codebook (CB) selection for downlink (DL) precoder quantization in channel state information (CSI) reporting. The accuracy of precoder quantization depends on propagation conditions, requiring independent parameter adaptation for each user equipment (UE). To enable optimal CB selection, this paper proposes UE-assisted CB selection at the base station (BS) using reported by the UE statistical channel properties across time, frequency, and spatial domains. The reported assistance information serves as input to a neural network (NN), which predicts the quantization accuracy of various CB types for each served user. The predicted accuracy is then used to select the optimal CB while considering the associated CSI reporting overhead and precoding performance. System-level simulations demonstrate that the proposed approach reduces total CSI overhead while maintaining the target system throughput performance.

</details>


### [13] [Waveform Design for ISAC System: A Consensus ADMM Approach](https://arxiv.org/abs/2602.15544)
*Ngoc-Son Duong,Huyen-Trang Ta,Quang-Tang Ngo,Thi-Hue Duong,Van-Lap Nguyen,Cong-Minh Nguyen,Minh-Tran Nguyen,Thai-Mai Dinh*

Main category: eess.SP

TL;DR: 提出一种用于多用户下行链路ISAC系统的联合发射波形和接收滤波器设计方法，在恒定模和相似性约束下平衡通信和感知性能


<details>
  <summary>Details</summary>
Motivation: 在集成感知与通信系统中，需要在通信和感知性能之间取得平衡，同时满足实际约束条件如恒定模和相似性约束

Method: 使用共识交替方向乘子法框架，交替更新发射波形和雷达滤波器，处理非凸的感知SINR分数形式

Result: 仿真结果表明，相比现有基准方案，所提方法在通信总速率和感知SINR之间实现了更好的权衡

Conclusion: 提出的基于共识ADMM的算法能有效解决ISAC系统在实用约束下的联合设计问题，实现通信与感知性能的良好折衷

Abstract: We study joint transmit-waveform and receive-filter design for a multi-user downlink integrated sensing and communication (ISAC) system under practical constant-modulus and similarity constraints. We cast the design as a unified multi-objective program that balances communication sum rate and sensing signal-to-interference-plus-noise ratio (SINR). To address this, we introduce an efficient algorithm that use consensus alternating direction method of multipliers (ADMM) framework to alternately update the transmit waveform and radar filter. The proposed method effectively handles the non-convex fractional sensing's SINR formulation and ensures fast convergence. Simulation results demonstrate that the proposed approach achieves better trade-offs between communication sum rate and sensing's SINR compared to existing benchmark schemes.

</details>


### [14] [Tracking Time-Varying Multipath Channels forActive Sonar Applications](https://arxiv.org/abs/2602.15555)
*Ashwani Koul,Gustaf Hendeby,Isaac Skog*

Main category: eess.SP

TL;DR: 提出直接在原始测量域学习和跟踪多径背景的框架，通过状态空间模型和扩展卡尔曼滤波实现信道跟踪，集成到目标检测的序贯似然比检验中


<details>
  <summary>Details</summary>
Motivation: 传统方法在距离-多普勒域进行背景学习计算成本高，且可能掩盖对监测和跟踪有用的相位相干结构。需要在时变浅水环境中实现更可靠的目标检测

Method: 从宽带多普勒线性化的时变多径信道冲激响应出发，推导具有异方差测量方程的状态空间模型，使用扩展卡尔曼滤波进行信道跟踪，通过边缘化似然学习未知参数

Result: 基于BELLHOP的仿真表明，所提模型能更好地捕捉海面波动和收发器漂移引起的信道动态，在时变浅水环境中实现更可靠的检测

Conclusion: 直接在原始测量域学习和跟踪多径背景的框架比传统方法更有效，能更好地建模信道动态并提高目标检测的可靠性

Abstract: Reliable detection and tracking in active sonar require accurate and efficient learning of the acoustic multipath background environment. Conventionally, background learning is performed after transforming measurements into the range-Doppler domain, a step that is computationally expensive and can obscure phase-coherent structure useful for monitoring and tracking. This paper proposes a framework for learning and tracking the multipath background directly in the raw measurement domain. Starting from a wideband Doppler linearization of the impulse response of a time-varying multipath channel, a state-space model with a heteroscedastic measurement equation is derived. This model enables channel tracking using an extended Kalman filter (EKF), and unknown model parameters are learned from the marginalized likelihood. The statistical adequacy of the proposed models is assessed via a p-value significance test. Finally, this paper integrates the learned channel model into a sequential likelihood-ratio test for target detection. BELLHOP-based simulations show that the proposed model better captures channel dynamics induced by sea-surface fluctuations and transmitter and receiver drift, yielding more reliable detection in time-varying shallow-water environments

</details>


### [15] [Physics-Informed Anomaly Detection of Terrain Material Change in Radar Imagery](https://arxiv.org/abs/2602.15618)
*Abdel Hakiem Mohamed Abbas Mohamed Ahmed,Beth Jelfs,Airlie Chapman,Eric Schoof,Christopher Gilliam*

Main category: eess.SP

TL;DR: 提出基于物理的雷达图像地形材料变化检测方法，通过电磁前向模型生成双时相SLC图像，结合相干性和鲁棒协方差特征，在重尾杂波中实现材料变化的异常检测。


<details>
  <summary>Details</summary>
Motivation: 传统雷达图像变化检测主要关注几何变化，而忽略材料属性（介电常数、粗糙度、湿度）的变化。需要开发能够检测这些物理属性变化的轻量级方法。

Method: 1) 构建轻量级电磁前向模型模拟双时相单视复图像；2) 提取物理感知特征堆栈（包括干涉相干性）；3) 评估多种无监督检测器：RX/Local-RX（使用Tyler's M估计器）、相干变化检测(CCD)、紧凑卷积自编码器；4) 通过蒙特卡洛实验分析不同参数下的性能。

Result: 实验表明：相干性和鲁棒协方差显著改善材料变化的异常检测性能；在重尾杂波环境中，简单的分数级融合方法获得最佳F1分数。

Conclusion: 基于物理的雷达图像分析方法能够有效检测地形材料变化，相干性和鲁棒统计特征在重尾杂波条件下表现优异，为实际应用提供了有前景的解决方案。

Abstract: In this paper we consider physics-informed detection of terrain material change in radar imagery (e.g., shifts in permittivity, roughness or moisture). We propose a lightweight electromagnetic (EM) forward model to simulate bi-temporal single-look complex (SLC) images from labelled material maps. On these data, we derive physics-aware feature stacks that include interferometric coherence, and evaluate unsupervised detectors: Reed-Xiaoli (RX)/Local-RX with robust scatter (Tyler's M-estimator), Coherent Change Detection (CCD), and a compact convolutional auto-encoder. Monte Carlo experiments sweep dielectric/roughness/moisture changes, number of looks and clutter regimes (gamma vs K-family) at fixed probability of false alarm. Results on synthetic but physically grounded scenes show that coherence and robust covariance markedly improve anomaly detection of material changes; a simple score-level fusion achieves the best F1 in heavy-tailed clutter.

</details>


### [16] [Passive Imaging with Ambient Noise Under Wave Speed Mismatch: Mathematical Analysis and Wave Speed Estimation](https://arxiv.org/abs/2602.15623)
*Zetao Fei,Josselin Garnier*

Main category: eess.SP

TL;DR: 提出了一种基于被动相关成像的波速估计方法，利用环境噪声源和传感器阵列，通过引入搜索波速分析迁移函数，在均匀和随机介质中都能有效估计真实波速。


<details>
  <summary>Details</summary>
Motivation: 被动成像中，从部分边界测量重建介质反射率是一个挑战性问题，特别是在背景波速未知的情况下。本文旨在解决在日光配置（环境噪声源照射介质，传感器阵列记录环境场）下的被动相关成像中的波速估计问题。

Method: 1. 首先分析均匀背景中嵌入点反射器的日光迁移，通过引入搜索波速到迁移函数中，推导波速不匹配引起的确定性偏移和散焦效应的显式表征。2. 扩展到相关长度小于波长的随机介质，利用均匀情况得到的偏移公式，引入在迁移过程中保持固定的虚拟导星，基于虚拟导星周围的空间平均实现有效的波速估计。

Result: 1. 证明了迁移函数包络的最大值提供了真实波速的可靠估计器。2. 为均匀和随机介质建立了所提波速估计器的分辨率分析。3. 通过数值实验验证了理论结果的有效性。

Conclusion: 本文提出了一种在被动相关成像中估计未知背景波速的有效方法，通过分析迁移函数对波速不匹配的响应，在均匀和随机介质中都能实现可靠的波速估计，为被动成像中的介质参数反演提供了新思路。

Abstract: It is known that waves generated by ambient noise sources and recorded by passive receivers can be used to image the reflectivities of an unknown medium. However, reconstructing the reflectivity of the medium from partial boundary measurements remains a challenging problem, particularly when the background wave speed is unknown. In this paper, we investigate passive correlation-based imaging in the daylight configuration, where uncontrolled noise sources illuminate the medium and only ambient fields are recorded by a sensor array. We first analyze daylight migration for a point reflector embedded in a homogeneous background. By introducing a searching wave speed into the migration functional, we derive an explicit characterization of the deterministic shift and defocusing effects induced by wave-speed mismatch. We show that the maximum of the envelope of the resulting functional provides a reliable estimator of the true wave speed. We then extend the analysis to a random medium with correlation length smaller than the wavelength. Leveraging the shift formula obtained in the homogeneous case, we introduce a virtual guide star that remains fixed under migration with different searching speeds. This property enables an effective wave-speed estimation strategy based on spatial averaging around the virtual guide star. For both homogeneous and random media, we establish resolution analyses for the proposed wave-speed estimators. Numerical experiments are conducted to validate the theoretical result.

</details>


### [17] [Latency-aware Human-in-the-Loop Reinforcement Learning for Semantic Communications](https://arxiv.org/abs/2602.15640)
*Peizheng Li,Xinyi Lin,Adnan Aijaz*

Main category: eess.SP

TL;DR: 提出TC-HITL-RL框架，结合人类反馈和语义效用，在语义感知Open RAN架构中实现延迟约束下的语义通信优化。


<details>
  <summary>Details</summary>
Motivation: 语义通信需要在保证语义保真度的同时满足沉浸式和关键安全服务的严格延迟要求，需要解决语义适应与延迟控制之间的平衡问题。

Method: 提出时间约束的人机协同强化学习框架，将人类反馈驱动的语义适应建模为约束马尔可夫决策过程，采用原始-对偶近端策略优化算法，结合动作屏蔽和延迟感知奖励塑造。

Result: 在具有异构截止时间的点对多点链路仿真中，TC-HITL-RL始终满足每个用户的时序约束，在奖励方面优于基线调度器，并稳定资源消耗。

Conclusion: 该框架为延迟感知的语义适应提供了实用蓝图，能够在语义感知Open RAN架构中有效平衡语义质量和延迟要求。

Abstract: Semantic communication promises task-aligned transmission but must reconcile semantic fidelity with stringent latency guarantees in immersive and safety-critical services. This paper introduces a time-constrained human-in-the-loop reinforcement learning (TC-HITL-RL) framework that embeds human feedback, semantic utility, and latency control within a semantic-aware Open radio access network (RAN) architecture. We formulate semantic adaptation driven by human feedback as a constrained Markov decision process (CMDP) whose state captures semantic quality, human preferences, queue slack, and channel dynamics, and solve it via a primal--dual proximal policy optimization algorithm with action shielding and latency-aware reward shaping. The resulting policy preserves PPO-level semantic rewards while tightening the variability of both air-interface and near-real-time RAN intelligent controller processing budgets. Simulations over point-to-multipoint links with heterogeneous deadlines show that TC-HITL-RL consistently meets per-user timing constraints, outperforms baseline schedulers in reward, and stabilizes resource consumption, providing a practical blueprint for latency-aware semantic adaptation.

</details>


### [18] [NYUSIM: A Roadmap to AI-Enabled Statistical Channel Modeling and Simulation](https://arxiv.org/abs/2602.15737)
*Isha Jariwala,Xinquan Wang,Bridget Meier,Guanyue Qian,Dipankar Shakya,Mingjun Ying,Homa Nikbakht,Daniel Abraham,Theodore S. Rappaport*

Main category: eess.SP

TL;DR: NYUSIM从MATLAB迁移到Python，增强了无线信道建模的可扩展性，支持6G研究，并集成了AI工作流程


<details>
  <summary>Details</summary>
Motivation: 将AI集成到无线信道建模需要大量准确且物理一致的真实测量数据集。现有的NYUSIM框架基于MATLAB，需要迁移到Python以提升可扩展性，支持6G研究，并更好地与AI工作流程集成。

Method: 将完整的NYUSIM框架从MATLAB迁移到Python，并整合新的统计模型生成能力（基于6.75 GHz和16.95 GHz的现场测量）。引入Ant3D 3D天线数据格式，通过Kolmogorov-Smirnov测试、矩分析和端到端测试进行严格验证。

Result: 成功迁移并验证了NYUSIM Python版本，保持了与MATLAB v4.0的统计一致性，能够再现时空信道统计特性。新版本支持大规模并行数据生成，并与现代AI工作流程集成。

Conclusion: NYUSIM Python版本为未来AI驱动的信道建模建立了稳健、可验证且可扩展的基础，支持6G研究和大规模AI应用。

Abstract: Integrating artificial intelligence (AI) into wireless channel modeling requires large, accurate, and physically consistent datasets derived from real measurements. Such datasets are essential for training and validating models that learn spatio-temporal channel behavior across frequencies and environments. NYUSIM, introduced by NYU WIRELESS in 2016, generates realistic spatio-temporal channel data using extensive outdoor and indoor measurements between 28 and 142 GHz. To improve scalability and support 6G research, we migrated the complete NYUSIM framework from MATLAB to Python, and are incorporating new statistical model generation capabilities from extensive field measurements in the new 6G upper mid-band spectrum at 6.75 GHz (FR1(C)) and 16.95 GHz (FR3) [1]. The NYUSIM Python also incorporates a 3D antenna data format, referred to as Ant3D, which is a standardized, full-sphere format for defining canonical, commercial, or measured antenna patterns for any statistical or site-specific ray tracing modeling tool. Migration from MATLAB to Python was rigorously validated through Kolmogorov-Smirnov (K-S) tests, moment analysis, and end-to-end testing with unified randomness control, confirming statistical consistency and reproduction of spatio-temporal channel statistics, including spatial consistency with the open-source MATLAB NYUSIM v4.0 implementation. The NYUSIM Python version is designed to integrate with modern AI workflows and enable large-scale parallel data generation, establishing a robust, verified, and extensible foundation for future AI-enabled channel modeling.

</details>


### [19] [Measurement-Based Validation of Geometry-Driven RIS Beam Steering in Industrial Environments](https://arxiv.org/abs/2602.15808)
*Adam Umra,Simon Tewes,Niklas Beckmann,Niels König,Aydin Sezgin,Robert Schmitt*

Main category: eess.SP

TL;DR: 该论文通过实验验证了在工业大厅环境中几何驱动RIS波束赋形的可行性，展示了空间选择性聚焦能力，支持其在非理想传播条件下的应用。


<details>
  <summary>Details</summary>
Motivation: 可重构智能表面(RIS)为未来无线系统提供可编程的无线电传播控制。几何驱动的分析方法因其简单性和实时操作而具有吸引力，但它们在具有密集多径和金属散射的工业大厅等挑战性环境中的性能尚未得到充分验证。

Method: 提出了一种新颖的RIS配置，在RIS前方近距离安装四个贴片天线来引导入射场并实现可控反射。使用5 GHz RIS原型在大型工业大厅进行测量评估，实现分析计算和量化配置，生成二维接收功率图。

Result: 测量结果显示了一致的空间选择性聚焦：在接收器附近优化的配置产生清晰的功率最大值，而转向偏移位置则触发20-30 dB的快速衰减。随着RIS-接收器距离增加，由于有限孔径和几何约束，仰角选择性变宽，而方位角转向保持稳健。

Conclusion: 这些结果证实了几何驱动RIS波束赋形在工业环境中的实际可行性，支持其在非理想传播条件下用于空间场控制和定位。

Abstract: Reconfigurable intelligent surfaces (RISs) offer programmable control of radio propagation for future wireless systems. For configuration, geometry-driven analytical approaches are appealing for their simplicity and real-time operation, but their performance in challenging environments such as industrial halls with dense multipath and metallic scattering is not well established. To this end, we present a measurement-based evaluation of geometry-driven RIS beam steering in a large industrial hall using a 5 GHz RIS prototype. A novel RIS configuration is proposed in which four patch antennas are mounted in close proximity in front of the RIS to steer the incident field and enable controlled reflection. For this setup, analytically computed, quantized configurations are implemented. Two-dimensional received power maps from two measurement areas reveal consistent, spatially selective focusing. Configurations optimized near the receiver produce clear power maxima, while steering to offset locations triggers a rapid 20-30 dB reduction. With increasing RIS-receiver distance, elevation selectivity broadens due to finite-aperture and geometric constraints, while azimuth steering remains robust. These results confirm the practical viability of geometry-driven RIS beam steering in industrial environments and support its use for spatial field control and localization under non-ideal propagation.

</details>
