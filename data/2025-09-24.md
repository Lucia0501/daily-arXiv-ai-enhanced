<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 60]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Dynamic Prompt Fusion for Multi-Task and Cross-Domain Adaptation in LLMs](https://arxiv.org/abs/2509.18113)
*Xin Hu,Yue Kang,Guanzi Yao,Tianze Kang,Mengjie Wang,Heyao Liu*

Main category: cs.CL

TL;DR: 本文提出了一种统一的多任务学习框架，通过动态提示调度机制解决大语言模型在多任务和跨域设置下的泛化限制问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法如SPoT依赖固定提示模板，存在泛化能力不足的问题。本文旨在开发一种能够动态适应不同任务的统一多任务学习框架。

Method: 引入提示池和任务感知调度策略，通过任务嵌入和门控机制动态组合和对齐不同任务的提示，同时采用联合多任务学习优化目标和自动学习调度权重策略。

Result: 实验结果表明，该方法在语言理解和知识推理任务上显著提升性能，有效维持模型稳定性并增强可迁移性。

Conclusion: 所提出的提示调度方法在统一多任务建模和跨域适应方面具有显著的应用性和有效性。

Abstract: This study addresses the generalization limitations commonly observed in
large language models under multi-task and cross-domain settings. Unlike prior
methods such as SPoT, which depends on fixed prompt templates, our study
introduces a unified multi-task learning framework with dynamic prompt
scheduling mechanism. By introducing a prompt pool and a task-aware scheduling
strategy, the method dynamically combines and aligns prompts for different
tasks. This enhances the model's ability to capture semantic differences across
tasks. During prompt fusion, the model uses task embeddings and a gating
mechanism to finely control the prompt signals. This ensures alignment between
prompt content and task-specific demands. At the same time, it builds flexible
sharing pathways across tasks. In addition, the proposed optimization objective
centers on joint multi-task learning. It incorporates an automatic learning
strategy for scheduling weights, which effectively mitigates task interference
and negative transfer. To evaluate the effectiveness of the method, a series of
sensitivity experiments were conducted. These experiments examined the impact
of prompt temperature parameters and task number variation. The results confirm
the advantages of the proposed mechanism in maintaining model stability and
enhancing transferability. Experimental findings show that the prompt
scheduling method significantly improves performance on a range of language
understanding and knowledge reasoning tasks. These results fully demonstrate
its applicability and effectiveness in unified multi-task modeling and
cross-domain adaptation.

</details>


### [2] [GAUSS: Benchmarking Structured Mathematical Skills for Large Language Models](https://arxiv.org/abs/2509.18122)
*Yue Zhang,Jiaxin Zhang,Qiuyu Ren,Tahsin Saffat,Xiaoxuan Liu,Zitong Yang,Banghua Zhu,Yi Ma*

Main category: cs.CL

TL;DR: GAUSS是一个评估LLMs数学能力的基准测试，涵盖12个核心技能维度，分为三个领域：知识与理解、问题解决与沟通、元技能与创造力。


<details>
  <summary>Details</summary>
Motivation: 通过按认知技能分类问题和设计隔离特定能力的任务，GAUSS构建全面、细粒度且可解释的模型数学能力配置文件，以忠实反映其底层数学智能。

Method: 将数学问题按认知技能分类，设计能够隔离特定能力的任务，从而构建多维度的技能评估框架。

Result: 通过GAUSS基准测试，获得了GPT-5-thinking的技能配置文件，揭示了其优势和弱点以及与o4-mini-high的差异。

Conclusion: 多维度的基于技能的评估方法具有重要价值，能够更全面地理解LLMs的数学能力。

Abstract: We introduce \textbf{GAUSS} (\textbf{G}eneral \textbf{A}ssessment of
\textbf{U}nderlying \textbf{S}tructured \textbf{S}kills in Mathematics), a
benchmark that evaluates LLMs' mathematical abilities across twelve core skill
dimensions, grouped into three domains: knowledge and understanding, problem
solving and communication, and meta-skills and creativity. By categorizing
problems according to cognitive skills and designing tasks that isolate
specific abilities, GAUSS constructs comprehensive, fine-grained, and
interpretable profiles of models' mathematical abilities. These profiles
faithfully represent their underlying mathematical intelligence. To exemplify
how to use the \textsc{GAUSS} benchmark, we have derived the skill profile of
\textsc{GPT-5-thinking}, revealing its strengths and weaknesses as well as its
differences relative to \textsc{o4-mini-high}, thereby underscoring the value
of multidimensional, skill-based evaluation.

</details>


### [3] [Event Causality Identification with Synthetic Control](https://arxiv.org/abs/2509.18156)
*Haoyu Wang,Fengze Liu,Jiayao Zhang,Dan Roth,Kyle Richardson*

Main category: cs.CL

TL;DR: 本文提出了一种基于Rubin因果模型的事件因果关系识别方法，通过将第一个事件视为治疗、第二个事件视为结果，并利用合成控制方法生成'双胞胎'来估计因果效应，在COPES-hard基准测试中表现优于包括GPT-4在内的现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的事件因果关系识别方法主要依赖语言模式和多跳关系推理，容易因因果关系的非正式使用和虚假的图形推理而导致错误识别。需要更稳健的方法来区分因果关系和相关关系。

Method: 采用Rubin因果模型框架，将时序上先发生的事件视为治疗，后发生的事件视为结果。由于无法在文本领域实际实施干预，使用合成控制方法从相关历史数据中生成'双胞胎'，利用文本嵌入合成和反演技术来估计因果效应。

Result: 该方法在因果关系基准测试COPES-hard上表现出色，识别因果关系的鲁棒性优于包括GPT-4在内的先前方法。

Conclusion: 基于Rubin因果模型的合成控制方法为事件因果关系识别提供了更可靠的框架，能够有效避免传统方法中的虚假因果关系识别问题，在复杂场景下表现出优越性能。

Abstract: Event causality identification (ECI), a process that extracts causal
relations between events from text, is crucial for distinguishing causation
from correlation. Traditional approaches to ECI have primarily utilized
linguistic patterns and multi-hop relational inference, risking false causality
identification due to informal usage of causality and specious graphical
inference. In this paper, we adopt the Rubin Causal Model to identify event
causality: given two temporally ordered events, we see the first event as the
treatment and the second one as the observed outcome. Determining their
causality involves manipulating the treatment and estimating the resultant
change in the likelihood of the outcome. Given that it is only possible to
implement manipulation conceptually in the text domain, as a work-around, we
try to find a twin for the protagonist from existing corpora. This twin should
have identical life experiences with the protagonist before the treatment but
undergoes an intervention of treatment. However, the practical difficulty of
locating such a match limits its feasibility. Addressing this issue, we use the
synthetic control method to generate such a twin' from relevant historical
data, leveraging text embedding synthesis and inversion techniques. This
approach allows us to identify causal relations more robustly than previous
methods, including GPT-4, which is demonstrated on a causality benchmark,
COPES-hard.

</details>


### [4] [ZERA: Zero-init Instruction Evolving Refinement Agent - From Zero Instructions to Structured Prompts via Principle-based Optimization](https://arxiv.org/abs/2509.18158)
*Seungyoun Yi,Minsoo Khang,Sungrae Park*

Main category: cs.CL

TL;DR: ZERA是一种自动提示优化框架，通过联合优化系统提示和用户提示，使用结构化评分标准实现快速收敛到高质量提示。


<details>
  <summary>Details</summary>
Motivation: 现有的自动提示优化方法通常只关注用户提示，依赖非结构化反馈，需要大量样本和长迭代周期，导致成本高且脆弱。

Method: ZERA使用八个可泛化的评分标准对提示进行评分，并通过自动推断权重进行结构化批判来修订提示，实现低开销的精炼。

Result: 在五个LLM和九个不同数据集上的实验结果显示，ZERA相比强基线方法取得了持续改进。消融研究验证了各组件对提示构建的有效贡献。

Conclusion: ZERA框架通过联合优化系统提示和用户提示，使用结构化评分方法，能够以最小样本和短迭代周期快速收敛到高质量提示。

Abstract: Automatic Prompt Optimization (APO) improves large language model (LLM)
performance by refining prompts for specific tasks. However, prior APO methods
typically focus only on user prompts, rely on unstructured feedback, and
require large sample sizes and long iteration cycles-making them costly and
brittle. We propose ZERA (Zero-init Instruction Evolving Refinement Agent), a
novel framework that jointly optimizes both system and user prompts through
principled, low-overhead refinement. ZERA scores prompts using eight
generalizable criteria with automatically inferred weights, and revises prompts
based on these structured critiques. This enables fast convergence to
high-quality prompts using minimal examples and short iteration cycles. We
evaluate ZERA across five LLMs and nine diverse datasets spanning reasoning,
summarization, and code generation tasks. Experimental results demonstrate
consistent improvements over strong baselines. Further ablation studies
highlight the contribution of each component to more effective prompt
construction. Our implementation including all prompts is publicly available at
https://github.com/younatics/zera-agent.

</details>


### [5] [Thinking in a Crowd: How Auxiliary Information Shapes LLM Reasoning](https://arxiv.org/abs/2509.18163)
*Haodong Zhao,Chenyan Zhao,Yansi Li,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.CL

TL;DR: 该论文研究了外部信息对具有逐步推理能力的大语言模型的影响，发现思考过程会放大误导信息的负面效果


<details>
  <summary>Details</summary>
Motivation: 在现实场景中，LLMs经常需要处理可能有用、无关甚至误导的外部信息，需要系统评估这些信息对模型推理过程的影响

Method: 创建SciAux数据集（基于ScienceQA），系统测试模型对不同类型辅助信息的鲁棒性，分析思考模式对信息处理的影响

Result: 发现模型的思考模式具有双重性：有帮助的上下文能提高准确性，但误导信息会导致性能灾难性下降，且思考过程会放大错误程度

Conclusion: 关键挑战不仅是让模型"思考"，更要赋予其评估推理依据信息的批判能力，思考过程反而会强化错误信息的影响

Abstract: The capacity of Large Language Models (LLMs) to reason is fundamental to
their application in complex, knowledge-intensive domains. In real-world
scenarios, LLMs are often augmented with external information that can be
helpful, irrelevant, or even misleading. This paper investigates the causal
impact of such auxiliary information on the reasoning process of LLMs with
explicit step-by-step thinking capabilities. We introduce SciAux, a new dataset
derived from ScienceQA, to systematically test the robustness of the model
against these types of information. Our findings reveal a critical
vulnerability: the model's deliberative "thinking mode" is a double-edged
sword. While helpful context improves accuracy, misleading information causes a
catastrophic drop in performance, which is amplified by the thinking process.
Instead of conferring robustness, thinking reinforces the degree of error when
provided with misinformation. This highlights that the challenge is not merely
to make models "think", but to endow them with the critical faculty to evaluate
the information upon which their reasoning is based. The SciAux dataset is
available at https://huggingface.co/datasets/billhdzhao/SciAux.

</details>


### [6] [SIRAG: Towards Stable and Interpretable RAG with A Process-Supervised Multi-Agent Framework](https://arxiv.org/abs/2509.18167)
*Junlin Wang,Zehao Wu,Shaowei Lu,Yanlan Li,Xinghao Huang*

Main category: cs.CL

TL;DR: 提出了一种过程监督的多智能体框架来优化检索增强生成（RAG）系统中检索器和生成器之间的协调问题，通过决策制定器和知识选择器两个轻量级智能体，结合过程级奖励和树状结构探索策略，实现了更高的准确性和更稳定的收敛。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统中检索器和生成器独立开发导致交互不理想：检索器可能返回不相关或冗余文档，生成器未能充分利用检索到的证据。需要解决两者之间的协调问题。

Method: 采用过程监督的多智能体框架，包含决策制定器（决定何时停止检索）和知识选择器（过滤无用文档）。使用LLM作为评判员提供过程级奖励，采用树状结构探索策略和PPO算法进行端到端训练。

Result: 在单跳和多跳问答基准测试中，该方法相比标准RAG基线实现了更高的准确性、更稳定的收敛性，并产生了更可解释的推理轨迹。

Conclusion: 该框架具有模块化和即插即用特性，无需修改检索器或生成器，适用于实际RAG应用，有效提升了RAG系统的性能。

Abstract: Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to
access external knowledge sources, but the effectiveness of RAG relies on the
coordination between the retriever and the generator. Since these components
are developed independently, their interaction is often suboptimal: the
retriever may return irrelevant or redundant documents, while the generator may
fail to fully leverage retrieved evidence. In this work, we propose a
process-supervised multi-agent framework to bridge the gap between retriever
and generator. The framework introduces two lightweight agents: a Decision
Maker, which determines when to continue retrieval or stop for answer
generation, and a Knowledge Selector, which filters retrieved documents to
retain only the most useful evidence. To provide fine-grained supervision, we
employ an LLM-as-a-Judge that evaluates each intermediate action with
process-level rewards, ensuring more accurate credit assignment than relying
solely on final answer correctness. We further adopt a tree-structured rollout
strategy to explore diverse reasoning paths, and train both agents with
Proximal Policy Optimization (PPO) in an end-to-end manner. Experiments on
single-hop and multi-hop question answering benchmarks show that our approach
achieves higher accuracy, more stable convergence, and produces more
interpretable reasoning trajectories compared with standard RAG baselines.
Importantly, the proposed framework is modular and plug-and-play, requiring no
modification to the retriever or generator, making it practical for real-world
RAG applications.

</details>


### [7] [ERFC: Happy Customers with Emotion Recognition and Forecasting in Conversation in Call Centers](https://arxiv.org/abs/2509.18175)
*Aditi Debsharma,Bhushan Jagyasi,Surajit Sen,Priyanka Pandey,Devicharith Dovari,Yuvaraj V. C,Rosalin Parida,Gopali Contractor*

Main category: cs.CL

TL;DR: 提出了一种新颖的对话情感识别和预测架构ERFC，用于预测未来话语的情感，在呼叫中心等场景中具有重要商业价值


<details>
  <summary>Details</summary>
Motivation: 在呼叫中心等对话场景中，了解未来话语的情感可以帮助客服人员及时调整策略，提升客户体验，将不满意的客户转变为满意的客户

Method: ERFC架构考虑多模态、情感的不同属性、上下文以及对话中说话者话语之间的相互依赖关系

Result: 在IEMOCAP数据集上的密集实验证明了所提出ERFC方法的可行性

Conclusion: 该方法在呼叫中心等客户满意度至关重要的应用中具有巨大的商业价值

Abstract: Emotion Recognition in Conversation has been seen to be widely applicable in
call center analytics, opinion mining, finance, retail, healthcare, and other
industries. In a call center scenario, the role of the call center agent is not
just confined to receiving calls but to also provide good customer experience
by pacifying the frustration or anger of the customers. This can be achieved by
maintaining neutral and positive emotion from the agent. As in any
conversation, the emotion of one speaker is usually dependent on the emotion of
other speaker. Hence the positive emotion of an agent, accompanied with the
right resolution will help in enhancing customer experience. This can change an
unhappy customer to a happy one. Imparting the right resolution at right time
becomes easier if the agent has the insight of the emotion of future
utterances. To predict the emotions of the future utterances we propose a novel
architecture, Emotion Recognition and Forecasting in Conversation. Our proposed
ERFC architecture considers multi modalities, different attributes of emotion,
context and the interdependencies of the utterances of the speakers in the
conversation. Our intensive experiments on the IEMOCAP dataset have shown the
feasibility of the proposed ERFC. This approach can provide a tremendous
business value for the applications like call center, where the happiness of
customer is utmost important.

</details>


### [8] [Evaluating Large Language Models for Detecting Antisemitism](https://arxiv.org/abs/2509.18293)
*Jay Patel,Hrudayangam Mehta,Jeremy Blackburn*

Main category: cs.CL

TL;DR: 本文评估了8个开源LLM检测反犹内容的能力，提出了Guided-CoT提示方法，显著提升了模型性能，并分析了LLM在实用性、可解释性和可靠性方面的差异。


<details>
  <summary>Details</summary>
Motivation: 检测仇恨内容是重要但具有挑战性的任务，需要自动化工具不断适应社交媒体环境的变化。

Method: 使用上下文定义作为政策指导，探索多种提示技术，设计了新的Guided-CoT提示方法，评估了不同模型在不同解码配置下的表现。

Result: Guided-CoT方法显著提升了所有评估模型的性能，Llama 3.1 70B甚至超越了微调的GPT-3.5。同时发现了LLM在语义分歧和矛盾行为方面的差异。

Conclusion: 研究揭示了不同LLM在实用性、可解释性和可靠性方面的显著差异，为仇恨内容检测提供了有效的提示方法。

Abstract: Detecting hateful content is a challenging and important problem. Automated
tools, like machine-learning models, can help, but they require continuous
training to adapt to the ever-changing landscape of social media. In this work,
we evaluate eight open-source LLMs' capability to detect antisemitic content,
specifically leveraging in-context definition as a policy guideline. We explore
various prompting techniques and design a new CoT-like prompt, Guided-CoT.
Guided-CoT handles the in-context policy well, increasing performance across
all evaluated models, regardless of decoding configuration, model sizes, or
reasoning capability. Notably, Llama 3.1 70B outperforms fine-tuned GPT-3.5.
Additionally, we examine LLM errors and introduce metrics to quantify semantic
divergence in model-generated rationales, revealing notable differences and
paradoxical behaviors among LLMs. Our experiments highlight the differences
observed across LLMs' utility, explainability, and reliability.

</details>


### [9] [Exploiting Tree Structure for Credit Assignment in RL Training of LLMs](https://arxiv.org/abs/2509.18314)
*Hieu Tran,Zonghai Yao,Hong Yu*

Main category: cs.CL

TL;DR: 论文提出了一种名为TEMPO的无评论者强化学习算法，通过前缀树结构解决LLM推理任务中的令牌级信用分配问题，在数学和医疗QA任务上优于PPO和GRPO方法。


<details>
  <summary>Details</summary>
Motivation: 强化学习虽然能改进LLM推理能力，但长序列中的稀疏延迟奖励使得令牌级信用分配成为关键瓶颈。现有方法如PPO需要同时训练行动者和评论者模型，复杂度高且容易过拟合；GRPO虽然无评论者但忽略了分支结构。

Method: 提出Prefix-to-Tree(P2T)方法将多个响应转换为前缀树，计算非参数化前缀值。基于此开发TEMPO算法，在GRPO的基础上加入分支门控的时间差分修正，在分支令牌处提供精确的令牌级信用分配。

Result: 在Qwen3-1.7B/4B模型上，TEMPO在分布内(MATH、MedQA)和分布外(GSM-HARD、AMC23等)基准测试中均优于PPO和GRPO，在相同训练时间内达到更高的验证准确率。

Conclusion: TEMPO提供了一种简单有效的无评论者强化学习方法，通过树结构的时间差分修正解决了令牌级信用分配问题，在推理任务中表现出优越性能。

Abstract: Reinforcement learning improves LLM reasoning, yet sparse delayed reward over
long sequences makes token-level credit assignment the key bottleneck. We study
the verifiable-reward setting, where the final answer is checkable and multiple
responses can be drawn per prompt. Reasoning tasks in math and medical QA align
with this setup, where only a few decision tokens significantly impact the
outcome. PPO offers token-level advantages with a learned value model, but it
is complex to train both the actor and critic models simultaneously, and it is
not easily generalizable, as the token-level values from the critic model can
make training prone to overfitting. GRPO is critic-free and supports verifiable
rewards, but spreads a single sequence-level return across tokens and ignores
branching. We introduce \textbf{Prefix-to-Tree (P2T)}, a simple procedure that
converts a group of responses into a prefix tree and computes
\emph{nonparametric} prefix values \(V(s)\) by aggregating descendant outcomes.
Built on P2T, we propose \textbf{TEMPO} (\emph{\textbf{T}ree-\textbf{E}stimated
\textbf{M}ean Prefix Value for \textbf{P}olicy \textbf{O}ptimization}), a
critic-free algorithm that augments the group-relative outcome signal of GRPO
with \emph{branch-gated} temporal-difference corrections derived from the tree.
At non-branch tokens, the temporal-difference (TD) term is zero, so TEMPO
reduces to GRPO; at branching tokens, it supplies precise token-level credit
without a learned value network or extra judges/teachers. On Qwen3-1.7B/4B,
TEMPO outperforms PPO and GRPO on in-distribution (MATH, MedQA) and
out-of-distribution (GSM-HARD, AMC23, MedMCQA, MMLU-Medical) benchmarks, and
reaches higher validation accuracy with roughly the same wall-clock time.

</details>


### [10] [Brittleness and Promise: Knowledge Graph Based Reward Modeling for Diagnostic Reasoning](https://arxiv.org/abs/2509.18316)
*Saksham Khatwani,He Cheng,Majid Afshar,Dmitriy Dligach,Yanjun Gao*

Main category: cs.CL

TL;DR: 该论文探索了一种替代范式：将LLM作为知识图谱推理路径的奖励模型，让模型学习判断候选路径是否能正确诊断患者输入，而不是直接将KG内容插入提示中。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在诊断推理方面有潜力但缺乏可靠的知识基础推理。知识图谱提供结构化生物医学知识来支持可信推理，但现有方法通常通过检索增强生成或微调来集成KG，而不是实现结构化推理。

Method: 将LLM作为KG推理路径的奖励模型，系统评估五种知识路径判断任务制定和八种训练范式，测试路径判断能力是否能泛化到下游诊断任务。

Result: 实验显示特定奖励优化和蒸馏能带来强大的路径判断性能，但向下游任务的可迁移性仍然较弱。

Conclusion: 这是对临床KG进行"奖励模型风格"推理的首次系统评估，为结构化、基于奖励的监督如何影响医疗GenAI系统中的诊断推理提供了见解。

Abstract: Large language models (LLMs) show promise for diagnostic reasoning but often
lack reliable, knowledge grounded inference. Knowledge graphs (KGs), such as
the Unified Medical Language System (UMLS), offer structured biomedical
knowledge that can support trustworthy reasoning. Prior approaches typically
integrate KGs via retrieval augmented generation or fine tuning, inserting KG
content into prompts rather than enabling structured reasoning. We explore an
alternative paradigm: treating the LLM as a reward model of KG reasoning paths,
where the model learns to judge whether a candidate path leads to correct
diagnosis for a given patient input. This approach is inspired by recent work
that leverages reward training to enhance model reasoning abilities, and
grounded in computational theory, which suggests that verifying a solution is
often easier than generating one from scratch. It also parallels physicians'
diagnostic assessment, where they judge which sequences of findings and
intermediate conditions most plausibly support a diagnosis. We first
systematically evaluate five task formulation for knowledge path judging and
eight training paradigm. Second, we test whether the path judging abilities
generalize to downstream diagnostic tasks, including diagnosis summarization
and medical question answering. Experiments with three open source
instruct-tuned LLMs reveal both promise and brittleness: while specific reward
optimization and distillation lead to strong path-judging performance, the
transferability to downstream tasks remain weak. Our finding provides the first
systematic assessment of "reward model style" reasoning over clinical KGs,
offering insights into how structured, reward-based supervision influences
diagnostic reasoning in GenAI systems for healthcare.

</details>


### [11] [Speculate Deep and Accurate: Lossless and Training-Free Acceleration for Offloaded LLMs via Substitute Speculative Decoding](https://arxiv.org/abs/2509.18344)
*Pei-Shuo Wang,Jian-Jia Chen,Chun-Che Yang,Chi-Chih Chang,Ning-Chi Huang,Mohamed S. Abdelfattah,Kai-Chiang Wu*

Main category: cs.CL

TL;DR: SubSpec是一种无损、无需训练的即插即用方法，通过生成低比特量化替代层来构建高度对齐的草稿模型，加速参数卸载，在有限VRAM下实现显著推理加速。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在内存受限GPU上部署的挑战，现有方法存在质量下降或推理速度慢的问题，需要一种既能保持质量又能加速推理的解决方案。

Method: 构建高度对齐的草稿模型，生成低比特量化替代层从卸载的目标LLM部分，共享GPU驻留层和KV-Cache以减少内存开销并增强对齐。

Result: 在8GB VRAM限制下，Qwen2.5 7B在MT-Bench上实现9.1倍加速；在24GB VRAM限制下，Qwen2.5 32B在流行生成基准测试中平均实现12.5倍加速。

Conclusion: SubSpec通过构建高度对齐的草稿模型，有效解决了参数卸载中的推理速度问题，实现了显著的加速效果，且无需额外训练。

Abstract: The immense model sizes of large language models (LLMs) challenge deployment
on memory-limited consumer GPUs. Although model compression and parameter
offloading are common strategies to address memory limitations, compression can
degrade quality, and offloading maintains quality but suffers from slow
inference. Speculative decoding presents a promising avenue to accelerate
parameter offloading, utilizing a fast draft model to propose multiple draft
tokens, which are then verified by the target LLM in parallel with a single
forward pass. This method reduces the time-consuming data transfers in forward
passes that involve offloaded weight transfers. Existing methods often rely on
pretrained weights of the same family, but require additional training to align
with custom-trained models. Moreover, approaches that involve draft model
training usually yield only modest speedups. This limitation arises from
insufficient alignment with the target model, preventing higher token
acceptance lengths. To address these challenges and achieve greater speedups,
we propose SubSpec, a plug-and-play method to accelerate parameter offloading
that is lossless and training-free. SubSpec constructs a highly aligned draft
model by generating low-bit quantized substitute layers from offloaded target
LLM portions. Additionally, our method shares the remaining GPU-resident layers
and the KV-Cache, further reducing memory overhead and enhance alignment.
SubSpec achieves a high average acceptance length, delivering 9.1x speedup for
Qwen2.5 7B on MT-Bench (8GB VRAM limit) and an average of 12.5x speedup for
Qwen2.5 32B on popular generation benchmarks (24GB VRAM limit).

</details>


### [12] [Speech Vecalign: an Embedding-based Method for Aligning Parallel Speech Documents](https://arxiv.org/abs/2509.18360)
*Chutong Meng,Philipp Koehn*

Main category: cs.CL

TL;DR: Speech Vecalign是一种并行语音文档对齐方法，通过单调对齐语音段嵌入，不依赖文本转录，相比现有方法能产生更长的语音对齐且噪声更少。


<details>
  <summary>Details</summary>
Motivation: 现有的语音挖掘方法如Global Mining和Local Mining在语音对齐方面存在对齐长度不足和噪声较多的问题，需要一种更鲁棒的语音对齐方法。

Method: 该方法通过单调对齐语音段嵌入来实现语音文档的对齐，不依赖文本转录，能够处理未标注的并行语音数据。

Result: 在3000小时的英语-德语语音数据上应用Speech Vecalign，获得了约1000小时的高质量对齐数据，训练出的语音翻译模型性能优于Global Mining方法，且使用8倍少的原始语音数据就能达到或超过SpeechMatrix模型的性能。

Conclusion: Speech Vecalign是一种有效的语音对齐方法，能够显著提升语音翻译模型的性能，同时大幅减少对原始数据量的需求。

Abstract: We present Speech Vecalign, a parallel speech document alignment method that
monotonically aligns speech segment embeddings and does not depend on text
transcriptions. Compared to the baseline method Global Mining, a variant of
speech mining, Speech Vecalign produces longer speech-to-speech alignments. It
also demonstrates greater robustness than Local Mining, another speech mining
variant, as it produces less noise. We applied Speech Vecalign to 3,000 hours
of unlabeled parallel English-German (En-De) speech documents from VoxPopuli,
yielding about 1,000 hours of high-quality alignments. We then trained En-De
speech-to-speech translation models on the aligned data. Speech Vecalign
improves the En-to-De and De-to-En performance over Global Mining by 0.37 and
0.18 ASR-BLEU, respectively. Moreover, our models match or outperform
SpeechMatrix model performance, despite using 8 times fewer raw speech
documents.

</details>


### [13] [Interactive Real-Time Speaker Diarization Correction with Human Feedback](https://arxiv.org/abs/2509.18377)
*Xinlu He,Yiwen Guan,Badrivishal Paurana,Zilin Dai,Jacob Whitehill*

Main category: cs.CL

TL;DR: 提出了一种LLM辅助的说话人日志校正系统，通过实时用户反馈来修正说话人归属错误，结合流式ASR和说话人日志技术，显著降低错误率。


<details>
  <summary>Details</summary>
Motivation: 大多数自动语音处理系统在"开环"模式下运行，缺乏用户反馈，而人机协作工作流可以显著提高准确率。

Method: 采用流式ASR和说话人日志，使用LLM生成简洁摘要，接受用户语音反馈并实时整合。开发了分割合并技术（SWM）来检测和分割被错误归因的单说话人段，以及基于用户校正的在线说话人注册。

Result: 在AMI测试集上的LLM驱动模拟显示，系统显著降低了DER（说话人日志错误率）9.92%和说话人混淆错误44.23%。

Conclusion: 该系统通过人机协作有效提升了说话人日志的准确性，分析了不同设置下的校正效果，包括摘要与完整转录显示、在线注册数量限制和校正频率等因素。

Abstract: Most automatic speech processing systems operate in "open loop" mode without
user feedback about who said what; yet, human-in-the-loop workflows can
potentially enable higher accuracy. We propose an LLM-assisted speaker
diarization correction system that lets users fix speaker attribution errors in
real time. The pipeline performs streaming ASR and diarization, uses an LLM to
deliver concise summaries to the users, and accepts brief verbal feedback that
is immediately incorporated without disrupting interactions. Moreover, we
develop techniques to make the workflow more effective: First, a
split-when-merged (SWM) technique detects and splits multi-speaker segments
that the ASR erroneously attributes to just a single speaker. Second, online
speaker enrollments are collected based on users' diarization corrections, thus
helping to prevent speaker diarization errors from occurring in the future.
LLM-driven simulations on the AMI test set indicate that our system
substantially reduces DER by 9.92% and speaker confusion error by 44.23%. We
further analyze correction efficacy under different settings, including summary
vs full transcript display, the number of online enrollments limitation, and
correction frequency.

</details>


### [14] [NormGenesis: Multicultural Dialogue Generation via Exemplar-Guided Social Norm Modeling and Violation Recovery](https://arxiv.org/abs/2509.18395)
*Minki Hong,Jangho Choi,Jihie Kim*

Main category: cs.CL

TL;DR: NormGenesis是一个多文化框架，用于生成和标注基于社会规范的对话，涵盖英语、中文和韩语。该框架引入了违规到解决的新型对话类型，并通过基于示例的迭代优化提高语言一致性。


<details>
  <summary>Details</summary>
Motivation: 社会规范决定了文化上适当的沟通行为，使对话系统能够产生不仅连贯而且社会可接受的回应。现有方法主要关注静态规范分类，缺乏对社交互动动态过程的建模。

Method: 提出违规到解决对话类型，建模规范违规后的对话进展过程；实施基于示例的迭代优化方法，在对话合成早期引入语言、情感和社会文化期望的对齐；构建包含10,800个多轮对话的数据集。

Result: 人类和LLM评估表明，NormGenesis在优化质量、对话自然度和泛化性能方面显著优于现有数据集；使用V2R增强数据训练的模型在伦理敏感情境中表现出更好的语用能力。

Conclusion: 该工作为文化自适应对话建模建立了新基准，并为跨语言和文化的规范感知生成提供了可扩展的方法论。

Abstract: Social norms govern culturally appropriate behavior in communication,
enabling dialogue systems to produce responses that are not only coherent but
also socially acceptable. We present NormGenesis, a multicultural framework for
generating and annotating socially grounded dialogues across English, Chinese,
and Korean. To model the dynamics of social interaction beyond static norm
classification, we propose a novel dialogue type, Violation-to-Resolution
(V2R), which models the progression of conversations following norm violations
through recognition and socially appropriate repair. To improve pragmatic
consistency in underrepresented languages, we implement an exemplar-based
iterative refinement early in the dialogue synthesis process. This design
introduces alignment with linguistic, emotional, and sociocultural expectations
before full dialogue generation begins. Using this framework, we construct a
dataset of 10,800 multi-turn dialogues annotated at the turn level for norm
adherence, speaker intent, and emotional response. Human and LLM-based
evaluations demonstrate that NormGenesis significantly outperforms existing
datasets in refinement quality, dialogue naturalness, and generalization
performance. We show that models trained on our V2R-augmented data exhibit
improved pragmatic competence in ethically sensitive contexts. Our work
establishes a new benchmark for culturally adaptive dialogue modeling and
provides a scalable methodology for norm-aware generation across linguistically
and culturally diverse languages.

</details>


### [15] [Evaluating the Creativity of LLMs in Persian Literary Text Generation](https://arxiv.org/abs/2509.18401)
*Armin Tourajmehr,Mohammad Reza Modarres,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型生成波斯文学文本的能力，建立了包含20个主题的波斯文学数据集，采用托兰斯创造力测试的四个维度进行评估，并使用LLM作为自动评分工具验证其可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注英语文学，缺乏对非英语文学传统的探索，且缺乏标准化的创造力评估方法。本文旨在填补这一空白，评估LLMs在生成富含文化相关表达的波斯文学文本方面的能力。

Method: 构建包含20个多样化主题的波斯文学数据集；采用托兰斯创造力测试的四个维度（原创性、流畅性、灵活性和精细性）进行评估；使用LLM作为自动评分工具，并通过组内相关系数验证其与人类判断的一致性；分析模型对四种核心文学手法（明喻、隐喻、夸张和对立）的理解和运用能力。

Result: LLM作为评分工具与人类判断具有强一致性；模型在波斯文学文本生成方面表现出优势和局限性；需要进一步改进模型以更好地理解和运用文学手法。

Conclusion: LLMs在波斯文学文本生成方面具有潜力，但仍需进一步优化，特别是在理解和运用文学手法方面。研究强调了跨文化文学评估的重要性，并为未来研究提供了标准化评估框架。

Abstract: Large language models (LLMs) have demonstrated notable creative abilities in
generating literary texts, including poetry and short stories. However, prior
research has primarily centered on English, with limited exploration of
non-English literary traditions and without standardized methods for assessing
creativity. In this paper, we evaluate the capacity of LLMs to generate Persian
literary text enriched with culturally relevant expressions. We build a dataset
of user-generated Persian literary spanning 20 diverse topics and assess model
outputs along four creativity dimensions-originality, fluency, flexibility, and
elaboration-by adapting the Torrance Tests of Creative Thinking. To reduce
evaluation costs, we adopt an LLM as a judge for automated scoring and validate
its reliability against human judgments using intraclass correlation
coefficients, observing strong agreement. In addition, we analyze the models'
ability to understand and employ four core literary devices: simile, metaphor,
hyperbole, and antithesis. Our results highlight both the strengths and
limitations of LLMs in Persian literary text generation, underscoring the need
for further refinement.

</details>


### [16] [Developing an AI framework to automatically detect shared decision-making in patient-doctor conversations](https://arxiv.org/abs/2509.18439)
*Oscar J. Ponce-Ponte,David Toro-Tobon,Luis F. Figueroa,Michael Gionfriddo,Megan Branda,Victor M. Montori,Saturnino Luz,Juan P. Brito*

Main category: cs.CL

TL;DR: 本研究开发了一种使用语言建模和对话对齐(CA)评分自动测量医患共享决策(SDM)的方法，通过深度学习模型和微调BERT模型计算CA分数，并与SDM结果关联分析。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏自动测量医患共享决策(SDM)的方法，需要开发可扩展的自动化评估工具来促进以患者为中心的护理。

Method: 使用157个视频记录的医患对话转录成42,559个句子，通过上下文-响应对和负采样训练深度学习模型和微调BERT模型，计算四种CA分数，并与SDM结果(DCS和OPTION12评分)进行关联分析。

Result: 微调BERTbase模型获得最高召回率0.640，DL模型和BERT模型计算的CA分数与OPTION12和DCS评分显著相关，表明CA分数可以有效测量SDM。

Conclusion: 本研究首次提出了通过可解释的CA分数自动、可扩展测量医患共享决策的方法，具有大规模评估SDM策略的潜力。

Abstract: Shared decision-making (SDM) is necessary to achieve patient-centred care.
Currently no methodology exists to automatically measure SDM at scale. This
study aimed to develop an automated approach to measure SDM by using language
modelling and the conversational alignment (CA) score. A total of 157
video-recorded patient-doctor conversations from a randomized multi-centre
trial evaluating SDM decision aids for anticoagulation in atrial fibrillations
were transcribed and segmented into 42,559 sentences. Context-response pairs
and negative sampling were employed to train deep learning (DL) models and
fine-tuned BERT models via the next sentence prediction (NSP) task. Each
top-performing model was used to calculate four types of CA scores. A
random-effects analysis by clinician, adjusting for age, sex, race, and trial
arm, assessed the association between CA scores and SDM outcomes: the
Decisional Conflict Scale (DCS) and the Observing Patient Involvement in
Decision-Making 12 (OPTION12) scores. p-values were corrected for multiple
comparisons with the Benjamini-Hochberg method. Among 157 patients (34% female,
mean age 70 SD 10.8), clinicians on average spoke more words than patients
(1911 vs 773). The DL model without the stylebook strategy achieved a recall@1
of 0.227, while the fine-tuned BERTbase (110M) achieved the highest recall@1
with 0.640. The AbsMax (18.36 SE7.74 p=0.025) and Max CA (21.02 SE7.63 p=0.012)
scores generated with the DL without stylebook were associated with OPTION12.
The Max CA score generated with the fine-tuned BERTbase (110M) was associated
with the DCS score (-27.61 SE12.63 p=0.037). BERT model sizes did not have an
impact the association between CA scores and SDM. This study introduces an
automated, scalable methodology to measure SDM in patient-doctor conversations
through explainable CA scores, with potential to evaluate SDM strategies at
scale.

</details>


### [17] [CogniLoad: A Synthetic Natural Language Reasoning Benchmark With Tunable Length, Intrinsic Difficulty, and Distractor Density](https://arxiv.org/abs/2509.18458)
*Daniel Kaiser,Arnoldo Frigessi,Ali Ramezani-Kebrya,Benjamin Ricaud*

Main category: cs.CL

TL;DR: CogniLoad是一个基于认知负荷理论的新型合成基准，通过独立可调参数评估LLM的长上下文推理能力，揭示了任务长度是主要限制因素。


<details>
  <summary>Details</summary>
Motivation: 当前长上下文推理基准模糊了关键因素，需要更精确的故障分析工具来系统评估LLM的推理限制。

Method: 基于认知负荷理论生成自然语言逻辑谜题，通过三个独立可调参数（内在难度d、干扰信号比ρ、任务长度N）控制认知负荷的三个维度。

Result: 评估22个先进推理LLM，发现任务长度是主导约束，模型对内在复杂性有不同容忍度，对干扰比呈现U型响应。

Conclusion: CogniLoad提供了可重现、可扩展且诊断性丰富的工具，可用于剖析LLM推理限制并指导未来模型开发。

Abstract: Current benchmarks for long-context reasoning in Large Language Models (LLMs)
often blur critical factors like intrinsic task complexity, distractor
interference, and task length. To enable more precise failure analysis, we
introduce CogniLoad, a novel synthetic benchmark grounded in Cognitive Load
Theory (CLT). CogniLoad generates natural-language logic puzzles with
independently tunable parameters that reflect CLT's core dimensions: intrinsic
difficulty ($d$) controls intrinsic load; distractor-to-signal ratio ($\rho$)
regulates extraneous load; and task length ($N$) serves as an operational proxy
for conditions demanding germane load. Evaluating 22 SotA reasoning LLMs,
CogniLoad reveals distinct performance sensitivities, identifying task length
as a dominant constraint and uncovering varied tolerances to intrinsic
complexity and U-shaped responses to distractor ratios. By offering systematic,
factorial control over these cognitive load dimensions, CogniLoad provides a
reproducible, scalable, and diagnostically rich tool for dissecting LLM
reasoning limitations and guiding future model development.

</details>


### [18] [LAWCAT: Efficient Distillation from Quadratic to Linear Attention with Convolution across Tokens for Long Context Modeling](https://arxiv.org/abs/2509.18467)
*Zeyu Liu,Souvik Kundu,Lianghao Jiang,Anni Li,Srikanth Ronanki,Sravan Bodapati,Gourav Datta,Peter A. Beerel*

Main category: cs.CL

TL;DR: LAWCAT是一种线性注意力框架，通过将预训练Transformer转换为线性复杂度架构，显著降低长序列处理的计算成本，仅需少量训练即可扩展上下文窗口至22K token。


<details>
  <summary>Details</summary>
Motivation: Transformer的二次计算复杂度限制了其在长上下文应用中的效率，而从头训练线性复杂度模型又需要大量资源。LAWCAT旨在高效迁移预训练Transformer能力到线性架构。

Method: 整合因果Conv1D层增强局部依赖建模，使用归一化门控线性注意力提升不同上下文长度的泛化能力，通过知识蒸馏方法转换预训练模型。

Result: 仅用1K长度序列蒸馏Mistral-7B，在22K token内实现90%+的passkey检索准确率；Llama3.2-1B变体在多个长上下文基准测试中表现优异，预训练token需求减少99.9%。

Conclusion: LAWCAT为边缘部署提供了高效的高性能长上下文线性模型路径，减少了对大量长序列训练数据和计算资源的依赖。

Abstract: Although transformer architectures have achieved state-of-the-art performance
across diverse domains, their quadratic computational complexity with respect
to sequence length remains a significant bottleneck, particularly for
latency-sensitive long-context applications. While recent linear-complexity
alternatives are increasingly powerful, effectively training them from scratch
is still resource-intensive. To overcome these limitations, we propose LAWCAT
(Linear Attention with Convolution Across Time), a novel linearization
framework designed to efficiently transfer the capabilities of pre-trained
transformers into a performant linear attention architecture. LAWCAT integrates
causal Conv1D layers to enhance local dependency modeling and employs
normalized gated linear attention to improve generalization across varying
context lengths. Our comprehensive evaluations demonstrate that, distilling
Mistral-7B with only 1K-length sequences yields over 90\% passkey retrieval
accuracy up to 22K tokens, significantly extending its effective context
window. Similarly, Llama3.2-1B LAWCAT variant achieves competitive performance
on S-NIAH 1\&2\&3 tasks (1K-8K context length) and BABILong benchmark
(QA2\&QA3, 0K-16K context length), requiring less than 0.1\% pre-training
tokens compared with pre-training models. Furthermore, LAWCAT exhibits faster
prefill speeds than FlashAttention-2 for sequences exceeding 8K tokens. LAWCAT
thus provides an efficient pathway to high-performance, long-context linear
models suitable for edge deployment, reducing reliance on extensive
long-sequence training data and computational resources.

</details>


### [19] [Actions Speak Louder than Prompts: A Large-Scale Study of LLMs for Graph Inference](https://arxiv.org/abs/2509.18487)
*Ben Finkelshtein,Silviu Cucerzan,Sujay Kumar Jauhar,Ryen White*

Main category: cs.CL

TL;DR: 本文对LLM在图数据上的能力进行了系统评估，发现代码生成方法在图形任务中表现最佳，特别是在长文本或高密度图上优势明显，且所有交互策略在异质图上都有效。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在文本丰富的图机器学习任务中应用日益广泛（如欺诈检测和推荐系统），但缺乏对LLM与图数据交互能力的系统理解，因此需要系统评估LLM在图数据上的表现。

Method: 通过大规模控制实验，评估LLM-图交互模式（提示、工具使用、代码生成）、数据集领域、结构机制、特征特性和模型配置等多个维度，并分析输入类型的依赖性。

Result: 1）代码生成方法整体表现最强，在长文本或高密度图上优势显著；2）所有交互策略在异质图上都有效；3）代码生成能灵活调整对结构、特征或标签的依赖程度。

Conclusion: 研究全面揭示了当前LLM-图交互模式的优势与局限，为未来方法设计提供了关键指导原则。

Abstract: Large language models (LLMs) are increasingly used for text-rich graph
machine learning tasks such as node classification in high-impact domains like
fraud detection and recommendation systems. Yet, despite a surge of interest,
the field lacks a principled understanding of the capabilities of LLMs in their
interaction with graph data. In this work, we conduct a large-scale, controlled
evaluation across several key axes of variability to systematically assess the
strengths and weaknesses of LLM-based graph reasoning methods in text-based
applications. The axes include the LLM-graph interaction mode, comparing
prompting, tool-use, and code generation; dataset domains, spanning citation,
web-link, e-commerce, and social networks; structural regimes contrasting
homophilic and heterophilic graphs; feature characteristics involving both
short- and long-text node attributes; and model configurations with varying LLM
sizes and reasoning capabilities. We further analyze dependencies by
methodically truncating features, deleting edges, and removing labels to
quantify reliance on input types. Our findings provide practical and actionable
guidance. (1) LLMs as code generators achieve the strongest overall performance
on graph data, with especially large gains on long-text or high-degree graphs
where prompting quickly exceeds the token budget. (2) All interaction
strategies remain effective on heterophilic graphs, challenging the assumption
that LLM-based methods collapse under low homophily. (3) Code generation is
able to flexibly adapt its reliance between structure, features, or labels to
leverage the most informative input type. Together, these findings provide a
comprehensive view of the strengths and limitations of current LLM-graph
interaction modes and highlight key design principles for future approaches.

</details>


### [20] [A Rhythm-Aware Phrase Insertion for Classical Arabic Poetry Composition](https://arxiv.org/abs/2509.18514)
*Mohamad Elzohbi,Richard Zhao*

Main category: cs.CL

TL;DR: 提出一种基于ByT5的方法，在阿拉伯诗歌中插入短语以符合特定韵律，通过规则化字形到节拍的转换和条件去噪目标来保持韵律对齐和语义连贯性。


<details>
  <summary>Details</summary>
Motivation: 开发能够辅助创作古典阿拉伯诗歌的协同创作工具，解决诗歌创作中韵律对齐的技术挑战。

Method: 使用基于规则的字形到节拍转换提取韵律，采用条件去噪目标微调ByT5模型，结合课程学习策略（先在通用阿拉伯语数据集预训练，再在诗歌数据集微调），并探索从英语到阿拉伯语的跨语言迁移。

Result: 实验结果表明，模型能够实现高度的韵律对齐，同时保持语义连贯性。

Conclusion: 所提出的模型在古典阿拉伯诗歌创作过程中具有协同创作的应用潜力。

Abstract: This paper presents a methodology for inserting phrases in Arabic poems to
conform to a specific rhythm using ByT5, a byte-level multilingual
transformer-based model. Our work discusses a rule-based grapheme-to-beat
transformation tailored for extracting the rhythm from fully diacritized Arabic
script. Our approach employs a conditional denoising objective to fine-tune
ByT5, where the model reconstructs masked words to match a target rhythm. We
adopt a curriculum learning strategy, pre-training on a general Arabic dataset
before fine-tuning on poetic dataset, and explore cross-lingual transfer from
English to Arabic. Experimental results demonstrate that our models achieve
high rhythmic alignment while maintaining semantic coherence. The proposed
model has the potential to be used in co-creative applications in the process
of composing classical Arabic poems.

</details>


### [21] [Trace Is In Sentences: Unbiased Lightweight ChatGPT-Generated Text Detector](https://arxiv.org/abs/2509.18535)
*Mo Mu,Dianqiao Lei,Chang Li*

Main category: cs.CL

TL;DR: 本文提出了一种轻量级框架，用于检测原始和经过提示修改的AI生成文本，通过分析文本内部结构来应对现有词级检测器的局限性。


<details>
  <summary>Details</summary>
Motivation: ChatGPT的广泛使用引发了对AI生成文本滥用的担忧，现有词级检测器存在易受改写攻击、存在偏见、对修改文本性能下降等问题，需要更鲁棒的检测方法。

Method: 提出基于文本内部结构的分类框架，使用预训练语言模型编码句子嵌入，通过注意力机制建模关系，采用对比学习减轻自回归生成的嵌入偏见，并结合因果图和反事实方法分离结构特征与主题相关偏见。

Result: 在两个精心策划的数据集（包括摘要比较和修订的生活FAQ）上的实验验证了该方法的有效性。

Conclusion: 该方法能够有效检测原始和经过提示修改的AI生成文本，解决了现有词级检测器的多个局限性，为AI文本检测提供了新的解决方案。

Abstract: The widespread adoption of ChatGPT has raised concerns about its misuse,
highlighting the need for robust detection of AI-generated text. Current
word-level detectors are vulnerable to paraphrasing or simple prompts (PSP),
suffer from biases induced by ChatGPT's word-level patterns (CWP) and training
data content, degrade on modified text, and often require large models or
online LLM interaction. To tackle these issues, we introduce a novel task to
detect both original and PSP-modified AI-generated texts, and propose a
lightweight framework that classifies texts based on their internal structure,
which remains invariant under word-level changes. Our approach encodes sentence
embeddings from pre-trained language models and models their relationships via
attention. We employ contrastive learning to mitigate embedding biases from
autoregressive generation and incorporate a causal graph with counterfactual
methods to isolate structural features from topic-related biases. Experiments
on two curated datasets, including abstract comparisons and revised life FAQs,
validate the effectiveness of our method.

</details>


### [22] [CCQA: Generating Question from Solution Can Improve Inference-Time Reasoning in SLMs](https://arxiv.org/abs/2509.18536)
*Jin Young Kim,Ji Won Yoon*

Main category: cs.CL

TL;DR: CCQA是一种针对小型语言模型的新型推理方法，通过循环一致性机制生成问题并评估相似度来选择最佳答案，在数学和常识推理任务上超越了现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有的推理策略在大型语言模型上效果显著，但在小型模型上表现不佳，需要开发专门适用于小型模型的有效推理方法。

Method: 基于循环一致性原理，CCQA从每个推理路径和答案生成问题，通过与原问题的相似度评估来筛选最佳答案。使用专门的Flan-T5模型进行问题生成以支持该过程。

Result: 在8个模型上的数学和常识推理基准测试中，CCQA一致性地超越了现有SOTA方法，为小型语言模型建立了新的高效推理基准。

Conclusion: CCQA为小型语言模型提供了一种有效的推理方法，证明了循环一致性机制在提升小型模型推理能力方面的有效性。

Abstract: Recently, inference-time reasoning strategies have further improved the
accuracy of large language models (LLMs), but their effectiveness on smaller
models remains unclear. Based on the observation that conventional approaches
often fail to improve performance in this context, we propose
\textbf{C}ycle-\textbf{C}onsistency in \textbf{Q}uestion \textbf{A}nswering
(CCQA), a novel reasoning method that can be effectively applied to SLMs.
Inspired by cycle consistency, CCQA generates a question from each reasoning
path and answer, evaluates each by its similarity to the original question, and
then selects the candidate solution with the highest similarity score as the
final response. Since conventional SLMs struggle to generate accurate questions
from their own reasoning paths and answers, we employ a lightweight Flan-T5
model specialized for question generation to support this process efficiently.
From the experimental results, it is verified that CCQA consistently
outperforms existing state-of-the-art (SOTA) methods across eight models on
mathematical and commonsense reasoning benchmarks. Furthermore, our method
establishes a new practical baseline for efficient reasoning in SLMs. Source
code can be found at https://github.com/scai-research/ccqa_official.

</details>


### [23] [Prior-based Noisy Text Data Filtering: Fast and Strong Alternative For Perplexity](https://arxiv.org/abs/2509.18577)
*Yeongbin Seo,Gayoung Kim,Jaehyung Kim,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 提出了一种基于先验的数据过滤方法，使用语料库级别的词频统计来估计标记先验，作为困惑度（PPL）过滤的快速替代方案，无需模型推理即可实现高效数据筛选。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型预训练需要有效的数据筛选方法。困惑度（PPL）过滤虽然性能良好，但存在时间成本高和面对噪声或分布外样本时不可靠的问题。

Method: 基于语言学的词角色和词汇密度洞察，使用语料库级别的词频统计估计标记先验，通过标记先验的均值和标准差来过滤文档。

Result: 该方法在20个下游基准测试中取得了最高平均性能，同时将时间成本相比PPL过滤降低了1000倍以上，并且适用于代码、数学等符号语言以及多语言语料库。

Conclusion: 先验过滤方法是一种简单而强大的数据筛选替代方案，在保持高性能的同时显著提高了效率，具有广泛的应用潜力。

Abstract: As large language models (LLMs) are pretrained on massive web corpora,
careful selection of data becomes essential to ensure effective and efficient
learning. While perplexity (PPL)-based filtering has shown strong performance,
it suffers from drawbacks: substantial time costs and inherent unreliability of
the model when handling noisy or out-of-distribution samples. In this work, we
propose a simple yet powerful alternative: a prior-based data filtering method
that estimates token priors using corpus-level term frequency statistics,
inspired by linguistic insights on word roles and lexical density. Our approach
filters documents based on the mean and standard deviation of token priors,
serving as a fast proxy to PPL while requiring no model inference. Despite its
simplicity, the prior-based filter achieves the highest average performance
across 20 downstream benchmarks, while reducing time cost by over 1000x
compared to PPL-based filtering. We further demonstrate its applicability to
symbolic languages such as code and math, and its dynamic adaptability to
multilingual corpora without supervision

</details>


### [24] [TsqLoRA: Towards Sensitivity and Quality Low-Rank Adaptation for Efficient Fine-Tuning](https://arxiv.org/abs/2509.18585)
*Yu Chen,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: TsqLoRA是一种新的参数高效微调方法，通过数据质量驱动选择和敏感度感知的低秩适配来提高微调效率。


<details>
  <summary>Details</summary>
Motivation: 完全微调所有模型参数计算成本高且内存密集，现有参数高效微调方法忽视了不同模型层的敏感度差异和训练数据的重要性。

Method: TsqLoRA包含两个主要组件：质量感知采样机制选择最有信息量的训练数据，以及动态秩分配模块根据每层对参数更新的敏感度调整其秩。

Result: 实验结果表明TsqLoRA在多种NLP任务上提高了微调效率，同时保持甚至改善了性能。

Conclusion: TsqLoRA通过结合数据质量选择和敏感度感知的低秩适配，为资源受限环境下的模型微调提供了有效解决方案。

Abstract: Fine-tuning large pre-trained models for downstream tasks has become a
fundamental approach in natural language processing. Fully fine-tuning all
model parameters is computationally expensive and memory-intensive, especially
in resource-constrained environments. Existing parameter-efficient fine-tuning
methods reduce the number of trainable parameters but typically overlook the
varying sensitivity of different model layers and the importance of training
data. In this work, we propose TsqLoRA, a novel method that integrates
data-quality-driven selection with sensitivity-aware low-rank adaptation,
consisted of two main components: a quality-aware sampling mechanism for
selecting the most informative training data, and a dynamic rank allocation
module that adjusts the rank of each layer based on its sensitivity to
parameter updates. The experimental results demonstrate that TsqLoRA improves
fine-tuning efficiency while maintaining or even improving performance on a
variety of NLP tasks. Our code will be available at
https://github.com/Benjamin-Ricky/TsqLoRA.

</details>


### [25] [UniECG: Understanding and Generating ECG in One Unified Model](https://arxiv.org/abs/2509.18588)
*Jiarui Jin,Haoyu Wang,Xiang Lan,Jun Li,Gaofeng Cheng,Hongyan Li,Shenda Hong*

Main category: cs.CL

TL;DR: UniECG是首个能够同时执行基于证据的心电图解释和文本条件心电图生成任务的统一模型，通过解耦的两阶段训练方法实现心电图到文本和文本到心电图的转换。


<details>
  <summary>Details</summary>
Motivation: 现有的统一模型（如GPT-5）在视觉语言任务上取得了进展，但无法正确理解心电图信号并提供准确的医学诊断，也不能正确生成心电图信号。

Method: 采用解耦的两阶段训练方法：首先学习基于证据的解释技能（ECG-to-Text），然后通过潜在空间对齐注入心电图生成能力（Text-to-ECG）。

Result: UniECG能够根据用户输入自主选择解释或生成心电图，显著扩展了当前心电图模型的能力边界。

Conclusion: UniECG作为首个统一的心电图模型，成功解决了现有模型在心电图理解和生成方面的局限性，代码和检查点将在接受后公开。

Abstract: Recent unified models such as GPT-5 have achieved encouraging progress on
vision-language tasks. However, these unified models typically fail to
correctly understand ECG signals and provide accurate medical diagnoses, nor
can they correctly generate ECG signals. To address these limitations, we
propose UniECG, the first unified model for ECG capable of concurrently
performing evidence-based ECG interpretation and text-conditioned ECG
generation tasks. Through a decoupled two-stage training approach, the model
first learns evidence-based interpretation skills (ECG-to-Text), and then
injects ECG generation capabilities (Text-to-ECG) via latent space alignment.
UniECG can autonomously choose to interpret or generate an ECG based on user
input, significantly extending the capability boundaries of current ECG models.
Our code and checkpoints will be made publicly available at
https://github.com/PKUDigitalHealth/UniECG upon acceptance.

</details>


### [26] [A Good Plan is Hard to Find: Aligning Models with Preferences is Misaligned with What Helps Users](https://arxiv.org/abs/2509.18632)
*Nishant Balepur,Matthew Shu,Yoo Yeon Sung,Seraphina Goldfarb-Tarrant,Shi Feng,Fumeng Yang,Rachel Rudinger,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: 研究发现用户偏好与AI计划的实际帮助性存在差距，常用的对齐方法可能无法准确反映计划对用户的实际帮助效果


<details>
  <summary>Details</summary>
Motivation: 测试LLM生成计划的帮助性与用户偏好之间的一致性，验证现有对齐方法（如RLHF和ChatbotArena）是否能真正反映计划对用户的实际帮助效果

Method: 使用Planorama界面，让126名用户回答300个多步骤问题，收集4388个计划执行记录和5584个比较数据，测量计划帮助性（QA成功率）和用户偏好

Result: 1）用户/模型偏好和代理成功率不能准确预测哪些计划真正帮助用户；2）这种差距不是由于用户特定偏好；3）表面线索（如简洁性和问题相似性）与偏好相关但不能预测帮助性

Conclusion: 需要基于真实用户交互的反馈来对齐有帮助的LLM，而不仅仅是基于看起来有帮助的偏好，并讨论了解决此问题的研究路径

Abstract: To assist users in complex tasks, LLMs generate plans: step-by-step
instructions towards a goal. While alignment methods aim to ensure LLM plans
are helpful, they train (RLHF) or evaluate (ChatbotArena) on what users prefer,
assuming this reflects what helps them. We test this with Planorama: an
interface where 126 users answer 300 multi-step questions with LLM plans. We
get 4388 plan executions and 5584 comparisons to measure plan helpfulness (QA
success) and user preferences on plans, and recreate the setup in agents and
reward models to see if they simulate or prefer what helps users. We expose: 1)
user/model preferences and agent success do not accurately predict which plans
help users, so common alignment feedback can misalign with helpfulness; 2) this
gap is not due to user-specific preferences, as users are similarly successful
when using plans they prefer/disprefer; 3) surface-level cues like brevity and
question similarity strongly link to preferences, but such biases fail to
predict helpfulness. In all, we argue aligning helpful LLMs needs feedback from
real user interactions, not just preferences of what looks helpful, so we
discuss the plan NLP researchers can execute to solve this problem.

</details>


### [27] [Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop Question Answering](https://arxiv.org/abs/2509.18655)
*Lingwen Deng,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: CAPE-KG是一个基于知识图谱的一致性感知参数保留知识编辑框架，用于多跳问答任务，通过确保知识图谱构建、更新和检索的一致性来解决现有方法的知识污染和不稳定更新问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于知识图谱的参数保留知识编辑方法在多跳问答中存在一致性问题，导致知识污染、不稳定更新和检索行为与编辑意图不符，影响了多跳推理的可靠性。

Method: 提出CAPE-KG框架，通过确保知识图谱的构建、更新和检索过程始终与多跳问答任务需求对齐，在未编辑和已编辑知识上保持连贯推理。

Result: 在MQuAKE基准测试上的广泛实验显示，该方法在多跳问答的参数保留知识编辑性能上取得了准确性提升。

Conclusion: CAPE-KG通过解决一致性问题，有效提升了参数保留知识编辑在多跳问答中的性能，证明了在PPKE中处理一致性的重要性。

Abstract: Parameter-Preserving Knowledge Editing (PPKE) enables updating models with
new or corrected information without retraining or parameter adjustment. Recent
PPKE approaches based on knowledge graphs (KG) to extend knowledge editing (KE)
capabilities to multi-hop question answering (MHQA). However, these methods
often lack consistency, leading to knowledge contamination, unstable updates,
and retrieval behaviors that fail to reflect the intended edits. Such
inconsistencies undermine the reliability of PPKE in multi- hop reasoning. We
present CAPE-KG, Consistency-Aware Parameter-Preserving Editing with Knowledge
Graphs, a novel consistency-aware framework for PPKE on MHQA. CAPE-KG ensures
KG construction, update, and retrieval are always aligned with the requirements
of the MHQA task, maintaining coherent reasoning over both unedited and edited
knowledge. Extensive experiments on the MQuAKE benchmark show accuracy
improvements in PPKE performance for MHQA, demonstrating the effectiveness of
addressing consistency in PPKE.

</details>


### [28] [Analyzing Uncertainty of LLM-as-a-Judge: Interval Evaluations with Conformal Prediction](https://arxiv.org/abs/2509.18658)
*Huanxin Sheng,Xinyi Liu,Hangfeng He,Jieyu Zhao,Jian Kang*

Main category: cs.CL

TL;DR: 本文提出了首个通过保形预测分析LLM作为评判者不确定性的框架，为LLM评分提供预测区间，并设计了针对离散评分任务的边界调整方法。


<details>
  <summary>Details</summary>
Motivation: LLM作为评判者的评估不确定性尚未充分探索，这种可靠性不足可能限制其在许多应用中的部署。

Method: 使用保形预测构建连续预测区间，设计针对离散评分任务的序数边界调整，提出区间中点作为低偏差替代评分方法。

Result: 实验表明保形预测能提供具有覆盖保证的有效预测区间，区间中点和重新提示评判者能改善判断质量。

Conclusion: 该框架为LLM评判者的不确定性提供了量化方法，增强了评估的可靠性，为实际应用提供了更好的保障。

Abstract: LLM-as-a-judge has become a promising paradigm for using large language
models (LLMs) to evaluate natural language generation (NLG), but the
uncertainty of its evaluation remains underexplored. This lack of reliability
may limit its deployment in many applications. This work presents the first
framework to analyze the uncertainty by offering a prediction interval of
LLM-based scoring via conformal prediction. Conformal prediction constructs
continuous prediction intervals from a single evaluation run, and we design an
ordinal boundary adjustment for discrete rating tasks. We also suggest a
midpoint-based score within the interval as a low-bias alternative to raw model
score and weighted average. We perform extensive experiments and analysis,
which show that conformal prediction can provide valid prediction interval with
coverage guarantees. We also explore the usefulness of interval midpoint and
judge reprompting for better judgment.

</details>


### [29] [MemOrb: A Plug-and-Play Verbal-Reinforcement Memory Layer for E-Commerce Customer Service](https://arxiv.org/abs/2509.18713)
*Yizhe Huang,Yang Liu,Ruiyu Zhao,Xiaolong Zhong,Xingming Yue,Ling Jiang*

Main category: cs.CL

TL;DR: 提出了MemOrb，一种轻量级即插即用的语言强化记忆层，用于解决LLM智能体在客户服务中的遗忘和重复错误问题，通过策略反思来提升长期可靠性。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在客户服务中经常出现跨会话遗忘、重复错误和缺乏持续自我改进机制的问题，在动态环境中可靠性不足。

Method: MemOrb将多轮交互提炼为紧凑的策略反思，存储在共享记忆库中，并在决策时检索使用，无需微调。

Result: 实验显示MemOrb显著提高了任务成功率和稳定性，多轮成功率提升高达63个百分点，在重复试验中表现更一致。

Conclusion: 结构化反思是增强冻结LLM智能体在客户服务场景中长期可靠性的有效机制。

Abstract: Large Language Model-based agents(LLM-based agents) are increasingly deployed
in customer service, yet they often forget across sessions, repeat errors, and
lack mechanisms for continual self-improvement. This makes them unreliable in
dynamic settings where stability and consistency are critical. To better
evaluate these properties, we emphasize two indicators: task success rate as a
measure of overall effectiveness, and consistency metrics such as Pass$^k$ to
capture reliability across multiple trials. To address the limitations of
existing approaches, we propose MemOrb, a lightweight and plug-and-play verbal
reinforcement memory layer that distills multi-turn interactions into compact
strategy reflections. These reflections are stored in a shared memory bank and
retrieved to guide decision-making, without requiring any fine-tuning.
Experiments show that MemOrb significantly improves both success rate and
stability, achieving up to a 63 percentage-point gain in multi-turn success
rate and delivering more consistent performance across repeated trials. Our
results demonstrate that structured reflection is a powerful mechanism for
enhancing long-term reliability of frozen LLM agents in customer service
scenarios.

</details>


### [30] [LOTUSDIS: A Thai far-field meeting corpus for robust conversational ASR](https://arxiv.org/abs/2509.18722)
*Pattara Tipaksorn,Sumonmas Thatphithakkul,Vataya Chunwijitra,Kwanchiva Thangthai*

Main category: cs.CL

TL;DR: LOTUSDIS是一个公开的泰语会议语料库，包含114小时自然对话，用于推进远场对话语音识别研究，通过多设备远距离录音和微调Whisper模型显著提升了ASR性能。


<details>
  <summary>Details</summary>
Motivation: 当前远场对话ASR系统在处理泰语远场语音时存在性能下降问题，缺乏适合的训练数据来应对距离、混响和噪声等真实环境挑战。

Method: 收集114小时自发对话数据，使用9个独立单通道设备在0.12-10米距离录音，提供标准数据集划分和可复现基线系统，对Whisper模型进行零样本和微调测试。

Result: 微调后泰语Whisper基线模型将整体WER从64.3%降至38.3%，远场WER从81.6%降至49.5%，在远距离麦克风上提升尤其显著。

Conclusion: 距离多样化的训练数据对鲁棒ASR至关重要，LOTUSDIS语料库为远场语音识别研究提供了有价值的资源。

Abstract: We present LOTUSDIS, a publicly available Thai meeting corpus designed to
advance far-field conversational ASR. The dataset comprises 114 hours of
spontaneous, unscripted dialogue collected in 15-20 minute sessions with three
participants, where overlapping speech is frequent and natural. Speech was
recorded simultaneously by nine independent single-channel devices spanning six
microphone types at distances from 0.12 m to 10 m, preserving the authentic
effects of reverberation, noise, and device coloration without relying on
microphone arrays. We provide standard train, dev, test splits and release a
reproducible baseline system. We benchmarked several Whisper variants under
zero-shot and fine-tuned conditions. Off-the-shelf models showed strong
degradation with distance, confirming a mismatch between pre-training data and
Thai far-field speech. Fine-tuning on LOTUSDIS dramatically improved
robustness: a Thai Whisper baseline reduced overall WER from 64.3 to 38.3 and
far-field WER from 81.6 to 49.5, with especially large gains on the most
distant microphones. These results underscore the importance of
distance-diverse training data for robust ASR. The corpus is available under
CC-BY-SA 4.0. We also release training and evaluation scripts as a baseline
system to promote reproducible research in this field.

</details>


### [31] [Global-Recent Semantic Reasoning on Dynamic Text-Attributed Graphs with Large Language Models](https://arxiv.org/abs/2509.18742)
*Yunan Wang,Jianxin Li,Ziwei Zhang*

Main category: cs.CL

TL;DR: DyGRASP是一种针对动态文本属性图（DyTAGs）的新方法，结合LLMs和时序GNNs，有效捕捉近期和全局时间语义，在节点检索任务中实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注静态文本属性图，难以处理DyTAGs中的时间演化特性和文本语义依赖，且LLMs在处理大量动态文本时存在效率问题。

Method: 设计节点中心隐式推理和滑动窗口机制捕捉近期语义；利用显式推理和RNN-like链结构捕获全局语义动态；通过更新和融合层整合近期/全局语义与图结构信息。

Result: 在DyTAG基准测试中，DyGRASP在目标节点检索任务的Hit@10指标上提升高达34%，且在不同时序GNNs和LLMs上表现出强泛化能力。

Conclusion: DyGRASP有效解决了DyTAGs中的时间语义捕捉问题，为动态图与文本融合分析提供了高效解决方案。

Abstract: Dynamic Text-Attribute Graphs (DyTAGs), characterized by time-evolving graph
interactions and associated text attributes, are prevalent in real-world
applications. Existing methods, such as Graph Neural Networks (GNNs) and Large
Language Models (LLMs), mostly focus on static TAGs. Extending these existing
methods to DyTAGs is challenging as they largely neglect the recent-global
temporal semantics: the recent semantic dependencies among interaction texts
and the global semantic evolution of nodes over time. Furthermore, applying
LLMs to the abundant and evolving text in DyTAGs faces efficiency issues. To
tackle these challenges, we propose Dynamic Global-Recent Adaptive Semantic
Processing (DyGRASP), a novel method that leverages LLMs and temporal GNNs to
efficiently and effectively reason on DyTAGs. Specifically, we first design a
node-centric implicit reasoning method together with a sliding window mechanism
to efficiently capture recent temporal semantics. In addition, to capture
global semantic dynamics of nodes, we leverage explicit reasoning with tailored
prompts and an RNN-like chain structure to infer long-term semantics. Lastly,
we intricately integrate the recent and global temporal semantics as well as
the dynamic graph structural information using updating and merging layers.
Extensive experiments on DyTAG benchmarks demonstrate DyGRASP's superiority,
achieving up to 34% improvement in Hit@10 for destination node retrieval task.
Besides, DyGRASP exhibits strong generalization across different temporal GNNs
and LLMs.

</details>


### [32] [False Friends Are Not Foes: Investigating Vocabulary Overlap in Multilingual Language Models](https://arxiv.org/abs/2509.18750)
*Julie Kallini,Dan Jurafsky,Christopher Potts,Martijn Bartelds*

Main category: cs.CL

TL;DR: 该研究通过控制实验探讨了多语言分词器中词汇重叠对跨语言迁移的影响，发现词汇重叠有助于跨语言语义关系的捕获，并能提升模型在跨语言任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 先前关于多语言分词器中词汇重叠对跨语言迁移影响的研究结果不一致，部分原因是实验设置和混杂因素（如词频、分词粒度）的差异。本研究旨在通过控制实验明确词汇重叠的作用。

Method: 设计控制实验，在多种语言对上训练双语自回归模型，系统性地改变词汇重叠设置。特别关注跨语言共享词汇的语义相似性这一新维度，分析模型的隐藏表示。

Result: 研究发现任何类型的词汇重叠都能创建捕获跨语言语义关系的嵌入空间，而词汇不重叠的模型效果较弱。在XNLI和XQuAD任务上，有重叠词汇的模型表现优于无重叠模型，且随着重叠增加，迁移性能普遍提升。

Conclusion: 词汇重叠在多语言模型中具有优势，保持大量共享词汇仍然是多语言分词器的有益设计选择。

Abstract: Subword tokenizers trained on multilingual corpora naturally produce
overlapping tokens across languages. Does token overlap facilitate
cross-lingual transfer or instead introduce interference between languages?
Prior work offers mixed evidence, partly due to varied setups and confounders,
such as token frequency or subword segmentation granularity. To address this
question, we devise a controlled experiment where we train bilingual
autoregressive models on multiple language pairs under systematically varied
vocabulary overlap settings. Crucially, we explore a new dimension to
understanding how overlap affects transfer: the semantic similarity of tokens
shared across languages. We first analyze our models' hidden representations
and find that overlap of any kind creates embedding spaces that capture
cross-lingual semantic relationships, while this effect is much weaker in
models with disjoint vocabularies. On XNLI and XQuAD, we find that models with
overlap outperform models with disjoint vocabularies, and that transfer
performance generally improves as overlap increases. Overall, our findings
highlight the advantages of token overlap in multilingual models and show that
substantial shared vocabulary remains a beneficial design choice for
multilingual tokenizers.

</details>


### [33] [When Long Helps Short: How Context Length in Supervised Fine-tuning Affects Behavior of Large Language Models](https://arxiv.org/abs/2509.18762)
*Yingming Zheng,Hanqi Li,Kai Yu,Lu Chen*

Main category: cs.CL

TL;DR: 本文研究发现，与长上下文预训练导致短上下文任务性能下降不同，长上下文监督微调（SFT）反而能提升短上下文任务性能。通过分析多头注意力（MHA）和前馈网络（FFN）的作用机制，揭示了长上下文SFT偏好上下文知识，而短上下文SFT偏好参数知识，混合训练可缓解这种偏差。


<details>
  <summary>Details</summary>
Motivation: 随着现实应用对长上下文窗口需求增加，长上下文数据的持续预训练和SFT成为常见方法。虽然数据长度在持续预训练中的影响已有研究，但其在SFT中的影响尚不明确，需要系统研究SFT数据长度如何影响LLM在短上下文任务中的行为。

Method: 系统研究SFT数据长度对LLM短上下文任务性能的影响，解耦分析MHA和FFN两个关键组件的作用，研究它们之间的交互，并揭示知识偏好偏差机制。

Result: 发现长上下文SFT能提升短上下文性能，MHA和FFN均独立受益于长上下文SFT。长上下文SFT促进上下文知识，短上下文SFT偏好参数知识，仅依赖长上下文SFT并非最优。

Conclusion: 混合训练可以缓解知识偏好偏差，为LLM微调提供了可解释的指导。这一发现挑战了长上下文训练必然损害短上下文性能的传统认知。

Abstract: Large language models (LLMs) have achieved impressive performance across
natural language processing (NLP) tasks. As real-world applications
increasingly demand longer context windows, continued pretraining and
supervised fine-tuning (SFT) on long-context data has become a common approach.
While the effects of data length in continued pretraining have been extensively
studied, their implications for SFT remain unclear. In this work, we
systematically investigate how SFT data length influences LLM behavior on
short-context tasks. Counterintuitively, we find that long-context SFT improves
short-context performance, contrary to the commonly observed degradation from
long-context pretraining. To uncover the underlying mechanisms of this
phenomenon, we first decouple and analyze two key components, Multi-Head
Attention (MHA) and Feed-Forward Network (FFN), and show that both
independently benefit from long-context SFT. We further study their interaction
and reveal a knowledge preference bias: long-context SFT promotes contextual
knowledge, while short-context SFT favors parametric knowledge, making
exclusive reliance on long-context SFT suboptimal. Finally, we demonstrate that
hybrid training mitigates this bias, offering explainable guidance for
fine-tuning LLMs.

</details>


### [34] [Financial Risk Relation Identification through Dual-view Adaptation](https://arxiv.org/abs/2509.18775)
*Wei-Ning Chiu,Yu-Hsiang Wang,Andy Hsiao,Yu-Shiang Huang,Chuan-Ju Wang*

Main category: cs.CL

TL;DR: 提出一种从10-K文件中提取企业间风险关系的系统性方法，使用自然语言处理技术基于时间顺序和词汇模式进行无监督微调，开发领域特定的金融编码器。


<details>
  <summary>Details</summary>
Motivation: 传统依赖专家判断和手动分析企业间风险关系的方法主观、劳动密集且难以扩展，需要更系统、可量化的解决方案。

Method: 利用10-K文件作为数据源，通过自然语言处理技术基于时间顺序和词汇模式进行无监督微调，开发领域特定的金融编码器，并引入定量风险关系评分。

Result: 大量实验表明，该方法在多个评估设置中优于强基线模型。

Conclusion: 该方法能够有效识别企业间隐含和抽象的风险联系，为投资组合管理和投资策略等应用提供透明、可解释的分析工具。

Abstract: A multitude of interconnected risk events -- ranging from regulatory changes
to geopolitical tensions -- can trigger ripple effects across firms.
Identifying inter-firm risk relations is thus crucial for applications like
portfolio management and investment strategy. Traditionally, such assessments
rely on expert judgment and manual analysis, which are, however, subjective,
labor-intensive, and difficult to scale. To address this, we propose a
systematic method for extracting inter-firm risk relations using Form 10-K
filings -- authoritative, standardized financial documents -- as our data
source. Leveraging recent advances in natural language processing, our approach
captures implicit and abstract risk connections through unsupervised
fine-tuning based on chronological and lexical patterns in the filings. This
enables the development of a domain-specific financial encoder with a deeper
contextual understanding and introduces a quantitative risk relation score for
transparency, interpretable analysis. Extensive experiments demonstrate that
our method outperforms strong baselines across multiple evaluation settings.

</details>


### [35] [AECBench: A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field](https://arxiv.org/abs/2509.18776)
*Chen Liang,Zhaoqi Huang,Haofen Wang,Fu Chai,Chunying Yu,Huanhuan Wei,Zhengjie Liu,Yanpeng Li,Hongjun Wang,Ruifeng Luo,Xianzhong Zhao*

Main category: cs.CL

TL;DR: 本文建立了AECBench基准测试，用于评估大语言模型在建筑、工程和施工领域的性能表现，发现模型在高级认知任务上存在显著性能缺陷。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在安全关键的建筑工程领域的鲁棒性和可靠性，因为该领域对模型性能有特殊要求。

Method: 建立包含23个代表性任务的五级认知评估框架，创建4800个问题的数据集，采用LLM-as-a-Judge方法评估复杂长文本回答。

Result: 评估9个LLM显示，模型在知识记忆和理解层面表现良好，但在表格知识解释、复杂推理计算和领域文档生成方面存在显著性能下降。

Conclusion: 该研究为未来在安全关键工程实践中可靠集成LLM奠定了基础，揭示了当前模型在高级认知任务上的局限性。

Abstract: Large language models (LLMs), as a novel information technology, are seeing
increasing adoption in the Architecture, Engineering, and Construction (AEC)
field. They have shown their potential to streamline processes throughout the
building lifecycle. However, the robustness and reliability of LLMs in such a
specialized and safety-critical domain remain to be evaluated. To address this
challenge, this paper establishes AECBench, a comprehensive benchmark designed
to quantify the strengths and limitations of current LLMs in the AEC domain.
The benchmark defines 23 representative tasks within a five-level
cognition-oriented evaluation framework encompassing Knowledge Memorization,
Understanding, Reasoning, Calculation, and Application. These tasks were
derived from authentic AEC practice, with scope ranging from codes retrieval to
specialized documents generation. Subsequently, a 4,800-question dataset
encompassing diverse formats, including open-ended questions, was crafted
primarily by engineers and validated through a two-round expert review.
Furthermore, an LLM-as-a-Judge approach was introduced to provide a scalable
and consistent methodology for evaluating complex, long-form responses
leveraging expert-derived rubrics. Through the evaluation of nine LLMs, a clear
performance decline across five cognitive levels was revealed. Despite
demonstrating proficiency in foundational tasks at the Knowledge Memorization
and Understanding levels, the models showed significant performance deficits,
particularly in interpreting knowledge from tables in building codes, executing
complex reasoning and calculation, and generating domain-specific documents.
Consequently, this study lays the groundwork for future research and
development aimed at the robust and reliable integration of LLMs into
safety-critical engineering practices.

</details>


### [36] [Beyond the Leaderboard: Understanding Performance Disparities in Large Language Models via Model Diffing](https://arxiv.org/abs/2509.18792)
*Sabri Boughorbel,Fahim Dalvi,Nadir Durrani,Majd Hawasly*

Main category: cs.CL

TL;DR: 本文使用模型差异分析（model diffing）方法比较Gemma-2-9b-it模型与其SimPO增强变体，发现SimPO主要提升了安全性、多语言能力和指令跟随能力，同时减少了模型自引用和幻觉管理。


<details>
  <summary>Details</summary>
Motivation: 随着微调成为改进大语言模型的主要方法，理解微调过程中的具体变化变得日益重要。传统基准测试往往无法解释为什么一个模型优于另一个。

Method: 采用模型差异分析（一种机制可解释性方法），使用crosscoders识别和分类两个模型之间的潜在表示差异。

Result: SimPO获得的潜在概念主要增强了安全机制（+32.8%）、多语言能力（+43.8%）和指令跟随（+151.7%），同时减少了模型自引用（-44.1%）和幻觉管理（-68.5%）。

Conclusion: 模型差异分析能够提供超越排行榜指标的细粒度见解，将性能差距归因于具体的机制能力，为比较LLMs提供了透明和有针对性的框架。

Abstract: As fine-tuning becomes the dominant paradigm for improving large language
models (LLMs), understanding what changes during this process is increasingly
important. Traditional benchmarking often fails to explain why one model
outperforms another. In this work, we use model diffing, a mechanistic
interpretability approach, to analyze the specific capability differences
between Gemma-2-9b-it and a SimPO-enhanced variant. Using crosscoders, we
identify and categorize latent representations that differentiate the two
models. We find that SimPO acquired latent concepts predominantly enhance
safety mechanisms (+32.8%), multilingual capabilities (+43.8%), and
instruction-following (+151.7%), while its additional training also reduces
emphasis on model self-reference (-44.1%) and hallucination management
(-68.5%). Our analysis shows that model diffing can yield fine-grained insights
beyond leaderboard metrics, attributing performance gaps to concrete
mechanistic capabilities. This approach offers a transparent and targeted
framework for comparing LLMs.

</details>


### [37] [MAPEX: A Multi-Agent Pipeline for Keyphrase Extraction](https://arxiv.org/abs/2509.18813)
*Liting Zhang,Shiwan Zhao,Aobo Kong,Qicheng Li*

Main category: cs.CL

TL;DR: MAPEX是一个用于关键词提取的多智能体协作框架，通过动态适应文档长度的双路径策略，在多个基准数据集上超越了现有最先进的非监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于提示的非监督方法通常采用单阶段推理流程和统一提示策略，无法充分利用LLMs的推理和生成能力，特别是在处理不同长度文档的复杂关键词提取场景时。

Method: MAPEX引入多智能体协作，包含专家招募、候选提取、主题引导、知识增强和后处理模块，采用双路径策略：知识驱动提取用于短文本，主题引导提取用于长文本。

Result: 在6个基准数据集和3种不同LLMs上的实验表明，MAPEX在F1@5指标上平均比最先进的非监督方法高出2.44%，比标准LLM基线高出4.01%。

Conclusion: MAPEX框架通过多智能体协作和动态适应策略，显著提升了关键词提取的性能，展现了强大的泛化能力和普适性。

Abstract: Keyphrase extraction is a fundamental task in natural language processing.
However, existing unsupervised prompt-based methods for Large Language Models
(LLMs) often rely on single-stage inference pipelines with uniform prompting,
regardless of document length or LLM backbone. Such one-size-fits-all designs
hinder the full exploitation of LLMs' reasoning and generation capabilities,
especially given the complexity of keyphrase extraction across diverse
scenarios. To address these challenges, we propose MAPEX, the first framework
that introduces multi-agent collaboration into keyphrase extraction. MAPEX
coordinates LLM-based agents through modules for expert recruitment, candidate
extraction, topic guidance, knowledge augmentation, and post-processing. A
dual-path strategy dynamically adapts to document length: knowledge-driven
extraction for short texts and topic-guided extraction for long texts.
Extensive experiments on six benchmark datasets across three different LLMs
demonstrate its strong generalization and universality, outperforming the
state-of-the-art unsupervised method by 2.44\% and standard LLM baselines by
4.01\% in F1@5 on average. Code is available at
https://github.com/NKU-LITI/MAPEX.

</details>


### [38] [Are Smaller Open-Weight LLMs Closing the Gap to Proprietary Models for Biomedical Question Answering?](https://arxiv.org/abs/2509.18843)
*Damian Stachura,Joanna Konieczna,Artur Nowak*

Main category: cs.CL

TL;DR: 本文比较了开源大语言模型与专有模型在生物医学问答任务中的表现，发现开源模型在某些情况下甚至能超越闭源模型，特别是在使用集成策略时。


<details>
  <summary>Details</summary>
Motivation: 随着开源大语言模型的快速发展，研究者希望了解小型开源模型是否能够有效替代大型闭源模型，特别是在生物医学问答这一专业领域。

Method: 通过参与BioASQ挑战赛的Task 13B Phase B，使用嵌入距离检索相关片段、上下文学习和结构化输出等技术，并对精确答案问题采用集成方法。

Result: 研究结果表明，开源大语言模型与专有模型表现相当，在某些情况下，特别是应用集成策略时，开源模型甚至超越了闭源模型。

Conclusion: 开源大语言模型在生物医学问答领域具有与专有模型相当的竞争力，集成策略能进一步提升其性能，所有代码已公开。

Abstract: Open-weight versions of large language models (LLMs) are rapidly advancing,
with state-of-the-art models like DeepSeek-V3 now performing comparably to
proprietary LLMs. This progression raises the question of whether small
open-weight LLMs are capable of effectively replacing larger closed-source
models. We are particularly interested in the context of biomedical
question-answering, a domain we explored by participating in Task 13B Phase B
of the BioASQ challenge. In this work, we compare several open-weight models
against top-performing systems such as GPT-4o, GPT-4.1, Claude 3.5 Sonnet, and
Claude 3.7 Sonnet. To enhance question answering capabilities, we use various
techniques including retrieving the most relevant snippets based on embedding
distance, in-context learning, and structured outputs. For certain submissions,
we utilize ensemble approaches to leverage the diverse outputs generated by
different models for exact-answer questions. Our results demonstrate that
open-weight LLMs are comparable to proprietary ones. In some instances,
open-weight LLMs even surpassed their closed counterparts, particularly when
ensembling strategies were applied. All code is publicly available at
https://github.com/evidenceprime/BioASQ-13b.

</details>


### [39] [Multi-Hierarchical Feature Detection for Large Language Model Generated Text](https://arxiv.org/abs/2509.18862)
*Luyan Zhang,Xinyu Xie*

Main category: cs.CL

TL;DR: 本文系统研究了多层级特征集成在AI文本检测中的效果，发现尽管理论上多特征方法应能提升检测性能，但实际实验表明多特征集成仅带来微小改进（0.4-0.5%），却产生显著计算开销（4.2倍），表明现代神经网络模型可能已有效捕获大部分检测信号。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型技术的快速发展，研究者对多特征方法是否能显著超越单一神经模型在AI文本检测方面的表现产生兴趣。虽然直觉上语义、句法和统计特征的结合应能提供互补信号，但这一假设尚未在现代LLM生成文本上得到严格验证。

Method: 实现MHFD（多层级特征检测）方法，通过自适应融合集成基于DeBERTa的语义分析、句法解析和统计概率特征。

Result: 在多个基准数据集上的实验结果表明，MHFD方法在域内检测中达到89.7%的准确率，在跨域检测中保持84.2%的稳定性能，相比现有方法有0.4-2.6%的微小改进。

Conclusion: 多特征集成虽然理论上具有优势，但实际应用中带来的性能提升有限且计算成本高昂，表明现代神经网络语言模型可能已经高效地捕获了大部分相关检测信号。

Abstract: With the rapid advancement of large language model technology, there is
growing interest in whether multi-feature approaches can significantly improve
AI text detection beyond what single neural models achieve. While intuition
suggests that combining semantic, syntactic, and statistical features should
provide complementary signals, this assumption has not been rigorously tested
with modern LLM-generated text. This paper provides a systematic empirical
investigation of multi-hierarchical feature integration for AI text detection,
specifically testing whether the computational overhead of combining multiple
feature types is justified by performance gains. We implement MHFD
(Multi-Hierarchical Feature Detection), integrating DeBERTa-based semantic
analysis, syntactic parsing, and statistical probability features through
adaptive fusion. Our investigation reveals important negative results: despite
theoretical expectations, multi-feature integration provides minimal benefits
(0.4-0.5% improvement) while incurring substantial computational costs (4.2x
overhead), suggesting that modern neural language models may already capture
most relevant detection signals efficiently. Experimental results on multiple
benchmark datasets demonstrate that the MHFD method achieves 89.7% accuracy in
in-domain detection and maintains 84.2% stable performance in cross-domain
detection, showing modest improvements of 0.4-2.6% over existing methods.

</details>


### [40] [Diversity Boosts AI-Generated Text Detection](https://arxiv.org/abs/2509.18880)
*Advik Raj Basani,Pin-Yu Chen*

Main category: cs.CL

TL;DR: DivEye是一个新颖的AI文本检测框架，通过基于惊讶度的特征捕捉文本中不可预测性的波动，在检测AI生成文本方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在教育、商业合规、新闻和社交媒体中的滥用增加，检测AI生成文本变得日益重要。现有检测器通常依赖token级似然度或不透明的黑盒分类器，这些方法在面对高质量生成文本时效果不佳且缺乏可解释性。

Method: DivEye捕捉人类撰写文本比LLM输出在词汇和结构不可预测性上表现出更丰富变异性这一观察，通过一组可解释的统计特征来捕获这一信号。

Result: DivEye在多个基准测试中比现有零样本检测器性能提升高达33.2%，与微调基线模型性能相当。该方法对改写和对抗攻击具有鲁棒性，跨领域和模型泛化能力强，作为辅助信号可将现有检测器性能提升高达18.7%。

Conclusion: 除了检测功能外，DivEye提供了关于为何标记文本的可解释性见解，指出节奏不可预测性是LLM检测中一个强大且未被充分探索的信号。

Abstract: Detecting AI-generated text is an increasing necessity to combat misuse of
LLMs in education, business compliance, journalism, and social media, where
synthetic fluency can mask misinformation or deception. While prior detectors
often rely on token-level likelihoods or opaque black-box classifiers, these
approaches struggle against high-quality generations and offer little
interpretability. In this work, we propose DivEye, a novel detection framework
that captures how unpredictability fluctuates across a text using
surprisal-based features. Motivated by the observation that human-authored text
exhibits richer variability in lexical and structural unpredictability than LLM
outputs, DivEye captures this signal through a set of interpretable statistical
features. Our method outperforms existing zero-shot detectors by up to 33.2%
and achieves competitive performance with fine-tuned baselines across multiple
benchmarks. DivEye is robust to paraphrasing and adversarial attacks,
generalizes well across domains and models, and improves the performance of
existing detectors by up to 18.7% when used as an auxiliary signal. Beyond
detection, DivEye provides interpretable insights into why a text is flagged,
pointing to rhythmic unpredictability as a powerful and underexplored signal
for LLM detection.

</details>


### [41] [Extractive Fact Decomposition for Interpretable Natural Language Inference in one Forward Pass](https://arxiv.org/abs/2509.18901)
*Nicholas Popovič,Michael Färber*

Main category: cs.CL

TL;DR: JEDI是一种仅使用编码器的架构，联合执行提取式原子事实分解和可解释推理，无需在推理时使用生成模型，在NLI任务中实现了竞争性的准确性和更好的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖资源密集型的生成式大语言模型进行原子事实分解，需要更高效且可解释的解决方案。

Method: 提出JEDI编码器架构，使用合成理性语料库进行训练，联合执行提取式原子事实分解和可解释推理。

Result: JEDI在分布内达到竞争性准确率，在分布外和对抗性设置中显著提高了鲁棒性。

Conclusion: 研究表明使用仅编码器架构和合成理性可以实现NLI中的可解释性和鲁棒泛化。

Abstract: Recent works in Natural Language Inference (NLI) and related tasks, such as
automated fact-checking, employ atomic fact decomposition to enhance
interpretability and robustness. For this, existing methods rely on
resource-intensive generative large language models (LLMs) to perform
decomposition. We propose JEDI, an encoder-only architecture that jointly
performs extractive atomic fact decomposition and interpretable inference
without requiring generative models during inference. To facilitate training,
we produce a large corpus of synthetic rationales covering multiple NLI
benchmarks. Experimental results demonstrate that JEDI achieves competitive
accuracy in distribution and significantly improves robustness out of
distribution and in adversarial settings over models based solely on extractive
rationale supervision. Our findings show that interpretability and robust
generalization in NLI can be realized using encoder-only architectures and
synthetic rationales. Code and data available at https://jedi.nicpopovic.com

</details>


### [42] [DTW-Align: Bridging the Modality Gap in End-to-End Speech Translation with Dynamic Time Warping Alignment](https://arxiv.org/abs/2509.18987)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 本文提出了一种使用动态时间规整（DTW）来对齐语音和文本嵌入的方法，用于端到端语音翻译（E2E-ST），解决了模态差距问题，并在低资源设置下表现出色。


<details>
  <summary>Details</summary>
Motivation: 端到端语音翻译中，语音和文本模态之间的表示差异（模态差距）是一个关键挑战。现有方法需要对齐工具，但并非所有语言都可用，而基于最近邻相似度搜索的对齐方法准确性不足。

Method: 在训练过程中采用动态时间规整（DTW）来对齐语音和文本嵌入，无需依赖外部对齐工具，能够更准确地处理模态差距。

Result: 该方法在E2E-ST任务中产生了更准确的对齐结果，性能与之前工作相当但速度显著更快，在低资源设置的6个语言方向中有5个表现优于之前工作。

Conclusion: DTW方法有效解决了E2E-ST中的模态差距问题，特别是在资源有限的语言环境中具有优势，为跨模态对齐提供了更高效的解决方案。

Abstract: End-to-End Speech Translation (E2E-ST) is the task of translating source
speech directly into target text bypassing the intermediate transcription step.
The representation discrepancy between the speech and text modalities has
motivated research on what is known as bridging the modality gap.
State-of-the-art methods addressed this by aligning speech and text
representations on the word or token level. Unfortunately, this requires an
alignment tool that is not available for all languages. Although this issue has
been addressed by aligning speech and text embeddings using nearest-neighbor
similarity search, it does not lead to accurate alignments. In this work, we
adapt Dynamic Time Warping (DTW) for aligning speech and text embeddings during
training. Our experiments demonstrate the effectiveness of our method in
bridging the modality gap in E2E-ST. Compared to previous work, our method
produces more accurate alignments and achieves comparable E2E-ST results while
being significantly faster. Furthermore, our method outperforms previous work
in low resource settings on 5 out of 6 language directions.

</details>


### [43] [Investigating Test-Time Scaling with Reranking for Machine Translation](https://arxiv.org/abs/2509.19020)
*Shaomu Tan,Ryosuke Mitani,Ritvik Choudhary,Toshiyuki Sekiya*

Main category: cs.CL

TL;DR: 本文首次系统研究了测试时缩放（TTS）在机器翻译中的应用，通过best-of-N框架在WMT24基准测试上验证了TTS对翻译质量的提升效果，并分析了不同模型大小和计算预算下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 传统通过增加模型参数来提升NLP系统性能的方法计算成本高昂，测试时缩放（TTS）通过在推理时分配更多计算资源（生成多个候选并选择最佳）提供了替代方案，但在机器翻译领域尚未得到系统研究。

Method: 采用简单实用的best-of-N框架，在WMT24基准上进行了系统实验，覆盖6个高资源语言对和1个低资源语言对，5种模型规模（3B-72B），以及不同的TTS计算预算（N最大到1024）。

Result: a) 对于高资源语言，TTS能根据多种神经机器翻译评估指标提升翻译质量，人工评估也确认了这一增益；b) 用大N增强小模型可以匹配或超越N=1时的大模型，但计算成本更高；c) 在固定计算预算下，大模型通常更高效，而在低资源情况下TTS可能因评估指标盲点而降低质量。

Conclusion: TTS为机器翻译提供了有效的性能提升途径，特别是在高资源语言对中，但需要权衡计算成本与性能增益，且在低资源情况下需谨慎使用。

Abstract: Scaling model parameters has become the de facto strategy for improving NLP
systems, but it comes with substantial computational costs. Test-Time Scaling
(TTS) offers an alternative by allocating more computation at inference:
generating multiple candidates and selecting the best. While effective in tasks
such as mathematical reasoning, TTS has not been systematically explored for
machine translation (MT). In this paper, we present the first systematic study
of TTS for MT, investigating a simple but practical best-of-N framework on
WMT24 benchmarks. Our experiments cover six high-resource and one low-resource
language pairs, five model sizes (3B-72B), and various TTS compute budget (N up
to 1024). Our results show that a) For high-resource languages, TTS generally
improves translation quality according to multiple neural MT evaluation
metrics, and our human evaluation confirms these gains; b) Augmenting smaller
models with large $N$ can match or surpass larger models at $N{=}1$ with more
compute cost; c) Under fixed compute budgets, larger models are typically more
efficient, and TTS can degrade quality due to metric blind spots in
low-resource cases.

</details>


### [44] [Charting a Decade of Computational Linguistics in Italy: The CLiC-it Corpus](https://arxiv.org/abs/2509.19033)
*Chiara Alzetta,Serena Auriemma,Alessandro Bondielli,Luca Dini,Chiara Fazzone,Alessio Miaschi,Martina Miliani,Marta Sartor*

Main category: cs.CL

TL;DR: 本文分析了意大利计算语言学和自然语言处理社区过去十年的研究趋势，通过分析CLiC-it会议（2014-2024）的论文内容，追踪了从词汇语义资源到语言建模和多模态研究的转变。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer大语言模型的出现，计算语言学和自然语言处理领域发生了快速演变，需要跟踪意大利研究社区的研究趋势变化，为未来研究方向提供参考。

Method: 将CLiC-it会议前10届（2014-2024）的论文集编译成CLiC-it语料库，分析论文元数据（作者来源、性别、机构等）和内容主题。

Result: 研究发现研究重点从词汇语义资源转向语言建模和多模态研究，反映了领域的技术发展轨迹。

Conclusion: 该研究为意大利和国际研究社区提供了对新兴趋势和关键发展的宝贵见解，支持该领域的明智决策和未来方向。

Abstract: Over the past decade, Computational Linguistics (CL) and Natural Language
Processing (NLP) have evolved rapidly, especially with the advent of
Transformer-based Large Language Models (LLMs). This shift has transformed
research goals and priorities, from Lexical and Semantic Resources to Language
Modelling and Multimodality. In this study, we track the research trends of the
Italian CL and NLP community through an analysis of the contributions to
CLiC-it, arguably the leading Italian conference in the field. We compile the
proceedings from the first 10 editions of the CLiC-it conference (from 2014 to
2024) into the CLiC-it Corpus, providing a comprehensive analysis of both its
metadata, including author provenance, gender, affiliations, and more, as well
as the content of the papers themselves, which address various topics. Our goal
is to provide the Italian and international research communities with valuable
insights into emerging trends and key developments over time, supporting
informed decisions and future directions in the field.

</details>


### [45] [Pathways of Thoughts: Multi-Directional Thinking for Long-form Personalized Question Answering](https://arxiv.org/abs/2509.19094)
*Alireza Salemi,Cheng Li,Mingyang Zhang,Qiaozhu Mei,Zhuowan Li,Spurthi Amba Hombaiah,Weize Kong,Tao Chen,Hamed Zamani,Michael Bendersky*

Main category: cs.CL

TL;DR: PoT是一种无需微调的推理阶段方法，通过建模LLM的迭代决策过程，动态选择认知操作来生成多样化候选回答，并根据用户偏好聚合得到个性化响应。


<details>
  <summary>Details</summary>
Motivation: 个性化问答系统面临从长、嘈杂、隐式上下文中推断偏好，以及生成同时正确、上下文适当且符合用户期望和背景知识的响应的挑战。

Method: 提出思想路径（PoT）方法，将LLM推理建模为迭代决策过程，动态选择推理、修订、个性化和澄清等认知操作，探索多种推理轨迹生成候选回答，然后根据推断的用户偏好进行聚合和重加权。

Result: 在LaMP-QA个性化问答基准测试中，PoT始终优于竞争基线，相对改进高达13.1%。人工评估显示66%的情况下标注者偏好PoT输出，仅15%为平局。

Conclusion: PoT方法有效解决了个性化问答的挑战，通过多样化推理路径的互补优势生成高质量的个性化响应。

Abstract: Personalization is essential for adapting question answering (QA) systems to
user-specific information needs, thereby improving both accuracy and user
satisfaction. However, personalized QA remains relatively underexplored due to
challenges such as inferring preferences from long, noisy, and implicit
contexts, and generating responses that are simultaneously correct,
contextually appropriate, and aligned with user expectations and background
knowledge. To address these challenges, we propose Pathways of Thoughts (PoT),
an inference-stage method that applies to any large language model (LLM)
without requiring task-specific fine-tuning. The approach models the reasoning
of an LLM as an iterative decision process, where the model dynamically selects
among cognitive operations such as reasoning, revision, personalization, and
clarification. This enables exploration of multiple reasoning trajectories,
producing diverse candidate responses that capture different perspectives. PoT
then aggregates and reweights these candidates according to inferred user
preferences, yielding a final personalized response that benefits from the
complementary strengths of diverse reasoning paths. Experiments on the LaMP-QA
benchmark for personalized QA show that PoT consistently outperforms
competitive baselines, achieving up to a 13.1% relative improvement. Human
evaluation corroborates these results, with annotators preferring outputs from
PoT in 66% of cases and reporting ties in only 15% of cases.

</details>


### [46] [Are most sentences unique? An empirical examination of Chomskyan claims](https://arxiv.org/abs/2509.19108)
*Hiram Ring*

Main category: cs.CL

TL;DR: 本文通过实证研究检验了语言学中关于大多数语言表达都是独特的说法，使用NLTK库分析不同体裁语料库中的句子重复情况。


<details>
  <summary>Details</summary>
Motivation: 验证语言学中长期存在的观点——大多数语言表达都是独特的，利用大型语料库进行实证检验。

Method: 使用Python的NLTK库解析不同体裁的语料库，统计每个语料库中完全相同的字符串匹配数量。

Result: 研究发现，虽然完全独特的句子在多数语料库中占主导地位，但这高度依赖于体裁，重复句子在任何语料库中都不是无关紧要的部分。

Conclusion: 语言表达的独特性受到体裁的显著影响，重复句子在语言使用中具有重要地位，挑战了传统语言学观点。

Abstract: A repeated claim in linguistics is that the majority of linguistic utterances
are unique. For example, Pinker (1994: 10), summarizing an argument by Noam
Chomsky, states that "virtually every sentence that a person utters or
understands is a brand-new combination of words, appearing for the first time
in the history of the universe." With the increased availability of large
corpora, this is a claim that can be empirically investigated. The current
paper addresses the question by using the NLTK Python library to parse corpora
of different genres, providing counts of exact string matches in each. Results
show that while completely unique sentences are often the majority of corpora,
this is highly constrained by genre, and that duplicate sentences are not an
insignificant part of any individual corpus.

</details>


### [47] [Human-Annotated NER Dataset for the Kyrgyz Language](https://arxiv.org/abs/2509.19109)
*Timur Turatali,Anton Alekseev,Gulira Jumalieva,Gulnara Kabaeva,Sergey Nikolenko*

Main category: cs.CL

TL;DR: 本文介绍了首个吉尔吉斯语命名实体识别数据集KyrgyzNER，包含1,499篇新闻文章、10,900个句子和39,075个实体提及，涵盖27个实体类别。作者评估了多种NER模型，发现多语言RoBERTa模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 为资源有限的吉尔吉斯语创建首个手动标注的命名实体识别数据集，填补该语言在NLP领域的空白。

Method: 构建包含27个实体类别的标注方案，使用传统序列标注方法（如条件随机场）和基于多语言transformer的预训练模型进行对比评估。

Result: 所有模型在罕见实体类别上都表现困难，但多语言RoBERTa变体在精确率和召回率之间取得了有希望的平衡。多语言预训练模型整体表现相当。

Conclusion: 研究强调了使用多语言预训练模型处理资源有限语言的挑战和机遇，建议未来工作探索更细粒度的标注方案以提供更深入的见解。

Abstract: We introduce KyrgyzNER, the first manually annotated named entity recognition
dataset for the Kyrgyz language. Comprising 1,499 news articles from the 24.KG
news portal, the dataset contains 10,900 sentences and 39,075 entity mentions
across 27 named entity classes. We show our annotation scheme, discuss the
challenges encountered in the annotation process, and present the descriptive
statistics. We also evaluate several named entity recognition models, including
traditional sequence labeling approaches based on conditional random fields and
state-of-the-art multilingual transformer-based models fine-tuned on our
dataset. While all models show difficulties with rare entity categories, models
such as the multilingual RoBERTa variant pretrained on a large corpus across
many languages achieve a promising balance between precision and recall. These
findings emphasize both the challenges and opportunities of using multilingual
pretrained models for processing languages with limited resources. Although the
multilingual RoBERTa model performed best, other multilingual models yielded
comparable results. This suggests that future work exploring more granular
annotation schemes may offer deeper insights for Kyrgyz language processing
pipelines evaluation.

</details>


### [48] [Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering](https://arxiv.org/abs/2509.19125)
*Kun Zhu,Lizi Liao,Yuxuan Gu,Lei Huang,Xiaocheng Feng,Bing Qin*

Main category: cs.CL

TL;DR: 提出了一种新的上下文感知层次化分类法生成框架，结合LLM引导的多方面编码和动态聚类，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 科学文献快速增长需要高效的组织和综合方法，现有分类法构建方法缺乏连贯性和粒度

Method: 利用LLM识别论文关键方面并生成方面特定摘要，然后进行编码和聚类形成层次结构

Result: 在包含11.6k论文的156个专家构建分类法基准上，方法在连贯性、粒度和可解释性方面达到最先进性能

Conclusion: 该方法为科学文献组织提供了有效的层次化分类法生成解决方案

Abstract: The rapid growth of scientific literature demands efficient methods to
organize and synthesize research findings. Existing taxonomy construction
methods, leveraging unsupervised clustering or direct prompting of large
language models (LLMs), often lack coherence and granularity. We propose a
novel context-aware hierarchical taxonomy generation framework that integrates
LLM-guided multi-aspect encoding with dynamic clustering. Our method leverages
LLMs to identify key aspects of each paper (e.g., methodology, dataset,
evaluation) and generates aspect-specific paper summaries, which are then
encoded and clustered along each aspect to form a coherent hierarchy. In
addition, we introduce a new evaluation benchmark of 156 expert-crafted
taxonomies encompassing 11.6k papers, providing the first naturally annotated
dataset for this task. Experimental results demonstrate that our method
significantly outperforms prior approaches, achieving state-of-the-art
performance in taxonomy coherence, granularity, and interpretability.

</details>


### [49] [Anecdoctoring: Automated Red-Teaming Across Language and Place](https://arxiv.org/abs/2509.19143)
*Alejandro Cuevas,Saloni Dash,Bharat Kumar Nayak,Dan Vann,Madeleine I. G. Daepp*

Main category: cs.CL

TL;DR: 提出了一种名为"anecdoctoring"的新型红队测试方法，通过自动生成跨语言和跨文化的对抗性提示来评估生成式AI的虚假信息风险。该方法在英语、西班牙语和印地语三种语言上表现出更高的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的滥用风险中，虚假信息是主要威胁之一。当前的红队测试数据集通常以美国英语为中心，缺乏对多样语言和文化的鲁棒性评估。

Method: 从三个语言（英语、西班牙语、印地语）和两个地区（美国和印度）的事实核查网站收集虚假信息声明，将其聚类为更广泛的叙述，并使用知识图谱增强攻击者LLM。

Result: 该方法相比少样本提示产生了更高的攻击成功率，并提供了更好的可解释性优势。

Conclusion: 研究结果强调了需要基于真实世界对抗性滥用的、能够全球扩展的虚假信息缓解措施。

Abstract: Disinformation is among the top risks of generative artificial intelligence
(AI) misuse. Global adoption of generative AI necessitates red-teaming
evaluations (i.e., systematic adversarial probing) that are robust across
diverse languages and cultures, but red-teaming datasets are commonly US- and
English-centric. To address this gap, we propose "anecdoctoring", a novel
red-teaming approach that automatically generates adversarial prompts across
languages and cultures. We collect misinformation claims from fact-checking
websites in three languages (English, Spanish, and Hindi) and two geographies
(US and India). We then cluster individual claims into broader narratives and
characterize the resulting clusters with knowledge graphs, with which we
augment an attacker LLM. Our method produces higher attack success rates and
offers interpretability benefits relative to few-shot prompting. Results
underscore the need for disinformation mitigations that scale globally and are
grounded in real-world adversarial misuse.

</details>


### [50] [Measuring AI "Slop" in Text](https://arxiv.org/abs/2509.19163)
*Chantal Shaib,Tuhin Chakrabarty,Diego Garcia-Olano,Byron C. Wallace*

Main category: cs.CL

TL;DR: 本文提出了AI 'slop'（低质量AI生成文本）的分类体系和评估维度，通过专家访谈开发了可解释的评估框架，发现二元判断具有主观性但能与连贯性等维度相关。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对AI生成低质量文本（slop）的统一定义和测量方法，需要建立系统的评估体系。

Method: 通过采访NLP、写作和哲学领域的专家，开发slop的分类法，并进行span级标注分析二元判断与潜在维度的相关性。

Result: 发现二元slop判断具有一定主观性，但与连贯性、相关性等维度存在相关性，提出的框架可用于检测和偏好评估任务。

Conclusion: 该框架为评估AI生成文本质量提供了新视角，有助于理解影响质量判断的语言学和风格因素。

Abstract: AI "slop" is an increasingly popular term used to describe low-quality
AI-generated text, but there is currently no agreed upon definition of this
term nor a means to measure its occurrence. In this work, we develop a taxonomy
of "slop" through interviews with experts in NLP, writing, and philosophy, and
propose a set of interpretable dimensions for its assessment in text. Through
span-level annotation, we find that binary "slop" judgments are (somewhat)
subjective, but such determinations nonetheless correlate with latent
dimensions such as coherence and relevance. Our framework can be used to
evaluate AI-generated text in both detection and binary preference tasks,
potentially offering new insights into the linguistic and stylistic factors
that contribute to quality judgments.

</details>


### [51] [Soft Tokens, Hard Truths](https://arxiv.org/abs/2509.19170)
*Natasha Butt,Ariel Kwiatkowski,Ismail Labiad,Julia Kempe,Yann Ollivier*

Main category: cs.CL

TL;DR: 本文提出了首个通过强化学习学习连续CoT的可扩展方法，无需从离散CoT蒸馏，使用软标记和输入嵌入噪声实现RL探索，在数学推理任务上表现优于离散CoT。


<details>
  <summary>Details</summary>
Motivation: 连续标记在推理LLMs中具有更强的表达能力，但实际应用受限于训练困难，现有方法要么仅在推理时使用连续标记，要么需要从离散CoT蒸馏且计算成本高。

Method: 使用强化学习训练连续CoT，采用软标记（标记混合）和输入嵌入噪声进行探索，计算开销小，可学习数百个标记的连续CoT。

Result: 在Llama和Qwen模型上的数学推理基准测试中，连续CoT训练在pass@1上匹配离散CoT，在pass@32上超越，显示出更大的CoT多样性。最佳方案是训练时使用连续CoT，推理时使用离散标记。

Conclusion: 连续CoT RL训练能更好地保留基础模型在域外任务上的预测，为基模型提供更温和的调整。

Abstract: The use of continuous instead of discrete tokens during the Chain-of-Thought
(CoT) phase of reasoning LLMs has garnered attention recently, based on the
intuition that a continuous mixture of discrete tokens could simulate a
superposition of several reasoning paths simultaneously. Theoretical results
have formally proven that continuous tokens have much greater expressivity and
can solve specific problems more efficiently. However, practical use of
continuous tokens has been limited by strong training difficulties: previous
works either just use continuous tokens at inference time on a pre-trained
discrete-token model, or must distill the continuous CoT from ground-truth
discrete CoTs and face computational costs that limit the CoT to very few
tokens.
  This is the first work introducing a scalable method to learn continuous CoTs
via reinforcement learning (RL), without distilling from reference discrete
CoTs. We use "soft" tokens: mixtures of tokens together with noise on the input
embedding to provide RL exploration. Computational overhead is minimal,
enabling us to learn continuous CoTs with hundreds of tokens. On math reasoning
benchmarks with Llama and Qwen models up to 8B, training with continuous CoTs
match discrete-token CoTs for pass@1 and surpass them for pass@32, showing
greater CoT diversity. In systematic comparisons, the best-performing scenario
is to train with continuous CoT tokens then use discrete tokens for inference,
meaning the "soft" models can be deployed in a standard way. Finally, we show
continuous CoT RL training better preserves the predictions of the base model
on out-of-domain tasks, thus providing a softer touch to the base model.

</details>


### [52] [Online Process Reward Leanring for Agentic Reinforcement Learning](https://arxiv.org/abs/2509.19199)
*Xiaoqian Liu,Ke Wang,Yuchuan Wu,Fei Huang,Yongbin Li,Junge Zhang,Jianbin Jiao*

Main category: cs.CL

TL;DR: OPRL是一种用于智能体强化学习的在线过程奖励学习方法，通过优化隐式过程奖励模型将轨迹偏好转化为步骤奖励，结合结果奖励进行策略更新，解决了稀疏奖励环境中的信用分配问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型作为自主智能体在交互环境中进行长期推理和行动时，稀疏且有时不可验证的奖励使得时间信用分配极具挑战性。现有方法存在标注偏差、奖励攻击、方差过大等问题。

Method: OPRL交替优化隐式过程奖励模型和智能体策略，通过基于轨迹的DPO目标将轨迹偏好转化为隐式步骤奖励，然后结合结果奖励计算步骤级优势进行策略更新。

Result: 在WebShop、VisualSokoban和SOTOPIA等基准测试中，OPRL超越了前沿大语言模型和强RL基线，实现了最先进的结果，具有更高的样本效率和更低的训练方差。

Conclusion: OPRL通过理论保证和实证验证，展示了在稀疏奖励环境中进行智能体学习的潜力，能够实现高效探索和稳定训练。

Abstract: Large language models (LLMs) are increasingly trained with reinforcement
learning (RL) as autonomous agents that reason and act over long horizons in
interactive environments.
  However, sparse and sometimes unverifiable rewards make temporal credit
assignment extremely challenging.
  Recent work attempts to integrate process supervision into agent learning but
suffers from biased annotation, reward hacking, high-variance from overly
fine-grained signals or failtures when state overlap is rare.
  We therefore introduce Online Process Reward Learning (OPRL), a general
credit-assignment strategy for agentic RL that integrates seamlessly with
standard on-policy algorithms without relying on additional rollouts or
explicit step labels.
  In OPRL, we optimize an implicit process reward model (PRM) alternately with
the agent's policy to transform trajectory preferences into implicit step
rewards through a trajectory-based DPO objective.
  These step rewards are then used to compute step-level advantages, which are
combined with episode-level advantages from outcome rewards for policy update,
creating a self-reinforcing loop.
  Theoretical findings guarantee that the learned step rewards are consistent
with trajectory preferences and act as potential-based shaping rewards,
providing bounded gradients to stabilize training.
  Empirically, we evaluate OPRL on three distinct agent benmarks, including
WebShop and VisualSokoban, as well as open-ended social interactions with
unverfiable rewards in SOTOPIA.
  Crucially, OPRL shows superior performance over frontier LLMs and strong RL
baselines across domains, achieving state-of-the-art results with higher
sample-efficiency and lower variance during training.
  Further analysis also demonstrates the efficient exploration by OPRL using
fewer actions, underscoring its potential for agentic learning in real-world
scenarios.

</details>


### [53] [Steering Multimodal Large Language Models Decoding for Context-Aware Safety](https://arxiv.org/abs/2509.19212)
*Zheyuan Liu,Zhangchen Xu,Guangyao Dou,Xiangchi Yuan,Zhaoxuan Tan,Radha Poovendran,Meng Jiang*

Main category: cs.CL

TL;DR: SafeCoDe是一个轻量级、模型无关的解码框架，通过对比解码和全局感知令牌调制机制，动态调整多模态大语言模型的安全决策，解决现有方法在过敏感性和欠敏感性之间的平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在安全决策方面存在局限性，无法平衡过敏感（对良性查询的误拒）和欠敏感（对视觉风险的漏检）问题，需要一种能够根据多模态上下文动态调整安全决策的方法。

Method: SafeCoDe采用两阶段方法：1）对比解码机制，通过对比真实图像和高斯噪声图像来识别对视觉上下文敏感的令牌；2）全局感知令牌调制策略，将场景级推理与令牌级调整相结合，根据预测的安全判断自适应地调整拒绝行为。

Result: 在多种MLLM架构和安全基准测试上的广泛实验表明，SafeCoDe能够持续改进上下文敏感的拒绝行为，同时保持模型的有用性。

Conclusion: SafeCoDe框架有效解决了多模态大语言模型在安全对齐方面的挑战，提供了一种轻量级且模型无关的解决方案，显著提升了模型在复杂多模态环境下的安全决策能力。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly deployed in
real-world applications, yet their ability to make context-aware safety
decisions remains limited. Existing methods often fail to balance
oversensitivity (unjustified refusals of benign queries) and undersensitivity
(missed detection of visually grounded risks), leaving a persistent gap in
safety alignment. To address this issue, we introduce Safety-aware Contrastive
Decoding (SafeCoDe), a lightweight and model-agnostic decoding framework that
dynamically adjusts token generation based on multimodal context. SafeCoDe
operates in two stages: (1) a contrastive decoding mechanism that highlights
tokens sensitive to visual context by contrasting real and Gaussian-noised
images, and (2) a global-aware token modulation strategy that integrates
scene-level reasoning with token-level adjustment to adapt refusals according
to the predicted safety verdict. Extensive experiments across diverse MLLM
architectures and safety benchmarks, covering undersensitivity,
oversensitivity, and general safety evaluations, show that SafeCoDe
consistently improves context-sensitive refusal behaviors while preserving
model helpfulness.

</details>


### [54] [Systematic Comparative Analysis of Large Pretrained Language Models on Contextualized Medication Event Extraction](https://arxiv.org/abs/2509.19224)
*Tariq Abdul-Quddoos,Xishuang Dong,Lijun Qian*

Main category: cs.CL

TL;DR: 本研究比较了多种预训练注意力模型在电子健康记录信息提取任务上的表现，发现临床数据预训练的模型在检测药物和药物事件方面更有效，而通用领域预训练的Bert Base在药物相关事件上下文分类方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 基于注意力的模型已成为临床笔记自然语言处理的主要方法，但需要比较不同预训练模型在EHR信息提取任务上的表现，以确定最适合临床应用的模型。

Method: 使用Bert Base、BioBert、Bio+Clinical Bert变体、RoBerta和Clinical Longformer等预训练模型，在CMED数据集上进行微调，执行药物提取、医疗事件检测和多维药物事件上下文分类任务。

Result: 临床数据预训练的模型在检测药物和药物事件方面表现更好，而Bert Base在药物相关事件上下文分类方面效果最佳。

Conclusion: 不同类型的预训练模型在不同临床NLP任务中各有优势，需要根据具体任务需求选择合适的模型。

Abstract: Attention-based models have become the leading approach in modeling medical
language for Natural Language Processing (NLP) in clinical notes. These models
outperform traditional techniques by effectively capturing contextual rep-
resentations of language. In this research a comparative analysis is done
amongst pre- trained attention based models namely Bert Base, BioBert, two
variations of Bio+Clinical Bert, RoBerta, and Clinical Long- former on task
related to Electronic Health Record (EHR) information extraction. The tasks
from Track 1 of Harvard Medical School's 2022 National Clinical NLP Challenges
(n2c2) are considered for this comparison, with the Contextualized Medication
Event Dataset (CMED) given for these task. CMED is a dataset of unstructured
EHRs and annotated notes that contain task relevant information about the EHRs.
The goal of the challenge is to develop effective solutions for extracting
contextual information related to patient medication events from EHRs using
data driven methods. Each pre-trained model is fine-tuned and applied on CMED
to perform medication extraction, medical event detection, and
multi-dimensional medication event context classification. Pro- cessing methods
are also detailed for breaking down EHRs for compatibility with the applied
models. Performance analysis has been carried out using a script based on
constructing medical terms from the evaluation portion of CMED with metrics
including recall, precision, and F1-Score. The results demonstrate that models
pre-trained on clinical data are more effective in detecting medication and
medication events, but Bert Base, pre- trained on general domain data showed to
be the most effective for classifying the context of events related to
medications.

</details>


### [55] [CompLLM: Compression for Long Context Q&A](https://arxiv.org/abs/2509.19228)
*Gabriele Berton,Jayakrishnan Unnikrishnan,Son Tran,Mubarak Shah*

Main category: cs.CL

TL;DR: CompLLM是一种针对长上下文处理的软压缩技术，通过将上下文分割成独立压缩的片段，实现线性复杂度、可扩展性和可重用性，显著提升处理效率。


<details>
  <summary>Details</summary>
Motivation: 现有软上下文压缩方法将整个上下文作为单一单元压缩，导致二次压缩复杂度且无法在重叠上下文的查询间重用计算，限制了实际应用。

Method: 将上下文分割成独立片段分别压缩，支持线性扩展、模型泛化和片段缓存重用。

Result: 在2倍压缩率下，CompLLM在高上下文长度时将首令牌时间加速4倍，KV缓存减少50%，性能与未压缩上下文相当甚至更好。

Conclusion: CompLLM通过分段压缩设计实现了高效、可扩展和可重用的长上下文处理，具有实际部署价值。

Abstract: Large Language Models (LLMs) face significant computational challenges when
processing long contexts due to the quadratic complexity of self-attention.
While soft context compression methods, which map input text to smaller latent
representations, have shown promise, their real-world adoption is limited.
Existing techniques typically compress the context as a single unit, which
leads to quadratic compression complexity and an inability to reuse
computations across queries with overlapping contexts. In this work, we
introduce CompLLM, a soft compression technique designed for practical
deployment. Instead of processing the context holistically, CompLLM divides it
into segments and compresses each one independently. This simple design choice
yields three critical properties: efficiency, as the compression step scales
linearly with the context length; scalability, enabling models trained on short
sequences (e.g., 1k tokens) to generalize to contexts of 100k tokens; and
reusability, allowing compressed segments to be cached and reused across
different queries. Our experiments show that with a 2x compression rate, at
high context lengths CompLLM speeds up Time To First Token (TTFT) by up to 4x
and reduces the KV cache size by 50%. Furthermore, CompLLM achieves performance
comparable to that obtained with the uncompressed context, and even surpasses
it on very long sequences, demonstrating its effectiveness and practical
utility.

</details>


### [56] [Reinforcement Learning on Pre-Training Data](https://arxiv.org/abs/2509.19249)
*Siheng Li,Kejiao Li,Zenan Xu,Guanhua Huang,Evander Yang,Kun Li,Haoyuan Wu,Jiajia Wu,Zihao Zheng,Chenchen Zhang,Kun Shi,Kyrierl Deng,Qi Yi,Ruibin Xiong,Tingqiang Xu,Yuhao Jiang,Jianfeng Yan,Yuyuan Zeng,Guanghui Xu,Jinbao Xue,Zhijiang Xu,Zheng Fang,Shuai Li,Qibin Liu,Xiaoxue Li,Zhuoyu Li,Yangyu Tao,Fei Gao,Cheng Jiang,Bo Chao Wang,Kai Liu,Jianchen Zhu,Wai Lam,Wayyt Wang,Bo Zhou,Di Wang*

Main category: cs.CL

TL;DR: RLPT是一种新的训练时扩展范式，通过强化学习让LLM从预训练数据中自主探索有意义的轨迹来提升能力，无需人工标注奖励信号。


<details>
  <summary>Details</summary>
Motivation: 解决计算资源指数级增长与高质量文本数据有限增长之间的差距，突破传统LLM扩展方法的限制。

Method: 采用下一段推理目标，直接从预训练数据中推导奖励信号，让策略基于前文准确预测后续文本段来获得奖励。

Result: 在多个模型和基准测试中验证有效，如Qwen3-4B-Base在MMLU等基准上获得3.0-8.1分的绝对提升，展现出良好的扩展潜力。

Conclusion: RLPT扩展了LLM的推理边界，为RLVR等后续方法提供了坚实基础，具有持续增益的潜力。

Abstract: The growing disparity between the exponential scaling of computational
resources and the finite growth of high-quality text data now constrains
conventional scaling approaches for large language models (LLMs). To address
this challenge, we introduce Reinforcement Learning on Pre-Training data
(RLPT), a new training-time scaling paradigm for optimizing LLMs. In contrast
to prior approaches that scale training primarily through supervised learning,
RLPT enables the policy to autonomously explore meaningful trajectories to
learn from pre-training data and improve its capability through reinforcement
learning (RL). While existing RL strategies such as reinforcement learning from
human feedback (RLHF) and reinforcement learning with verifiable rewards (RLVR)
rely on human annotation for reward construction, RLPT eliminates this
dependency by deriving reward signals directly from pre-training data.
Specifically, it adopts a next-segment reasoning objective, rewarding the
policy for accurately predicting subsequent text segments conditioned on the
preceding context. This formulation allows RL to be scaled on pre-training
data, encouraging the exploration of richer trajectories across broader
contexts and thereby fostering more generalizable reasoning skills. Extensive
experiments on both general-domain and mathematical reasoning benchmarks across
multiple models validate the effectiveness of RLPT. For example, when applied
to Qwen3-4B-Base, RLPT yields absolute improvements of $3.0$, $5.1$, $8.1$,
$6.0$, $6.6$, and $5.3$ on MMLU, MMLU-Pro, GPQA-Diamond, KOR-Bench, AIME24, and
AIME25, respectively. The results further demonstrate favorable scaling
behavior, suggesting strong potential for continued gains with more compute. In
addition, RLPT provides a solid foundation, extending the reasoning boundaries
of LLMs and enhancing RLVR performance.

</details>


### [57] [Extracting Conceptual Spaces from LLMs Using Prototype Embeddings](https://arxiv.org/abs/2509.19269)
*Nitesh Kumar,Usashi Chatterjee,Steven Schockaert*

Main category: cs.CL

TL;DR: 本文提出了一种从大型语言模型中提取概念空间的方法，通过使用原型描述来编码特征，并通过对LLM进行微调来对齐原型嵌入与概念空间维度。


<details>
  <summary>Details</summary>
Motivation: 概念空间使用认知上有意义的维度来表示实体和概念，在认知科学中被广泛使用，并有望成为可解释AI的基石。然而，概念空间的学习一直很困难，尽管最近的LLM在捕获所需感知特征方面表现出色，但目前仍缺乏提取相应概念空间的实用方法。

Method: 提出一种策略，其中特征通过嵌入相应原型的描述来编码。为了改进这一策略，对LLM进行微调，使原型嵌入与相应的概念空间维度对齐。

Result: 实证分析发现这种方法非常有效。

Conclusion: 通过原型描述编码特征并结合LLM微调的方法，能够有效提取概念空间，为可解释AI提供了实用的解决方案。

Abstract: Conceptual spaces represent entities and concepts using cognitively
meaningful dimensions, typically referring to perceptual features. Such
representations are widely used in cognitive science and have the potential to
serve as a cornerstone for explainable AI. Unfortunately, they have proven
notoriously difficult to learn, although recent LLMs appear to capture the
required perceptual features to a remarkable extent. Nonetheless, practical
methods for extracting the corresponding conceptual spaces are currently still
lacking. While various methods exist for extracting embeddings from LLMs,
extracting conceptual spaces also requires us to encode the underlying
features. In this paper, we propose a strategy in which features (e.g.
sweetness) are encoded by embedding the description of a corresponding
prototype (e.g. a very sweet food). To improve this strategy, we fine-tune the
LLM to align the prototype embeddings with the corresponding conceptual space
dimensions. Our empirical analysis finds this approach to be highly effective.

</details>


### [58] [SloPalSpeech: A 2,8000-Hour Slovak Speech Corpus from Parliamentary Data](https://arxiv.org/abs/2509.19270)
*Erik Božík,Marek Šuppa*

Main category: cs.CL

TL;DR: 本文介绍了SloPalSpeech——一个新的斯洛伐克语ASR数据集，包含2,806小时的议会语音数据，并通过微调Whisper模型显著提升了斯洛伐克语语音识别性能。


<details>
  <summary>Details</summary>
Motivation: 斯洛伐克语等低资源语言的自动语音识别因训练数据稀缺而受到限制，需要构建大规模高质量数据集来解决这一问题。

Method: 开发了稳健的处理流程，将长格式录音对齐和分割成30秒的音频-文本对，并使用该数据集微调多个OpenAI Whisper模型（small、medium、large-v3和large-v3-turbo）。

Result: 在标准斯洛伐克语基准测试中实现了显著的词错误率降低，微调后的Whisper-small模型WER降低了高达70%，接近更大的Whisper-large-v3模型的基线性能。

Conclusion: 公开发布完整的SloPalSpeech数据集、分割后的转录文本（6000万字）和所有微调模型，以促进低资源语音识别的未来研究。

Abstract: Automatic Speech Recognition (ASR) for low-resource languages like Slovak is
hindered by the scarcity of training data. To address this, we introduce
SloPalSpeech, a new, large-scale Slovak ASR dataset containing 2,806 hours of
speech from parliamentary proceedings. We developed a robust processing
pipeline to align and segment long-form recordings into clean, 30-second
audio-transcript pairs suitable for model training. We use this dataset to
fine-tune several OpenAI Whisper models (small, medium, large-v3, and
large-v3-turbo), achieving significant Word Error Rate (WER) reductions on
standard Slovak benchmarks like Common Voice and FLEURS. For instance, the
fine-tuned Whisper-small model's WER dropped by up to 70\%, approaching the
baseline performance of the much larger Whisper-large-v3 model. To foster
future research in low-resource speech recognition, we publicly release the
complete SloPalSpeech dataset, the fully segmented transcripts (60 million
words), and all our fine-tuned models.

</details>


### [59] [WolBanking77: Wolof Banking Speech Intent Classification Dataset](https://arxiv.org/abs/2509.19271)
*Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione*

Main category: cs.CL

TL;DR: 该论文发布了沃洛夫语意图分类数据集WolBanking77，填补了低资源语言意图分类研究的空白，包含9791个文本句子和4小时语音数据，在银行领域进行了基线实验并取得了有希望的结果。


<details>
  <summary>Details</summary>
Motivation: 现有意图分类研究主要关注高资源语言，导致低资源语言和文盲率较高地区（如塞内加尔的沃洛夫语）存在研究空白。沃洛夫语在西非有超过1000万使用者，但缺乏相关数据集。

Method: 构建了沃洛夫语意图分类数据集WolBanking77，包含银行领域的文本和语音数据。对多种基线模型进行了实验，包括文本和语音的SOTA模型。

Result: 在该数据集上取得了有希望的结果，报告了NLP模型的F1分数和ASR模型的词错误率，并进行了模型比较。

Conclusion: 该研究填补了沃洛夫语意图分类的数据空白，为低资源语言研究提供了重要资源，计划持续维护和更新数据集并开源代码。

Abstract: Intent classification models have made a lot of progress in recent years.
However, previous studies primarily focus on high-resource languages datasets,
which results in a gap for low-resource languages and for regions with a high
rate of illiterate people where languages are more spoken than read or written.
This is the case in Senegal, for example, where Wolof is spoken by around 90\%
of the population, with an illiteracy rate of 42\% for the country. Wolof is
actually spoken by more than 10 million people in West African region. To
tackle such limitations, we release a Wolof Intent Classification Dataset
(WolBanking77), for academic research in intent classification. WolBanking77
currently contains 9,791 text sentences in the banking domain and more than 4
hours of spoken sentences. Experiments on various baselines are conducted in
this work, including text and voice state-of-the-art models. The results are
very promising on this current dataset. This paper also provides detailed
analyses of the contents of the data. We report baseline f1-score and word
error rate metrics respectively on NLP and ASR models trained on WolBanking77
dataset and also comparisons between models. We plan to share and conduct
dataset maintenance, updates and to release open-source code.

</details>


### [60] [DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture](https://arxiv.org/abs/2509.19274)
*Arijit Maji,Raghvendra Kumar,Akash Ghosh,Anushka,Nemil Shah,Abhilekh Borah,Vanshika Shah,Nishant Mishra,Sriparna Saha*

Main category: cs.CL

TL;DR: DRISHTIKON是首个专门针对印度文化的多模态多语言基准测试，用于评估生成式AI系统的文化理解能力，涵盖15种语言、所有邦和联邦属地，包含超过64,000个对齐的文本-图像对。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试多为通用性或全球性，缺乏对特定文化（特别是印度文化）的深度覆盖，需要专门的文化理解评估工具来推动包容性AI研究。

Method: 构建了涵盖印度多样文化的多模态数据集，评估了包括开源小/大模型、专有系统、推理专用VLM和印度聚焦模型在内的多种视觉语言模型，在零样本和思维链设置下进行测试。

Result: 当前模型在处理文化基础的多模态输入推理方面存在明显局限，特别是在低资源语言和较少文献记载的传统方面表现不佳。

Conclusion: DRISHTIKON填补了包容性AI研究的重要空白，为推进文化感知、多模态能力的语言技术提供了强大的测试平台。

Abstract: We introduce DRISHTIKON, a first-of-its-kind multimodal and multilingual
benchmark centered exclusively on Indian culture, designed to evaluate the
cultural understanding of generative AI systems. Unlike existing benchmarks
with a generic or global scope, DRISHTIKON offers deep, fine-grained coverage
across India's diverse regions, spanning 15 languages, covering all states and
union territories, and incorporating over 64,000 aligned text-image pairs. The
dataset captures rich cultural themes including festivals, attire, cuisines,
art forms, and historical heritage amongst many more. We evaluate a wide range
of vision-language models (VLMs), including open-source small and large models,
proprietary systems, reasoning-specialized VLMs, and Indic-focused models,
across zero-shot and chain-of-thought settings. Our results expose key
limitations in current models' ability to reason over culturally grounded,
multimodal inputs, particularly for low-resource languages and less-documented
traditions. DRISHTIKON fills a vital gap in inclusive AI research, offering a
robust testbed to advance culturally aware, multimodally competent language
technologies.

</details>
