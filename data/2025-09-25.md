<div id=toc></div>

# Table of Contents

- [cs.IT](#cs.IT) [Total: 5]
- [eess.SP](#eess.SP) [Total: 42]


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [1] [Analyzing α-divergence in Gaussian Rate-Distortion-Perception Theory](https://arxiv.org/abs/2509.19572)
*Martha V. Sourla,Giuseppe Serra,Photios A. Stavrou,Marios Kountouris*

Main category: cs.IT

TL;DR: 该论文研究了高斯源在均方误差失真和α散度感知度量下的信息率失真感知函数估计问题，提出了参数化解决方案并建立了数值计算方法。


<details>
  <summary>Details</summary>
Motivation: 研究信息率失真感知函数对于目标导向的有损压缩和语义信息重建具有重要意义，特别是在高斯源和特定感知度量下的理论分析。

Method: 假设联合高斯RDPF形成凸优化问题，推导出参数化上界解，通过求解α度指数多项式的根来优化参数，并使用二分法进行数值计算。

Result: 建立了RDPF的解析特性，验证了数值结果与理论分析的一致性，并与现有研究成果建立了联系。

Conclusion: 该研究为高斯源在α散度感知度量下的信息率失真感知函数提供了有效的理论分析和数值计算方法。

Abstract: The problem of estimating the information rate distortion perception function
(RDPF), which is a relevant information-theoretic quantity in goal-oriented
lossy compression and semantic information reconstruction, is investigated
here. Specifically, we study the RDPF tradeoff for Gaussian sources subject to
a mean-squared error (MSE) distortion and a perception measure that belongs to
the family of {\alpha} divergences. Assuming a jointly Gaussian RDPF, which
forms a convex optimization problem, we characterize an upper bound for which
we find a parametric solution. We show that evaluating the optimal parameters
of this parametric solution is equivalent to finding the roots of a reduced
exponential polynomial of degree {\alpha}. Additionally, we determine which
disjoint sets contain each root, which enables us to evaluate them numerically
using the well-known bisection method. Finally, we validate our analytical
findings with numerical results and establish connections with existing
results.

</details>


### [2] [Efficient $\varepsilon$-approximate minimum-entropy couplings](https://arxiv.org/abs/2509.19598)
*Spencer Compton*

Main category: cs.IT

TL;DR: 本文提出了一种多项式时间近似方案（PTAS），用于计算多个离散概率分布的最小熵耦合问题，在分布数量m为常数时，能够在多项式时间内获得任意精度的近似解。


<details>
  <summary>Details</summary>
Motivation: 最小熵耦合问题是NP难问题，之前最好的多项式时间算法只能达到常数加性误差（对于m=2约为0.53，对于一般m约为1.22）。一个主要开放问题是该问题是否APX难，或者是否存在PTAS。

Method: 设计了一种算法，在运行时间n^O(poly(1/ε)·exp(m))内产生熵不超过H(OPT)+ε的耦合，其中OPT是最优解。

Result: 证明了对于常数m，存在多项式时间近似方案（PTAS），这是该问题的一个重要理论突破。

Conclusion: 这项工作解决了最小熵耦合问题的一个重要开放问题，表明对于固定数量的分布，该问题存在高效近似算法。

Abstract: Given $m \ge 2$ discrete probability distributions over $n$ states each, the
minimum-entropy coupling is the minimum-entropy joint distribution whose
marginals are the same as the input distributions. Computing the
minimum-entropy coupling is NP-hard, but there has been significant progress in
designing approximation algorithms; prior to this work, the best known
polynomial-time algorithms attain guarantees of the form $H(\operatorname{ALG})
\le H(\operatorname{OPT}) + c$, where $c \approx 0.53$ for $m=2$, and $c
\approx 1.22$ for general $m$ [CKQGK '23].
  A main open question is whether this task is APX-hard, or whether there
exists a polynomial-time approximation scheme (PTAS). In this work, we design
an algorithm that produces a coupling with entropy $H(\operatorname{ALG}) \le
H(\operatorname{OPT}) + \varepsilon$ in running time
$n^{O(\operatorname{poly}(1/\varepsilon) \cdot \operatorname{exp}(m) )}$:
showing a PTAS exists for constant $m$.

</details>


### [3] [Agentic AI for Low-Altitude Semantic Wireless Networks: An Energy Efficient Design](https://arxiv.org/abs/2509.19791)
*Zhouxiang Zhao,Ran Yi,Yihan Cang,Boyang Jin,Zhaohui Yang,Mingzhe Chen,Chongwen Huang,Zhaoyang Zhang*

Main category: cs.IT

TL;DR: 该论文提出了一种基于智能AI的低空语义无线网络框架，通过优化无人机位置、语义压缩比、传输功率等关键参数，解决无人机辅助自主系统中的能效问题，显著降低总能耗。


<details>
  <summary>Details</summary>
Motivation: 解决无人机辅助自主系统中的能量效率问题，提高任务续航能力。传统方法在能量优化方面存在不足，需要更智能的解决方案来协调感知-通信-决策-控制工作流程。

Method: 提出了一个系统级能耗最小化问题，综合考虑无人机位置、语义压缩比、传输功率和AI推理任务卸载决策等变量。开发了一种低复杂度算法，通过二维搜索获得全局最优解。

Result: 仿真结果表明，所提出的设计相比传统基线方法能够显著降低总能量消耗，验证了框架的有效性。

Conclusion: 该研究成功开发了一个高效的AI驱动框架，通过智能优化关键操作参数，有效解决了无人机系统的能量效率问题，为自主系统的长期运行提供了可行方案。

Abstract: This letter addresses the energy efficiency issue in unmanned aerial vehicle
(UAV)-assisted autonomous systems. We propose a framework for an agentic
artificial intelligence (AI)-powered low-altitude semantic wireless network,
that intelligently orchestrates a sense-communicate-decide-control workflow. A
system-wide energy consumption minimization problem is formulated to enhance
mission endurance. This problem holistically optimizes key operational
variables, including UAV's location, semantic compression ratio, transmit power
of the UAV and a mobile base station, and binary decision for AI inference task
offloading, under stringent latency and quality-of-service constraints. To
tackle the formulated mixed-integer non-convex problem, we develop a
low-complexity algorithm which can obtain the globally optimal solution with
two-dimensional search. Simulation results validate the effectiveness of our
proposed design, demonstrating significant reductions in total energy
consumption compared to conventional baseline approaches.

</details>


### [4] [Understanding the ratio of the partition sum to its Bethe approximation via double covers](https://arxiv.org/abs/2509.19910)
*Pascal O. Vontobel*

Main category: cs.IT

TL;DR: 本文研究了图形模型中配分函数与其Bethe近似之间的比率关系，特别是配分函数与Bethe近似的比率与配分函数与二阶Bethe近似的比率平方之间的关系。


<details>
  <summary>Details</summary>
Motivation: 观察到在各类图形模型中，配分函数与其Bethe近似的比率往往接近配分函数与其二阶Bethe近似的比率的平方，这一关系有助于更好地分析和量化配分函数。

Method: 对观察到的比率关系进行理论论证，并对两类对数超模图形模型中的这些比率进行分析。

Result: 为观察到的比率关系提供了理论依据，并对特定类别的图形模型进行了比率分析。

Conclusion: 研究结果支持了配分函数近似比率之间的平方关系，为图形模型配分函数的分析提供了新的理论工具。

Abstract: For various classes of graphical models it has been observed that the ratio
of the partition sum to its Bethe approximation is often close to being the
square of the ratio of the partition sum to its degree-2 Bethe approximation.
This is of relevance because the latter ratio can often better be analyzed
and/or quantified than the former ratio. In this paper, we give some
justifications for the observed relationship between these two ratios and then
analyze these ratios for two classes of log-supermodular graphical models.

</details>


### [5] [Constrained Higher-Order Binary Optimization for Wireless Communications Systems Using Ising Machines](https://arxiv.org/abs/2509.20092)
*Gan Zheng,Ioannis Krikidis*

Main category: cs.IT

TL;DR: 本文提出了一种基于Ising机器的迭代算法，用于解决无线通信系统中具有不等式约束的大规模高阶二进制优化问题，通过增强拉格朗日方法和泰勒展开将高阶多项式近似为二次型。


<details>
  <summary>Details</summary>
Motivation: 传统QUBO方法在无线通信资源优化中应用受限，因为实际问题通常包含高阶多项式项和严格不等式约束，需要开发能处理这些复杂性的新方法。

Method: 采用增强拉格朗日方法处理约束，使用泰勒展开将高阶多项式近似为二次型，在每个迭代中求解单个QUBO问题，无需辅助变量。

Result: 在同时无线信息和能量传输系统的相位优化案例中，仿真结果表明所提算法性能令人满意，优于启发式基准方案。

Conclusion: 该算法成功克服了QUBO在无线通信应用中的瓶颈，为利用Ising机器解决复杂资源优化问题提供了有效途径。

Abstract: This paper develops an algorithmic solution using Ising machines to solve
large-scale higher-order binary optimization (HOBO) problems with inequality
constraints for resource optimization in wireless communications systems.
Quadratic unconstrained binary optimization (QUBO) aims to solve a special
category of these problems widely encountered in engineering and science. To
solve QUBO instances, specialized Ising machines have been designed, while
sophisticated quantum annealing algorithm and quantum-inspired classical
heuristics have been developed. However, the application of QUBO in wireless
communications has limited practical interest mainly due to the complexity of
resource optimization problems which are often characterized by high-order
polynomial terms and strict inequality constraints. To overcome these
bottlenecks and take advantage of recent advancements in Ising machines, in
this paper, we propose an iterative algorithmic solution to solve HOBO
problems, which is based on the augmented Lagrangian method to handle
constraints. Specifically, Taylor expansion is employed to approximate
higher-order polynomials to quadratic ones in the augmented Lagrangian
function, which enables the solution of a single QUBO problem at each iteration
without auxiliary variables. As an illustrative case study, we consider the
problem of phase optimization in a simultaneous wireless information and power
transfer system, where a reconfigurable intelligent surface with 1-bit phase
resolution is used to facilitate information/energy transfer. Simulation
results verify that the proposed algorithm achieves satisfactory performance
and outperforms heuristic benchmark schemes.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [6] [Raspberry Pi Pico as a Radio Transmitter](https://arxiv.org/abs/2509.19304)
*M. Andrecut*

Main category: eess.SP

TL;DR: 将Raspberry Pi Pico微控制器通过简单方法转换为无线电发射器，使用廉价现成组件和开源软件，可能带来安全风险。


<details>
  <summary>Details</summary>
Motivation: 探索将常见微控制器转变为无线电发射器的可能性，揭示其在极端情况下可能带来的安全威胁。

Method: 使用廉价现成的电子组件和开源软件，通过简单方法对Raspberry Pi Pico进行改造。

Result: 成功将RP2微控制器转变为无线电发射器，能够建立多个本地隐蔽无线电通信通道。

Conclusion: 这种看似无害的技术改造在极端情况下可能构成安全风险，需要引起重视。

Abstract: In this paper we discuss several surprisingly simple methods for transforming
the Raspberry Pi Pico (RP2) microcontroller into a radio transmitter, by using
only cheap off the shelf electronic components, and open source software. While
initially this transformation may look as a harmless curiosity, in some extreme
cases it can also pose security risks, since it can be used to open a large
number of local stealth radio communication channels.

</details>


### [7] [A Federated Fine-Tuning Paradigm of Foundation Models in Heterogenous Wireless Networks](https://arxiv.org/abs/2509.19306)
*Jingyi Wang,Zhongyuan Zhao,Qingtian Wang,Zexu Li,Yue Wang,Tony Q. S. Quek*

Main category: eess.SP

TL;DR: 该论文提出了一种基于在线学习的优化方法，用于在异构无线网络中优化联邦微调，通过动态切换LoRA模块来应对设备异构性和传输不可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 边缘智能需要低延迟和普适性服务，但无线网络中的设备异构性和资源约束对联邦微调性能构成威胁。

Method: 提出了基于切换的联邦微调框架，将问题分解为模型切换、发射功率控制和带宽分配子问题，并开发了具有多项式计算复杂度的在线优化算法。

Result: 在SST-2和QNLI数据集上的仿真结果表明，该方法在测试准确性和能源效率方面取得了性能提升。

Conclusion: 该方法有效解决了异构无线网络中联邦微调的挑战，提高了边缘智能的性能和效率。

Abstract: Edge intelligence has emerged as a promising strategy to deliver low-latency
and ubiquitous services for mobile devices. Recent advances in fine-tuning
mechanisms of foundation models have enabled edge intelligence by integrating
low-rank adaptation (LoRA) with federated learning. However, in wireless
networks, the device heterogeneity and resource constraints on edge devices
pose great threats to the performance of federated fine-tuning. To tackle these
issues, we propose to optimize federated fine-tuning in heterogenous wireless
networks via online learning. First, the framework of switching-based federated
fine-tuning in wireless networks is provided. The edge devices switches to LoRA
modules dynamically for federated fine-tuning with base station to jointly
mitigate the impact of device heterogeneity and transmission unreliability.
Second, a tractable upper bound on the inference risk gap is derived based on
theoretical analysis. To improve the generalization capability, we formulate a
non-convex mixed-integer programming problem with long-term constraints, and
decouple it into model switching, transmit power control, and bandwidth
allocation subproblems. An online optimization algorithm is developed to solve
the problems with polynomial computational complexity. Finally, the simulation
results on the SST-2 and QNLI data sets demonstrate the performance gains in
test accuracy and energy efficiency.

</details>


### [8] [Bandwidth of Gamma-Distribution-Shaped Functions via Lambert W Function](https://arxiv.org/abs/2509.19307)
*Anthony LoPrete,Johannes Burge*

Main category: eess.SP

TL;DR: 本文推导并提出了伽马分布函数半高全宽（FWHM）的精确解析表达式，使用Lambert W函数计算伽马分布概率密度函数的逆函数，并比较了伽马形状函数与高斯近似的FWHM。


<details>
  <summary>Details</summary>
Motivation: 伽马形状函数的半高全宽（FWHM）是表征单峰函数带宽的重要参数，但目前缺乏其闭式表达式。

Method: 使用Lambert W函数计算伽马分布概率密度函数的逆函数，从而推导出伽马分布任意比例最大值的宽度精确解析表达式。

Result: 成功推导出伽马形状函数FWHM的精确解析表达式，并提供了八度带宽的表达式。

Conclusion: 该方法为伽马形状函数的带宽表征提供了精确的数学工具，并与高斯近似进行了比较。

Abstract: The full width at half maximum (FWHM) is a useful quantity for characterizing
the bandwidth of unimodal functions. However, a closed-form expression for the
FWHM of gamma-shaped functions-i.e. functions that are shaped like the gamma
distribution probability density function (PDF)-is not widely available. Here,
we derive and present just such an expression. To do so, we use the Lambert W
function to compute the inverse of the gamma PDF. We use this inverse to derive
an exact analytic expression for the width of a gamma distribution at an
arbitrary proportion of the maximum, from which the FWHM follows trivially. (An
expression for the octave bandwidth of gamma-shaped functions is also
provided.) The FWHM is then compared to the Gaussian approximation of
gamma-shaped functions. A few other related issues are discussed.

</details>


### [9] [A Novel Two-Dimensional Wigner Distribution Framework via the Quadratic Phase Fourier Transform with a Non-Separable Kernel](https://arxiv.org/abs/2509.19310)
*Mukul Chauhan,Waseem Z. Lone,Amit K. Verma*

Main category: eess.SP

TL;DR: 本文提出了一种新的二维非可分离二次相位Wigner分布（2D-NSQPWD），基于二维非可分离二次相位傅里叶变换框架，能有效捕捉复杂非可分离信号结构，并在二维线性调频信号处理中表现出优越的交叉项抑制和信号定位性能。


<details>
  <summary>Details</summary>
Motivation: 传统Wigner分布对复杂非可分离信号结构的处理能力有限，需要一种更有效的时频分布方法来捕捉这类信号的复杂特征。

Method: 通过用非可分离二次相位傅里叶变换核替换经典傅里叶核，构建了2D-NSQPWD，并严格证明了其时频移不变性、边缘行为、共轭对称性、卷积关系和Moyal恒等式等关键性质。

Result: 在单分量、双分量和三分量二维线性调频信号上的应用表明，该方法在交叉项抑制和信号定位方面具有优越性能。

Conclusion: 2D-NSQPWD是对经典Wigner分布的有效推广，为处理复杂非可分离信号提供了强有力的工具，在时频分析领域具有重要应用价值。

Abstract: This paper introduces a novel time-frequency distribution, referred to as the
Two-Dimensional Non-Separable Quadratic Phase Wigner Distribution (2D-NSQPWD),
formulated within the framework of the Two-Dimensional Non-Separable Quadratic
Phase Fourier Transform (2D-NSQPFT). By replacing the classical Fourier kernel
with the NSQPFT kernel, the proposed distribution generalizes the classical
Wigner distribution and effectively captures complex, non-separable signal
structures. We rigorously establish several key properties of the 2D-NSQPWD,
including time and frequency shift invariance, marginal behavior, conjugate
symmetry, convolution relations, and Moyal's identity. Furthermore, the
connection between the 2D-NSQPWD and the two-dimensional short-time Fourier
transform (2D-STFT) is explored. The distribution's effectiveness is
demonstrated through its application to single-, bi-, and tri-component
two-dimensional linear frequency modulated (2D-LFM) signals, where it shows
superior performance in cross-term suppression and signal localization.

</details>


### [10] [Graph-Based Spatio-temporal Attention and Multi-Scale Fusion for Clinically Interpretable, High-Fidelity Fetal ECG Extraction](https://arxiv.org/abs/2509.19308)
*Chang Wang,Ming Zhu,Shahram Latifi,Buddhadeb Dawn,Shengjie Zhai*

Main category: eess.SP

TL;DR: 提出了FetalHealthNet（FHNet）深度学习框架，结合图神经网络和多尺度增强transformer，用于从腹部心电图中提取干净的胎儿心电信号，在低信噪比条件下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 先天性心脏病是最常见的新生儿异常，需要早期检测来改善预后。但胎儿心电信号在腹部心电图中常被母体心电和噪声掩盖，传统方法在低信噪比条件下效果不佳。

Method: FHNet整合图神经网络和多尺度增强transformer，动态建模导联间的时空相关性，提取干净的胎儿心电信号。

Result: 在基准数据集上，FHNet显著优于LSTM、标准transformer和最先进模型，R²>0.99，RMSE=0.015，即使在严重噪声条件下也表现优异。可解释性分析显示模型具有生理学意义。

Conclusion: FHNet展示了AI驱动建模在推进胎儿监测和实现早期先天性心脏病筛查方面的潜力，强调了新一代生物医学信号处理的变革性影响。

Abstract: Congenital Heart Disease (CHD) is the most common neonatal anomaly,
highlighting the urgent need for early detection to improve outcomes. Yet,
fetal ECG (fECG) signals in abdominal ECG (aECG) are often masked by maternal
ECG and noise, challenging conventional methods under low signal-to-noise ratio
(SNR) conditions. We propose FetalHealthNet (FHNet), a deep learning framework
that integrates Graph Neural Networks with a multi-scale enhanced transformer
to dynamically model spatiotemporal inter-lead correlations and extract clean
fECG signals. On benchmark aECG datasets, FHNet consistently outperforms long
short-term memory (LSTM) models, standard transformers, and state-of-the-art
models, achieving R2>0.99 and RMSE = 0.015 even under severe noise.
Interpretability analyses highlight physiologically meaningful temporal and
lead contributions, supporting model transparency and clinical trust. FHNet
illustrates the potential of AI-driven modeling to advance fetal monitoring and
enable early CHD screening, underscoring the transformative impact of
next-generation biomedical signal processing.

</details>


### [11] [E2E Learning Massive MIMO for Multimodal Semantic Non-Orthogonal Transmission and Fusion](https://arxiv.org/abs/2509.19312)
*Minghui Wu,Zhen Gao*

Main category: eess.SP

TL;DR: 提出了一种端到端的上行-下行CSI融合预编码网络，将下行CSI参考信号设计、CSI反馈和基站预编码联合建模在一个单一架构中，以解决大规模MIMO系统中高维下行CSI获取和预编码的复杂性。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO系统虽然能提供高频谱效率，但高维下行信道状态信息使得实时信道获取和预编码变得复杂，需要一种更高效的解决方案。

Method: 构建基于MAXIM架构的投影网络处理上行探测参考信号，输出投影矩阵用于设计下行CSI-RS；用户设备压缩/量化CSI-RS观测值并反馈；基站通过两个互补分支（反馈专用预编码网络和SRS专用预编码网络）生成候选预编码器，最后由融合预编码网络结合生成最终发射预编码器。

Result: 仿真结果表明，该方法有效利用了SRS衍生信息和用户反馈，相比传统基线方法获得了显著更好的性能。

Conclusion: 所提出的端到端融合预编码网络能够有效解决大规模MIMO系统中的信道获取和预编码挑战，为实际部署提供了有前景的解决方案。

Abstract: Massive multiple-input multiple-output (MIMO) promises high spectral
efficiency but also leads to high-dimensional downlink channel state
information (CSI), which complicates real-time channel acquisition and
precoding. To address this, we propose an end-to-end (E2E) uplink-downlink CSI
fusion precoding network that jointly models downlink CSI reference signal
(CSI-RS) design, CSI feedback, and base-station (BS) precoding within a single
E2E neural architecture. Concretely, a projection network built on the MAXIM
architecture takes uplink sounding reference signals (SRS) as input and outputs
frequency-, beam-, and port-domain projection matrices for designing downlink
CSI-RS. User equipment (UE) then compresses/quantizes the resulting CSI-RS
observations and feeds back a compact representation. At the base station (BS),
two complementary branches produce candidate precoders: one is a feedback-only
precoding network driven by quantized downlink observations, and the other is
an SRS-only precoding network driven by uplink SRS. These candidate precoders
are subsequently combined by a fusion precoding network to yield the final
transmit precoder. All the modules are trained with a
spectral-efficiency-oriented loss under a three-stage schedule. Simulation
results show that the proposed approach effectively harnesses both SRS-derived
information and UE feedback, achieving markedly better performance than
conventional baselines.

</details>


### [12] [Joint Channel Estimation and Computation Offloading in Fluid Antenna-assisted MEC Networks](https://arxiv.org/abs/2509.19340)
*Ying Ju,Mingdong Li,Haoyu Wang,Lei Liu,Youyang Qu,Mianxiong Dong,Victor C. M. Leung,Chau Yuen*

Main category: eess.SP

TL;DR: 提出了一种流体天线辅助的移动边缘计算卸载框架，通过信息瓶颈度量增强信道压缩感知和博弈论辅助的分层双决斗多智能体算法来最小化系统延迟。


<details>
  <summary>Details</summary>
Motivation: 流体天线能够动态调整端口位置，为移动边缘计算系统提供空间分集和频谱效率优势，但面临信道估计复杂和联合优化问题非凸的挑战。

Method: 1. IBM-CCS：将信息相关性融入感知过程，有效捕获流体天线信道关键特征；2. HiTDMA：基于博弈论的分层结构，解耦用户侧和基站侧的优化任务，降低功率控制变量维度。

Result: 数值结果表明，所提方案显著降低系统延迟，提升卸载性能，优于基准方法。IBM-CCS在不同端口密度下表现出优越的准确性和鲁棒性。

Conclusion: 该框架成功解决了流体天线辅助MEC系统中的关键挑战，为高效通信提供了有效解决方案。

Abstract: With the emergence of fluid antenna (FA) in wireless communications, the
capability to dynamically adjust port positions offers substantial benefits in
spatial diversity and spectrum efficiency, which are particularly valuable for
mobile edge computing (MEC) systems. Therefore, we propose an FA-assisted MEC
offloading framework to minimize system delay. This framework faces two severe
challenges, which are the complexity of channel estimation due to dynamic port
configuration and the inherent non-convexity of the joint optimization problem.
Firstly, we propose Information Bottleneck Metric-enhanced Channel Compressed
Sensing (IBM-CCS), which advances FA channel estimation by integrating
information relevance into the sensing process and capturing key features of FA
channels effectively. Secondly, to address the non-convex and high-dimensional
optimization problem in FA-assisted MEC systems, which includes FA port
selection, beamforming, power control, and resource allocation, we propose a
game theory-assisted Hierarchical Twin-Dueling Multi-agent Algorithm (HiTDMA)
based offloading scheme, where the hierarchical structure effectively decouples
and coordinates the optimization tasks between the user side and the base
station side. Crucially, the game theory effectively reduces the dimensionality
of power control variables, allowing deep reinforcement learning (DRL) agents
to achieve improved optimization efficiency. Numerical results confirm that the
proposed scheme significantly reduces system delay and enhances offloading
performance, outperforming benchmarks. Additionally, the IBM-CCS channel
estimation demonstrates superior accuracy and robustness under varying port
densities, contributing to efficient communication under imperfect CSI.

</details>


### [13] [A Measurement Report Data-Driven Framework for Localized Statistical Channel Modeling](https://arxiv.org/abs/2509.19342)
*Xinyu Qin,Ye Xue,Qi Yan,Shutao Zhang,Bingsheng Peng,Tsung-Hui Chang*

Main category: eess.SP

TL;DR: 提出一种基于测量报告数据的本地化统计信道建模框架，通过超图神经网络解决MR数据位置缺失问题，并联合网格构建和信道APS估计来提升复杂环境下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖高成本的驱车测试数据，空间覆盖有限。利用低成本、广泛收集的MR数据进行本地化统计信道建模，以解决数字孪生网络优化中的性能评估问题。

Method: 框架包含两个模块：1）MR定位模块使用基于超图神经网络的半监督方法，通过距离感知超图建模和超图卷积提取位置信息；2）联合网格构建和信道APS估计模块，通过聚类和改进的稀疏恢复交替优化网格划分和APS估计。

Result: 在真实MR数据集上的综合实验表明，该框架在定位和信道建模方面具有优越的性能和鲁棒性。

Conclusion: 提出的MR数据驱动框架能够有效解决位置缺失问题，在复杂非均匀环境中实现鲁棒的本地化统计信道建模，为数字孪生网络优化提供可靠支持。

Abstract: Localized statistical channel modeling (LSCM) is crucial for effective
performance evaluation in digital twin-assisted network optimization. Solely
relying on the multi-beam reference signal receiving power (RSRP), LSCM aims to
model the localized statistical propagation environment by estimating the
channel angular power spectrum (APS). However, existing methods rely heavily on
drive test data with high collection costs and limited spatial coverage. In
this paper, we propose a measurement report (MR) data-driven framework for
LSCM, exploiting the low-cost and extensive collection of MR data. The
framework comprises two novel modules. The MR localization module addresses the
issue of missing locations in MR data by introducing a semi-supervised method
based on hypergraph neural networks, which exploits multi-modal information via
distance-aware hypergraph modeling and hypergraph convolution for location
extraction. To enhance the computational efficiency and solution robustness,
LSCM operates at the grid level. Compared to independently constructing
geographically uniform grids and estimating channel APS, the joint grid
construction and channel APS estimation module enhances robustness in complex
environments with spatially non-uniform data by exploiting their correlation.
This module alternately optimizes grid partitioning and APS estimation using
clustering and improved sparse recovery for the ill-conditioned measurement
matrix and incomplete observations. Through comprehensive experiments on a
real-world MR dataset, we demonstrate the superior performance and robustness
of our framework in localization and channel modeling.

</details>


### [14] [STL-FFT-STFT-TCN-LSTM: An Effective Wave Height High Accuracy Prediction Model Fusing Time-Frequency Domain Features](https://arxiv.org/abs/2509.19313)
*Huipeng Liu,Zhichao Zhu,Yuan Zhou,Changlu Li*

Main category: eess.SP

TL;DR: 本文提出了一种结合STL-FFT-STFT-TCN-LSTM的混合模型，用于精确预测有效波高，解决了波能信号的非线性、突变性、多尺度周期性等问题，显著提高了预测精度。


<details>
  <summary>Details</summary>
Motivation: 随着传统能源消耗加剧及其环境负面影响日益明显，波能因其高能量密度、稳定性、分布广泛和环境友好性而成为可再生能源家族中极具前景的成员。其发展的关键在于精确预测有效波高，但波能信号存在强非线性、突变、多尺度周期性、数据稀疏和高频噪声干扰等问题，且物理模型计算成本极高。

Method: 本研究提出了一种结合STL-FFT-STFT-TCN-LSTM的混合模型，利用季节性趋势分解（STL）、快速傅里叶变换（FFT）、短时傅里叶变换（STFT）、时序卷积网络（TCN）和长短期记忆网络（LSTM）技术，优化多尺度特征融合，捕捉极端波高，解决高频噪声和周期信号问题。

Result: 使用NOAA Station 41008和41047 2019-2022年的每小时数据进行实验，结果显示该模型在捕捉极端波高和抑制高频噪声方面预测精度显著更高，MAE降低15.8%-40.5%，SMAPE降低8.3%-20.3%，R增加1.31%-2.9%；消融实验也证明了各组件步骤的不可或缺性。

Conclusion: STL-FFT-STFT-TCN-LSTM模型在多尺度特征融合方面表现出优越性，验证了其在有效波高预测中的高效性和准确性。

Abstract: As the consumption of traditional energy sources intensifies and their
adverse environmental impacts become more pronounced, wave energy stands out as
a highly promising member of the renewable energy family due to its high energy
density, stability, widespread distribution, and environmental friendliness.
The key to its development lies in the precise prediction of Significant Wave
Height (WVHT). However, wave energy signals exhibit strong nonlinearity, abrupt
changes, multi-scale periodicity, data sparsity, and high-frequency noise
interference; additionally, physical models for wave energy prediction incur
extremely high computational costs. To address these challenges, this study
proposes a hybrid model combining STL-FFT-STFT-TCN-LSTM. This model exploits
the Seasonal-Trend Decomposition Procedure based on Loess (STL), Fast Fourier
Transform (FFT), Short-Time Fourier Transform (STFT), Temporal Convolutional
Network (TCN), and Long Short-Term Memory (LSTM) technologies. The model aims
to optimize multi-scale feature fusion, capture extreme wave heights, and
address issues related to high-frequency noise and periodic signals, thereby
achieving efficient and accurate prediction of significant wave height.
Experiments were conducted using hourly data from NOAA Station 41008 and 41047
spanning 2019 to 2022. The results showed that compared with other single
models and hybrid models, the STL-FFT-STFT-TCN-LSTM model achieved
significantly higher prediction accuracy in capturing extreme wave heights and
suppressing high-frequency noise, with MAE reduced by 15.8\%-40.5\%, SMAPE
reduced by 8.3\%-20.3\%, and R increased by 1.31\%-2.9\%; in ablation
experiments, the model also demonstrated the indispensability of each component
step, validating its superiority in multi-scale feature fusion.

</details>


### [15] [Neural Network Based Framework for Passive Intermodulation Cancellation in MIMO Systems](https://arxiv.org/abs/2509.19382)
*Xiaolong Li,Zhi-qin John Xu,Peiting You,Yifei Zhu*

Main category: eess.SP

TL;DR: 提出了一种基于深度可分离卷积和膨胀卷积的轻量级深度学习框架，用于抑制MIMO-OFDM系统中的无源互调干扰，在仅使用11k可训练参数的情况下实现了29dB的平均功率误差抑制。


<details>
  <summary>Details</summary>
Motivation: 5G及后续通信系统中，无源互调成为MIMO-OFDM系统自干扰的关键来源，传统非线性模型方法计算复杂且扩展性有限。

Method: 采用深度可分离卷积和膨胀卷积来高效捕捉天线和子载波间的非线性依赖关系，结合循环学习率调度和梯度裁剪来提升收敛性能。

Result: 在受控MIMO实验环境中，该方法有效抑制了三阶无源互调失真，平均功率误差达到29dB。

Conclusion: 紧凑的神经网络架构在未来无线通信系统中具有可扩展干扰抑制的潜力。

Abstract: Passive intermodulation (PIM) has emerged as a critical source of
self-interference in modern MIMO-OFDM systems, especially under the stringent
requirements of 5G and beyond. Conventional cancellation methods often rely on
complex nonlinear models with limited scalability and high computational cost.
In this work, we propose a lightweight deep learning framework for PIM
cancellation that leverages depthwise separable convolutions and dilated
convolutions to efficiently capture nonlinear dependencies across antennas and
subcarriers. To further enhance convergence, we adopt a cyclic learning rate
schedule and gradient clipping. In a controlled MIMO experimental setup, the
method effectively suppresses third-order passive intermodulation (PIM)
distortion, achieving up to 29dB of average power error (APE) with only 11k
trainable parameters. These results highlight the potential of compact neural
architectures for scalable interference mitigation in future wireless
communication systems.

</details>


### [16] [Advancing Few-Shot Pediatric Arrhythmia Classification with a Novel Contrastive Loss and Multimodal Learning](https://arxiv.org/abs/2509.19315)
*Yiqiao Chen,Zijian Huang,Zhenghui Feng*

Main category: eess.SP

TL;DR: 提出了一种多模态端到端深度学习框架，结合双分支卷积编码器、语义注意力和轻量级Transformer，用于儿科心律失常分类，在Leipzig心脏中心数据集上取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 儿科心律失常是残疾和心源性猝死的主要风险因素，但由于类别不平衡、少样本类别和复杂信号特征，其自动分类仍然具有挑战性，限制了早期筛查和临床干预的效率与可靠性。

Method: 多模态端到端深度学习框架，包括ECG和IEGM的双分支卷积编码器、跨模态特征对齐的语义注意力、全局依赖建模的轻量级Transformer编码器，以及新的对比损失函数AGCACL。

Result: 在Leipzig心脏中心儿科/先天性ECG+IEGM数据集上取得最佳性能：Top-1准确率97.76%，宏精度94.08%，宏召回率91.97%，宏F1 92.97%，宏F2 92.36%，相比最强基线有显著提升。

Conclusion: 该框架显著提高了少数心律失常类别的可检测性和鲁棒性，为儿科和先天性心脏病人群的心律筛查、术前评估和术后随访提供了潜在的临床价值。

Abstract: Pediatric arrhythmias are a major risk factor for disability and sudden
cardiac death, yet their automated classification remains challenging due to
class imbalance, few-shot categories, and complex signal characteristics, which
severely limit the efficiency and reliability of early screening and clinical
intervention. To address this problem, we propose a multimodal end-to-end deep
learning framework that combines dual-branch convolutional encoders for ECG and
IEGM, semantic attention for cross-modal feature alignment, and a lightweight
Transformer encoder for global dependency modeling. In addition, we introduce a
new contrastive loss fucntion named Adaptive Global Class-Aware Contrastive
Loss (AGCACL) to enhance intra-class compactness and inter-class separability
through class prototypes and a global similarity matrix. To the best of our
knowledge, this is the first systematic study based on the Leipzig Heart Center
pediatric/congenital ECG+IEGM dataset, for which we also provide a complete and
reproducible preprocessing pipeline. Experimental results demonstrate that the
proposed method achieves the overall best performance on this dataset,
including 97.76\% Top-1 Accuracy, 94.08\% Macro Precision, 91.97\% Macro
Recall, 92.97\% Macro F1, and 92.36\% Macro F2, with improvements of +13.64,
+15.96, +19.82, and +19.44 percentage points over the strongest baseline in
Macro Precision/Recall/F1/F2, respectively. These findings indicate that the
framework significantly improves the detectability and robustness for minority
arrhythmia classes, offering potential clinical value for rhythm screening,
pre-procedural assessment, and postoperative follow-up in pediatric and
congenital heart disease populations.

</details>


### [17] [Impact of RHIs and ipSIC on Active RIS-NOMA Systems with Low-Precision ADCs](https://arxiv.org/abs/2509.19383)
*Qianqian Li,Hua Li,Shiya Hao,Lintao Li,Xiaoming Dai*

Main category: eess.SP

TL;DR: 本研究评估了采用低精度模数转换器（ADC）的有源可重构智能表面（ARIS）辅助非正交多址（NOMA）系统的性能，推导了考虑残余硬件损伤（RHI）和不完美连续干扰消除（ipSIC）的中断概率（OP）分析近似值，并分析了高信噪比（SNR）下的渐近OP、系统吞吐量和分集阶数。


<details>
  <summary>Details</summary>
Motivation: 研究有源RIS辅助NOMA系统在低精度ADC下的性能，以解决传统无源RIS系统在能效和性能方面的限制，探索通过优化传输功率和反射元件数量来减轻低精度ADC负面影响的方法。

Method: 采用分析推导方法，建立了考虑残余硬件损伤和不完美连续干扰消除的系统模型，推导了中断概率的解析表达式，并通过仿真验证了理论分析结果。

Result: 仿真结果表明，所提出的量化ARIS-NOMA系统在中断概率和吞吐量方面优于无源对应系统（PRIS-NOMA），且需要更低的传输功率和更少的反射元件。通过增加反射元件数量可以显著改善系统性能。

Conclusion: 有源RIS-NOMA系统在低精度ADC条件下具有优越性能，通过优化系统参数可以有效缓解低精度ADC的负面影响，为未来无线通信系统设计提供了重要参考。

Abstract: This study evaluates the performance of an active reconfigurable intelligent
surface (ARIS)-assisted non-orthogonal multiple access (NOMA) system employing
low-precision analog-to-digital converters (ADCs). Analytical approximations
for the outage probability (OP) are derived, considering residual hardware
impairments (RHIs) and imperfect successive interference cancellation (ipSIC).
Additionally, we analyze the asymptotic OP, system throughput, and diversity
order at high signal-to-noise ratios (SNRs). Simulation results demonstrate
that the proposed quantized ARIS-NOMA system outperforms its passive
counterpart (PRIS-NOMA), achieving lower OP and higher throughput with reduced
transmit power requirements and fewer reflecting elements. Moreover, the outage
performance of both quantized ARIS-NOMA and PRIS-NOMA systems demonstrates
significant improvement as the number of reflecting elements increases. The
negative impacts of low-precision ADCs can be effectively mitigated by
optimizing transmit power and scaling the number of reflecting elements.

</details>


### [18] [Electric Vehicle Identification from Behind Smart Meter Data](https://arxiv.org/abs/2509.19316)
*Ammar Kamoona,Hui Song,Ali Moradi Amani,Mahdi Jalili,Xinghuo Yu,Peter McTaggart*

Main category: eess.SP

TL;DR: 本文提出了一种基于异常检测的无监督学习方法，用于从智能电表低频数据中识别电动汽车充电负荷，无需先验的充电配置文件知识。


<details>
  <summary>Details</summary>
Motivation: 电动汽车充电负荷识别对于电网运营商进行有效决策至关重要。当充电发生在电表后端时，充电负荷被视为用户总负荷的一部分，难以单独测量，因此需要开发非侵入式的识别方法。

Method: 采用基于深度时间卷积编码解码网络（TAE）的无监督异常检测技术，仅需非电动汽车用户的真实功率消耗数据，无需先验的电动汽车充电配置文件。

Result: 该方法在澳大利亚维多利亚州家庭智能电表数据上应用，显示出识别电动汽车家庭的优越性能。

Conclusion: 所提出的无监督学习方法能够有效识别电表后端的电动汽车充电负荷，为电网运营商提供重要信息支持。

Abstract: Electric vehicle (EV) charging loads identification from behind smart meter
recordings is an indispensable aspect that enables effective decision-making
for energy distributors to reach an informed and intelligent decision about the
power grid's reliability. When EV charging happens behind the meter (BTM), the
charging occurs on the customer side of the meter, which measures the overall
electricity consumption. In other words, the charging of the EV is considered
part of the customer's load and not separately measured by the Distribution
Network Operators (DNOs). DNOs require complete knowledge about the EV presence
in their network. Identifying the EV charging demand is essential to better
plan and manage the distribution grid. Unlike supervised methods, this paper
addresses the problem of EV charging load identification in a non-nonintrusive
manner from low-frequency smart meter using an unsupervised learning approach
based on anomaly detection technique. Our approach does not require prior
knowledge of EV charging profiles. It only requires real power consumption data
of non-EV users, which are abundant in practice. We propose a deep temporal
convolution encoding decoding (TAE) network. The TAE is applied to power
consumption from smart BTM from Victorian households in Australia, and the TAE
shows superior performance in identifying households with EVs.

</details>


### [19] [Scensory: Automated Real-Time Fungal Identification and Spatial Mapping](https://arxiv.org/abs/2509.19318)
*Yanbaihui Liu,Erica Babusci,Claudia K. Gunsch,Boyuan Chen*

Main category: eess.SP

TL;DR: 本文提出了一种名为Scensory的机器人嗅觉系统，使用低成本VOC传感器阵列和深度学习技术，能够同时识别真菌种类并定位其空间来源，实现了实时、空间感知的真菌监测。


<details>
  <summary>Details</summary>
Motivation: 现有真菌检测方法速度慢、成本高且缺乏空间分辨率，无法满足实时监测和大规模部署的需求。传统方法依赖实验室分析或高浓度采样，不适合实时监测应用。

Method: 利用机器人自动数据收集训练神经网络架构，通过时间VOC动态同时编码化学和空间特征。系统提供两种操作模式：被动多阵列配置用于环境监测，移动单阵列配置用于主动源跟踪。

Result: 在五种真菌物种上，系统在环境条件下实现了最高89.85%的物种检测准确率和87.31%的定位准确率，每个预测仅需3-7秒传感器输入。通过计算分析模型行为，无需额外实验室实验即可揭示关键生化特征。

Conclusion: 该方法实现了实时、空间感知的真菌监测，建立了可扩展且经济实惠的自主环境感知框架。

Abstract: Indoor fungal contamination poses significant risks to public health, yet
existing detection methods are slow, costly, and lack spatial resolution.
Conventional approaches rely on laboratory analysis or high-concentration
sampling, making them unsuitable for real-time monitoring and scalable
deployment. We introduce \textbf{\textit{Scensory}}, a robot-enabled olfactory
system that simultaneously identifies fungal species and localizes their
spatial origin using affordable volatile organic compound (VOC) sensor arrays
and deep learning. Our key idea is that temporal VOC dynamics encode both
chemical and spatial signatures, which we decode through neural architectures
trained on robot-automated data collection. We demonstrate two operational
modes: a passive multi-array configuration for environmental monitoring, and a
mobile single-array configuration for active source tracking. Across five
fungal species, our system achieves up to 89.85\% accuracy in species detection
and 87.31\% accuracy in localization under ambient conditions, where each
prediction only takes 3--7\,s sensor inputs. Additionally, by computationally
analyzing model behavior, we can uncover key biochemical signatures without
additional laboratory experiments. Our approach enables real-time, spatially
aware fungal monitoring and establishes a scalable and affordable framework for
autonomous environmental sensing.

</details>


### [20] [Human Activity Recognition Based on Electrocardiogram Data Only](https://arxiv.org/abs/2509.19328)
*Sina Montazeri,Waltenegus Dargie,Yunhe Feng,Kewei Sha*

Main category: eess.SP

TL;DR: 本文首次展示了仅使用心电图（ECG）在六种不同活动中实现稳健活动识别，超越了以往工作的范围。设计了三种新的深度学习模型，在54名受试者的数据上测试，所有模型对已见受试者准确率超过94%，CNNTransformer混合模型对未见受试者达到72%准确率。


<details>
  <summary>Details</summary>
Motivation: 传统活动识别依赖惯性测量单元（IMU），资源密集且需要校准。虽然已探索基于ECG的方法，但通常作为IMU的补充或仅限于宽泛分类。本文旨在推进仅使用ECG进行多活动识别的研究。

Method: 设计了三种深度学习模型：1）带有Squeeze-and-Excitation块的CNN分类器用于通道特征重校准；2）带有扩张卷积的ResNet分类器用于多尺度时间依赖捕获；3）新颖的CNNTransformer混合模型结合卷积特征提取和注意力机制用于长程时间关系建模。

Result: 在54名受试者的六种活动数据上测试，所有三种模型对已见受试者准确率超过94%，CNNTransformer混合模型对未见受试者达到72%最佳准确率，通过增加训练人群可进一步提高。

Conclusion: 本研究首次成功实现了仅使用ECG的多物理活动分类，为开发能够同时进行心脏监测和活动识别而无需额外运动传感器的下一代可穿戴设备提供了重要潜力。

Abstract: Human activity recognition is critical for applications such as early
intervention and health analytics. Traditional activity recognition relies on
inertial measurement units (IMUs), which are resource intensive and require
calibration. Although electrocardiogram (ECG)-based methods have been explored,
these have typically served as supplements to IMUs or have been limited to
broad categorical classification such as fall detection or active vs. inactive
in daily activities. In this paper, we advance the field by demonstrating, for
the first time, robust recognition of activity only with ECG in six distinct
activities, which is beyond the scope of previous work. We design and evaluate
three new deep learning models, including a CNN classifier with
Squeeze-and-Excitation blocks for channel-wise feature recalibration, a ResNet
classifier with dilated convolutions for multiscale temporal dependency
capture, and a novel CNNTransformer hybrid combining convolutional feature
extraction with attention mechanisms for long-range temporal relationship
modeling. Tested on data from 54 subjects for six activities, all three models
achieve over 94% accuracy for seen subjects, while CNNTransformer hybrid
reaching the best accuracy of 72% for unseen subjects, a result that can be
further improved by increasing the training population. This study demonstrates
the first successful ECG-only activity classification in multiple physical
activities, offering significant potential for developing next-generation
wearables capable of simultaneous cardiac monitoring and activity recognition
without additional motion sensors.

</details>


### [21] [LibEMER: A novel benchmark and algorithms library for EEG-based Multimodal Emotion Recognition](https://arxiv.org/abs/2509.19330)
*Zejun Liu,Yunshan Chen,Chengxi Xie,Huan Liu*

Main category: eess.SP

TL;DR: 本文介绍了LibEMER，一个用于EEG多模态情感识别的开源评估框架，旨在解决该领域缺乏开源实现、标准化基准和深入讨论的问题。


<details>
  <summary>Details</summary>
Motivation: EEG多模态情感识别领域存在三个关键问题：缺乏开源实现、缺少标准化透明基准、缺乏对主要挑战和研究方向的深入讨论。

Method: 开发了LibEMER框架，提供可复现的PyTorch实现、标准化数据预处理、模型实现和实验设置协议。

Result: 该框架在三个广泛使用的公共数据集和两个学习任务上实现了无偏性能评估。

Conclusion: LibEMER为解决EEG多模态情感识别领域的标准化和可复现性问题提供了有效方案。

Abstract: EEG-based multimodal emotion recognition(EMER) has gained significant
attention and witnessed notable advancements, the inherent complexity of human
neural systems has motivated substantial efforts toward multimodal approaches.
However, this field currently suffers from three critical limitations: (i) the
absence of open-source implementations. (ii) the lack of standardized and
transparent benchmarks for fair performance analysis. (iii) in-depth discussion
regarding main challenges and promising research directions is a notable
scarcity. To address these challenges, we introduce LibEMER, a unified
evaluation framework that provides fully reproducible PyTorch implementations
of curated deep learning methods alongside standardized protocols for data
preprocessing, model realization, and experimental setups. This framework
enables unbiased performance assessment on three widely-used public datasets
across two learning tasks. The open-source library is publicly accessible at:
https://anonymous.4open.science/r/2025ULUIUBUEUMUEUR485384

</details>


### [22] [Holographic Transformers for Complex-Valued Signal Processing: Integrating Phase Interference into Self-Attention](https://arxiv.org/abs/2509.19331)
*Enhao Huang,Zhiyu Zhang,Tianxiang Xu,Chunshu Xia,Kaichun Hu,Yuchen Yang,Tongtong Pan,Dong Dong,Zhan Qin*

Main category: eess.SP

TL;DR: Holographic Transformer是一种受物理启发的架构，将波干涉原理融入自注意力机制，通过相对相位调制交互并相干叠加值，确保幅度和相位的一致性，在复数信号处理中表现出色。


<details>
  <summary>Details</summary>
Motivation: 大多数深度学习模型将注意力视为实值相关性，忽略了复数信号中同时包含幅度和相位的干涉效应，需要一种能够处理复数信号物理一致性的架构。

Method: 提出全息注意力机制，通过相对相位调制交互并相干叠加值；采用双头解码器同时重建输入和预测任务输出，防止相位塌陷；实现离散干涉算子并在线性混合下保持相位一致性。

Result: 在PolSAR图像分类和无线信道预测实验中表现出强大性能，获得高分类准确率和F1分数、低回归误差，并对相位扰动具有更强的鲁棒性。

Conclusion: 在注意力中强制执行物理一致性可以带来复数学习中的可泛化改进，为相干信号建模提供了一个统一的物理基础框架。

Abstract: Complex-valued signals encode both amplitude and phase, yet most deep models
treat attention as real-valued correlation, overlooking interference effects.
We introduce the Holographic Transformer, a physics-inspired architecture that
incorporates wave interference principles into self-attention. Holographic
attention modulates interactions by relative phase and coherently superimposes
values, ensuring consistency between amplitude and phase. A dual-headed decoder
simultaneously reconstructs the input and predicts task outputs, preventing
phase collapse when losses prioritize magnitude over phase. We demonstrate that
holographic attention implements a discrete interference operator and maintains
phase consistency under linear mixing. Experiments on PolSAR image
classification and wireless channel prediction show strong performance,
achieving high classification accuracy and F1 scores, low regression error, and
increased robustness to phase perturbations. These results highlight that
enforcing physical consistency in attention leads to generalizable improvements
in complex-valued learning and provides a unified, physics-based framework for
coherent signal modeling. The code is available at
https://github.com/EonHao/Holographic-Transformers.

</details>


### [23] [A Spatio-Temporal Feature Fusion EEG Virtual Channel Signal Generation Network and Its Application in Anxiety Assessment](https://arxiv.org/abs/2509.19334)
*Shangqing Yuan,Wenshuang Zhai,Shengwen Guo*

Main category: eess.SP

TL;DR: 本研究提出了一种基于时空特征融合的EEG虚拟通道信号生成网络，通过4个前额叶通道生成13个重要脑区的虚拟EEG信号，有效解决了便携式EEG设备通道有限的问题。


<details>
  <summary>Details</summary>
Motivation: 便携式EEG设备通道数量有限，导致信息采集不足，限制了其在脑电信号分析和情绪识别等应用中的性能。

Method: 采用二维卷积神经网络架构，包含并行的时间域和空间域特征提取模块，以及特征融合模块，基于PRED+CT数据库的119名受试者多通道EEG数据进行验证。

Result: 生成的虚拟通道EEG信号与真实信号的平均相关系数为0.6724，平均绝对误差为3.9470；结合原始信号用于焦虑分类时，显著提升了支持向量机的分类性能。

Conclusion: 该网络生成的虚拟EEG信号与真实信号具有高度一致性，并能显著增强机器学习算法在焦虑分类中的性能，有效缓解了便携式EEG设备信息获取不足的问题。

Abstract: To address the issue of limited channels and insufficient information
collection in portable EEG devices, this study explores an EEG virtual channel
signal generation network using a novel spatio-temporal feature fusion
strategy. Based on the EEG signals from four frontal lobe channels, the network
aims to generate virtual channel EEG signals for other 13 important brain
regions. The architecture of the network is a two-dimensional convolutional
neural network and it includes a parallel module for temporal and spatial
domain feature extraction, followed by a feature fusion module. The public
PRED+CT database, which includes multi-channel EEG signals from 119 subjects,
was selected to verify the constructed network. The results showed that the
average correlation coefficient between the generated virtual channel EEG
signals and the original real signals was 0.6724, with an average absolute
error of 3.9470. Furthermore, the 13 virtual channel EEG signals were combined
with the original EEG signals of four brain regions and then used for anxiety
classification with a support vector machine. The results indicate that the
virtual EEG signals generated by the constructed network not only have a high
degree of consistency with the real channel EEG signals but also significantly
enhance the performance of machine learning algorithms for anxiety
classification. This study effectively alleviates the problem of insufficient
information acquisition by portable EEG devices with few channels.

</details>


### [24] [CSIYOLO: An Intelligent CSI-based Scatter Sensing Framework for Integrated Sensing and Communication Systems](https://arxiv.org/abs/2509.19335)
*Xudong Zhang,Jingbo Tan,Zhizhen Ren,Jintao Wang,Yihua Ma,Jian Song*

Main category: eess.SP

TL;DR: CSIYOLO是一个基于CSI的散射体定位框架，通过将散射参数提取转化为图像检测问题，使用YOLO架构实现单基站-用户设备对的散射体定位，无需修改波形或硬件。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC散射感知方法依赖波形硬件修改或传统信号处理，与当前通信系统兼容性差且感知精度有限。需要一种仅使用CSI就能实现散射定位的兼容方案。

Method: 提出两阶段框架：1）基于锚点的散射参数检测，将参数提取建模为图像检测问题；2）CSI定位算法确定散射体位置。采用可扩展网络结构、多尺度锚点检测和噪声注入训练策略。

Result: 实验表明该方法在不同散射体数量和估计误差下，显著优于现有方法，定位精度更高且复杂度相对较低。

Conclusion: CSIYOLO框架可作为插件无缝集成到现有通信系统中，为ISAC散射感知提供了高效兼容的解决方案。

Abstract: ISAC is regarded as a promising technology for next-generation communication
systems, enabling simultaneous data transmission and target sensing. Among
various tasks in ISAC, scatter sensing plays a crucial role in exploiting the
full potential of ISAC and supporting applications such as autonomous driving
and low-altitude economy. However, most existing methods rely on either
waveform and hardware modifications or traditional signal processing schemes,
leading to poor compatibility with current communication systems and limited
sensing accuracy. To address these challenges, we propose CSIYOLO, a framework
that performs scatter localization only using estimated CSI from a single base
station-user equipment pair. This framework comprises two main components:
anchor-based scatter parameter detection and CSI-based scatter localization.
First, by formulating scatter parameter extraction as an image detection
problem, we propose an anchor-based scatter parameter detection method inspired
by You Only Look Once architectures. After that, a CSI-based localization
algorithm is derived to determine scatter locations with extracted parameters.
Moreover, to improve localization accuracy and implementation efficiency, we
design an extendable network structure with task-oriented optimizations,
enabling multi-scale anchor detection and better adaptation to CSI
characteristics. A noise injection training strategy is further designed to
enhance robustness against channel estimation errors. Since the proposed
framework operates solely on estimated CSI without modifying waveforms or
signal processing pipelines, it can be seamlessly integrated into existing
communication systems as a plugin. Experiments show that our proposed method
can significantly outperform existing methods in scatter localization accuracy
with relatively low complexities under varying numbers of scatters and
estimation errors.

</details>


### [25] [Low-Cost Sensor Fusion Framework for Organic Substance Classification and Quality Control Using Classification Methods](https://arxiv.org/abs/2509.19367)
*Borhan Uddin Chowdhury,Damian Valles,Md Raf E Ul Shougat*

Main category: eess.SP

TL;DR: 提出基于Arduino Mega 2560微控制器的传感器融合框架，结合机器学习算法实现有机物质的快速无损分类和质量控制


<details>
  <summary>Details</summary>
Motivation: 开发低成本、非破坏性的有机物质分类和质量控制方法，解决传统检测方法的局限性

Method: 使用三个商用环境传感器收集10种有机物质数据，采用相关性分析进行特征选择，应用PCA/LDA降维，训练SVM、决策树、随机森林、ANN和集成投票分类器

Result: 最佳模型（调优随机森林、集成分类器和ANN）在测试集上达到93-94%的准确率

Conclusion: 基于Arduino的低成本多传感器平台结合先进机器学习和相关性驱动的特征工程，能够可靠地识别有机化合物并进行质量控制

Abstract: We present a sensor-fusion framework for rapid, non-destructive
classification and quality control of organic substances, built on a standard
Arduino Mega 2560 microcontroller platform equipped with three commercial
environmental and gas sensors. All data used in this study were generated
in-house: sensor outputs for ten distinct classes - including fresh and expired
samples of apple juice, onion, garlic, and ginger, as well as cinnamon and
cardamom - were systematically collected and labeled using this hardware setup,
resulting in a unique, application-specific dataset. Correlation analysis was
employed as part of the preprocessing pipeline for feature selection. After
preprocessing and dimensionality reduction (PCA/LDA), multiple supervised
learning models - including Support Vector Machine (SVM), Decision Tree (DT),
and Random Forest (RF), each with hyperparameter tuning, as well as an
Artificial Neural Network (ANN) and an ensemble voting classifier - were
trained and cross-validated on the collected dataset. The best-performing
models, including tuned Random Forest, ensemble, and ANN, achieved test
accuracies in the 93 to 94 percent range. These results demonstrate that
low-cost, multisensory platforms based on the Arduino Mega 2560, combined with
advanced machine learning and correlation-driven feature engineering, enable
reliable identification and quality control of organic compounds.

</details>


### [26] [Short-Term Regional Electricity Demand Forecasting in Argentina Using LSTM Networks](https://arxiv.org/abs/2509.19374)
*Oscar A. Oviedo*

Main category: eess.SP

TL;DR: 基于LSTM网络的深度学习模型，用于预测阿根廷科尔多瓦的短期小时用电需求，整合历史用电数据和外生变量，实现了高精度预测。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够准确预测短期用电需求的模型，为电网运营商提供优化的规划和控制策略，应对不同需求场景。

Method: 使用LSTM网络，整合历史用电数据、气候因素、时间周期和人口统计等外生变量，进行模型设计和超参数优化，并辅以随机森林回归的可解释性研究和日需求极值时间预测评估。

Result: 模型预测精度高，平均绝对百分比误差为3.20%，决定系数为0.95；在日需求极值时间预测中，超过三分之二的测试日达到精确小时准确度，90%以上的情况误差在1小时内。

Conclusion: 该框架不仅具有高预测精度，还具有操作相关性，为电网运营商提供了有价值的见解，有助于优化规划和控制策略。

Abstract: This study presents the development and optimization of a deep learning model
based on Long Short-Term Memory (LSTM) networks to predict short-term hourly
electricity demand in C\'ordoba, Argentina. Integrating historical consumption
data with exogenous variables (climatic factors, temporal cycles, and
demographic statistics), the model achieved high predictive precision, with a
mean absolute percentage error of 3.20\% and a determination coefficient of
0.95. The inclusion of periodic temporal encodings and weather variables proved
crucial to capture seasonal patterns and extreme consumption events, enhancing
the robustness and generalizability of the model. In addition to the design and
hyperparameter optimization of the LSTM architecture, two complementary
analyses were carried out: (i) an interpretability study using Random Forest
regression to quantify the relative importance of exogenous drivers, and (ii)
an evaluation of model performance in predicting the timing of daily demand
maxima and minima, achieving exact-hour accuracy in more than two-thirds of the
test days and within abs(1) hour in over 90\% of cases. Together, these results
highlight both the predictive accuracy and operational relevance of the
proposed framework, providing valuable insights for grid operators seeking
optimized planning and control strategies under diverse demand scenarios.

</details>


### [27] [Data-Driven Reconstruction of Significant Wave Heights from Sparse Observations](https://arxiv.org/abs/2509.19384)
*Hongyuan Shi,Yilin Zhai,Ping Dong,Zaijin You,Chao Zhan,Qing Wang*

Main category: eess.SP

TL;DR: AUWave是一个混合深度学习框架，用于从稀疏浮标观测重建高分辨率区域有效波高场，通过多尺度U-Net和自注意力层实现32×32区域的重建。


<details>
  <summary>Details</summary>
Motivation: 从稀疏不均匀的浮标观测重建高分辨率区域有效波高场是海洋监测和风险感知操作的核心挑战。

Method: 融合站点序列编码器（MLP）与增强多尺度U-Net（包含瓶颈自注意力层）的混合深度学习框架，使用贝叶斯超参数搜索优化学习率等参数。

Result: 在夏威夷区域达到最小验证损失0.043285，空间误差在观测点附近最低，随距离增加而增大，在数据丰富配置下显著优于基线方法。

Conclusion: AUWave为数据同化提供了可扩展的高分辨率先验，并为网络设计提供了可操作的指导，特别适用于间隙填补和应急重建。

Abstract: Reconstructing high-resolution regional significant wave height fields from
sparse and uneven buoy observations remains a core challenge for ocean
monitoring and risk-aware operations. We introduce AUWave, a hybrid deep
learning framework that fuses a station-wise sequence encoder (MLP) with a
multi-scale U-Net enhanced by a bottleneck self-attention layer to recover
32$\times$32 regional SWH fields. A systematic Bayesian hyperparameter search
with Optuna identifies the learning rate as the dominant driver of
generalization, followed by the scheduler decay and the latent dimension. Using
NDBC buoy observations and ERA5 reanalysis over the Hawaii region, AUWave
attains a minimum validation loss of 0.043285 and a slightly right-skewed RMSE
distribution. Spatial errors are lowest near observation sites and increase
with distance, reflecting identifiability limits under sparse sampling.
Sensitivity experiments show that AUWave consistently outperforms a
representative baseline in data-richer configurations, while the baseline is
only marginally competitive in the most underdetermined single-buoy cases. The
architecture's multi-scale and attention components translate into accuracy
gains when minimal but non-trivial spatial anchoring is available. Error maps
and buoy ablations reveal key anchor stations whose removal disproportionately
degrades performance, offering actionable guidance for network design. AUWave
provides a scalable pathway for gap filling, high-resolution priors for data
assimilation, and contingency reconstruction.

</details>


### [28] [A Statistical Mixture-of-Experts Framework for EMG Artifact Removal in EEG: Empirical Insights and a Proof-of-Concept Application](https://arxiv.org/abs/2509.19385)
*Benjamin J. Choi,Griffin Milsap,Clara A. Scholl,Francesco Tenore,Mattson Ogg*

Main category: eess.SP

TL;DR: 本文提出了一种基于混合专家（MoE）框架的EEG信号去噪算法，专门针对高噪声环境下的EMG伪影去除问题，通过三个新的统计洞察和CNN-RNN混合网络结构，在EEGdenoiseNet数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前神经接口控制受限于信号质量差的问题，特别是在高噪声环境下，现有的基于神经网络的EEG去噪方法对EMG伪影的去除效果不理想。

Method: 提出基于MoE框架的信号滤波算法，利用三个新统计洞察：1）将EMG伪影分类为可量化的子类型；2）在更窄信噪比范围内训练局部专家实现专业化；3）使用基于相关性的目标函数和重缩放算法加速收敛。算法采用CNN和RNN混合神经网络结构。

Result: 在EEGdenoiseNet数据集（67名受试者）上的测试表明，MoE去噪模型在整体性能上与现有最优ML去噪算法相当，在高噪声环境下具有更优的下界性能。

Conclusion: MoE框架在EMG伪影去除方面显示出良好前景，特别是在高噪声设置下，未来需要进一步研究其在更广泛真实场景中的应用潜力。

Abstract: Effective control of neural interfaces is limited by poor signal quality.
While neural network-based electroencephalography (EEG) denoising methods for
electromyogenic (EMG) artifacts have improved in recent years, current
state-of-the-art (SOTA) models perform suboptimally in settings with high
noise. To address the shortcomings of current machine learning (ML)-based
denoising algorithms, we present a signal filtration algorithm driven by a new
mixture-of-experts (MoE) framework. Our algorithm leverages three new
statistical insights into the EEG-EMG denoising problem: (1) EMG artifacts can
be partitioned into quantifiable subtypes to aid downstream MoE classification,
(2) local experts trained on narrower signal-to-noise ratio (SNR) ranges can
achieve performance increases through specialization, and (3) correlation-based
objective functions, in conjunction with rescaling algorithms, can enable
faster convergence in a neural network-based denoising context. We empirically
demonstrate these three insights into EMG artifact removal and use our findings
to create a new downstream MoE denoising algorithm consisting of convolutional
(CNN) and recurrent (RNN) neural networks. We tested all results on a major
benchmark dataset (EEGdenoiseNet) collected from 67 subjects. We found that our
MoE denoising model achieved competitive overall performance with SOTA ML
denoising algorithms and superior lower bound performance in high noise
settings. These preliminary results highlight the promise of our MoE framework
for enabling advances in EMG artifact removal for EEG processing, especially in
high noise settings. Further research and development will be necessary to
assess our MoE framework on a wider range of real-world test cases and explore
its downstream potential to unlock more effective neural interfaces.

</details>


### [29] [Hybrid Pipeline SWD Detection in Long-Term EEG Signals](https://arxiv.org/abs/2509.19387)
*Antonio Quintero Rincon,Nicolas Masino,Veronica Marsico,Hadj Batatia*

Main category: eess.SP

TL;DR: 提出了一种轻量级混合管道，结合分析特征和浅层人工神经网络，用于在长期单极脑电图中准确检测棘慢波放电（SWD），实现实时自动化筛查。


<details>
  <summary>Details</summary>
Motivation: 手动识别多天记录中的棘慢波放电（SWD）既费时又容易出错，需要一种自动化的准确检测方法。

Method: 使用双边移动平均滤波器抑制正常背景活动的高频成分，然后计算残差信号的均值和标准差作为特征向量，输入单隐藏层人工神经网络进行分类。

Result: 在12名患者的780个通道上测试，正确检测384个事件（灵敏度98%），特异性96.2%，总体准确率97.2%。

Conclusion: 正态分布描述符结合小型神经网络为延长脑电图记录中的自动化SWD筛查提供了有效且计算成本低的解决方案。

Abstract: Spike-and-wave discharges (SWDs) are the electroencephalographic hallmark of
absence epilepsy, yet their manual identification in multi-day recordings
remains labour-intensive and error-prone. We present a lightweight hybrid
pipeline that couples analytical features with a shallow artificial neural
network (ANN) for accurate, patient-specific SWD detection in long-term,
monopolar EEG. A two-sided moving-average (MA) filter first suppresses the
high-frequency components of normal background activity. The residual signal is
then summarised by the mean and the standard deviation of its normally
distributed samples, yielding a compact, two-dimensional feature vector for
every 20s window. These features are fed to a single-hidden-layer ANN trained
via back-propagation to classify each window as SWD or non-SWD. The method was
evaluated on 780 channels sampled at 256 Hz from 12 patients, comprising 392
annotated SWD events. It correctly detected 384 events (sensitivity: 98%) while
achieving a specificity of 96.2 % and an overall accuracy of 97.2%. Because
feature extraction is analytic, and the classifier is small, the pipeline runs
in real-time and requires no manual threshold tuning. These results indicate
that normal-distribution descriptors combined with a modest ANN provide an
effective and computationally inexpensive solution for automated SWD screening
in extended EEG recordings.

</details>


### [30] [Self-Alignment Learning to Improve Myocardial Infarction Detection from Single-Lead ECG](https://arxiv.org/abs/2509.19397)
*Jiarui Jin,Xiaocheng Fang,Haoyu Wang,Jun Li,Che Liu,Donglin Xie,Hongyan Li,Shenda Hong*

Main category: eess.SP

TL;DR: SelfMIS提出了一种新的潜在空间对齐学习框架，通过自切割策略将单导联ECG与多导联ECG在潜在空间直接对齐，显著提高了单导联心电图对心肌梗死的检测性能。


<details>
  <summary>Details</summary>
Motivation: 单导联心电图检测心肌梗死存在空间信息有限的问题，传统生成方法在信号级别优化时存在潜在空间差距，而现有对齐方法主要关注变换不变性学习，这与单导联检测目标不匹配。

Method: SelfMIS采用自切割策略，将多导联ECG与其对应的单导联片段配对，直接在潜在空间进行对齐，使单导联编码器能够从局部信号推断全局心脏上下文信息。

Result: 实验表明SelfMIS在九种心肌梗死类型上均优于基线模型，同时保持了更简单的架构和更低的计算开销。

Conclusion: 直接潜在空间对齐是有效的，SelfMIS框架为单导联心电图心肌梗死检测提供了一种高效解决方案。

Abstract: Myocardial infarction is a critical manifestation of coronary artery disease,
yet detecting it from single-lead electrocardiogram (ECG) remains challenging
due to limited spatial information. An intuitive idea is to convert single-lead
into multiple-lead ECG for classification by pre-trained models, but generative
methods optimized at the signal level in most cases leave a large latent space
gap, ultimately degrading diagnostic performance. This naturally raises the
question of whether latent space alignment could help. However, most prior ECG
alignment methods focus on learning transformation invariance, which mismatches
the goal of single-lead detection. To address this issue, we propose SelfMIS, a
simple yet effective alignment learning framework to improve myocardial
infarction detection from single-lead ECG. Discarding manual data
augmentations, SelfMIS employs a self-cutting strategy to pair multiple-lead
ECG with their corresponding single-lead segments and directly align them in
the latent space. This design shifts the learning objective from pursuing
transformation invariance to enriching the single-lead representation,
explicitly driving the single-lead ECG encoder to learn a representation
capable of inferring global cardiac context from the local signal.
Experimentally, SelfMIS achieves superior performance over baseline models
across nine myocardial infarction types while maintaining a simpler
architecture and lower computational overhead, thereby substantiating the
efficacy of direct latent space alignment. Our code and checkpoint will be
publicly available after acceptance.

</details>


### [31] [SpellerSSL: Self-Supervised Learning with P300 Aggregation for Speller BCIs](https://arxiv.org/abs/2509.19401)
*Jiazhen Hong,Geoff Mackellar,Soheila Ghane*

Main category: eess.SP

TL;DR: SpellerSSL是一个结合自监督学习和P300聚合的框架，用于解决EEG P300拼写器BCI的低信噪比、泛化能力差和校准耗时的问题。该方法通过聚合策略增强信噪比，使用定制1D U-Net骨干网络在跨域和域内EEG数据上预训练，然后通过轻量级ERP-Head分类器进行微调。实验表明该方法显著减少了校准负担，在II-B数据集上达到了94%的字符识别率和21.86 bits/min的信息传输率。


<details>
  <summary>Details</summary>
Motivation: 解决EEG P300拼写器BCI面临的三个主要挑战：低信噪比、泛化能力差和耗时校准。传统方法需要大量特定受试者的校准数据，限制了BCI的实际应用。

Method: 1. 引入P300聚合策略增强信噪比；2. 使用定制1D U-Net骨干网络在跨域和域内EEG数据上进行自监督预训练；3. 通过轻量级ERP-Head分类器对预训练模型进行微调，适应特定受试者数据。

Result: 1. 在域内设置下达到94%的字符识别率（仅需7次重复）和21.86 bits/min的最高信息传输率；2. 结合P300聚合的自监督学习将所需校准数据量减少60%；3. 显著提高了跨受试者的鲁棒性。

Conclusion: 这是首个将自监督学习应用于P300拼写器的研究，证明了该方法在提高BCI效率和泛化能力方面的潜力，为构建P300拼写器BCI的EEG基础模型铺平了道路。

Abstract: Electroencephalogram (EEG)-based P300 speller brain-computer interfaces
(BCIs) face three main challenges: low signal-to-noise ratio (SNR), poor
generalization, and time-consuming calibration. We propose SpellerSSL, a
framework that combines self-supervised learning (SSL) with P300 aggregation to
address these issues. First, we introduce an aggregation strategy to enhance
SNR. Second, to achieve generalization in training, we employ a customized 1D
U-Net backbone and pretrain the model on both cross-domain and in-domain EEG
data. The pretrained model is subsequently fine-tuned with a lightweight
ERP-Head classifier for P300 detection, which adapts the learned
representations to subject-specific data. Our evaluations on calibration time
demonstrate that combining the aggregation strategy with SSL significantly
reduces the calibration burden per subject and improves robustness across
subjects. Experimental results show that SSL learns effective EEG
representations in both in-domain and cross-domain, with in-domain achieving a
state-of-the-art character recognition rate of 94% with only 7 repetitions and
the highest information transfer rate (ITR) of 21.86 bits/min on the public
II-B dataset. Moreover, in-domain SSL with P300 aggregation reduces the
required calibration size by 60% while maintaining a comparable character
recognition rate. To the best of our knowledge, this is the first study to
apply SSL to P300 spellers, highlighting its potential to improve both
efficiency and generalization in speller BCIs and paving the way toward an EEG
foundation model for P300 speller BCIs.

</details>


### [32] [Online Adaptation via Dual-Stage Alignment and Self-Supervision for Fast-Calibration Brain-Computer Interfaces](https://arxiv.org/abs/2509.19403)
*Sheng-Bin Duan,Jian-Long Hao,Tian-Yu Xiang,Xiao-Hu Zhou,Mei-Jiang Gui,Xiao-Liang Xie,Shi-Qi Liu,Zeng-Guang Hou*

Main category: eess.SP

TL;DR: 提出一种基于双阶段对齐和自监督的在线自适应算法，用于解决脑机接口系统中个体脑电信号差异问题，实现无需校准的快速操作。


<details>
  <summary>Details</summary>
Motivation: 脑电信号的个体差异阻碍了基于脑电的脑机接口系统的在线应用，需要克服这一限制以实现快速校准操作。

Method: 采用双阶段对齐方法：先在EEG数据空间进行欧几里得对齐，然后在表示空间更新批归一化统计量；设计自监督损失函数，使用解码器生成的软伪标签作为未知真实标签的代理，并通过香农熵进行校准。

Result: 在五个公共数据集和七个解码器上的实验表明，该算法可以无缝集成到不同BCI范式和解码器架构中，每次迭代只需一个在线试验即可更新解码器，在SSVEP和运动想象任务上分别获得平均4.9%和3.6%的准确率提升。

Conclusion: 该算法支持快速校准操作，在脑机接口应用中具有巨大潜力。

Abstract: Individual differences in brain activity hinder the online application of
electroencephalogram (EEG)-based brain computer interface (BCI) systems. To
overcome this limitation, this study proposes an online adaptation algorithm
for unseen subjects via dual-stage alignment and self-supervision. The
alignment process begins by applying Euclidean alignment in the EEG data space
and then updates batch normalization statistics in the representation space.
Moreover, a self-supervised loss is designed to update the decoder. The loss is
computed by soft pseudo-labels derived from the decoder as a proxy for the
unknown ground truth, and is calibrated by Shannon entropy to facilitate
self-supervised training. Experiments across five public datasets and seven
decoders show the proposed algorithm can be integrated seamlessly regardless of
BCI paradigm and decoder architecture. In each iteration, the decoder is
updated with a single online trial, which yields average accuracy gains of 4.9%
on steady-state visual evoked potentials (SSVEP) and 3.6% on motor imagery.
These results support fast-calibration operation and show that the proposed
algorithm has great potential for BCI applications.

</details>


### [33] [Insights into Xona Pulsar LEO PNT: Constellation, Signals, and Receiver Design](https://arxiv.org/abs/2509.19551)
*Jérôme Leclère,Thyagaraja Marathe,Tyler G. R. Reid*

Main category: eess.SP

TL;DR: 本文分析了低地球轨道（LEO）卫星导航系统Pulsar的特性，通过与GPS对比，探讨了LEEO系统对接收机设计的影响，并提出了优化策略以减少捕获时间和功耗。


<details>
  <summary>Details</summary>
Motivation: 随着LEO星座如Pulsar在定位、导航和授时（PNT）领域的兴起，需要深入理解其信号特性和对接收机设计的新要求，以充分利用其优势（如强信号、快速动态）。

Method: 使用GNSS模拟器分析Pulsar的参数（如卫星通过时长、仰角、多普勒频移、多普勒变化率、距离和可见卫星数），并与GPS对比；评估参数的时间演化、统计分布及相互依赖关系；在多纬度进行测试，并讨论仰角掩模的影响。

Result: LEO系统表现出更短的卫星通过时间、更高的多普勒频移和变化率，以及独特的星座几何结构；参数间存在依赖关系（如多普勒变化率与多普勒频移相关），可用于优化接收机设计。

Conclusion: Pulsar的LEO特性要求接收机适应扩展的多普勒范围和高动态，但通过优化采集策略（如预测和优先级技术）可提升性能，降低功耗和捕获时间。

Abstract: The landscape of global navigation satellite systems (GNSS) is expanding with
the emergence of low Earth orbit (LEO) constellations such as Pulsar, which are
expected to play a key role in the future of positioning, navigation, and
timing (PNT). LEO-based systems provide advantages including stronger signals
for greater robustness, faster dynamics that aid convergence and multipath
mitigation, and shorter time to first fix (TTFF) enabled by high data rates.
These benefits, however, come with changes in signal behavior and constellation
geometry that require careful consideration in receiver design. This paper
investigates Pulsar properties using a GNSS simulator, analyzing parameters
such as satellite pass duration, elevation, Doppler shift, Doppler rate, range,
and number of satellites in view. Comparisons with GPS highlight the
differences introduced by LEO operation. The analysis examines temporal
evolution, statistical distributions, and maximum and minimum values. Beyond
these statistical insights, the study explores interdependencies between
parameters and differences across satellites, providing additional perspective.
Evaluations are performed at multiple latitudes to ensure a worldwide
perspective, and the impact of applying different elevation masks is discussed
where relevant. Building on these findings, the paper assesses Pulsar's impact
on receiver design from two standpoints: design considerations, addressing
expanded Doppler ranges, higher Doppler rates, and unique constellation
structure; and design optimizations, exploiting parameter analyses and
interdependencies (e.g., Doppler rate vs Doppler) to refine acquisition
strategies and applying prediction and prioritization techniques to avoid
unnecessary computations. Together, these optimizations can reduce acquisition
time and lower receiver power consumption.

</details>


### [34] [DNN-Based Nulling Control Beam Focusing for Near-Field Multi-User Interference Mitigation](https://arxiv.org/abs/2509.19594)
*Mohammadhossein Karimi,Yuanzhe Gong,Tho Le-Ngoc*

Main category: eess.SP

TL;DR: 提出基于深度学习的近场零陷控制波束聚焦框架，用于超大规模MIMO系统中的多用户干扰抑制


<details>
  <summary>Details</summary>
Motivation: 解决超大规模MIMO系统中多用户干扰问题，实现有效的干扰抑制和实时波束聚焦

Method: 采用双估计器架构，包含两个全连接深度神经网络，分别预测NCBF权重的相位和幅度分量，使用期望用户和干扰用户的位置信息

Result: DNN模型预测精度高，相位估计误差0.067弧度，幅度估计误差0.206 dB，平均MUI抑制达到36.7 dB

Conclusion: 该方法能够实现可扩展的实时波束聚焦和有效干扰抑制，为未来近场多用户无线通信提供了有前景的解决方案

Abstract: This paper proposes a deep learning-based framework for near-field nulling
control beam focusing (NCBF) in extra-large MIMO (XL-MIMO) systems to mitigate
multi-user interference (MUI). A dual-estimator architecture comprising two
fully connected deep neural networks (FCDNNs) is developed to separately
predict the phase and magnitude components of NCBF weights, using locations of
both desired and interfering users. The models are trained on a large dataset
generated via a Linearly Constrained Minimum Variance (LCMV) beamforming
algorithm to accommodate diverse user configurations, including both collinear
and non-collinear scenarios. Illustrative results demonstrate that the proposed
DNN models achieve high prediction accuracy, with test errors of only 0.067
radians for phase estimation and 0.206 dB for magnitude estimation. Full-wave
simulations incorporating realistic element radiation patterns and
inter-element coupling confirm the close agreement between the beam patterns
produced by the DNN-predicted and LCMV-based NCBF schemes under practical
deployment conditions. An average MUI suppression of 36.7 dB is achieved, with
interference mitigation exceeding 17.5 dB across all tested cases. The proposed
approach enables scalable and real-time beam focusing with effective
interference suppression, offering a promising solution for future near-field
multi-user wireless communications.

</details>


### [35] [Non-locally averaged pruned reassigned spectrograms: a tool for glottal pulse visualization and analysis](https://arxiv.org/abs/2509.19686)
*Gabriel J. Griswold,Mark A. Griswold*

Main category: eess.SP

TL;DR: 提出了一种改进的重新分配谱图方法NAPReS，通过堆叠、求和和修剪大量声门脉冲来简化说话人声门脉冲模式的可视化，并在高噪声环境下比传统LPC方法更具可重复性。


<details>
  <summary>Details</summary>
Motivation: 重新分配谱图虽然在精确共振峰测量和说话人区分方面有优势，但无法以易于理解和可重复的方式可视化大量数据。

Method: 开发了非局部平均修剪重新分配谱图(NAPReS)，通过堆叠、求和和修剪大量声门脉冲来简化数据可视化，并结合高斯混合模型(GMM)进行共振峰拟合。

Result: NAPReS能够以易于理解和量化的方式显示大量数据，使低振幅循环结构的观察更加容易，在高噪声情况下比传统LPC拟合更具可重复性。

Conclusion: NAPReS方法为说话人声门脉冲模式分析提供了更有效的可视化工具，在高噪声环境下表现出优于传统方法的性能。

Abstract: Reassigned spectrograms have shown advantages in precise formant measuring
and inter-speaker differentiation. However, reassigned spectrograms suffer from
their inability to visualize larger amounts of data in an easily comprehensible
and reproducible manner. Utilizing the techniques and tools developed by Fulop
and Fitz, a variation of the reassigned spectrogram is proposed. Non-locally
Averaged Pruned Reassigned Spectrograms (NAPReS) provide a simplified view into
the characteristics of a speaker's glottal pulsation patterns throughout the
centroid of a vowel through the stacking, summing, and pruning of large numbers
of glottal pulses. In this exploratory study, NAPReS has been shown to display
a large amount of data in an easily comprehensible and quantifiable manner,
while also making the observation of low-amplitude cyclical structures more
accessible. NAPReS also allows for alternative formant fitting methods such as
Gaussian mixture modeling. In this study, NAPReS with GMM was compared against
conventional LPC fitting of formant values and was shown to be more
reproducible than conventional LPC fitting in high-noise situations.

</details>


### [36] [Timeliness-Aware Joint Source and Channel Coding for Adaptive Image Transmission](https://arxiv.org/abs/2509.19754)
*Xiaolei Yang,Zijing Wang,Zhijin Qin,Xiaoming Tao*

Main category: eess.SP

TL;DR: 本文提出了一种基于价值信息(VoI)的自适应联合源信道编码(JSCC)方法，用于时间敏感应用中的图像传输，同时考虑重建质量和时效性。


<details>
  <summary>Details</summary>
Motivation: 现有无线系统带宽限制难以满足高保真和低延迟图像传输需求，语义通信有望通过传输目标导向的语义信息来突破性能瓶颈。

Method: 设计了自适应码长的JSCC图像传输框架，构建VoI最大化问题，并提出基于深度强化学习的算法来优化传输码长。

Result: 实验结果表明，该方法在重建质量和时效性方面显著优于基线方案，特别是在低信噪比条件下表现优异。

Conclusion: 该方法为时间敏感无线网络中的高效鲁棒图像传输提供了有前景的解决方案。

Abstract: Accurate and timely image transmission is critical for emerging
time-sensitive applications such as remote sensing in satellite-assisted
Internet of Things. However, the bandwidth limitation poses a significant
challenge in existing wireless systems, making it difficult to fulfill the
requirements of both high-fidelity and low-latency image transmission. Semantic
communication is expected to break through the performance bottleneck by
focusing on the transmission of goal-oriented semantic information rather than
raw data. In this paper, we employ a new timeliness metric named the value of
information (VoI) and propose an adaptive joint source and channel coding
(JSCC) method for image transmission that simultaneously considers both
reconstruction quality and timeliness. Specifically, we first design a JSCC
framework for image transmission with adaptive code length. Next, we formulate
a VoI maximization problem by optimizing the transmission code length of the
adaptive JSCC under the reconstruction quality constraint. Then, a deep
reinforcement learning-based algorithm is proposed to solve the optimization
problem efficiently. Experimental results show that the proposed method
significantly outperforms baseline schemes in terms of reconstruction quality
and timeliness, particularly in low signal-to-noise ratio conditions, offering
a promising solution for efficient and robust image transmission in
time-sensitive wireless networks.

</details>


### [37] [Electromagnetics-Compliant Optimization of Dynamic Metasurface Antennas for Bistatic Sensing](https://arxiv.org/abs/2509.19801)
*Ioannis Gavras,George C. Alexandropoulos*

Main category: eess.SP

TL;DR: 本文提出了一种动态超表面天线（DMA）的优化设计方法，用于双基地传感应用。通过考虑物理约束和互耦效应，开发了低复杂度的波束赋形算法，在存在定位和同步不确定性的情况下实现高精度定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有DMA研究大多依赖理想化模型，忽略了超材料固有的结构约束和物理限制（如互耦效应和波导传播损耗），这影响了实际系统的定位性能。

Method: 1）提出DMA响应的可处理近似模型；2）构建鲁棒波束赋形优化问题，最小化最坏情况位置误差；3）开发两种低复杂度波束码本搜索方法；4）通过蒙特卡洛仿真验证设计准确性。

Result: 仿真结果表明：准确建模互耦效应对维持高定位性能至关重要；所提设计在定位和同步不确定性下，性能可与全数字和模拟对应方案相媲美，同时满足DMA结构约束。

Conclusion: 本文证明了考虑物理约束的DMA建模和优化设计的有效性，为下一代无线系统中低成本、可重构天线阵列的实际应用提供了重要指导。

Abstract: Dynamic Metasurface Antennas (DMAs) are recently attracting considerable
research interests due to their potential to enable low-cost, reconfigurable,
and highly scalable antenna array architectures for next generation wireless
systems. However, most of the existing literature relies on idealized models
for the DMA operation, often overlooking critical structural and physical
constraints inherent to their constituent metamaterials. In this paper,
leveraging a recently proposed model for this antenna architecture
incorporating physically consistent modeling of mutual coupling and waveguide
propagation losses, we optimize DMA-based transmission for bistatic sensing. A
tractable approximation for the DMA response is first presented, which enables
efficient optimization of the dynamically reconfigurable Lorentzian-constrained
responses of the array's metamaterials. In particular, we formulate a robust
beamforming optimization problem with the objective to minimize the worst-case
position error bound, in the presence of spatial uncertainties for the
environment's scatterers as well as synchronization uncertainties at the analog
combining multi-antenna receiver. To address the resulting high computational
complexity due to the possibly excessive number of metamaterial-based antennas
and their operation constraints, two low complexity beamforming design
approaches are presented that perform offline searching over a novel beam
codebook. The accuracy of all presented DMA designs is assessed by means of
Monte Carlo simulations for various system parameters, confirming that
accurately modeling mutual coupling is essential for maintaining increased
localization performance. It is also shown that, even under positioning and
synchronization uncertainties, the proposed designs yield accuracy comparable
to their fully digital and analog counterparts, while adhering to the
structural DMA constraints.

</details>


### [38] [Generalized Nonnegative Structured Kruskal Tensor Regression](https://arxiv.org/abs/2509.19900)
*Xinjue Wang,Esa Ollila,Sergiy A. Vorobyov,Ammar Mian*

Main category: eess.SP

TL;DR: 本文提出了广义非负结构化Kruskal张量回归(NS-KTR)框架，通过模式特定的混合正则化和非负约束来增强可解释性和性能。


<details>
  <summary>Details</summary>
Motivation: 解决多维张量数据中存在的结构异质性，同时适应线性和逻辑回归公式来处理不同的响应变量。

Method: 集成融合LASSO、全变差和岭正则化器，针对特定张量模式进行定制，并开发了基于交替方向乘子法(ADMM)的高效参数估计算法。

Result: 在合成信号和真实高光谱数据集上的综合实验表明，NS-KTR始终优于传统的张量回归方法。

Conclusion: 该框架能够在保持张量维度间不同结构特征的同时确保物理可解释性，特别适用于信号处理和高光谱图像分析应用。

Abstract: This paper introduces Generalized Nonnegative Structured Kruskal Tensor
Regression (NS-KTR), a novel tensor regression framework that enhances
interpretability and performance through mode-specific hybrid regularization
and nonnegativity constraints. Our approach accommodates both linear and
logistic regression formulations for diverse response variables while
addressing the structural heterogeneity inherent in multidimensional tensor
data. We integrate fused LASSO, total variation, and ridge regularizers, each
tailored to specific tensor modes, and develop an efficient alternating
direction method of multipliers (ADMM) based algorithm for parameter
estimation. Comprehensive experiments on synthetic signals and real
hyperspectral datasets demonstrate that NS-KTR consistently outperforms
conventional tensor regression methods. The framework's ability to preserve
distinct structural characteristics across tensor dimensions while ensuring
physical interpretability makes it especially suitable for applications in
signal processing and hyperspectral image analysis.

</details>


### [39] [Rotatable Antenna Enabled Spectrum Sharing: Joint Antenna Orientation and Beamforming Design](https://arxiv.org/abs/2509.19912)
*Xingxiang Peng,Qingqing Wu,Ziyuan Zheng,Wen Chen,Yanze Zhu,Ying Gao*

Main category: eess.SP

TL;DR: 本文研究了可旋转天线（RAs）在多输入单输出（MISO）干扰信道中的应用，通过联合优化发射波束成形和天线方向来最大化加权和速率，提出了交替优化框架和离散方向选择的交叉熵方法。


<details>
  <summary>Details</summary>
Motivation: 传统天线阵列通过增加元件数量来窄化波束宽度和抑制干扰，但这会带来高昂的硬件和功耗成本。可旋转天线通过动态调整元件方向，在不扩大阵列规模的情况下利用空间灵活性，显著改善链路对齐和干扰抑制。

Method: 提出了交替优化（AO）框架，结合加权最小均方误差（WMMSE）波束成形和Frank-Wolfe方向更新。针对有限分辨率执行器，构建了球面斐波那契码本，并设计了基于交叉熵方法（CEM）的离散方向选择算法。

Result: 仿真结果表明，将可旋转天线与传统波束成形相结合显著提高了加权和速率，增益随元件方向性的增强而增加。在离散方向控制下，提出的CEM算法始终优于最近投影基线方法。

Conclusion: 可旋转天线为干扰信道中的空间控制提供了有效的解决方案，通过联合优化波束成形和天线方向，能够在保持阵列规模的同时显著提升系统性能。

Abstract: Conventional antenna arrays rely primarily on digital beamforming for spatial
control. While adding more elements can narrow beamwidth and suppress
interference, such scaling incurs prohibitive hardware and power costs.
Rotatable antennas (RAs), which allow mechanical or electronic adjustment of
element orientations, introduce a new degree of freedom to exploit spatial
flexibility without enlarging the array. By dynamically optimizing
orientations, RAs can substantially improve desired link alignment and
interference suppression. This paper investigates RA-enabled multiple-input
single-output (MISO) interference channels under co-channel spectrum sharing
and formulates a weighted sum-rate maximization problem that jointly optimizes
transmit beamforming and antenna orientations. To tackle this nonconvex
problem, we develop an alternating optimization (AO) framework that integrates
weighted minimum mean-square error (WMMSE)-based beamforming with
Frank-Wolfe-based orientation updates. To reduce complexity, we further study
orientation optimization under maximum-ratio transmission (MRT) and
zero-forcing (ZF) beamforming schemes. For finite-resolution actuators, we
construct spherical Fibonacci codebooks and design a cross-entropy method
(CEM)-based algorithm for discrete orientation selection. Simulations show that
integrating RAs with conventional beamforming markedly increases weighted
sum-rate, with gains rising with element directivity. Under discrete
orientation control, the proposed CEM algorithm consistently outperforms the
nearest-projection baseline.

</details>


### [40] [On the Invariance of Cross-Correlation Peak Positions Under Monotonic Signal Transformations, with Application to Fast Time Difference Estimation](https://arxiv.org/abs/2509.19974)
*Natsuki Ueno,Ryotaro Sato,Nobutaka Ono*

Main category: eess.SP

TL;DR: 提出关于互相关峰值位置不变性的定理，为一种比传统FFT方法更快速的时间差估计方法提供理论基础


<details>
  <summary>Details</summary>
Motivation: 传统基于FFT的互相关方法计算复杂度高，需要寻找更高效的替代方案

Method: 利用互相关峰值位置在信号单调变换下不变的性质，设计基于低比特整数量化信号的互相关估计算法，仅需整数运算

Result: 数值实验表明该方法处理时间短于传统FFT方法

Conclusion: 该方法为时间差估计提供了一种计算效率更高的替代方案

Abstract: We present a theorem concerning the invariance of cross-correlation peak
positions, which provides a foundation for a new method for time difference
estimation that is potentially faster than the conventional fast Fourier
transform (FFT) approach for real/complex sequences. This theoretical result
shows that the peak position of the cross-correlation function between two
shifted discrete-time signals remains unchanged under arbitrary monotonic
transformations of the input signals. By exploiting this property, we design an
efficient estimation algorithm based on the cross-correlation function between
signals quantized into low-bit integers. The proposed method requires only
integer arithmetic instead of real-valued operations, and further computational
efficiency can be achieved through number-theoretic algorithms. Numerical
experiments demonstrate that the proposed method achieves a shorter processing
time than conventional FFT-based approaches.

</details>


### [41] [Near-field Spatial-domain Channel Extrapolation for XL-MIMO Systems](https://arxiv.org/abs/2509.20026)
*Jiayi Lu,Jiayi Zhang,Hao Lei,Huahua Xiao,Bo Ai,Derrick Wing Kwan Ng*

Main category: eess.SP

TL;DR: 提出了一种用于多子载波XL-MIMO系统的自适应近场信道外推框架，通过选择天线子集和开发网格/非网格算法来提升精度和降低复杂度


<details>
  <summary>Details</summary>
Motivation: XL-MIMO系统需要低复杂度获取准确CSI，现有方法忽视近场球面波前或过度依赖稀疏先验，导致性能下降

Method: 开发基于天线子集的网格和非网格算法，引入交叉验证方案降低复杂度，提出相干度最小化的随机模式

Result: 数值结果表明所提算法在信道外推精度和可达速率上显著优于现有方法，同时保持低计算复杂度

Conclusion: 提出的CV比率提供了精度与效率的灵活权衡，非网格算法以传统网格方法的复杂度实现了高精度

Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) systems are
pivotal to next-generation wireless communications, where dynamic RF chain
architectures offer enhanced performance. However, efficient precoding in such
systems requires accurate channel state information (CSI) obtained with low
complexity. To address this challenge, spatial-domain channel extrapolation has
attracted growing interest. Existing methods often overlook near-field
spherical wavefronts or rely heavily on sparsity priors, leading to performance
degradation. In this paper, we propose an adaptive near-field channel
extrapolation framework for multi-subcarrier XL-MIMO systems, leveraging a
strategically selected subset of antennas. Subsequently, we develop both
on-grid and off-grid algorithms, where the latter refines the former's
estimates for improved accuracy. To further reduce complexity, a
cross-validation (CV)-based scheme is introduced. Additionally, we analytically
formulate the mutual coherence of the sensing matrix and propose a
coherence-minimizing-based random pattern to ensure robust extrapolation.
Numerical results validate that the proposed algorithms significantly
outperform existing methods in both extrapolation accuracy and achievable rate,
while maintaining low computational complexity. In particular, our proposed CV
ratio offers a flexible trade-off between accuracy and efficiency, and the
corresponding off-grid algorithm achieves high accuracy with complexity
comparable to conventional on-grid methods.

</details>


### [42] [Multi-Stage CD-Kennedy Receiver for QPSK Modulated CV-QKD in Turbulent Channels](https://arxiv.org/abs/2509.20030)
*Renzhi Yuan,Zhixing Wang,Shouye Miao,Mufei Zhao,Haifeng Yao,Bin Cao,Mugen Peng*

Main category: eess.SP

TL;DR: 本文研究了在湍流信道中使用多级CD-Kennedy量子接收器来增强QPSK调制的连续变量量子密钥分发协议的性能，提出了三种不同类型的接收器并分析了它们的误码率和密钥率表现。


<details>
  <summary>Details</summary>
Motivation: 连续变量量子密钥分发协议具有高密钥率和与现有光通信基础设施的良好兼容性，但在卫星对地光通信中必须克服大气湍流的影响。传统相干接收器的检测性能受限于标准量子极限，而量子接收器有望突破这一限制。

Method: 提出了三种多级CD-Kennedy量子接收器（Type-I、Type-II、Type-III），推导了它们在湍流信道中检测QPSK信号的误码概率，并进一步推导了使用该接收器和后选择策略的QPSK调制CV-QKD协议的密钥率。

Result: 数值结果表明，多级CD-Kennedy接收器在湍流信道中的误码率和密钥率性能均优于传统相干接收器，其中Type-II接收器在误码率性能方面能够容忍更差的信道条件。

Conclusion: 量子接收器在湍流信道中的CV-QKD协议中具有显著优势，多级CD-Kennedy接收器特别是Type-II型能够有效提升系统性能，为卫星量子通信提供了有前景的技术方案。

Abstract: Continuous variable-quantum key distribution (CV-QKD) protocols attract
increasing attentions in recent years because they enjoy high secret key rate
(SKR) and good compatibility with existing optical communication
infrastructure. Classical coherent receivers are widely employed in coherent
states based CV-QKD protocols, whose detection performance is bounded by the
standard quantum limit (SQL). Recently, quantum receivers based on displacement
operators are experimentally demonstrated with detection performance
outperforming the SQL in various practical conditions. However, potential
applications of quantum receivers in CV-QKD protocols under turbulent channels
are still not well explored, while practical CV-QKD protocols must survive from
the atmospheric turbulence in satellite-to-ground optical communication links.
In this paper, we consider the possibility of using a quantum receiver called
multi-stage CD-Kennedy receiver to enhance the SKR performance of a quadrature
phase shift keying (QPSK) modulated CV-QKD protocol in turbulent channels. We
first derive the error probability of the multi-stage CD-Kennedy receiver for
detecting QPSK signals in turbulent channels and further propose three types of
multi-stage CD-Kennedy receiver with different displacement choices, i.e., the
Type-I, Type-II, and Type-III receivers. Then we derive the SKR of a QPSK
modulated CV-QKD protocol using the multi-stage CD-Kennedy receiver and
post-selection strategy in turbulent channels. Numerical results show that the
multi-stage CD-Kennedy receiver can outperform the classical coherent receiver
in turbulent channels in terms of both error probability and SKR performance
and the Type-II receiver can tolerate worse channel conditions compared with
Type-I and Type-III receivers in terms of error probability performance.

</details>


### [43] [Reproduction Number and Spatial Connectivity Structure Estimation via Graph Sparsity-Promoting Penalized Functional](https://arxiv.org/abs/2509.20034)
*Etienne Lasalle,Barbara Pascal*

Main category: eess.SP

TL;DR: 本文提出了一种联合估计有效再生数和空间连通性结构的方法，以解决COVID-19疫情期间监测数据质量差的问题，通过利用空间数据结构来提高再生数估计的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: COVID-19大流行监测面临前所未有的挑战，全球报告的感染计数质量较差。在同时监测不同地区的疫情时，利用数据的空间结构可以显著提高再生数估计的准确性和鲁棒性，但这需要良好的空间结构估计。

Method: 开发了一种联合估计再生数和连通性结构的程序，通过在精心设计的合成数据上进行密集数值模拟来评估该方法，并在真实的COVID-19时空感染计数数据上进行验证。

Result: 该方法能够同时估计有效再生数和空间连通性结构，解决了现有方法在空间结构估计方面的主要局限性。

Conclusion: 提出的联合估计程序为流行病监测提供了更准确和稳健的工具，特别是在数据质量较差的情况下，通过利用空间信息来改进病原体传播的监控。

Abstract: During an epidemic outbreak, decision makers crucially need accurate and
robust tools to monitor the pathogen propagation. The effective reproduction
number, defined as the expected number of secondary infections stemming from
one contaminated individual, is a state-of-the-art indicator quantifying the
epidemic intensity. Numerous estimators have been developed to precisely track
the reproduction number temporal evolution. Yet, COVID-19 pandemic surveillance
raised unprecedented challenges due to the poor quality of worldwide reported
infection counts. When monitoring the epidemic in different territories
simultaneously, leveraging the spatial structure of data significantly enhances
both the accuracy and robustness of reproduction number estimates. However,
this requires a good estimate of the spatial structure. To tackle this major
limitation, the present work proposes a joint estimator of the reproduction
number and connectivity structure. The procedure is assessed through intensive
numerical simulations on carefully designed synthetic data and illustrated on
real COVID-19 spatiotemporal infection counts.

</details>


### [44] [A dual bistatic optical forward transceiver configuration for determining the position of an acoustic communication source detected by optical communication fibers](https://arxiv.org/abs/2509.20046)
*Knut H. Grythe,Jan Erik Håkegård*

Main category: eess.SP

TL;DR: 本文提出了一种基于双端光纤配置的水声通信系统源定位方法，利用双静态雷达原理通过传播时延差进行位置估计。


<details>
  <summary>Details</summary>
Motivation: 传统分布式声学传感(DAS)在双向配置中缺乏源定位功能，而水下通信场景中源位置信息具有重要价值，需要一种集成通信和定位的解决方案。

Method: 采用双光纤布局，每端配备光学发射器和接收器，基于到达时间差(TDOA)进行位置估计，使用交叉模糊函数作为最大似然估计器。

Result: 推导了Cramér-Rao界以表征定位精度理论极限，分析表明增加声学带宽和载波频率可提高空间分辨率。仿真结果验证了方法在不同系统条件下的性能。

Conclusion: 该方法为集成通信和定位提供了可行替代方案，但实际应用中仍需解决关键技术挑战。

Abstract: Optical fibers have long been employed as sensors in a wide range of
commercial systems. Distributed Acoustic Sensing (DAS) extends this concept by
enabling the detection and localization of acoustic sources along the fiber,
using backscattered light from small segments to achieve spatial resolution on
the order of meters. Recently, DAS has also been explored as a component in
underwater acoustic communication systems. Emerging interest in bidirectional
configurations where both transmitter and receiver are placed at opposite ends
of the fiber has opened new possibilities. However, in such setups, source
localization is not inherently integrated into the signal decoding process. For
scenarios where source positioning is valuable, we propose an approach inspired
by bi-static radar principles. This configuration utilizes acoustic signals
received at both ends of the fiber to estimate source position based on
propagation delay differences. Although the localization accuracy is lower than
that of DAS due to reduced sampling rates, the method offers a viable
alternative for integrated communication and positioning. We present the system
topology and configuration for a dual-fiber layout, each end equipped with
optical transmitters and receivers. The position estimation is derived from the
time difference of arrival (TDOA) between the two receivers. The Cram\'er-Rao
Bound is derived to characterize the theoretical limits of localization
accuracy, highlighting dependencies on system parameters such as optical power
loss. Our analysis shows that increased acoustic bandwidth and higher carrier
frequencies enhance spatial resolution. We formulate the Cross Ambiguity
Function as a maximum likelihood estimator for TDOA and provide simulation
results illustrating its performance under varying system conditions. Finally,
we discuss key challenges that must be addressed for practical implementation.

</details>


### [45] [Joint Ex-Post Location Calibration and Radio Map Construction under Biased Positioning Errors](https://arxiv.org/abs/2509.20059)
*Koki Kanzaki,Koya Sato*

Main category: eess.SP

TL;DR: 提出了一种针对定位信息存在突发误差环境的高精度无线电地图构建方法，通过建模定位误差和空间相关性，在无线电地图构建过程中进行事后校准。


<details>
  <summary>Details</summary>
Motivation: 现有无线电地图构建方法大多假设定位信息无噪声，但实际设备定位系统（如GNSS）会产生几米到几十米的误差，忽略这些误差会导致无线电地图精度显著下降。研究发现移动设备作为传感器时这些误差往往存在偏差。

Method: 引入一个新颖框架，将定位误差和无线电传播的空间相关性作为可调参数嵌入边际对数似然函数中，实现无线电地图构建过程中的位置不确定性事后校准。

Result: 基于实际人类移动数据的数值结果表明，所提方法能将RMSE退化限制在约0.25-0.29 dB，而基线方法的性能损失超过1 dB。

Conclusion: 该方法能有效处理定位误差问题，在存在定位误差的情况下仍能保持较高的无线电地图构建精度。

Abstract: This paper proposes a high-accuracy radio map construction method tailored
for environments where location information is affected by bursty errors. Radio
maps are an effective tool for visualizing wireless environments. Although
extensive research has been conducted on accurate radio map construction, most
existing approaches assume noise-free location information during sensing. In
practice, however, positioning errors ranging from a few to several tens of
meters can arise due to device-based positioning systems (e.g., GNSS). Ignoring
such errors during inference can lead to significant degradation in radio map
accuracy. This study highlights that these errors often tend to be biased when
using mobile devices as sensors. We introduce a novel framework that models
these errors together with spatial correlation in radio propagation by
embedding them as tunable parameters in the marginal log-likelihood function.
This enables ex-post calibration of location uncertainty during radio map
construction. Numerical results based on practical human mobility data
demonstrate that the proposed method can limit RMSE degradation to
approximately 0.25-0.29 dB, compared with Gaussian process regression using
noise-free location data, whereas baseline methods suffer performance losses
exceeding 1 dB.

</details>


### [46] [Reciprocal Beyond-Diagonal Reconfigurable Intelligent Surface (BD-RIS): Scattering Matrix Design via Manifold Optimization](https://arxiv.org/abs/2509.20246)
*Marko Fidanovski,Iván Alexander Morales Sandoval,Hyeon Seok Rou,Giuseppe Thadeu Freitas de Abreu,Emil Björnson*

Main category: eess.SP

TL;DR: 本文研究BD-RIS在无线通信中的和速率最大化问题，通过强制对称性约束实现低复杂度物理实现，提出基于流形优化的方法。


<details>
  <summary>Details</summary>
Motivation: BD-RIS技术因其低成本和高信号处理能力，能在恶劣城市环境中提升无线系统性能。现有方法在实现复杂度和性能之间存在权衡，需要找到既能保证性能又易于物理实现的解决方案。

Method: 采用流形优化框架，在目标函数中加入惩罚项来确保对称性约束，并通过投影到可行散射矩阵集来进一步强制执行互易性。

Result: 仿真结果表明，所提方法在和速率最大化方面优于当前最先进的方法。

Conclusion: 通过对称散射矩阵设计和流形优化方法，BD-RIS能够有效提升无线系统的和速率性能，同时保证实现的可行性。

Abstract: Beyond-diagonal reconfigurable intelligent surfaces (BD-RISs) are emerging as
a transformative technology in wireless communications, enabling enhanced
performance and quality of service (QoS) of wireless systems in harsh urban
environments due to their relatively low cost and advanced signal processing
capabilities. Generally, BD-RIS systems are employed to improve robustness,
increase achievable rates, and enhance energy efficiency of wireless systems in
both direct and indirect ways. The direct way is to produce a favorable
propagation environment via the design of optimized scattering matrices, while
the indirect way is to reap additional improvements via the design of
multiple-input multiple-output (MIMO) beamformers that further exploit the
latter "engineered" medium. In this article, the problem of sum-rate
maximization via BD-RIS is examined, with a focus on feasibility, namely
low-complexity physical implementation, by enforcing reciprocity in the BD-RIS
design. We begin by outlining the system model and formulating an optimization
problem that aims to enhance the system's sum-rate by designing a symmetric
scattering matrix. In particular, the approach leverages a manifold
optimization framework, where a penalty term is added to the objective function
to ensure that the symmetry constraint is upheld, with reciprocity further
enforced by projecting the obtained solution onto a set of feasible scattering
matrices. Simulation results demonstrate the effectiveness of the proposed
method in outperforming current state-of-the-art (SotA) approaches in terms of
sum-rate maximization.

</details>


### [47] [Geometric Port Selection in CUMA Systems](https://arxiv.org/abs/2509.20299)
*Chenguang Rao,Kai-Kit Wong,Mohd Hamza Naim Shaikh,Hanjiang Hong,Hyundong Shin,Yangyang Zhang*

Main category: eess.SP

TL;DR: 本文提出了两种自适应单射频端口选择方案（EOHS和PCA），用于改进紧凑超大规模天线阵列（CUMA）技术，在保持低复杂度的同时显著提升性能。


<details>
  <summary>Details</summary>
Motivation: CUMA技术虽然能通过简单的端口选择机制实现大规模连接，但其随机端口选择策略存在优化空间，需要更智能的自适应方案来提升干扰抑制性能。

Method: 提出了两种端口选择方案：1）EOHS方案动态选择最大化瞬时信号累积的投影方向；2）PCA方案基于主成分分析，将端口分区与信道向量的主要统计方向对齐，提供闭式低复杂度解。

Result: 仿真结果表明，EOHS和PCA方案在不同用户密度、端口数量和FAS孔径尺寸下均优于传统CUMA，PCA方案能以较低计算成本实现接近EOHS的性能。

Conclusion: 所提方案能有效扩展到大规模用户场景，为下一代多址接入系统提供了有吸引力的复杂度-性能权衡。

Abstract: Compact ultra-massive antenna-array (CUMA) is a novel multiple access
technology built on the fluid antenna system (FAS) concept, offering an
improved scheme over fluid antenna multiple access (FAMA) that can support
massive connectivity on the same physical channel without the need of precoding
and interference cancellation. By employing a simple port-selection mechanism
that leverages random channel superposition, CUMA can suppress inter-user
interference while keeping hardware costs low. Nevertheless, its ad-hoc
port-selection strategy leaves considerable room for optimization. In this
work, we revisit CUMA and propose two adaptive single-RF port-selection schemes
that retain its simplicity while significantly enhancing performance. The first
one, referred to as exact optimal half-space (EOHS), dynamically selects the
projection direction that maximizes the instantaneous signal build-up across
active ports. To reduce complexity while preserving most of the gains, we
furthermore introduce a principal component analysis (PCA)-based scheme, which
aligns port partitioning with the dominant statistical direction of per-port
channel vectors. This method yields a closed-form low-complexity solution,
complemented by a tractable analytical framework that provides a closed-form
expression for the signal-to-interference ratio (SIR) probability density
function (PDF). Simulation results corroborate the analysis, demonstrating that
both EOHS and PCA consistently outperform conventional CUMA across diverse user
densities, port counts, and FAS aperture sizes. Notably, PCA achieves
performance close to EOHS at a fraction of the computational cost. The proposed
schemes scale effectively to large-user regimes, offering a compelling
complexity-performance trade-off for next-generation multiple access systems.

</details>
