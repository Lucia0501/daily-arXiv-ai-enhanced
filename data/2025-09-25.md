<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 42]
- [cs.IT](#cs.IT) [Total: 5]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Raspberry Pi Pico as a Radio Transmitter](https://arxiv.org/abs/2509.19304)
*M. Andrecut*

Main category: eess.SP

TL;DR: 将树莓派Pico微控制器通过简单方法转换为无线电发射器，使用廉价现成组件和开源软件，可能带来安全风险。


<details>
  <summary>Details</summary>
Motivation: 探索树莓派Pico微控制器作为无线电发射器的潜力，研究其安全影响。

Method: 使用廉价现成电子组件和开源软件对树莓派Pico进行改造。

Result: 成功将树莓派Pico转换为无线电发射器，可建立大量本地隐蔽无线电通信通道。

Conclusion: 这种看似无害的技术在极端情况下可能构成安全风险，需要引起重视。

Abstract: In this paper we discuss several surprisingly simple methods for transforming
the Raspberry Pi Pico (RP2) microcontroller into a radio transmitter, by using
only cheap off the shelf electronic components, and open source software. While
initially this transformation may look as a harmless curiosity, in some extreme
cases it can also pose security risks, since it can be used to open a large
number of local stealth radio communication channels.

</details>


### [2] [A Federated Fine-Tuning Paradigm of Foundation Models in Heterogenous Wireless Networks](https://arxiv.org/abs/2509.19306)
*Jingyi Wang,Zhongyuan Zhao,Qingtian Wang,Zexu Li,Yue Wang,Tony Q. S. Quek*

Main category: eess.SP

TL;DR: 该论文提出了一种基于在线学习的优化方法，用于解决异构无线网络中联邦微调的设备异构性和资源约束问题，通过动态切换LoRA模块来提升边缘智能的性能。


<details>
  <summary>Details</summary>
Motivation: 边缘智能需要低延迟和泛在服务，但无线网络中的设备异构性和资源约束对联邦微调性能构成威胁，需要新的优化方法。

Method: 提出了基于切换的联邦微调框架，设备动态切换LoRA模块；推导了推理风险间隙的上界；将非凸混合整数规划问题分解为模型切换、发射功率控制和带宽分配子问题，开发了多项式复杂度的在线优化算法。

Result: 在SST-2和QNLI数据集上的仿真结果表明，该方法在测试准确率和能量效率方面取得了性能提升。

Conclusion: 所提出的在线优化方法能有效应对异构无线网络中的联邦微调挑战，提高边缘智能的泛化能力和能效。

Abstract: Edge intelligence has emerged as a promising strategy to deliver low-latency
and ubiquitous services for mobile devices. Recent advances in fine-tuning
mechanisms of foundation models have enabled edge intelligence by integrating
low-rank adaptation (LoRA) with federated learning. However, in wireless
networks, the device heterogeneity and resource constraints on edge devices
pose great threats to the performance of federated fine-tuning. To tackle these
issues, we propose to optimize federated fine-tuning in heterogenous wireless
networks via online learning. First, the framework of switching-based federated
fine-tuning in wireless networks is provided. The edge devices switches to LoRA
modules dynamically for federated fine-tuning with base station to jointly
mitigate the impact of device heterogeneity and transmission unreliability.
Second, a tractable upper bound on the inference risk gap is derived based on
theoretical analysis. To improve the generalization capability, we formulate a
non-convex mixed-integer programming problem with long-term constraints, and
decouple it into model switching, transmit power control, and bandwidth
allocation subproblems. An online optimization algorithm is developed to solve
the problems with polynomial computational complexity. Finally, the simulation
results on the SST-2 and QNLI data sets demonstrate the performance gains in
test accuracy and energy efficiency.

</details>


### [3] [Bandwidth of Gamma-Distribution-Shaped Functions via Lambert W Function](https://arxiv.org/abs/2509.19307)
*Anthony LoPrete,Johannes Burge*

Main category: eess.SP

TL;DR: 本文推导了伽马分布函数半高全宽（FWHM）的精确解析表达式，使用Lambert W函数计算伽马分布概率密度函数的逆函数，并比较了伽马形函数的高斯近似。


<details>
  <summary>Details</summary>
Motivation: 伽马形函数的半高全宽（FWHM）是表征单峰函数带宽的重要参数，但目前缺乏其闭式表达式。

Method: 使用Lambert W函数计算伽马分布概率密度函数的逆函数，从而推导出任意比例最大值处伽马分布宽度的精确解析表达式。

Result: 得到了伽马分布FWHM的精确解析表达式，并提供了伽马形函数的倍频带宽表达式。

Conclusion: 成功推导出伽马形函数FWHM的闭式解，为相关应用提供了便利的数学工具。

Abstract: The full width at half maximum (FWHM) is a useful quantity for characterizing
the bandwidth of unimodal functions. However, a closed-form expression for the
FWHM of gamma-shaped functions-i.e. functions that are shaped like the gamma
distribution probability density function (PDF)-is not widely available. Here,
we derive and present just such an expression. To do so, we use the Lambert W
function to compute the inverse of the gamma PDF. We use this inverse to derive
an exact analytic expression for the width of a gamma distribution at an
arbitrary proportion of the maximum, from which the FWHM follows trivially. (An
expression for the octave bandwidth of gamma-shaped functions is also
provided.) The FWHM is then compared to the Gaussian approximation of
gamma-shaped functions. A few other related issues are discussed.

</details>


### [4] [Graph-Based Spatio-temporal Attention and Multi-Scale Fusion for Clinically Interpretable, High-Fidelity Fetal ECG Extraction](https://arxiv.org/abs/2509.19308)
*Chang Wang,Ming Zhu,Shahram Latifi,Buddhadeb Dawn,Shengjie Zhai*

Main category: eess.SP

TL;DR: FHNet是一个深度学习框架，结合图神经网络和多尺度增强transformer，用于从腹部心电图中提取干净的胎儿心电图信号，在低信噪比条件下表现出色。


<details>
  <summary>Details</summary>
Motivation: 先天性心脏病是最常见的新生儿异常，需要早期检测以改善预后。但胎儿心电图信号在腹部心电图中常被母体心电图和噪声掩盖，传统方法在低信噪比条件下面临挑战。

Method: 提出FetalHealthNet（FHNet）框架，集成图神经网络和多尺度增强transformer，动态建模时空导联间相关性，提取干净的胎儿心电图信号。

Result: 在基准aECG数据集上，FHNet持续优于LSTM模型、标准transformer和最先进模型，即使在严重噪声下也达到R2>0.99和RMSE=0.015。可解释性分析显示生理学意义的时间导联贡献。

Conclusion: FHNet展示了AI驱动建模在推进胎儿监测和实现早期CHD筛查方面的潜力，强调了新一代生物医学信号处理的变革性影响。

Abstract: Congenital Heart Disease (CHD) is the most common neonatal anomaly,
highlighting the urgent need for early detection to improve outcomes. Yet,
fetal ECG (fECG) signals in abdominal ECG (aECG) are often masked by maternal
ECG and noise, challenging conventional methods under low signal-to-noise ratio
(SNR) conditions. We propose FetalHealthNet (FHNet), a deep learning framework
that integrates Graph Neural Networks with a multi-scale enhanced transformer
to dynamically model spatiotemporal inter-lead correlations and extract clean
fECG signals. On benchmark aECG datasets, FHNet consistently outperforms long
short-term memory (LSTM) models, standard transformers, and state-of-the-art
models, achieving R2>0.99 and RMSE = 0.015 even under severe noise.
Interpretability analyses highlight physiologically meaningful temporal and
lead contributions, supporting model transparency and clinical trust. FHNet
illustrates the potential of AI-driven modeling to advance fetal monitoring and
enable early CHD screening, underscoring the transformative impact of
next-generation biomedical signal processing.

</details>


### [5] [A Novel Two-Dimensional Wigner Distribution Framework via the Quadratic Phase Fourier Transform with a Non-Separable Kernel](https://arxiv.org/abs/2509.19310)
*Mukul Chauhan,Waseem Z. Lone,Amit K. Verma*

Main category: eess.SP

TL;DR: 本文提出了一种基于二维不可分二次相位傅里叶变换的新型时频分布方法2D-NSQPWD，它通过替换经典傅里叶核来推广经典Wigner分布，能有效捕捉复杂的不可分信号结构。


<details>
  <summary>Details</summary>
Motivation: 传统Wigner分布在处理复杂不可分信号结构时存在局限性，需要一种能够更好捕捉非分离信号特征的新型时频分布方法。

Method: 使用二维不可分二次相位傅里叶变换核替换经典傅里叶核，构建2D-NSQPWD分布，并严格证明其数学性质如时频移不变性、边缘行为等。

Result: 在单分量、双分量和三分量二维线性调频信号上的应用表明，该方法在交叉项抑制和信号定位方面表现出优越性能。

Conclusion: 2D-NSQPWD是一种有效的时频分析工具，特别适用于处理复杂的非分离信号结构，在信号定位和交叉项抑制方面优于传统方法。

Abstract: This paper introduces a novel time-frequency distribution, referred to as the
Two-Dimensional Non-Separable Quadratic Phase Wigner Distribution (2D-NSQPWD),
formulated within the framework of the Two-Dimensional Non-Separable Quadratic
Phase Fourier Transform (2D-NSQPFT). By replacing the classical Fourier kernel
with the NSQPFT kernel, the proposed distribution generalizes the classical
Wigner distribution and effectively captures complex, non-separable signal
structures. We rigorously establish several key properties of the 2D-NSQPWD,
including time and frequency shift invariance, marginal behavior, conjugate
symmetry, convolution relations, and Moyal's identity. Furthermore, the
connection between the 2D-NSQPWD and the two-dimensional short-time Fourier
transform (2D-STFT) is explored. The distribution's effectiveness is
demonstrated through its application to single-, bi-, and tri-component
two-dimensional linear frequency modulated (2D-LFM) signals, where it shows
superior performance in cross-term suppression and signal localization.

</details>


### [6] [E2E Learning Massive MIMO for Multimodal Semantic Non-Orthogonal Transmission and Fusion](https://arxiv.org/abs/2509.19312)
*Minghui Wu,Zhen Gao*

Main category: eess.SP

TL;DR: 本文提出了一种端到端的上行-下行CSI融合预编码网络，通过联合建模下行CSI参考信号设计、CSI反馈和基站预编码，有效利用上行SRS信息和用户反馈来提升大规模MIMO系统的性能。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO系统虽然能提供高频谱效率，但高维下行信道状态信息(CSI)使得实时信道获取和预编码变得复杂。现有方法通常独立处理上行和下行信息，未能充分利用两者的互补优势。

Method: 构建基于MAXIM架构的投影网络，输入上行探测参考信号(SRS)，输出用于设计下行CSI-RS的投影矩阵。用户设备压缩/量化CSI-RS观测值并反馈。基站端有两个互补分支：基于量化下行观测的反馈预编码网络和基于上行SRS的SRS预编码网络，通过融合预编码网络结合两者生成最终预编码器。所有模块采用三阶段训练策略，以频谱效率为导向的损失函数进行优化。

Result: 仿真结果表明，该方法能有效利用SRS衍生信息和用户反馈，相比传统基线方法取得了显著更好的性能。

Conclusion: 提出的端到端融合预编码网络成功解决了大规模MIMO系统中高维CSI带来的挑战，通过联合优化上行和下行信息处理，实现了更高效的预编码性能。

Abstract: Massive multiple-input multiple-output (MIMO) promises high spectral
efficiency but also leads to high-dimensional downlink channel state
information (CSI), which complicates real-time channel acquisition and
precoding. To address this, we propose an end-to-end (E2E) uplink-downlink CSI
fusion precoding network that jointly models downlink CSI reference signal
(CSI-RS) design, CSI feedback, and base-station (BS) precoding within a single
E2E neural architecture. Concretely, a projection network built on the MAXIM
architecture takes uplink sounding reference signals (SRS) as input and outputs
frequency-, beam-, and port-domain projection matrices for designing downlink
CSI-RS. User equipment (UE) then compresses/quantizes the resulting CSI-RS
observations and feeds back a compact representation. At the base station (BS),
two complementary branches produce candidate precoders: one is a feedback-only
precoding network driven by quantized downlink observations, and the other is
an SRS-only precoding network driven by uplink SRS. These candidate precoders
are subsequently combined by a fusion precoding network to yield the final
transmit precoder. All the modules are trained with a
spectral-efficiency-oriented loss under a three-stage schedule. Simulation
results show that the proposed approach effectively harnesses both SRS-derived
information and UE feedback, achieving markedly better performance than
conventional baselines.

</details>


### [7] [STL-FFT-STFT-TCN-LSTM: An Effective Wave Height High Accuracy Prediction Model Fusing Time-Frequency Domain Features](https://arxiv.org/abs/2509.19313)
*Huipeng Liu,Zhichao Zhu,Yuan Zhou,Changlu Li*

Main category: eess.SP

TL;DR: 本文提出了一种结合STL-FFT-STFT-TCN-LSTM的混合模型，用于精确预测有效波高，解决了波浪能信号的非线性、突变、多尺度周期性等挑战，在极端波高捕获和高频噪声抑制方面表现出显著优势。


<details>
  <summary>Details</summary>
Motivation: 随着传统能源消耗加剧和环境问题日益严重，波浪能因其高能量密度、稳定性、分布广泛和环境友好性而成为可再生能源的重要成员。精确预测有效波高是波浪能开发的关键，但现有方法面临非线性、数据稀疏、计算成本高等挑战。

Method: 提出STL-FFT-STFT-TCN-LSTM混合模型，结合季节性趋势分解、快速傅里叶变换、短时傅里叶变换、时序卷积网络和长短期记忆网络技术，优化多尺度特征融合，捕获极端波高，处理高频噪声和周期信号问题。

Result: 使用NOAA站点2019-2022年每小时数据进行实验，相比其他单模型和混合模型，该模型在极端波高捕获和噪声抑制方面显著提升：MAE降低15.8%-40.5%，SMAPE降低8.3%-20.3%，R增加1.31%-2.9%。消融实验验证了各组件步骤的必要性。

Conclusion: STL-FFT-STFT-TCN-LSTM混合模型在有效波高预测中表现出优越性能，特别是在多尺度特征融合方面，为波浪能的高效开发利用提供了可靠的技术支持。

Abstract: As the consumption of traditional energy sources intensifies and their
adverse environmental impacts become more pronounced, wave energy stands out as
a highly promising member of the renewable energy family due to its high energy
density, stability, widespread distribution, and environmental friendliness.
The key to its development lies in the precise prediction of Significant Wave
Height (WVHT). However, wave energy signals exhibit strong nonlinearity, abrupt
changes, multi-scale periodicity, data sparsity, and high-frequency noise
interference; additionally, physical models for wave energy prediction incur
extremely high computational costs. To address these challenges, this study
proposes a hybrid model combining STL-FFT-STFT-TCN-LSTM. This model exploits
the Seasonal-Trend Decomposition Procedure based on Loess (STL), Fast Fourier
Transform (FFT), Short-Time Fourier Transform (STFT), Temporal Convolutional
Network (TCN), and Long Short-Term Memory (LSTM) technologies. The model aims
to optimize multi-scale feature fusion, capture extreme wave heights, and
address issues related to high-frequency noise and periodic signals, thereby
achieving efficient and accurate prediction of significant wave height.
Experiments were conducted using hourly data from NOAA Station 41008 and 41047
spanning 2019 to 2022. The results showed that compared with other single
models and hybrid models, the STL-FFT-STFT-TCN-LSTM model achieved
significantly higher prediction accuracy in capturing extreme wave heights and
suppressing high-frequency noise, with MAE reduced by 15.8\%-40.5\%, SMAPE
reduced by 8.3\%-20.3\%, and R increased by 1.31\%-2.9\%; in ablation
experiments, the model also demonstrated the indispensability of each component
step, validating its superiority in multi-scale feature fusion.

</details>


### [8] [Advancing Few-Shot Pediatric Arrhythmia Classification with a Novel Contrastive Loss and Multimodal Learning](https://arxiv.org/abs/2509.19315)
*Yiqiao Chen,Zijian Huang,Zhenghui Feng*

Main category: eess.SP

TL;DR: 本文提出了一种多模态深度学习框架，结合ECG和IEGM信号，用于儿科心律失常的自动分类，在Leipzig心脏中心数据集上取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 儿科心律失常是导致残疾和心源性猝死的主要风险因素，但由于类别不平衡、小样本类别和复杂信号特征，其自动分类仍面临挑战，限制了早期筛查和临床干预的效率与可靠性。

Method: 提出多模态端到端深度学习框架，包括双分支卷积编码器处理ECG和IEGM信号、语义注意力机制进行跨模态特征对齐、轻量级Transformer编码器建模全局依赖关系，并引入自适应全局类感知对比损失函数（AGCACL）增强类内紧凑性和类间可分离性。

Result: 在Leipzig心脏中心儿科/先天性ECG+IEGM数据集上，该方法取得了97.76%的Top-1准确率、94.08%宏精确率、91.97%宏召回率、92.97%宏F1分数和92.36%宏F2分数，相比最强基线在宏精确率/召回率/F1/F2上分别提升了+13.64、+15.96、+19.82和+19.44个百分点。

Conclusion: 该框架显著提高了少数心律失常类别的可检测性和鲁棒性，为儿科和先天性心脏病人群的心律筛查、术前评估和术后随访提供了潜在的临床价值。

Abstract: Pediatric arrhythmias are a major risk factor for disability and sudden
cardiac death, yet their automated classification remains challenging due to
class imbalance, few-shot categories, and complex signal characteristics, which
severely limit the efficiency and reliability of early screening and clinical
intervention. To address this problem, we propose a multimodal end-to-end deep
learning framework that combines dual-branch convolutional encoders for ECG and
IEGM, semantic attention for cross-modal feature alignment, and a lightweight
Transformer encoder for global dependency modeling. In addition, we introduce a
new contrastive loss fucntion named Adaptive Global Class-Aware Contrastive
Loss (AGCACL) to enhance intra-class compactness and inter-class separability
through class prototypes and a global similarity matrix. To the best of our
knowledge, this is the first systematic study based on the Leipzig Heart Center
pediatric/congenital ECG+IEGM dataset, for which we also provide a complete and
reproducible preprocessing pipeline. Experimental results demonstrate that the
proposed method achieves the overall best performance on this dataset,
including 97.76\% Top-1 Accuracy, 94.08\% Macro Precision, 91.97\% Macro
Recall, 92.97\% Macro F1, and 92.36\% Macro F2, with improvements of +13.64,
+15.96, +19.82, and +19.44 percentage points over the strongest baseline in
Macro Precision/Recall/F1/F2, respectively. These findings indicate that the
framework significantly improves the detectability and robustness for minority
arrhythmia classes, offering potential clinical value for rhythm screening,
pre-procedural assessment, and postoperative follow-up in pediatric and
congenital heart disease populations.

</details>


### [9] [Electric Vehicle Identification from Behind Smart Meter Data](https://arxiv.org/abs/2509.19316)
*Ammar Kamoona,Hui Song,Ali Moradi Amani,Mahdi Jalili,Xinghuo Yu,Peter McTaggart*

Main category: eess.SP

TL;DR: 本文提出了一种基于异常检测的无监督学习方法，用于从智能电表数据中识别电动汽车充电负载，无需先验的EV充电配置文件知识。


<details>
  <summary>Details</summary>
Motivation: 当电动汽车充电发生在电表后端时，充电负载被视为用户总负载的一部分，而非单独测量。配电网络运营商需要了解网络中EV的存在情况以更好地规划和管理电网。

Method: 采用基于异常检测技术的无监督学习方法和深度时间卷积编码解码网络，仅需非EV用户的真实功耗数据。

Result: 该方法在澳大利亚维多利亚州家庭智能电表数据上表现出优异的性能，能够有效识别拥有EV的家庭。

Conclusion: 所提出的TAE网络为配电网络运营商提供了一种有效的非侵入式EV充电负载识别方法，有助于电网的智能决策和可靠性管理。

Abstract: Electric vehicle (EV) charging loads identification from behind smart meter
recordings is an indispensable aspect that enables effective decision-making
for energy distributors to reach an informed and intelligent decision about the
power grid's reliability. When EV charging happens behind the meter (BTM), the
charging occurs on the customer side of the meter, which measures the overall
electricity consumption. In other words, the charging of the EV is considered
part of the customer's load and not separately measured by the Distribution
Network Operators (DNOs). DNOs require complete knowledge about the EV presence
in their network. Identifying the EV charging demand is essential to better
plan and manage the distribution grid. Unlike supervised methods, this paper
addresses the problem of EV charging load identification in a non-nonintrusive
manner from low-frequency smart meter using an unsupervised learning approach
based on anomaly detection technique. Our approach does not require prior
knowledge of EV charging profiles. It only requires real power consumption data
of non-EV users, which are abundant in practice. We propose a deep temporal
convolution encoding decoding (TAE) network. The TAE is applied to power
consumption from smart BTM from Victorian households in Australia, and the TAE
shows superior performance in identifying households with EVs.

</details>


### [10] [Scensory: Automated Real-Time Fungal Identification and Spatial Mapping](https://arxiv.org/abs/2509.19318)
*Yanbaihui Liu,Erica Babusci,Claudia K. Gunsch,Boyuan Chen*

Main category: eess.SP

TL;DR: Scensory是一个机器人驱动的嗅觉系统，使用低成本VOC传感器阵列和深度学习，能够同时识别真菌种类并定位其空间来源，实现实时、空间感知的真菌监测。


<details>
  <summary>Details</summary>
Motivation: 现有真菌检测方法速度慢、成本高、缺乏空间分辨率，不适合实时监测和规模化部署。

Method: 利用机器人自动数据收集，通过分析VOC时间动态特征来解码化学和空间特征，采用被动多阵列配置进行环境监测和移动单阵列配置进行主动源跟踪。

Result: 在五种真菌物种上，系统在环境条件下达到89.85%的物种检测准确率和87.31%的定位准确率，每个预测仅需3-7秒传感器输入。

Conclusion: 该方法实现了实时、空间感知的真菌监测，建立了可扩展且经济实惠的自主环境感知框架，并能通过计算分析模型行为揭示关键生化特征。

Abstract: Indoor fungal contamination poses significant risks to public health, yet
existing detection methods are slow, costly, and lack spatial resolution.
Conventional approaches rely on laboratory analysis or high-concentration
sampling, making them unsuitable for real-time monitoring and scalable
deployment. We introduce \textbf{\textit{Scensory}}, a robot-enabled olfactory
system that simultaneously identifies fungal species and localizes their
spatial origin using affordable volatile organic compound (VOC) sensor arrays
and deep learning. Our key idea is that temporal VOC dynamics encode both
chemical and spatial signatures, which we decode through neural architectures
trained on robot-automated data collection. We demonstrate two operational
modes: a passive multi-array configuration for environmental monitoring, and a
mobile single-array configuration for active source tracking. Across five
fungal species, our system achieves up to 89.85\% accuracy in species detection
and 87.31\% accuracy in localization under ambient conditions, where each
prediction only takes 3--7\,s sensor inputs. Additionally, by computationally
analyzing model behavior, we can uncover key biochemical signatures without
additional laboratory experiments. Our approach enables real-time, spatially
aware fungal monitoring and establishes a scalable and affordable framework for
autonomous environmental sensing.

</details>


### [11] [Human Activity Recognition Based on Electrocardiogram Data Only](https://arxiv.org/abs/2509.19328)
*Sina Montazeri,Waltenegus Dargie,Yunhe Feng,Kewei Sha*

Main category: eess.SP

TL;DR: 本文首次展示了仅使用ECG信号在六种不同活动中实现稳健的活动识别，超越了以往工作的范畴。设计了三种新的深度学习模型，在54名受试者的数据上测试，所有模型对已知受试者准确率超过94%，CNNTransformer混合模型对未知受试者达到72%准确率。


<details>
  <summary>Details</summary>
Motivation: 传统活动识别依赖惯性测量单元(IMU)，资源密集且需要校准。虽然ECG方法已被探索，但通常作为IMU的补充或仅限于宽泛分类。本文旨在推进仅使用ECG进行多活动识别的能力。

Method: 设计了三种深度学习模型：1)带Squeeze-and-Excitation块的CNN分类器用于通道特征重校准；2)带扩张卷积的ResNet分类器用于多尺度时间依赖捕获；3)新颖的CNNTransformer混合模型结合卷积特征提取和注意力机制用于长程时间关系建模。

Result: 在54名受试者的六种活动数据上测试，所有三种模型对已知受试者准确率超过94%，CNNTransformer混合模型对未知受试者达到72%准确率，且可通过增加训练人群进一步改进。

Conclusion: 本研究首次成功实现了仅基于ECG的多项身体活动分类，为开发能够同时进行心脏监测和活动识别的下一代可穿戴设备提供了重要潜力，无需额外运动传感器。

Abstract: Human activity recognition is critical for applications such as early
intervention and health analytics. Traditional activity recognition relies on
inertial measurement units (IMUs), which are resource intensive and require
calibration. Although electrocardiogram (ECG)-based methods have been explored,
these have typically served as supplements to IMUs or have been limited to
broad categorical classification such as fall detection or active vs. inactive
in daily activities. In this paper, we advance the field by demonstrating, for
the first time, robust recognition of activity only with ECG in six distinct
activities, which is beyond the scope of previous work. We design and evaluate
three new deep learning models, including a CNN classifier with
Squeeze-and-Excitation blocks for channel-wise feature recalibration, a ResNet
classifier with dilated convolutions for multiscale temporal dependency
capture, and a novel CNNTransformer hybrid combining convolutional feature
extraction with attention mechanisms for long-range temporal relationship
modeling. Tested on data from 54 subjects for six activities, all three models
achieve over 94% accuracy for seen subjects, while CNNTransformer hybrid
reaching the best accuracy of 72% for unseen subjects, a result that can be
further improved by increasing the training population. This study demonstrates
the first successful ECG-only activity classification in multiple physical
activities, offering significant potential for developing next-generation
wearables capable of simultaneous cardiac monitoring and activity recognition
without additional motion sensors.

</details>


### [12] [LibEMER: A novel benchmark and algorithms library for EEG-based Multimodal Emotion Recognition](https://arxiv.org/abs/2509.19330)
*Zejun Liu,Yunshan Chen,Chengxi Xie,Huan Liu*

Main category: eess.SP

TL;DR: 本文介绍了LibEMER，一个用于EEG多模态情感识别的统一评估框架，旨在解决该领域缺乏开源实现、标准化基准和深入讨论的问题。


<details>
  <summary>Details</summary>
Motivation: 当前EEG多模态情感识别领域存在三个关键问题：缺乏开源实现、缺少标准化透明基准、以及缺乏对主要挑战和前景研究方向的深入讨论。

Method: 开发了LibEMER框架，提供可完全复现的PyTorch实现，包含标准化的数据预处理、模型实现和实验设置协议。

Result: 该框架在三个广泛使用的公共数据集和两个学习任务上实现了无偏性能评估。

Conclusion: LibEMER为EEG多模态情感识别研究提供了统一的评估标准，有助于推动该领域的公平比较和进一步发展。

Abstract: EEG-based multimodal emotion recognition(EMER) has gained significant
attention and witnessed notable advancements, the inherent complexity of human
neural systems has motivated substantial efforts toward multimodal approaches.
However, this field currently suffers from three critical limitations: (i) the
absence of open-source implementations. (ii) the lack of standardized and
transparent benchmarks for fair performance analysis. (iii) in-depth discussion
regarding main challenges and promising research directions is a notable
scarcity. To address these challenges, we introduce LibEMER, a unified
evaluation framework that provides fully reproducible PyTorch implementations
of curated deep learning methods alongside standardized protocols for data
preprocessing, model realization, and experimental setups. This framework
enables unbiased performance assessment on three widely-used public datasets
across two learning tasks. The open-source library is publicly accessible at:
https://anonymous.4open.science/r/2025ULUIUBUEUMUEUR485384

</details>


### [13] [Joint Channel Estimation and Computation Offloading in Fluid Antenna-assisted MEC Networks](https://arxiv.org/abs/2509.19340)
*Ying Ju,Mingdong Li,Haoyu Wang,Lei Liu,Youyang Qu,Mianxiong Dong,Victor C. M. Leung,Chau Yuen*

Main category: eess.SP

TL;DR: 本文提出了一种流体天线辅助的移动边缘计算卸载框架，通过信息瓶颈度量增强的信道压缩感知和博弈论辅助的分层双决斗多智能体算法，有效解决了信道估计复杂性和非凸优化问题，显著降低了系统延迟。


<details>
  <summary>Details</summary>
Motivation: 流体天线能够动态调整端口位置，为移动边缘计算系统提供空间分集和频谱效率优势，但面临信道估计复杂和联合优化非凸的挑战。

Method: 提出IBM-CCS方法增强流体天线信道估计，集成信息相关性；开发HiTDMA算法通过分层结构和博弈论解耦优化任务，降低功率控制变量维度。

Result: 数值结果表明所提方案显著降低系统延迟，提升卸载性能，优于基准方法；IBM-CCS在不同端口密度下表现出优越的准确性和鲁棒性。

Conclusion: 该框架通过创新的信道估计和优化算法，有效解决了流体天线辅助MEC系统的关键挑战，实现了高效的通信和计算卸载性能。

Abstract: With the emergence of fluid antenna (FA) in wireless communications, the
capability to dynamically adjust port positions offers substantial benefits in
spatial diversity and spectrum efficiency, which are particularly valuable for
mobile edge computing (MEC) systems. Therefore, we propose an FA-assisted MEC
offloading framework to minimize system delay. This framework faces two severe
challenges, which are the complexity of channel estimation due to dynamic port
configuration and the inherent non-convexity of the joint optimization problem.
Firstly, we propose Information Bottleneck Metric-enhanced Channel Compressed
Sensing (IBM-CCS), which advances FA channel estimation by integrating
information relevance into the sensing process and capturing key features of FA
channels effectively. Secondly, to address the non-convex and high-dimensional
optimization problem in FA-assisted MEC systems, which includes FA port
selection, beamforming, power control, and resource allocation, we propose a
game theory-assisted Hierarchical Twin-Dueling Multi-agent Algorithm (HiTDMA)
based offloading scheme, where the hierarchical structure effectively decouples
and coordinates the optimization tasks between the user side and the base
station side. Crucially, the game theory effectively reduces the dimensionality
of power control variables, allowing deep reinforcement learning (DRL) agents
to achieve improved optimization efficiency. Numerical results confirm that the
proposed scheme significantly reduces system delay and enhances offloading
performance, outperforming benchmarks. Additionally, the IBM-CCS channel
estimation demonstrates superior accuracy and robustness under varying port
densities, contributing to efficient communication under imperfect CSI.

</details>


### [14] [Holographic Transformers for Complex-Valued Signal Processing: Integrating Phase Interference into Self-Attention](https://arxiv.org/abs/2509.19331)
*Enhao Huang,Zhiyu Zhang,Tianxiang Xu,Chunshu Xia,Kaichun Hu,Yuchen Yang,Tongtong Pan,Dong Dong,Zhan Qin*

Main category: eess.SP

TL;DR: Holographic Transformer是一种受物理学启发的架构，将波干涉原理融入自注意力机制，通过相对相位调制交互并相干叠加值，确保幅度和相位的一致性。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习模型将注意力视为实值相关性，忽略了复值信号中同时包含幅度和相位信息的干涉效应。

Method: 引入全息注意力机制，通过相对相位调制交互并相干叠加值；采用双头解码器同时重建输入和预测任务输出，防止相位崩溃。

Result: 在PolSAR图像分类和无线信道预测实验中表现出色，获得高分类精度和F1分数，低回归误差，并对相位扰动具有更强鲁棒性。

Conclusion: 在注意力中强制执行物理一致性可带来复值学习的泛化改进，为相干信号建模提供了统一的物理基础框架。

Abstract: Complex-valued signals encode both amplitude and phase, yet most deep models
treat attention as real-valued correlation, overlooking interference effects.
We introduce the Holographic Transformer, a physics-inspired architecture that
incorporates wave interference principles into self-attention. Holographic
attention modulates interactions by relative phase and coherently superimposes
values, ensuring consistency between amplitude and phase. A dual-headed decoder
simultaneously reconstructs the input and predicts task outputs, preventing
phase collapse when losses prioritize magnitude over phase. We demonstrate that
holographic attention implements a discrete interference operator and maintains
phase consistency under linear mixing. Experiments on PolSAR image
classification and wireless channel prediction show strong performance,
achieving high classification accuracy and F1 scores, low regression error, and
increased robustness to phase perturbations. These results highlight that
enforcing physical consistency in attention leads to generalizable improvements
in complex-valued learning and provides a unified, physics-based framework for
coherent signal modeling. The code is available at
https://github.com/EonHao/Holographic-Transformers.

</details>


### [15] [A Measurement Report Data-Driven Framework for Localized Statistical Channel Modeling](https://arxiv.org/abs/2509.19342)
*Xinyu Qin,Ye Xue,Qi Yan,Shutao Zhang,Bingsheng Peng,Tsung-Hui Chang*

Main category: eess.SP

TL;DR: 提出了一种基于测量报告数据的局部统计信道建模框架，通过超图神经网络解决MR数据定位问题，并联合优化网格划分和信道角度功率谱估计


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖高成本的驱测数据且空间覆盖有限，而MR数据成本低、收集广泛但缺乏位置信息，需要解决定位和信道建模问题

Method: 框架包含两个模块：基于超图神经网络的MR定位模块，以及联合网格构建和信道APS估计模块，通过聚类和改进的稀疏恢复方法交替优化

Result: 在真实MR数据集上的实验表明，该框架在定位和信道建模方面具有优越性能和鲁棒性

Conclusion: 该MR数据驱动的LSCM框架能够有效利用低成本MR数据，在复杂环境中实现鲁棒的局部统计信道建模

Abstract: Localized statistical channel modeling (LSCM) is crucial for effective
performance evaluation in digital twin-assisted network optimization. Solely
relying on the multi-beam reference signal receiving power (RSRP), LSCM aims to
model the localized statistical propagation environment by estimating the
channel angular power spectrum (APS). However, existing methods rely heavily on
drive test data with high collection costs and limited spatial coverage. In
this paper, we propose a measurement report (MR) data-driven framework for
LSCM, exploiting the low-cost and extensive collection of MR data. The
framework comprises two novel modules. The MR localization module addresses the
issue of missing locations in MR data by introducing a semi-supervised method
based on hypergraph neural networks, which exploits multi-modal information via
distance-aware hypergraph modeling and hypergraph convolution for location
extraction. To enhance the computational efficiency and solution robustness,
LSCM operates at the grid level. Compared to independently constructing
geographically uniform grids and estimating channel APS, the joint grid
construction and channel APS estimation module enhances robustness in complex
environments with spatially non-uniform data by exploiting their correlation.
This module alternately optimizes grid partitioning and APS estimation using
clustering and improved sparse recovery for the ill-conditioned measurement
matrix and incomplete observations. Through comprehensive experiments on a
real-world MR dataset, we demonstrate the superior performance and robustness
of our framework in localization and channel modeling.

</details>


### [16] [A Spatio-Temporal Feature Fusion EEG Virtual Channel Signal Generation Network and Its Application in Anxiety Assessment](https://arxiv.org/abs/2509.19334)
*Shangqing Yuan,Wenshuang Zhai,Shengwen Guo*

Main category: eess.SP

TL;DR: 本研究提出了一种基于时空特征融合的EEG虚拟通道信号生成网络，旨在解决便携式EEG设备通道有限的问题，通过4个额叶通道生成13个脑区的虚拟EEG信号，显著提升了焦虑分类性能。


<details>
  <summary>Details</summary>
Motivation: 解决便携式EEG设备通道数量有限、信息采集不足的问题，通过生成虚拟通道信号来扩展可用脑区信息。

Method: 采用二维卷积神经网络，包含并行时空特征提取模块和特征融合模块，基于PRED+CT数据库的119名受试者多通道EEG数据进行验证。

Result: 生成的虚拟通道EEG信号与真实信号的平均相关系数为0.6724，平均绝对误差为3.9470；结合原始信号进行焦虑分类时显著提升了机器学习算法性能。

Conclusion: 该网络生成的虚拟EEG信号与真实信号高度一致，有效缓解了便携式EEG设备信息获取不足的问题，为脑电信号分析提供了新思路。

Abstract: To address the issue of limited channels and insufficient information
collection in portable EEG devices, this study explores an EEG virtual channel
signal generation network using a novel spatio-temporal feature fusion
strategy. Based on the EEG signals from four frontal lobe channels, the network
aims to generate virtual channel EEG signals for other 13 important brain
regions. The architecture of the network is a two-dimensional convolutional
neural network and it includes a parallel module for temporal and spatial
domain feature extraction, followed by a feature fusion module. The public
PRED+CT database, which includes multi-channel EEG signals from 119 subjects,
was selected to verify the constructed network. The results showed that the
average correlation coefficient between the generated virtual channel EEG
signals and the original real signals was 0.6724, with an average absolute
error of 3.9470. Furthermore, the 13 virtual channel EEG signals were combined
with the original EEG signals of four brain regions and then used for anxiety
classification with a support vector machine. The results indicate that the
virtual EEG signals generated by the constructed network not only have a high
degree of consistency with the real channel EEG signals but also significantly
enhance the performance of machine learning algorithms for anxiety
classification. This study effectively alleviates the problem of insufficient
information acquisition by portable EEG devices with few channels.

</details>


### [17] [Neural Network Based Framework for Passive Intermodulation Cancellation in MIMO Systems](https://arxiv.org/abs/2509.19382)
*Xiaolong Li,Zhi-qin John Xu,Peiting You,Yifei Zhu*

Main category: eess.SP

TL;DR: 提出了一种基于深度学习的轻量级PIM消除框架，使用深度可分离卷积和扩张卷积来高效捕获天线和子载波间的非线性依赖关系，在MIMO实验设置中实现了29dB的平均功率误差消除效果。


<details>
  <summary>Details</summary>
Motivation: 被动互调(PIM)已成为现代MIMO-OFDM系统中的关键自干扰源，特别是在5G及更高标准的严格要求下。传统消除方法依赖复杂的非线性模型，存在可扩展性有限和计算成本高的问题。

Method: 采用深度可分离卷积和扩张卷积构建轻量级深度学习框架，结合循环学习率调度和梯度裁剪来增强收敛性，仅使用11k可训练参数。

Result: 在受控MIMO实验设置中，该方法有效抑制了三阶被动互调失真，实现了高达29dB的平均功率误差消除效果。

Conclusion: 这些结果凸显了紧凑神经网络架构在未来无线通信系统中进行可扩展干扰抑制的潜力。

Abstract: Passive intermodulation (PIM) has emerged as a critical source of
self-interference in modern MIMO-OFDM systems, especially under the stringent
requirements of 5G and beyond. Conventional cancellation methods often rely on
complex nonlinear models with limited scalability and high computational cost.
In this work, we propose a lightweight deep learning framework for PIM
cancellation that leverages depthwise separable convolutions and dilated
convolutions to efficiently capture nonlinear dependencies across antennas and
subcarriers. To further enhance convergence, we adopt a cyclic learning rate
schedule and gradient clipping. In a controlled MIMO experimental setup, the
method effectively suppresses third-order passive intermodulation (PIM)
distortion, achieving up to 29dB of average power error (APE) with only 11k
trainable parameters. These results highlight the potential of compact neural
architectures for scalable interference mitigation in future wireless
communication systems.

</details>


### [18] [CSIYOLO: An Intelligent CSI-based Scatter Sensing Framework for Integrated Sensing and Communication Systems](https://arxiv.org/abs/2509.19335)
*Xudong Zhang,Jingbo Tan,Zhizhen Ren,Jintao Wang,Yihua Ma,Jian Song*

Main category: eess.SP

TL;DR: 提出了CSIYOLO框架，仅使用单个基站-用户设备对的估计CSI进行散射体定位，无需修改波形或信号处理流程，可无缝集成到现有通信系统中


<details>
  <summary>Details</summary>
Motivation: 现有ISAC散射感知方法依赖波形硬件修改或传统信号处理方案，与当前通信系统兼容性差且感知精度有限

Method: 包含基于锚点的散射参数检测和CSI定位算法两部分：将散射参数提取建模为图像检测问题，采用YOLO架构的锚点检测方法；设计可扩展网络结构支持多尺度检测和CSI特性适配；采用噪声注入训练增强鲁棒性

Result: 实验表明该方法在不同散射体数量和估计误差下，能以较低复杂度显著超越现有方法的定位精度

Conclusion: CSIYOLO框架为ISAC散射感知提供了高兼容性、高精度的解决方案，可作为插件无缝集成到现有通信系统

Abstract: ISAC is regarded as a promising technology for next-generation communication
systems, enabling simultaneous data transmission and target sensing. Among
various tasks in ISAC, scatter sensing plays a crucial role in exploiting the
full potential of ISAC and supporting applications such as autonomous driving
and low-altitude economy. However, most existing methods rely on either
waveform and hardware modifications or traditional signal processing schemes,
leading to poor compatibility with current communication systems and limited
sensing accuracy. To address these challenges, we propose CSIYOLO, a framework
that performs scatter localization only using estimated CSI from a single base
station-user equipment pair. This framework comprises two main components:
anchor-based scatter parameter detection and CSI-based scatter localization.
First, by formulating scatter parameter extraction as an image detection
problem, we propose an anchor-based scatter parameter detection method inspired
by You Only Look Once architectures. After that, a CSI-based localization
algorithm is derived to determine scatter locations with extracted parameters.
Moreover, to improve localization accuracy and implementation efficiency, we
design an extendable network structure with task-oriented optimizations,
enabling multi-scale anchor detection and better adaptation to CSI
characteristics. A noise injection training strategy is further designed to
enhance robustness against channel estimation errors. Since the proposed
framework operates solely on estimated CSI without modifying waveforms or
signal processing pipelines, it can be seamlessly integrated into existing
communication systems as a plugin. Experiments show that our proposed method
can significantly outperform existing methods in scatter localization accuracy
with relatively low complexities under varying numbers of scatters and
estimation errors.

</details>


### [19] [Impact of RHIs and ipSIC on Active RIS-NOMA Systems with Low-Precision ADCs](https://arxiv.org/abs/2509.19383)
*Qianqian Li,Hua Li,Shiya Hao,Lintao Li,Xiaoming Dai*

Main category: eess.SP

TL;DR: 本文评估了采用低精度ADC的主动可重构智能表面辅助非正交多址系统的性能，推导了考虑硬件损伤和干扰消除不完美的中断概率分析近似，并证明主动RIS-NOMA系统在性能上优于被动RIS-NOMA系统。


<details>
  <summary>Details</summary>
Motivation: 研究主动可重构智能表面在低精度ADC条件下的性能表现，探索如何通过优化发射功率和反射元件数量来缓解低精度ADC的负面影响，提升NOMA系统的性能。

Method: 推导了考虑残余硬件损伤和不完美连续干扰消除的中断概率分析近似，分析了高信噪比下的渐近中断概率、系统吞吐量和分集阶数，并通过仿真验证理论分析。

Result: 仿真结果表明，量化主动RIS-NOMA系统在中断概率和吞吐量方面优于被动RIS-NOMA系统，且随着反射元件数量的增加，两种系统的中断性能均有显著改善。

Conclusion: 通过优化发射功率和增加反射元件数量，可以有效缓解低精度ADC的负面影响，主动RIS-NOMA系统在降低发射功率需求和减少反射元件数量的同时，仍能实现更好的性能表现。

Abstract: This study evaluates the performance of an active reconfigurable intelligent
surface (ARIS)-assisted non-orthogonal multiple access (NOMA) system employing
low-precision analog-to-digital converters (ADCs). Analytical approximations
for the outage probability (OP) are derived, considering residual hardware
impairments (RHIs) and imperfect successive interference cancellation (ipSIC).
Additionally, we analyze the asymptotic OP, system throughput, and diversity
order at high signal-to-noise ratios (SNRs). Simulation results demonstrate
that the proposed quantized ARIS-NOMA system outperforms its passive
counterpart (PRIS-NOMA), achieving lower OP and higher throughput with reduced
transmit power requirements and fewer reflecting elements. Moreover, the outage
performance of both quantized ARIS-NOMA and PRIS-NOMA systems demonstrates
significant improvement as the number of reflecting elements increases. The
negative impacts of low-precision ADCs can be effectively mitigated by
optimizing transmit power and scaling the number of reflecting elements.

</details>


### [20] [Low-Cost Sensor Fusion Framework for Organic Substance Classification and Quality Control Using Classification Methods](https://arxiv.org/abs/2509.19367)
*Borhan Uddin Chowdhury,Damian Valles,Md Raf E Ul Shougat*

Main category: eess.SP

TL;DR: 提出基于Arduino Mega 2560微控制器平台的低成本传感器融合框架，用于有机物质的快速无损分类和质量控制，通过机器学习模型实现93-94%的准确率。


<details>
  <summary>Details</summary>
Motivation: 开发低成本、非破坏性的有机物质分类和质量控制方法，利用商业环境传感器和微控制器平台，为食品和农产品质量检测提供实用解决方案。

Method: 使用Arduino Mega 2560配备三个商业传感器收集10类有机物质数据，进行相关性分析和特征选择，应用PCA/LDA降维，训练SVM、决策树、随机森林、ANN和集成投票分类器。

Result: 优化的随机森林、集成分类器和ANN模型在测试集上达到93-94%的准确率，证明了该低成本平台的可靠性。

Conclusion: 基于Arduino的低成本多传感器平台结合先进的机器学习和相关性驱动的特征工程，能够实现对有机化合物的可靠识别和质量控制。

Abstract: We present a sensor-fusion framework for rapid, non-destructive
classification and quality control of organic substances, built on a standard
Arduino Mega 2560 microcontroller platform equipped with three commercial
environmental and gas sensors. All data used in this study were generated
in-house: sensor outputs for ten distinct classes - including fresh and expired
samples of apple juice, onion, garlic, and ginger, as well as cinnamon and
cardamom - were systematically collected and labeled using this hardware setup,
resulting in a unique, application-specific dataset. Correlation analysis was
employed as part of the preprocessing pipeline for feature selection. After
preprocessing and dimensionality reduction (PCA/LDA), multiple supervised
learning models - including Support Vector Machine (SVM), Decision Tree (DT),
and Random Forest (RF), each with hyperparameter tuning, as well as an
Artificial Neural Network (ANN) and an ensemble voting classifier - were
trained and cross-validated on the collected dataset. The best-performing
models, including tuned Random Forest, ensemble, and ANN, achieved test
accuracies in the 93 to 94 percent range. These results demonstrate that
low-cost, multisensory platforms based on the Arduino Mega 2560, combined with
advanced machine learning and correlation-driven feature engineering, enable
reliable identification and quality control of organic compounds.

</details>


### [21] [Short-Term Regional Electricity Demand Forecasting in Argentina Using LSTM Networks](https://arxiv.org/abs/2509.19374)
*Oscar A. Oviedo*

Main category: eess.SP

TL;DR: 开发基于LSTM网络的深度学习模型来预测阿根廷科尔多瓦的短期小时电力需求，整合历史消费数据和外部变量，实现高精度预测。


<details>
  <summary>Details</summary>
Motivation: 为电网运营商提供优化的规划和控制策略，应对不同需求场景下的电力调度挑战。

Method: 使用LSTM网络结合历史消费数据、气候因素、时间周期和人口统计等外部变量，进行模型设计和超参数优化，并辅以随机森林回归的可解释性分析和日需求极值时间预测评估。

Result: 模型预测精度高，平均绝对百分比误差为3.20%，决定系数为0.95；在日需求极值时间预测中，超过三分之二的测试日达到精确小时准确度，90%以上案例误差在1小时内。

Conclusion: 所提出的框架具有高预测精度和操作相关性，为电网运营商提供了有价值的见解，有助于优化不同需求场景下的规划和控制策略。

Abstract: This study presents the development and optimization of a deep learning model
based on Long Short-Term Memory (LSTM) networks to predict short-term hourly
electricity demand in C\'ordoba, Argentina. Integrating historical consumption
data with exogenous variables (climatic factors, temporal cycles, and
demographic statistics), the model achieved high predictive precision, with a
mean absolute percentage error of 3.20\% and a determination coefficient of
0.95. The inclusion of periodic temporal encodings and weather variables proved
crucial to capture seasonal patterns and extreme consumption events, enhancing
the robustness and generalizability of the model. In addition to the design and
hyperparameter optimization of the LSTM architecture, two complementary
analyses were carried out: (i) an interpretability study using Random Forest
regression to quantify the relative importance of exogenous drivers, and (ii)
an evaluation of model performance in predicting the timing of daily demand
maxima and minima, achieving exact-hour accuracy in more than two-thirds of the
test days and within abs(1) hour in over 90\% of cases. Together, these results
highlight both the predictive accuracy and operational relevance of the
proposed framework, providing valuable insights for grid operators seeking
optimized planning and control strategies under diverse demand scenarios.

</details>


### [22] [Data-Driven Reconstruction of Significant Wave Heights from Sparse Observations](https://arxiv.org/abs/2509.19384)
*Hongyuan Shi,Yilin Zhai,Ping Dong,Zaijin You,Chao Zhan,Qing Wang*

Main category: eess.SP

TL;DR: AUWave是一个混合深度学习框架，用于从稀疏浮标观测重建高分辨率区域有效波高场，通过多尺度U-Net和自注意力层实现32×32区域重建，在夏威夷区域验证中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 从稀疏不均匀的浮标观测重建高分辨率区域有效波高场是海洋监测和风险感知操作的核心挑战，现有方法在稀疏采样条件下存在重建精度不足的问题。

Method: 提出AUWave混合深度学习框架，结合站点序列编码器（MLP）和带瓶颈自注意力层的多尺度U-Net，通过贝叶斯超参数搜索优化学习率等关键参数。

Result: 在夏威夷区域使用NDBC浮标观测和ERA5再分析数据，AUWave达到最小验证损失0.043285，空间误差在观测站点附近最低，随距离增加而增大，在数据较丰富配置下持续优于基线方法。

Conclusion: AUWave为数据同化提供了可扩展的高分辨率先验路径，误差分析和站点消融实验为网络设计提供了可操作的指导，特别在具有最小但非平凡空间锚定的情况下表现出色。

Abstract: Reconstructing high-resolution regional significant wave height fields from
sparse and uneven buoy observations remains a core challenge for ocean
monitoring and risk-aware operations. We introduce AUWave, a hybrid deep
learning framework that fuses a station-wise sequence encoder (MLP) with a
multi-scale U-Net enhanced by a bottleneck self-attention layer to recover
32$\times$32 regional SWH fields. A systematic Bayesian hyperparameter search
with Optuna identifies the learning rate as the dominant driver of
generalization, followed by the scheduler decay and the latent dimension. Using
NDBC buoy observations and ERA5 reanalysis over the Hawaii region, AUWave
attains a minimum validation loss of 0.043285 and a slightly right-skewed RMSE
distribution. Spatial errors are lowest near observation sites and increase
with distance, reflecting identifiability limits under sparse sampling.
Sensitivity experiments show that AUWave consistently outperforms a
representative baseline in data-richer configurations, while the baseline is
only marginally competitive in the most underdetermined single-buoy cases. The
architecture's multi-scale and attention components translate into accuracy
gains when minimal but non-trivial spatial anchoring is available. Error maps
and buoy ablations reveal key anchor stations whose removal disproportionately
degrades performance, offering actionable guidance for network design. AUWave
provides a scalable pathway for gap filling, high-resolution priors for data
assimilation, and contingency reconstruction.

</details>


### [23] [A Statistical Mixture-of-Experts Framework for EMG Artifact Removal in EEG: Empirical Insights and a Proof-of-Concept Application](https://arxiv.org/abs/2509.19385)
*Benjamin J. Choi,Griffin Milsap,Clara A. Scholl,Francesco Tenore,Mattson Ogg*

Main category: eess.SP

TL;DR: 本文提出了一种基于混合专家（MoE）框架的EEG信号去噪算法，专门针对高噪声环境下的EMG伪影去除问题，在EEGdenoiseNet数据集上取得了竞争性的整体性能和优越的高噪声处理能力。


<details>
  <summary>Details</summary>
Motivation: 当前神经接口控制效果受限的主要原因是信号质量差。虽然基于神经网络的EEG去噪方法近年来有所改进，但在高噪声环境下，现有最先进模型表现不佳。需要解决当前机器学习去噪算法在高噪声设置下的不足。

Method: 提出了基于混合专家框架的信号滤波算法，包含三个关键统计洞察：1）将EMG伪影划分为可量化的子类型以辅助MoE分类；2）在较窄信噪比范围内训练的局部专家可通过专业化实现性能提升；3）基于相关性的目标函数与重缩放算法结合可加速神经网络去噪的收敛。算法结合了CNN和RNN神经网络。

Result: 在67名受试者的EEGdenoiseNet基准数据集上测试，MoE去噪模型在整体性能上与最先进ML去噪算法相当，在高噪声环境下表现出更优越的下界性能。

Conclusion: 初步结果显示了MoE框架在EEG处理中EMG伪影去除方面的潜力，特别是在高噪声环境下。需要进一步研究来评估该框架在更广泛真实场景中的应用，探索其解锁更有效神经接口的下游潜力。

Abstract: Effective control of neural interfaces is limited by poor signal quality.
While neural network-based electroencephalography (EEG) denoising methods for
electromyogenic (EMG) artifacts have improved in recent years, current
state-of-the-art (SOTA) models perform suboptimally in settings with high
noise. To address the shortcomings of current machine learning (ML)-based
denoising algorithms, we present a signal filtration algorithm driven by a new
mixture-of-experts (MoE) framework. Our algorithm leverages three new
statistical insights into the EEG-EMG denoising problem: (1) EMG artifacts can
be partitioned into quantifiable subtypes to aid downstream MoE classification,
(2) local experts trained on narrower signal-to-noise ratio (SNR) ranges can
achieve performance increases through specialization, and (3) correlation-based
objective functions, in conjunction with rescaling algorithms, can enable
faster convergence in a neural network-based denoising context. We empirically
demonstrate these three insights into EMG artifact removal and use our findings
to create a new downstream MoE denoising algorithm consisting of convolutional
(CNN) and recurrent (RNN) neural networks. We tested all results on a major
benchmark dataset (EEGdenoiseNet) collected from 67 subjects. We found that our
MoE denoising model achieved competitive overall performance with SOTA ML
denoising algorithms and superior lower bound performance in high noise
settings. These preliminary results highlight the promise of our MoE framework
for enabling advances in EMG artifact removal for EEG processing, especially in
high noise settings. Further research and development will be necessary to
assess our MoE framework on a wider range of real-world test cases and explore
its downstream potential to unlock more effective neural interfaces.

</details>


### [24] [Hybrid Pipeline SWD Detection in Long-Term EEG Signals](https://arxiv.org/abs/2509.19387)
*Antonio Quintero Rincon,Nicolas Masino,Veronica Marsico,Hadj Batatia*

Main category: eess.SP

TL;DR: 提出了一种轻量级混合管道，结合分析特征和浅层人工神经网络，用于在长期单极脑电图中准确检测棘慢波放电（SWD），实现实时、无需手动阈值调整的自动化筛查。


<details>
  <summary>Details</summary>
Motivation: 棘慢波放电（SWD）是失神癫痫的脑电图标志，但在多日记录中手动识别SWD仍然劳动密集且容易出错，需要自动化解决方案。

Method: 使用双边移动平均滤波器抑制正常背景活动的高频成分，然后计算残差信号的正态分布样本的均值和标准差作为特征向量，输入单隐藏层人工神经网络进行分类。

Result: 在12名患者的780个通道上评估，正确检测384个事件（灵敏度98%），特异性96.2%，总体准确率97.2%。

Conclusion: 正态分布描述符与适度的人工神经网络结合，为扩展脑电图记录中的自动化SWD筛查提供了有效且计算成本低的解决方案。

Abstract: Spike-and-wave discharges (SWDs) are the electroencephalographic hallmark of
absence epilepsy, yet their manual identification in multi-day recordings
remains labour-intensive and error-prone. We present a lightweight hybrid
pipeline that couples analytical features with a shallow artificial neural
network (ANN) for accurate, patient-specific SWD detection in long-term,
monopolar EEG. A two-sided moving-average (MA) filter first suppresses the
high-frequency components of normal background activity. The residual signal is
then summarised by the mean and the standard deviation of its normally
distributed samples, yielding a compact, two-dimensional feature vector for
every 20s window. These features are fed to a single-hidden-layer ANN trained
via back-propagation to classify each window as SWD or non-SWD. The method was
evaluated on 780 channels sampled at 256 Hz from 12 patients, comprising 392
annotated SWD events. It correctly detected 384 events (sensitivity: 98%) while
achieving a specificity of 96.2 % and an overall accuracy of 97.2%. Because
feature extraction is analytic, and the classifier is small, the pipeline runs
in real-time and requires no manual threshold tuning. These results indicate
that normal-distribution descriptors combined with a modest ANN provide an
effective and computationally inexpensive solution for automated SWD screening
in extended EEG recordings.

</details>


### [25] [Self-Alignment Learning to Improve Myocardial Infarction Detection from Single-Lead ECG](https://arxiv.org/abs/2509.19397)
*Jiarui Jin,Xiaocheng Fang,Haoyu Wang,Jun Li,Che Liu,Donglin Xie,Hongyan Li,Shenda Hong*

Main category: eess.SP

TL;DR: SelfMIS是一个用于从单导联心电图检测心肌梗死的框架，通过自切割策略将多导联心电图与对应的单导联段配对，并在潜在空间中对齐，从而提升诊断性能。


<details>
  <summary>Details</summary>
Motivation: 单导联心电图由于空间信息有限，检测心肌梗死具有挑战性。传统生成方法在信号级别优化时存在潜在空间差距，影响诊断效果。

Method: 提出SelfMIS框架，采用自切割策略将多导联心电图与单导联段配对，直接在潜在空间中对齐，避免手动数据增强，使单导联编码器学习从局部信号推断全局心脏上下文的能力。

Result: 实验显示，SelfMIS在九种心肌梗死类型上均优于基线模型，同时保持更简单的架构和较低的计算开销。

Conclusion: 直接潜在空间对齐有效提升了单导联心电图的心肌梗死检测性能，证明了该方法的有效性。

Abstract: Myocardial infarction is a critical manifestation of coronary artery disease,
yet detecting it from single-lead electrocardiogram (ECG) remains challenging
due to limited spatial information. An intuitive idea is to convert single-lead
into multiple-lead ECG for classification by pre-trained models, but generative
methods optimized at the signal level in most cases leave a large latent space
gap, ultimately degrading diagnostic performance. This naturally raises the
question of whether latent space alignment could help. However, most prior ECG
alignment methods focus on learning transformation invariance, which mismatches
the goal of single-lead detection. To address this issue, we propose SelfMIS, a
simple yet effective alignment learning framework to improve myocardial
infarction detection from single-lead ECG. Discarding manual data
augmentations, SelfMIS employs a self-cutting strategy to pair multiple-lead
ECG with their corresponding single-lead segments and directly align them in
the latent space. This design shifts the learning objective from pursuing
transformation invariance to enriching the single-lead representation,
explicitly driving the single-lead ECG encoder to learn a representation
capable of inferring global cardiac context from the local signal.
Experimentally, SelfMIS achieves superior performance over baseline models
across nine myocardial infarction types while maintaining a simpler
architecture and lower computational overhead, thereby substantiating the
efficacy of direct latent space alignment. Our code and checkpoint will be
publicly available after acceptance.

</details>


### [26] [SpellerSSL: Self-Supervised Learning with P300 Aggregation for Speller BCIs](https://arxiv.org/abs/2509.19401)
*Jiazhen Hong,Geoff Mackellar,Soheila Ghane*

Main category: eess.SP

TL;DR: 本文提出SpellerSSL框架，结合自监督学习和P300聚合策略，解决EEG P300拼写器面临的低信噪比、泛化能力差和校准耗时三大挑战。


<details>
  <summary>Details</summary>
Motivation: EEG P300拼写器面临低信噪比、泛化能力差和校准耗时的挑战，需要一种能够减少校准负担并提高跨被试鲁棒性的解决方案。

Method: 采用自监督学习预训练1D U-Net骨干网络，结合P300聚合策略增强信噪比，然后通过轻量级ERP-Head分类器进行微调以适应被试特定数据。

Result: 在II-B数据集上达到94%的字符识别率（仅需7次重复）和21.86 bits/min的最高信息传输率，校准数据量减少60%的同时保持可比性能。

Conclusion: 这是首个将自监督学习应用于P300拼写器的研究，展示了其在提高拼写器BCI效率和泛化能力方面的潜力，为P300拼写器BCI的EEG基础模型铺平了道路。

Abstract: Electroencephalogram (EEG)-based P300 speller brain-computer interfaces
(BCIs) face three main challenges: low signal-to-noise ratio (SNR), poor
generalization, and time-consuming calibration. We propose SpellerSSL, a
framework that combines self-supervised learning (SSL) with P300 aggregation to
address these issues. First, we introduce an aggregation strategy to enhance
SNR. Second, to achieve generalization in training, we employ a customized 1D
U-Net backbone and pretrain the model on both cross-domain and in-domain EEG
data. The pretrained model is subsequently fine-tuned with a lightweight
ERP-Head classifier for P300 detection, which adapts the learned
representations to subject-specific data. Our evaluations on calibration time
demonstrate that combining the aggregation strategy with SSL significantly
reduces the calibration burden per subject and improves robustness across
subjects. Experimental results show that SSL learns effective EEG
representations in both in-domain and cross-domain, with in-domain achieving a
state-of-the-art character recognition rate of 94% with only 7 repetitions and
the highest information transfer rate (ITR) of 21.86 bits/min on the public
II-B dataset. Moreover, in-domain SSL with P300 aggregation reduces the
required calibration size by 60% while maintaining a comparable character
recognition rate. To the best of our knowledge, this is the first study to
apply SSL to P300 spellers, highlighting its potential to improve both
efficiency and generalization in speller BCIs and paving the way toward an EEG
foundation model for P300 speller BCIs.

</details>


### [27] [Online Adaptation via Dual-Stage Alignment and Self-Supervision for Fast-Calibration Brain-Computer Interfaces](https://arxiv.org/abs/2509.19403)
*Sheng-Bin Duan,Jian-Long Hao,Tian-Yu Xiang,Xiao-Hu Zhou,Mei-Jiang Gui,Xiao-Liang Xie,Shi-Qi Liu,Zeng-Guang Hou*

Main category: eess.SP

TL;DR: 该论文提出了一种用于脑机接口系统的在线自适应算法，通过双阶段对齐和自监督学习来解决个体脑电活动差异问题，能够在单次在线试验中更新解码器，显著提高分类准确率。


<details>
  <summary>Details</summary>
Motivation: 个体脑电活动的差异阻碍了基于脑电图的脑机接口系统的在线应用，需要开发能够快速适应新用户的方法。

Method: 采用双阶段对齐方法：首先在脑电数据空间进行欧几里得对齐，然后在表示空间更新批归一化统计量。同时设计自监督损失函数，使用解码器生成的软伪标签作为未知真实标签的代理，并通过香农熵校准以促进自监督训练。

Result: 在五个公共数据集和七个解码器上的实验表明，该算法可以无缝集成到不同脑机接口范式和解码器架构中。每次迭代仅需一个在线试验即可更新解码器，在稳态视觉诱发电位任务上平均准确率提升4.9%，在运动想象任务上提升3.6%。

Conclusion: 该算法支持快速校准操作，在脑机接口应用中具有巨大潜力，能够有效解决个体差异问题并提高系统性能。

Abstract: Individual differences in brain activity hinder the online application of
electroencephalogram (EEG)-based brain computer interface (BCI) systems. To
overcome this limitation, this study proposes an online adaptation algorithm
for unseen subjects via dual-stage alignment and self-supervision. The
alignment process begins by applying Euclidean alignment in the EEG data space
and then updates batch normalization statistics in the representation space.
Moreover, a self-supervised loss is designed to update the decoder. The loss is
computed by soft pseudo-labels derived from the decoder as a proxy for the
unknown ground truth, and is calibrated by Shannon entropy to facilitate
self-supervised training. Experiments across five public datasets and seven
decoders show the proposed algorithm can be integrated seamlessly regardless of
BCI paradigm and decoder architecture. In each iteration, the decoder is
updated with a single online trial, which yields average accuracy gains of 4.9%
on steady-state visual evoked potentials (SSVEP) and 3.6% on motor imagery.
These results support fast-calibration operation and show that the proposed
algorithm has great potential for BCI applications.

</details>


### [28] [Insights into Xona Pulsar LEO PNT: Constellation, Signals, and Receiver Design](https://arxiv.org/abs/2509.19551)
*Jérôme Leclère,Thyagaraja Marathe,Tyler G. R. Reid*

Main category: eess.SP

TL;DR: 本文分析了低地球轨道(LEO)卫星导航系统Pulsar的特性，通过与GPS对比研究其信号参数差异，并探讨了这些差异对接收机设计的影响和优化策略。


<details>
  <summary>Details</summary>
Motivation: 随着LEO星座如Pulsar在定位导航授时(PNT)领域的重要性日益增加，需要深入理解其信号特性和对接收机设计的新要求。

Method: 使用GNSS模拟器分析Pulsar的卫星过境时间、仰角、多普勒频移、多普勒变化率、距离和可见卫星数等参数，并与GPS进行对比分析。

Result: 研究发现LEO系统具有更强的信号、更快的动态特性、更短的首次定位时间，但也带来了更大的多普勒范围和更高的多普勒变化率等挑战。

Conclusion: 通过优化获取策略和应用预测优先技术，可以有效降低接收机的获取时间和功耗，为LEO导航系统的接收机设计提供重要指导。

Abstract: The landscape of global navigation satellite systems (GNSS) is expanding with
the emergence of low Earth orbit (LEO) constellations such as Pulsar, which are
expected to play a key role in the future of positioning, navigation, and
timing (PNT). LEO-based systems provide advantages including stronger signals
for greater robustness, faster dynamics that aid convergence and multipath
mitigation, and shorter time to first fix (TTFF) enabled by high data rates.
These benefits, however, come with changes in signal behavior and constellation
geometry that require careful consideration in receiver design. This paper
investigates Pulsar properties using a GNSS simulator, analyzing parameters
such as satellite pass duration, elevation, Doppler shift, Doppler rate, range,
and number of satellites in view. Comparisons with GPS highlight the
differences introduced by LEO operation. The analysis examines temporal
evolution, statistical distributions, and maximum and minimum values. Beyond
these statistical insights, the study explores interdependencies between
parameters and differences across satellites, providing additional perspective.
Evaluations are performed at multiple latitudes to ensure a worldwide
perspective, and the impact of applying different elevation masks is discussed
where relevant. Building on these findings, the paper assesses Pulsar's impact
on receiver design from two standpoints: design considerations, addressing
expanded Doppler ranges, higher Doppler rates, and unique constellation
structure; and design optimizations, exploiting parameter analyses and
interdependencies (e.g., Doppler rate vs Doppler) to refine acquisition
strategies and applying prediction and prioritization techniques to avoid
unnecessary computations. Together, these optimizations can reduce acquisition
time and lower receiver power consumption.

</details>


### [29] [DNN-Based Nulling Control Beam Focusing for Near-Field Multi-User Interference Mitigation](https://arxiv.org/abs/2509.19594)
*Mohammadhossein Karimi,Yuanzhe Gong,Tho Le-Ngoc*

Main category: eess.SP

TL;DR: 提出一种基于深度学习的近场零陷控制波束聚焦框架，用于超大规模MIMO系统中的多用户干扰抑制


<details>
  <summary>Details</summary>
Motivation: 解决超大规模MIMO系统中多用户干扰问题，实现可扩展的实时波束聚焦和有效干扰抑制

Method: 开发双估计器架构，包含两个全连接深度神经网络，分别预测NCBF权重的相位和幅度分量，使用期望用户和干扰用户的位置信息，基于LCMV波束形成算法生成的大数据集进行训练

Result: DNN模型实现高预测精度，相位估计测试误差仅0.067弧度，幅度估计误差0.206 dB，平均MUI抑制达到36.7 dB，所有测试案例中干扰抑制超过17.5 dB

Conclusion: 该方法为未来近场多用户无线通信提供了一种有前景的解决方案，能够实现可扩展的实时波束聚焦和有效干扰抑制

Abstract: This paper proposes a deep learning-based framework for near-field nulling
control beam focusing (NCBF) in extra-large MIMO (XL-MIMO) systems to mitigate
multi-user interference (MUI). A dual-estimator architecture comprising two
fully connected deep neural networks (FCDNNs) is developed to separately
predict the phase and magnitude components of NCBF weights, using locations of
both desired and interfering users. The models are trained on a large dataset
generated via a Linearly Constrained Minimum Variance (LCMV) beamforming
algorithm to accommodate diverse user configurations, including both collinear
and non-collinear scenarios. Illustrative results demonstrate that the proposed
DNN models achieve high prediction accuracy, with test errors of only 0.067
radians for phase estimation and 0.206 dB for magnitude estimation. Full-wave
simulations incorporating realistic element radiation patterns and
inter-element coupling confirm the close agreement between the beam patterns
produced by the DNN-predicted and LCMV-based NCBF schemes under practical
deployment conditions. An average MUI suppression of 36.7 dB is achieved, with
interference mitigation exceeding 17.5 dB across all tested cases. The proposed
approach enables scalable and real-time beam focusing with effective
interference suppression, offering a promising solution for future near-field
multi-user wireless communications.

</details>


### [30] [Non-locally averaged pruned reassigned spectrograms: a tool for glottal pulse visualization and analysis](https://arxiv.org/abs/2509.19686)
*Gabriel J. Griswold,Mark A. Griswold*

Main category: eess.SP

TL;DR: 提出了一种改进的重分配谱图方法NAPReS，通过堆叠、求和和修剪大量声门脉冲数据，解决了传统重分配谱图难以可视化大量数据的问题，并在高噪声环境下比传统LPC方法更具可重复性。


<details>
  <summary>Details</summary>
Motivation: 传统重分配谱图在精确共振峰测量和说话人区分方面有优势，但无法以易于理解和可重复的方式可视化大量数据。

Method: 开发了非局部平均修剪重分配谱图(NAPReS)，通过堆叠、求和和修剪大量声门脉冲来简化说话人声门脉动模式的表征，并采用高斯混合模型(GMM)进行共振峰拟合。

Result: NAPReS能够以易于理解和量化的方式显示大量数据，使低幅度循环结构的观察更加容易，在高噪声情况下比传统LPC拟合更具可重复性。

Conclusion: NAPReS提供了一种改进的声学分析方法，特别是在噪声环境下具有更好的性能和可重复性，为语音分析提供了新的工具。

Abstract: Reassigned spectrograms have shown advantages in precise formant measuring
and inter-speaker differentiation. However, reassigned spectrograms suffer from
their inability to visualize larger amounts of data in an easily comprehensible
and reproducible manner. Utilizing the techniques and tools developed by Fulop
and Fitz, a variation of the reassigned spectrogram is proposed. Non-locally
Averaged Pruned Reassigned Spectrograms (NAPReS) provide a simplified view into
the characteristics of a speaker's glottal pulsation patterns throughout the
centroid of a vowel through the stacking, summing, and pruning of large numbers
of glottal pulses. In this exploratory study, NAPReS has been shown to display
a large amount of data in an easily comprehensible and quantifiable manner,
while also making the observation of low-amplitude cyclical structures more
accessible. NAPReS also allows for alternative formant fitting methods such as
Gaussian mixture modeling. In this study, NAPReS with GMM was compared against
conventional LPC fitting of formant values and was shown to be more
reproducible than conventional LPC fitting in high-noise situations.

</details>


### [31] [Timeliness-Aware Joint Source and Channel Coding for Adaptive Image Transmission](https://arxiv.org/abs/2509.19754)
*Xiaolei Yang,Zijing Wang,Zhijin Qin,Xiaoming Tao*

Main category: eess.SP

TL;DR: 提出了一种基于价值信息(VoI)的自适应联合源信道编码(JSCC)方法，用于时间敏感应用中的图像传输，同时考虑重建质量和时效性。


<details>
  <summary>Details</summary>
Motivation: 现有无线系统带宽受限，难以同时满足高保真和低延迟的图像传输需求。语义通信通过传输目标导向的语义信息有望突破性能瓶颈。

Method: 设计自适应码长的JSCC框架，构建VoI最大化问题，并提出基于深度强化学习的算法来优化传输码长。

Result: 实验结果表明，该方法在重建质量和时效性方面显著优于基线方案，特别是在低信噪比条件下表现优异。

Conclusion: 该方法为时间敏感无线网络中的高效鲁棒图像传输提供了有前景的解决方案。

Abstract: Accurate and timely image transmission is critical for emerging
time-sensitive applications such as remote sensing in satellite-assisted
Internet of Things. However, the bandwidth limitation poses a significant
challenge in existing wireless systems, making it difficult to fulfill the
requirements of both high-fidelity and low-latency image transmission. Semantic
communication is expected to break through the performance bottleneck by
focusing on the transmission of goal-oriented semantic information rather than
raw data. In this paper, we employ a new timeliness metric named the value of
information (VoI) and propose an adaptive joint source and channel coding
(JSCC) method for image transmission that simultaneously considers both
reconstruction quality and timeliness. Specifically, we first design a JSCC
framework for image transmission with adaptive code length. Next, we formulate
a VoI maximization problem by optimizing the transmission code length of the
adaptive JSCC under the reconstruction quality constraint. Then, a deep
reinforcement learning-based algorithm is proposed to solve the optimization
problem efficiently. Experimental results show that the proposed method
significantly outperforms baseline schemes in terms of reconstruction quality
and timeliness, particularly in low signal-to-noise ratio conditions, offering
a promising solution for efficient and robust image transmission in
time-sensitive wireless networks.

</details>


### [32] [Electromagnetics-Compliant Optimization of Dynamic Metasurface Antennas for Bistatic Sensing](https://arxiv.org/abs/2509.19801)
*Ioannis Gavras,George C. Alexandropoulos*

Main category: eess.SP

TL;DR: 本文提出了一种动态超表面天线（DMA）的优化设计方法，用于双基地传感系统，考虑了物理约束和不确定性因素，通过低复杂度波束成形方案实现接近全数字系统的定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有DMA研究多依赖理想化模型，忽略了超材料天线中固有的结构约束和物理限制（如互耦效应和波导传播损耗），这在实际应用中会影响定位精度。

Method: 1. 提出物理一致的DMA模型，包含互耦效应和波导损耗；2. 开发可处理的DMA响应近似，优化洛伦兹约束的超材料响应；3. 构建鲁棒波束成形优化问题，最小化最坏情况位置误差；4. 提出两种低复杂度波束成形设计方法，基于新型波束码本进行离线搜索。

Result: 蒙特卡洛仿真验证了所提设计的准确性，表明精确建模互耦效应对保持高定位性能至关重要。在存在定位和同步不确定性的情况下，所提设计能达到与全数字和模拟对应方案相当的精度，同时满足DMA结构约束。

Conclusion: 本文提出的DMA优化方法能够有效处理物理约束和系统不确定性，为下一代无线系统中的低成本、可重构天线阵列架构提供了实用的解决方案。

Abstract: Dynamic Metasurface Antennas (DMAs) are recently attracting considerable
research interests due to their potential to enable low-cost, reconfigurable,
and highly scalable antenna array architectures for next generation wireless
systems. However, most of the existing literature relies on idealized models
for the DMA operation, often overlooking critical structural and physical
constraints inherent to their constituent metamaterials. In this paper,
leveraging a recently proposed model for this antenna architecture
incorporating physically consistent modeling of mutual coupling and waveguide
propagation losses, we optimize DMA-based transmission for bistatic sensing. A
tractable approximation for the DMA response is first presented, which enables
efficient optimization of the dynamically reconfigurable Lorentzian-constrained
responses of the array's metamaterials. In particular, we formulate a robust
beamforming optimization problem with the objective to minimize the worst-case
position error bound, in the presence of spatial uncertainties for the
environment's scatterers as well as synchronization uncertainties at the analog
combining multi-antenna receiver. To address the resulting high computational
complexity due to the possibly excessive number of metamaterial-based antennas
and their operation constraints, two low complexity beamforming design
approaches are presented that perform offline searching over a novel beam
codebook. The accuracy of all presented DMA designs is assessed by means of
Monte Carlo simulations for various system parameters, confirming that
accurately modeling mutual coupling is essential for maintaining increased
localization performance. It is also shown that, even under positioning and
synchronization uncertainties, the proposed designs yield accuracy comparable
to their fully digital and analog counterparts, while adhering to the
structural DMA constraints.

</details>


### [33] [Generalized Nonnegative Structured Kruskal Tensor Regression](https://arxiv.org/abs/2509.19900)
*Xinjue Wang,Esa Ollila,Sergiy A. Vorobyov,Ammar Mian*

Main category: eess.SP

TL;DR: 本文提出了广义非负结构化Kruskal张量回归(NS-KTR)，这是一个通过模式特定的混合正则化和非负性约束来增强可解释性和性能的新型张量回归框架。


<details>
  <summary>Details</summary>
Motivation: 解决多维张量数据中存在的结构异质性，同时适应线性和逻辑回归公式来处理不同的响应变量。

Method: 集成融合LASSO、全变分和岭正则化器，每个都针对特定的张量模式定制，并开发了基于交替方向乘子法(ADMM)的高效参数估计算法。

Result: 在合成信号和真实高光谱数据集上的综合实验表明，NS-KTR始终优于传统的张量回归方法。

Conclusion: 该框架能够保留张量维度上的不同结构特征，同时确保物理可解释性，使其特别适用于信号处理和高光谱图像分析应用。

Abstract: This paper introduces Generalized Nonnegative Structured Kruskal Tensor
Regression (NS-KTR), a novel tensor regression framework that enhances
interpretability and performance through mode-specific hybrid regularization
and nonnegativity constraints. Our approach accommodates both linear and
logistic regression formulations for diverse response variables while
addressing the structural heterogeneity inherent in multidimensional tensor
data. We integrate fused LASSO, total variation, and ridge regularizers, each
tailored to specific tensor modes, and develop an efficient alternating
direction method of multipliers (ADMM) based algorithm for parameter
estimation. Comprehensive experiments on synthetic signals and real
hyperspectral datasets demonstrate that NS-KTR consistently outperforms
conventional tensor regression methods. The framework's ability to preserve
distinct structural characteristics across tensor dimensions while ensuring
physical interpretability makes it especially suitable for applications in
signal processing and hyperspectral image analysis.

</details>


### [34] [Rotatable Antenna Enabled Spectrum Sharing: Joint Antenna Orientation and Beamforming Design](https://arxiv.org/abs/2509.19912)
*Xingxiang Peng,Qingqing Wu,Ziyuan Zheng,Wen Chen,Yanze Zhu,Ying Gao*

Main category: eess.SP

TL;DR: 本文研究了可旋转天线（RAs）在多输入单输出（MISO）干扰信道中的应用，通过联合优化发射波束成形和天线方向来最大化加权和速率。


<details>
  <summary>Details</summary>
Motivation: 传统天线阵列主要通过数字波束成形进行空间控制，但增加天线元素会导致硬件和功耗成本急剧上升。可旋转天线通过机械或电子方式调整元素方向，在不扩大阵列规模的情况下引入新的自由度来利用空间灵活性。

Method: 提出了交替优化（AO）框架，结合加权最小均方误差（WMMSE）波束成形和Frank-Wolfe方向更新算法。针对有限分辨率执行器，构建了球面斐波那契码本，并设计了基于交叉熵方法（CEM）的离散方向选择算法。

Result: 仿真结果表明，将可旋转天线与传统波束成形相结合显著提高了加权和速率，增益随元素方向性的增强而增加。在离散方向控制下，提出的CEM算法始终优于最近投影基线方法。

Conclusion: 可旋转天线为无线通信系统提供了一种有效的方法，在不增加阵列规模的情况下通过优化天线方向来改善链路对准和干扰抑制性能。

Abstract: Conventional antenna arrays rely primarily on digital beamforming for spatial
control. While adding more elements can narrow beamwidth and suppress
interference, such scaling incurs prohibitive hardware and power costs.
Rotatable antennas (RAs), which allow mechanical or electronic adjustment of
element orientations, introduce a new degree of freedom to exploit spatial
flexibility without enlarging the array. By dynamically optimizing
orientations, RAs can substantially improve desired link alignment and
interference suppression. This paper investigates RA-enabled multiple-input
single-output (MISO) interference channels under co-channel spectrum sharing
and formulates a weighted sum-rate maximization problem that jointly optimizes
transmit beamforming and antenna orientations. To tackle this nonconvex
problem, we develop an alternating optimization (AO) framework that integrates
weighted minimum mean-square error (WMMSE)-based beamforming with
Frank-Wolfe-based orientation updates. To reduce complexity, we further study
orientation optimization under maximum-ratio transmission (MRT) and
zero-forcing (ZF) beamforming schemes. For finite-resolution actuators, we
construct spherical Fibonacci codebooks and design a cross-entropy method
(CEM)-based algorithm for discrete orientation selection. Simulations show that
integrating RAs with conventional beamforming markedly increases weighted
sum-rate, with gains rising with element directivity. Under discrete
orientation control, the proposed CEM algorithm consistently outperforms the
nearest-projection baseline.

</details>


### [35] [On the Invariance of Cross-Correlation Peak Positions Under Monotonic Signal Transformations, with Application to Fast Time Difference Estimation](https://arxiv.org/abs/2509.19974)
*Natsuki Ueno,Ryotaro Sato,Nobutaka Ono*

Main category: eess.SP

TL;DR: 提出了一种基于互相关峰值位置不变性定理的时间差估计新方法，比传统FFT方法更快


<details>
  <summary>Details</summary>
Motivation: 传统FFT方法在时间差估计中计算复杂度较高，需要寻找更高效的替代方案

Method: 利用互相关函数峰值位置在输入信号任意单调变换下保持不变的性质，设计基于低比特整数量化信号的互相关函数估计算法

Result: 数值实验表明该方法处理时间短于传统FFT方法，仅需整数运算而非实数运算

Conclusion: 该方法为时间差估计提供了更高效的计算框架，具有实际应用价值

Abstract: We present a theorem concerning the invariance of cross-correlation peak
positions, which provides a foundation for a new method for time difference
estimation that is potentially faster than the conventional fast Fourier
transform (FFT) approach for real/complex sequences. This theoretical result
shows that the peak position of the cross-correlation function between two
shifted discrete-time signals remains unchanged under arbitrary monotonic
transformations of the input signals. By exploiting this property, we design an
efficient estimation algorithm based on the cross-correlation function between
signals quantized into low-bit integers. The proposed method requires only
integer arithmetic instead of real-valued operations, and further computational
efficiency can be achieved through number-theoretic algorithms. Numerical
experiments demonstrate that the proposed method achieves a shorter processing
time than conventional FFT-based approaches.

</details>


### [36] [Near-field Spatial-domain Channel Extrapolation for XL-MIMO Systems](https://arxiv.org/abs/2509.20026)
*Jiayi Lu,Jiayi Zhang,Hao Lei,Huahua Xiao,Bo Ai,Derrick Wing Kwan Ng*

Main category: eess.SP

TL;DR: 提出了一种用于多子载波XL-MIMO系统的自适应近场信道外推框架，通过天线子集选择和相干最小化随机模式实现高效信道估计。


<details>
  <summary>Details</summary>
Motivation: XL-MIMO系统需要低复杂度的精确信道状态信息获取，现有方法忽略近场球面波前或过度依赖稀疏先验，导致性能下降。

Method: 开发了网格和非网格算法，非网格算法优化网格算法估计结果；引入交叉验证方案降低复杂度；分析传感矩阵互相干性并提出相干最小化随机模式。

Result: 数值结果表明，所提算法在外推精度和可达速率方面显著优于现有方法，同时保持低计算复杂度。

Conclusion: 提出的CV比在精度和效率之间提供了灵活权衡，相应的非网格算法以与传统网格方法相当的复杂度实现了高精度。

Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) systems are
pivotal to next-generation wireless communications, where dynamic RF chain
architectures offer enhanced performance. However, efficient precoding in such
systems requires accurate channel state information (CSI) obtained with low
complexity. To address this challenge, spatial-domain channel extrapolation has
attracted growing interest. Existing methods often overlook near-field
spherical wavefronts or rely heavily on sparsity priors, leading to performance
degradation. In this paper, we propose an adaptive near-field channel
extrapolation framework for multi-subcarrier XL-MIMO systems, leveraging a
strategically selected subset of antennas. Subsequently, we develop both
on-grid and off-grid algorithms, where the latter refines the former's
estimates for improved accuracy. To further reduce complexity, a
cross-validation (CV)-based scheme is introduced. Additionally, we analytically
formulate the mutual coherence of the sensing matrix and propose a
coherence-minimizing-based random pattern to ensure robust extrapolation.
Numerical results validate that the proposed algorithms significantly
outperform existing methods in both extrapolation accuracy and achievable rate,
while maintaining low computational complexity. In particular, our proposed CV
ratio offers a flexible trade-off between accuracy and efficiency, and the
corresponding off-grid algorithm achieves high accuracy with complexity
comparable to conventional on-grid methods.

</details>


### [37] [Multi-Stage CD-Kennedy Receiver for QPSK Modulated CV-QKD in Turbulent Channels](https://arxiv.org/abs/2509.20030)
*Renzhi Yuan,Zhixing Wang,Shouye Miao,Mufei Zhao,Haifeng Yao,Bin Cao,Mugen Peng*

Main category: eess.SP

TL;DR: 本文探讨了在湍流信道中使用多级CD-Kennedy量子接收器增强QPSK调制CV-QKD协议安全密钥率性能的可能性，提出了三种不同类型的接收器并分析了其性能。


<details>
  <summary>Details</summary>
Motivation: 连续变量量子密钥分发（CV-QKD）协议因其高安全密钥率和与现有光通信基础设施的良好兼容性而受到关注。然而，在卫星对地光通信链路中，大气湍流是实际CV-QKD协议必须克服的挑战，而量子接收器在湍流信道中的潜在应用尚未得到充分探索。

Method: 首先推导了多级CD-Kennedy接收器在湍流信道中检测QPSK信号的错误概率，然后提出了三种具有不同位移选择的多级CD-Kennedy接收器（Type-I、Type-II和Type-III），并推导了在湍流信道中使用该接收器和后选择策略的QPSK调制CV-QKD协议的安全密钥率。

Result: 数值结果表明，多级CD-Kennedy接收器在湍流信道中在错误概率和安全密钥率性能方面均优于经典相干接收器，且Type-II接收器在错误概率性能方面能够容忍比Type-I和Type-III接收器更差的信道条件。

Conclusion: 多级CD-Kennedy量子接收器能够有效提升CV-QKD协议在湍流信道中的性能，特别是Type-II接收器在恶劣信道条件下表现出更好的鲁棒性，为卫星量子通信提供了有前景的技术方案。

Abstract: Continuous variable-quantum key distribution (CV-QKD) protocols attract
increasing attentions in recent years because they enjoy high secret key rate
(SKR) and good compatibility with existing optical communication
infrastructure. Classical coherent receivers are widely employed in coherent
states based CV-QKD protocols, whose detection performance is bounded by the
standard quantum limit (SQL). Recently, quantum receivers based on displacement
operators are experimentally demonstrated with detection performance
outperforming the SQL in various practical conditions. However, potential
applications of quantum receivers in CV-QKD protocols under turbulent channels
are still not well explored, while practical CV-QKD protocols must survive from
the atmospheric turbulence in satellite-to-ground optical communication links.
In this paper, we consider the possibility of using a quantum receiver called
multi-stage CD-Kennedy receiver to enhance the SKR performance of a quadrature
phase shift keying (QPSK) modulated CV-QKD protocol in turbulent channels. We
first derive the error probability of the multi-stage CD-Kennedy receiver for
detecting QPSK signals in turbulent channels and further propose three types of
multi-stage CD-Kennedy receiver with different displacement choices, i.e., the
Type-I, Type-II, and Type-III receivers. Then we derive the SKR of a QPSK
modulated CV-QKD protocol using the multi-stage CD-Kennedy receiver and
post-selection strategy in turbulent channels. Numerical results show that the
multi-stage CD-Kennedy receiver can outperform the classical coherent receiver
in turbulent channels in terms of both error probability and SKR performance
and the Type-II receiver can tolerate worse channel conditions compared with
Type-I and Type-III receivers in terms of error probability performance.

</details>


### [38] [Reproduction Number and Spatial Connectivity Structure Estimation via Graph Sparsity-Promoting Penalized Functional](https://arxiv.org/abs/2509.20034)
*Etienne Lasalle,Barbara Pascal*

Main category: eess.SP

TL;DR: 本文提出了一种联合估计有效再生数和空间连接结构的方法，以解决COVID-19疫情期间由于数据质量差而导致的流行病监测挑战。


<details>
  <summary>Details</summary>
Motivation: 在COVID-19大流行期间，由于全球报告的感染数据质量较差，传统的再生数估计方法面临挑战。同时监测多个地区的流行病时，利用数据的空间结构可以显著提高估计的准确性和鲁棒性，但这需要良好的空间结构估计。

Method: 开发了一种联合估计再生数和连接结构的程序。该方法通过精心设计的合成数据进行了密集数值模拟评估，并在真实的COVID-19时空感染数据上进行了验证。

Result: 该方法能够同时准确估计有效再生数和空间连接结构，提高了流行病监测的准确性和鲁棒性。

Conclusion: 提出的联合估计方法为解决流行病监测中的空间结构估计问题提供了有效工具，特别是在数据质量较差的情况下能够提供更可靠的流行病强度指标。

Abstract: During an epidemic outbreak, decision makers crucially need accurate and
robust tools to monitor the pathogen propagation. The effective reproduction
number, defined as the expected number of secondary infections stemming from
one contaminated individual, is a state-of-the-art indicator quantifying the
epidemic intensity. Numerous estimators have been developed to precisely track
the reproduction number temporal evolution. Yet, COVID-19 pandemic surveillance
raised unprecedented challenges due to the poor quality of worldwide reported
infection counts. When monitoring the epidemic in different territories
simultaneously, leveraging the spatial structure of data significantly enhances
both the accuracy and robustness of reproduction number estimates. However,
this requires a good estimate of the spatial structure. To tackle this major
limitation, the present work proposes a joint estimator of the reproduction
number and connectivity structure. The procedure is assessed through intensive
numerical simulations on carefully designed synthetic data and illustrated on
real COVID-19 spatiotemporal infection counts.

</details>


### [39] [A dual bistatic optical forward transceiver configuration for determining the position of an acoustic communication source detected by optical communication fibers](https://arxiv.org/abs/2509.20046)
*Knut H. Grythe,Jan Erik Håkegård*

Main category: eess.SP

TL;DR: 提出了一种基于双静态雷达原理的光纤水下声学通信系统，利用光纤两端接收的声信号通过到达时间差(TDOA)进行源定位，虽然定位精度低于DAS但为集成通信和定位提供了可行方案。


<details>
  <summary>Details</summary>
Motivation: 在双向配置的水下声学通信系统中，源定位功能并未集成到信号解码过程中。对于需要源定位的场景，需要开发一种集成通信和定位的方法。

Method: 采用双光纤布局，每端配备光学发射器和接收器。利用两端接收的声信号传播延迟差异进行源位置估计，基于到达时间差(TDOA)原理，使用交叉模糊函数作为最大似然估计器。

Result: 推导了Cramér-Rao Bound来表征定位精度的理论极限，分析表明增加声学带宽和更高载波频率可提高空间分辨率。仿真结果验证了该方法在不同系统条件下的性能。

Conclusion: 该方法为集成水下声学通信和定位提供了可行方案，但实际应用中仍需解决一些关键挑战。

Abstract: Optical fibers have long been employed as sensors in a wide range of
commercial systems. Distributed Acoustic Sensing (DAS) extends this concept by
enabling the detection and localization of acoustic sources along the fiber,
using backscattered light from small segments to achieve spatial resolution on
the order of meters. Recently, DAS has also been explored as a component in
underwater acoustic communication systems. Emerging interest in bidirectional
configurations where both transmitter and receiver are placed at opposite ends
of the fiber has opened new possibilities. However, in such setups, source
localization is not inherently integrated into the signal decoding process. For
scenarios where source positioning is valuable, we propose an approach inspired
by bi-static radar principles. This configuration utilizes acoustic signals
received at both ends of the fiber to estimate source position based on
propagation delay differences. Although the localization accuracy is lower than
that of DAS due to reduced sampling rates, the method offers a viable
alternative for integrated communication and positioning. We present the system
topology and configuration for a dual-fiber layout, each end equipped with
optical transmitters and receivers. The position estimation is derived from the
time difference of arrival (TDOA) between the two receivers. The Cram\'er-Rao
Bound is derived to characterize the theoretical limits of localization
accuracy, highlighting dependencies on system parameters such as optical power
loss. Our analysis shows that increased acoustic bandwidth and higher carrier
frequencies enhance spatial resolution. We formulate the Cross Ambiguity
Function as a maximum likelihood estimator for TDOA and provide simulation
results illustrating its performance under varying system conditions. Finally,
we discuss key challenges that must be addressed for practical implementation.

</details>


### [40] [Joint Ex-Post Location Calibration and Radio Map Construction under Biased Positioning Errors](https://arxiv.org/abs/2509.20059)
*Koki Kanzaki,Koya Sato*

Main category: eess.SP

TL;DR: 提出了一种针对定位信息存在突发性误差环境的高精度无线电地图构建方法，通过建模定位误差和空间相关性，实现事后校准。


<details>
  <summary>Details</summary>
Motivation: 现有无线电地图构建方法大多假设定位信息无噪声，但实际设备定位系统（如GNSS）会产生几米到几十米的误差，忽略这些误差会显著降低地图精度。研究发现移动设备作为传感器时这些误差往往存在偏差。

Method: 引入新颖框架，将定位误差和无线电传播的空间相关性作为可调参数嵌入边际对数似然函数中，实现无线电地图构建过程中的位置不确定性事后校准。

Result: 基于实际人类移动数据的数值结果表明，所提方法能将RMSE退化限制在约0.25-0.29 dB，而基线方法的性能损失超过1 dB。

Conclusion: 该方法能有效应对定位误差问题，在存在定位误差的情况下仍能保持较高的无线电地图精度。

Abstract: This paper proposes a high-accuracy radio map construction method tailored
for environments where location information is affected by bursty errors. Radio
maps are an effective tool for visualizing wireless environments. Although
extensive research has been conducted on accurate radio map construction, most
existing approaches assume noise-free location information during sensing. In
practice, however, positioning errors ranging from a few to several tens of
meters can arise due to device-based positioning systems (e.g., GNSS). Ignoring
such errors during inference can lead to significant degradation in radio map
accuracy. This study highlights that these errors often tend to be biased when
using mobile devices as sensors. We introduce a novel framework that models
these errors together with spatial correlation in radio propagation by
embedding them as tunable parameters in the marginal log-likelihood function.
This enables ex-post calibration of location uncertainty during radio map
construction. Numerical results based on practical human mobility data
demonstrate that the proposed method can limit RMSE degradation to
approximately 0.25-0.29 dB, compared with Gaussian process regression using
noise-free location data, whereas baseline methods suffer performance losses
exceeding 1 dB.

</details>


### [41] [Reciprocal Beyond-Diagonal Reconfigurable Intelligent Surface (BD-RIS): Scattering Matrix Design via Manifold Optimization](https://arxiv.org/abs/2509.20246)
*Marko Fidanovski,Iván Alexander Morales Sandoval,Hyeon Seok Rou,Giuseppe Thadeu Freitas de Abreu,Emil Björnson*

Main category: eess.SP

TL;DR: 本文研究通过BD-RIS实现和速率最大化的问题，重点关注具有互易性的低复杂度物理实现，提出了一种流形优化框架来设计对称散射矩阵。


<details>
  <summary>Details</summary>
Motivation: BD-RIS技术因其低成本和高信号处理能力，在恶劣城市环境中能显著提升无线通信系统的性能和QoS。本文旨在解决BD-RIS设计中的互易性约束问题，以实现更实用的低复杂度实现。

Method: 采用流形优化框架，在目标函数中添加惩罚项以确保对称约束，并通过将解投影到可行散射矩阵集合上来进一步强制执行互易性。

Result: 仿真结果表明，所提方法在和速率最大化方面优于当前最先进的方法。

Conclusion: 基于互易性的BD-RIS设计方法在保证低复杂度物理实现的同时，能够有效提升无线系统的和速率性能。

Abstract: Beyond-diagonal reconfigurable intelligent surfaces (BD-RISs) are emerging as
a transformative technology in wireless communications, enabling enhanced
performance and quality of service (QoS) of wireless systems in harsh urban
environments due to their relatively low cost and advanced signal processing
capabilities. Generally, BD-RIS systems are employed to improve robustness,
increase achievable rates, and enhance energy efficiency of wireless systems in
both direct and indirect ways. The direct way is to produce a favorable
propagation environment via the design of optimized scattering matrices, while
the indirect way is to reap additional improvements via the design of
multiple-input multiple-output (MIMO) beamformers that further exploit the
latter "engineered" medium. In this article, the problem of sum-rate
maximization via BD-RIS is examined, with a focus on feasibility, namely
low-complexity physical implementation, by enforcing reciprocity in the BD-RIS
design. We begin by outlining the system model and formulating an optimization
problem that aims to enhance the system's sum-rate by designing a symmetric
scattering matrix. In particular, the approach leverages a manifold
optimization framework, where a penalty term is added to the objective function
to ensure that the symmetry constraint is upheld, with reciprocity further
enforced by projecting the obtained solution onto a set of feasible scattering
matrices. Simulation results demonstrate the effectiveness of the proposed
method in outperforming current state-of-the-art (SotA) approaches in terms of
sum-rate maximization.

</details>


### [42] [Geometric Port Selection in CUMA Systems](https://arxiv.org/abs/2509.20299)
*Chenguang Rao,Kai-Kit Wong,Mohd Hamza Naim Shaikh,Hanjiang Hong,Hyundong Shin,Yangyang Zhang*

Main category: eess.SP

TL;DR: 本文提出了两种自适应单RF端口选择方案（EOHS和PCA），用于改进紧凑型超大规模天线阵列（CUMA）技术，在保持低复杂度的同时显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统的CUMA技术采用固定的端口选择策略，存在优化空间。为了在保持硬件简单性的同时提升干扰抑制性能，需要开发更智能的自适应端口选择机制。

Method: 提出了两种方案：1）EOHS方案动态选择最大化瞬时信号累积的投影方向；2）PCA方案基于主成分分析，将端口分区与信道向量的主要统计方向对齐，提供闭式低复杂度解。

Result: 仿真结果表明，EOHS和PCA方案在各种用户密度、端口数量和FAS孔径尺寸下均优于传统CUMA。PCA方案以较低的计算成本实现了接近EOHS的性能。

Conclusion: 所提出的方案能够有效扩展到大规模用户场景，为下一代多址接入系统提供了有吸引力的复杂度-性能权衡。

Abstract: Compact ultra-massive antenna-array (CUMA) is a novel multiple access
technology built on the fluid antenna system (FAS) concept, offering an
improved scheme over fluid antenna multiple access (FAMA) that can support
massive connectivity on the same physical channel without the need of precoding
and interference cancellation. By employing a simple port-selection mechanism
that leverages random channel superposition, CUMA can suppress inter-user
interference while keeping hardware costs low. Nevertheless, its ad-hoc
port-selection strategy leaves considerable room for optimization. In this
work, we revisit CUMA and propose two adaptive single-RF port-selection schemes
that retain its simplicity while significantly enhancing performance. The first
one, referred to as exact optimal half-space (EOHS), dynamically selects the
projection direction that maximizes the instantaneous signal build-up across
active ports. To reduce complexity while preserving most of the gains, we
furthermore introduce a principal component analysis (PCA)-based scheme, which
aligns port partitioning with the dominant statistical direction of per-port
channel vectors. This method yields a closed-form low-complexity solution,
complemented by a tractable analytical framework that provides a closed-form
expression for the signal-to-interference ratio (SIR) probability density
function (PDF). Simulation results corroborate the analysis, demonstrating that
both EOHS and PCA consistently outperform conventional CUMA across diverse user
densities, port counts, and FAS aperture sizes. Notably, PCA achieves
performance close to EOHS at a fraction of the computational cost. The proposed
schemes scale effectively to large-user regimes, offering a compelling
complexity-performance trade-off for next-generation multiple access systems.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [43] [Analyzing α-divergence in Gaussian Rate-Distortion-Perception Theory](https://arxiv.org/abs/2509.19572)
*Martha V. Sourla,Giuseppe Serra,Photios A. Stavrou,Marios Kountouris*

Main category: cs.IT

TL;DR: 本文研究了高斯源在均方误差失真和α散度感知度量下的信息率失真感知函数估计问题，提出了参数化解并建立了数值求解方法。


<details>
  <summary>Details</summary>
Motivation: 研究信息率失真感知函数在目标导向的有损压缩和语义信息重建中的重要性，特别是针对高斯源在特定失真和感知度量下的理论分析需求。

Method: 假设联合高斯RDPF形成凸优化问题，推导出参数化解的上界，将最优参数求解转化为寻找α次简化指数多项式的根，并使用二分法进行数值计算。

Result: 建立了RDPF的参数化表征方法，证明了参数求解的等价性，并开发了有效的数值计算方案。

Conclusion: 验证了理论分析的正确性，建立了与现有结果的联系，为高斯源的信息率失真感知函数估计提供了有效的理论框架和计算方法。

Abstract: The problem of estimating the information rate distortion perception function
(RDPF), which is a relevant information-theoretic quantity in goal-oriented
lossy compression and semantic information reconstruction, is investigated
here. Specifically, we study the RDPF tradeoff for Gaussian sources subject to
a mean-squared error (MSE) distortion and a perception measure that belongs to
the family of {\alpha} divergences. Assuming a jointly Gaussian RDPF, which
forms a convex optimization problem, we characterize an upper bound for which
we find a parametric solution. We show that evaluating the optimal parameters
of this parametric solution is equivalent to finding the roots of a reduced
exponential polynomial of degree {\alpha}. Additionally, we determine which
disjoint sets contain each root, which enables us to evaluate them numerically
using the well-known bisection method. Finally, we validate our analytical
findings with numerical results and establish connections with existing
results.

</details>


### [44] [Efficient $\varepsilon$-approximate minimum-entropy couplings](https://arxiv.org/abs/2509.19598)
*Spencer Compton*

Main category: cs.IT

TL;DR: 本文提出了一种多项式时间近似方案（PTAS），用于计算多个离散概率分布的最小熵耦合问题，对于固定数量的分布实现了近似最优解。


<details>
  <summary>Details</summary>
Motivation: 最小熵耦合问题是NP难问题，之前最好的多项式时间算法只能达到常数近似保证（对于m=2分布约为0.53，对于一般m约为1.22）。主要开放问题是该问题是否APX难，或者是否存在PTAS。

Method: 设计了一种算法，在运行时间n^O(poly(1/ε)·exp(m))内产生熵不超过最优解加ε的耦合，表明对于常数m存在PTAS。

Result: 证明了对于固定数量的分布，最小熵耦合问题存在多项式时间近似方案，解决了该领域的一个重要开放问题。

Conclusion: 这项工作为最小熵耦合问题提供了第一个PTAS，对于常数m实现了任意精度的近似，是该问题计算复杂性研究的重要进展。

Abstract: Given $m \ge 2$ discrete probability distributions over $n$ states each, the
minimum-entropy coupling is the minimum-entropy joint distribution whose
marginals are the same as the input distributions. Computing the
minimum-entropy coupling is NP-hard, but there has been significant progress in
designing approximation algorithms; prior to this work, the best known
polynomial-time algorithms attain guarantees of the form $H(\operatorname{ALG})
\le H(\operatorname{OPT}) + c$, where $c \approx 0.53$ for $m=2$, and $c
\approx 1.22$ for general $m$ [CKQGK '23].
  A main open question is whether this task is APX-hard, or whether there
exists a polynomial-time approximation scheme (PTAS). In this work, we design
an algorithm that produces a coupling with entropy $H(\operatorname{ALG}) \le
H(\operatorname{OPT}) + \varepsilon$ in running time
$n^{O(\operatorname{poly}(1/\varepsilon) \cdot \operatorname{exp}(m) )}$:
showing a PTAS exists for constant $m$.

</details>


### [45] [Agentic AI for Low-Altitude Semantic Wireless Networks: An Energy Efficient Design](https://arxiv.org/abs/2509.19791)
*Zhouxiang Zhao,Ran Yi,Yihan Cang,Boyang Jin,Zhaohui Yang,Mingzhe Chen,Chongwen Huang,Zhaoyang Zhang*

Main category: cs.IT

TL;DR: 提出了一种AI驱动的低空语义无线网络框架，通过智能编排感知-通信-决策-控制工作流来解决无人机辅助自主系统的能效问题，旨在最小化系统总能耗以延长任务续航时间。


<details>
  <summary>Details</summary>
Motivation: 解决无人机辅助自主系统中的能量效率问题，提高任务续航能力，通过优化关键操作变量来降低整体能耗。

Method: 构建了系统级能耗最小化问题，联合优化无人机位置、语义压缩比、传输功率和AI推理任务卸载决策等变量，并开发了基于二维搜索的低复杂度全局最优算法。

Result: 仿真结果表明，所提出的设计方案相比传统基线方法能够显著降低总能耗。

Conclusion: 该框架有效解决了无人机系统的能效优化问题，提出的算法能够在满足延迟和服务质量约束的同时实现全局最优解。

Abstract: This letter addresses the energy efficiency issue in unmanned aerial vehicle
(UAV)-assisted autonomous systems. We propose a framework for an agentic
artificial intelligence (AI)-powered low-altitude semantic wireless network,
that intelligently orchestrates a sense-communicate-decide-control workflow. A
system-wide energy consumption minimization problem is formulated to enhance
mission endurance. This problem holistically optimizes key operational
variables, including UAV's location, semantic compression ratio, transmit power
of the UAV and a mobile base station, and binary decision for AI inference task
offloading, under stringent latency and quality-of-service constraints. To
tackle the formulated mixed-integer non-convex problem, we develop a
low-complexity algorithm which can obtain the globally optimal solution with
two-dimensional search. Simulation results validate the effectiveness of our
proposed design, demonstrating significant reductions in total energy
consumption compared to conventional baseline approaches.

</details>


### [46] [Understanding the ratio of the partition sum to its Bethe approximation via double covers](https://arxiv.org/abs/2509.19910)
*Pascal O. Vontobel*

Main category: cs.IT

TL;DR: 本文研究了图模型中配分函数与其Bethe近似之间比率的平方关系，并针对两类对数超模图模型分析了这些比率。


<details>
  <summary>Details</summary>
Motivation: 观察到配分函数与其Bethe近似的比率通常接近配分函数与其二阶Bethe近似的比率的平方，这一关系有助于更好地分析和量化配分函数。

Method: 对观察到的比率关系进行理论论证，并针对两类对数超模图模型进行比率分析。

Result: 为观察到的比率关系提供了理论依据，并对特定图模型类别的比率进行了分析。

Conclusion: 研究结果支持了配分函数近似比率之间的平方关系，为图模型配分函数的分析提供了新的视角。

Abstract: For various classes of graphical models it has been observed that the ratio
of the partition sum to its Bethe approximation is often close to being the
square of the ratio of the partition sum to its degree-2 Bethe approximation.
This is of relevance because the latter ratio can often better be analyzed
and/or quantified than the former ratio. In this paper, we give some
justifications for the observed relationship between these two ratios and then
analyze these ratios for two classes of log-supermodular graphical models.

</details>


### [47] [Constrained Higher-Order Binary Optimization for Wireless Communications Systems Using Ising Machines](https://arxiv.org/abs/2509.20092)
*Gan Zheng,Ioannis Krikidis*

Main category: cs.IT

TL;DR: 本文提出了一种使用伊辛机求解无线通信系统中具有不等式约束的大规模高阶二元优化问题的算法解决方案。通过增强拉格朗日方法和泰勒展开将高阶多项式近似为二次型，实现了无需辅助变量的迭代求解。


<details>
  <summary>Details</summary>
Motivation: 无线通信中的资源优化问题通常包含高阶多项式项和严格不等式约束，传统的QUBO方法应用受限。为了克服这些瓶颈并利用伊辛机的最新进展，需要开发能够处理高阶约束的优化算法。

Method: 提出基于增强拉格朗日方法的迭代算法，使用泰勒展开将高阶多项式近似为二次型，在每次迭代中求解单个QUBO问题，无需辅助变量。以同时无线信息和能量传输系统中的相位优化为例进行验证。

Result: 仿真结果表明，所提算法实现了令人满意的性能，并优于启发式基准方案。

Conclusion: 该算法成功解决了无线通信中具有不等式约束的高阶二元优化问题，为实际应用提供了有效的解决方案。

Abstract: This paper develops an algorithmic solution using Ising machines to solve
large-scale higher-order binary optimization (HOBO) problems with inequality
constraints for resource optimization in wireless communications systems.
Quadratic unconstrained binary optimization (QUBO) aims to solve a special
category of these problems widely encountered in engineering and science. To
solve QUBO instances, specialized Ising machines have been designed, while
sophisticated quantum annealing algorithm and quantum-inspired classical
heuristics have been developed. However, the application of QUBO in wireless
communications has limited practical interest mainly due to the complexity of
resource optimization problems which are often characterized by high-order
polynomial terms and strict inequality constraints. To overcome these
bottlenecks and take advantage of recent advancements in Ising machines, in
this paper, we propose an iterative algorithmic solution to solve HOBO
problems, which is based on the augmented Lagrangian method to handle
constraints. Specifically, Taylor expansion is employed to approximate
higher-order polynomials to quadratic ones in the augmented Lagrangian
function, which enables the solution of a single QUBO problem at each iteration
without auxiliary variables. As an illustrative case study, we consider the
problem of phase optimization in a simultaneous wireless information and power
transfer system, where a reconfigurable intelligent surface with 1-bit phase
resolution is used to facilitate information/energy transfer. Simulation
results verify that the proposed algorithm achieves satisfactory performance
and outperforms heuristic benchmark schemes.

</details>
