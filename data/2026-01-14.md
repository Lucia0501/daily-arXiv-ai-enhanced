<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 9]
- [cs.IT](#cs.IT) [Total: 15]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Modal Parameter Extraction via Propeller-Driven Vibration Testing](https://arxiv.org/abs/2601.08123)
*Gabriele Dessena,Alessandro Pontillo*

Main category: eess.SP

TL;DR: 螺旋桨驱动振动测试(PVT)作为传统地面振动测试(GVT)的替代方案，通过螺旋桨激励识别飞机结构模态参数，验证了其在低频模态提取方面的可行性。


<details>
  <summary>Details</summary>
Motivation: 传统地面振动测试(GVT)成本高、耗时长，需要寻找更经济高效的替代方法。螺旋桨驱动振动测试(PVT)作为一种输出式测试方法，旨在验证其作为GVT补充方案的可行性。

Method: 使用7075-T6铝制悬臂翼梁，安装7个加速度计，通过外置电机和螺旋桨激励。进行7次测试：基准测试(电机关闭)、5个恒定油门工况和1个手动油门扫频。采用自然激励技术与Loewner框架(NExT-LF)进行模态参数识别。

Result: 螺旋桨激励下主要共振峰仍可观测，但低油门工况会产生窄带谐波可能掩盖结构峰值，扫频测试能减少持续重叠。前两阶模态匹配良好(MAC>0.99)，第三阶模态重复性较差(MAC=0.827)且频率偏移较大，这与螺旋桨引起的弯扭耦合和非理想扫频控制有关。

Conclusion: PVT可作为GVT的可行补充方案，用于提取低频模态信息。未来需要研究自动油门调度和考虑耦合效应的测试规划。

Abstract: Ground Vibration Testing (GVT) supports aircraft certification but often requires lengthy and costly campaigns. Propeller-driven Vibration Testing (PVT) is assessed here as an output-only alternative, in line with Operational Modal Analysis approaches such as Taxi Vibration Testing and Flight Vibration Testing. A cantilever Aluminium 7075-T6 wing spar is instrumented with seven accelerometers and excited by an outboard electric motor and propeller. Seven runs are carried out: a motor-off baseline, five constant-throttle cases, and a manual up-down throttle sweep. The acquired spectra indicate that the dominant resonances remain observable under propeller excitation, while low-throttle conditions introduce narrowband harmonics that may mask structural peaks; the sweep reduces persistent overlap. Modal parameters are identified for the baseline and sweep cases using the Natural Excitation Technique with the Loewner Framework (NExT-LF). The first two modes remain closely matched (Modal Assurance Criterion (MAC) > 0.99), whereas the third mode shows reduced repeatability (MAC = 0.827) and a larger frequency shift, consistent with propeller-induced bending--torsion coupling and non-ideal sweep control. Overall, PVT provides a viable complement to GVT for extracting low-frequency modal information and motivates pursuing future work on automated throttle scheduling and coupling-aware test planning.

</details>


### [2] [Variable-Length Wideband CSI Feedback via Loewner Interpolation and Deep Learning](https://arxiv.org/abs/2601.08300)
*Meilin Li,Wei Xu,Zhixiang Hu,An Liu*

Main category: eess.SP

TL;DR: 提出一种用于U6G频段FDD大规模MIMO系统的可变长度宽带CSI反馈方案，采用Loewner插值框架和神经网络压缩，支持可变长度反馈并提升恢复精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于压缩感知和深度学习的CSI反馈方案在角延迟域截断信道，但在U6G等宽带信道中，DFT基引起的能量泄漏效应更严重，导致恢复精度瓶颈。

Method: 1) 引入Loewner插值框架，基于当前CSI矩阵生成动态基，在频域高效压缩；2) 通过神经网络在空域进一步压缩LI基；3) 设计无速率自编码器，支持可变长度反馈；4) 码字按重要性排序，支持尾部擦除；5) 开发自适应量化策略增强鲁棒性。

Result: 仿真结果表明，该方案能以更少或相等的反馈开销实现更高的CSI反馈精度，相比基线方案提升了频谱效率。

Conclusion: 提出的可变长度宽带CSI反馈方案有效解决了U6G频段宽带信道中的能量泄漏问题，通过动态基生成和神经网络压缩实现了反馈开销与恢复精度之间的灵活权衡。

Abstract: In this paper, we propose a variable-length wideband channel state information (CSI) feedback scheme for Frequency Division Duplex (FDD) massive multiple-input multipleoutput (MIMO) systems in U6G band (6425MHz-7125MHz). Existing compressive sensing (CS)-based and deep learning (DL)- based schemes preprocess the channel by truncating it in the angular-delay domain. However, the energy leakage effect caused by the Discrete Fourier Transform (DFT) basis will be more serious and leads to a bottleneck in recovery accuracy when applied to wideband channels such as those in U6G. To solve this problem, we introduce the Loewner Interpolation (LI) framework which generates a set of dynamic bases based on the current CSI matrix, enabling highly efficient compression in the frequency domain. Then, the LI basis is further compressed in the spatial domain through a neural network. To achieve a flexible trade-off between feedback overhead and recovery accuracy, we design a rateless auto-encoder trained with tail dropout and a multi-objective learning schedule, supporting variable-length feedback with a singular model. Meanwhile, the codewords are ranked by importance, ensuring that the base station (BS) can still maintain acceptable reconstruction performance under limited feedback with tail erasures. Furthermore, an adaptive quantization strategy is developed for the feedback framework to enhance robustness. Simulation results demonstrate that the proposed scheme could achieve higher CSI feedback accuracy with less or equal feedback overhead, and improve spectral efficiency compared with baseline schemes.

</details>


### [3] [Meta-Backscatter: Long-Distance Battery-Free Metamaterial-Backscatter Sensing and Communication](https://arxiv.org/abs/2601.08307)
*Taorui Liu,Xu Liu,Zhiquan Xu,Houfeng Chen,Hongliang Zhang,Lingyang Song*

Main category: eess.SP

TL;DR: 该论文提出了一种基于超材料标签的元反向散射系统，旨在解决传统无电池物联网通信距离短的问题，通过超材料单元集中反射信号功率，显著扩展通信范围，并建立了统一的设计框架和研究路线图。


<details>
  <summary>Details</summary>
Motivation: 传统无电池物联网（BF-IoT）虽然具有低成本、超低功耗和鲁棒性等优势，但其通信范围通常仅限于几米，这严重限制了实际部署。需要突破这一关键通信距离障碍，同时保留BF-IoT的固有优势。

Method: 1. 利用超材料标签替代传统全向天线标签，通过密集铺设的亚波长单元集中反射信号功率；2. 建立统一的设计框架，包括超材料标签及其兼容收发器的设计方法学；3. 实现元反向散射系统原型并进行实验验证。

Result: 超材料标签能够显著扩展通信范围，相比现有使用全向天线的BF-IoT标签有重大改进。论文展示了系统原型的实现和基于该原型的实验结果。

Conclusion: 元反向散射系统为解决BF-IoT通信距离限制提供了有前景的解决方案。论文总结了关键挑战，并指出了未来研究的潜在方向，为这一领域的发展提供了路线图。

Abstract: Battery-free Internet of Things (BF-IoT) enabled by backscatter communication is a rapidly evolving technology offering advantages of low cost, ultra-low power consumption, and robustness. However, the practical deployment of BF-IoT is significantly constrained by the limited communication range of common backscatter tags, which typically operate with a range of merely a few meters due to inherent round-trip path loss. Meta-backscatter systems that utilize metamaterial tags present a promising solution, retaining the inherent advantages of BF-IoT while breaking the critical communication range barrier. By leveraging densely paved sub-wavelength units to concentrate the reflected signal power, metamaterial tags enable a significant communication range extension over existing BF-IoT tags that employ omni-directional antennas. In this paper, we synthesize the principles and paradigms of metamaterial sensing to establish a unified design framework and a forward-looking research roadmap. Specifically, we first provide an overview of backscatter communication, encompassing its development history, working principles, and tag classification. We then introduce the design methodology for both metamaterial tags and their compatible transceivers. Moreover, we present the implementation of a meta-backscatter system prototype and report the experimental results based on it. Finally, we conclude by highlighting key challenges and outlining potential avenues for future research.

</details>


### [4] [Bio-RV: Low-Power Resource-Efficient RISC-V Processor for Biomedical Applications](https://arxiv.org/abs/2601.08428)
*Vijay Pratap Sharma,Annu Kumar,Mohd Faisal Khan,Mukul Lokhande,Santosh Kumar Vishvakarma*

Main category: eess.SP

TL;DR: Bio-RV是一个紧凑、资源高效的RISC-V处理器，专为生物医学控制应用设计，如加速器SoC和植入式起搏器系统，强调确定性执行、低硬件复杂度和集成灵活性。


<details>
  <summary>Details</summary>
Motivation: 为生物医学控制应用（如加速器SoC和植入式起搏器）开发一个紧凑、资源高效的处理器，满足超低功耗、安全关键系统的需求，优先考虑确定性执行而非峰值计算速度。

Method: 设计了一个多周期RV32I核心，提供显式执行控制和外部指令加载功能，支持受控固件部署、ASIC启动和后硅测试。作为轻量级主机控制器，协调加速器配置和数据传输，处理起搏、传感、心电图、遥测和电池管理等接口。

Result: FPGA原型使用708个LUT和235个触发器，在180nm CMOS技术中实现，工作频率50MHz，硬件占用面积小。后布局结果显示架构决策与最小能耗使用一致。

Conclusion: Bio-RV通过优先考虑确定性执行、最小硬件复杂度和集成灵活性，成功满足了超低功耗、安全关键生物医学系统的需求，为生物医学控制应用提供了高效的处理器解决方案。

Abstract: This work presents Bio-RV, a compact and resource-efficient RISC-V processor intended for biomedical control applications, such as accelerator-based biomedical SoCs and implantable pacemaker systems. The proposed Bio-RV is a multi-cycle RV32I core that provides explicit execution control and external instruction loading with capabilities that enable controlled firmware deployment, ASIC bring-up, and post-silicon testing. In addition to coordinating accelerator configuration and data transmission in heterogeneous systems, Bio-RV is designed to function as a lightweight host controller, handling interfaces with pacing, sensing, electrogram (EGM), telemetry, and battery management modules. With 708 LUTs and 235 flip-flops on FPGA prototypes, Bio-RV, implemented in a 180 nm CMOS technology, operate at 50 MHz and feature a compact hardware footprint. According to post-layout results, the proposed architectural decisions align with minimal energy use. Ultimately, Bio-RV prioritises deterministic execution, minimal hardware complexity, and integration flexibility over peak computing speed to meet the demands of ultra-low-power, safety-critical biomedical systems.

</details>


### [5] [Effective outdoor pathloss prediction: A multi-layer segmentation approach with weighting map](https://arxiv.org/abs/2601.08436)
*Yuan Gao,Tao Wen,Wenjing Xie,Jianbo Du,Yong Zeng,Dusit Niyato,Shugong Xu*

Main category: eess.SP

TL;DR: 提出基于ResNet的路径损耗预测模型，通过生成Tx/Rx深度图、距离图和权重图来捕捉环境特征，在计算复杂度降低60%的同时，性能优于现有方法1.2-3.0 dB。


<details>
  <summary>Details</summary>
Motivation: 传统射线追踪和基于模型的方法存在计算复杂度高、模型与现实环境差异大的问题，而深度学习为路径损耗预测提供了更准确、计算效率更高的替代方案。

Method: 使用ResNet架构，从地理数据生成Tx深度图、Rx深度图、距离图，并创新性地引入权重图来强调Tx-Rx直接路径相邻区域，以更好地捕捉信号反射和衍射造成的衰减。

Result: 在ITU挑战赛2024和ICASSP 2023数据集上的广泛仿真表明，该模型性能优于PPNet、RPNet和Vision Transformer 1.2-3.0 dB，且浮点运算量比基准方法减少60%。消融研究证实权重图的加入显著提升了预测性能。

Conclusion: 提出的ResNet-based模型通过创新的特征表示方法（特别是权重图），在降低计算复杂度的同时实现了更准确的路径损耗预测，为无线网络规划提供了有效的解决方案。

Abstract: Predicting pathloss by considering the physical environment is crucial for effective wireless network planning. Traditional methods, such as ray tracing and model-based approaches, often face challenges due to high computational complexity and discrepancies between models and real-world environments. In contrast, deep learning has emerged as a promising alternative, offering accurate path loss predictions with reduced computational complexity. In our research, we introduce a ResNet-based model designed to enhance path loss prediction. We employ innovative techniques to capture key features of the environment by generating transmission (Tx) and reception (Rx) depth maps, as well as a distance map from the geographic data. Recognizing the significant attenuation caused by signal reflection and diffraction, particularly at high frequencies, we have developed a weighting map that emphasizes the areas adjacent to the direct path between Tx and Rx for path loss prediction. {Extensive simulations demonstrate that our model outperforms PPNet, RPNet, and Vision Transformer (ViT) by 1.2-3.0 dB using dataset of ITU challenge 2024 and ICASSP 2023. In addition, the floating point operations (FLOPs) of the proposed model is 60\% less than those of benchmarks.} Additionally, ablation studies confirm that the inclusion of the weighting map significantly enhances prediction performance.

</details>


### [6] [SDP: A Unified Protocol and Benchmarking Framework for Reproducible Wireless Sensing](https://arxiv.org/abs/2601.08463)
*Di Zhang,Jiawei Huang,Yuanhao Cui,Xiaowen Cao,Tony Xiao Han,Xiaojun Jing,Christos Masouros*

Main category: eess.SP

TL;DR: SDP提出无线感知的统一协议层抽象和基准，通过标准化数据处理和评估流程解决硬件异构性和可复现性问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的无线感知研究缺乏统一的实验基础，硬件依赖的信道测量、预处理流程和评估协议在不同设备和数据集间差异巨大，阻碍公平比较和可复现性。

Method: 提出Sensing Data Protocol (SDP)作为协议级抽象层，强制确定性物理层净化、规范张量构建、标准化训练和评估流程，将学习任务与硬件异构性解耦。

Result: SDP在保持竞争力的准确率同时，显著提升稳定性，在复杂活动识别任务中将种子间性能方差降低数个数量级，并在商用Wi-Fi硬件上展示跨异构硬件的互操作性。

Conclusion: SDP为无线感知研究提供统一的协议和基准，支持从临时实验向可靠工程实践的转变，促进可复现和可比较的研究。

Abstract: Learning-based wireless sensing has made rapid progress, yet the field still lacks a unified and reproducible experimental foundation. Unlike computer vision, wireless sensing relies on hardware-dependent channel measurements whose representations, preprocessing pipelines, and evaluation protocols vary significantly across devices and datasets, hindering fair comparison and reproducibility.
  This paper proposes the Sensing Data Protocol (SDP), a protocol-level abstraction and unified benchmark for scalable wireless sensing. SDP acts as a standardization layer that decouples learning tasks from hardware heterogeneity. To this end, SDP enforces deterministic physical-layer sanitization, canonical tensor construction, and standardized training and evaluation procedures, decoupling learning performance from hardware-specific artifacts. Rather than introducing task-specific models, SDP establishes a principled protocol foundation for fair evaluation across diverse sensing tasks and platforms. Extensive experiments demonstrate that SDP achieves competitive accuracy while substantially improving stability, reducing inter-seed performance variance by orders of magnitude on complex activity recognition tasks. A real-world experiment using commercial off-the-shelf Wi-Fi hardware further illustrating the protocol's interoperability across heterogeneous hardware. By providing a unified protocol and benchmark, SDP enables reproducible and comparable wireless sensing research and supports the transition from ad hoc experimentation toward reliable engineering practice.

</details>


### [7] [Drone Surveillance via Coordinated Beam Sweeping in MIMO-ISAC Networks](https://arxiv.org/abs/2601.08483)
*Palatip Jopanya,Diana P. M. Osorio,Erik G. Larsson*

Main category: eess.SP

TL;DR: 提出一种与5G SSB同步信号块协调的无人机监控方案，通过多基站协作在波束扫描中同时进行通信和感知，设计预编码器保证感知波束与SSB正交性以最大化感知SINR


<details>
  <summary>Details</summary>
Motivation: 需要同时进行5G通信和低空无人机监控，传统方法存在通信与感知信号干扰问题，需要协调多基站实现高效协同感知

Method: 采用多基站配置，AP协作照射监控区域体素网格，通过波束扫描同时发送5G SSB信号和感知波束，设计预编码器保证感知波束与SSB正交性，最大化感知SINR同时确保用户SINR要求

Result: 提出的预编码器性能优于非协调预编码器，对无人机高度变化影响最小，能有效协调通信和感知任务

Conclusion: 该方案成功实现了5G通信与无人机监控的协同工作，通过预编码器设计解决了信号干扰问题，为未来集成通信感知系统提供了有效解决方案

Abstract: This paper introduces a scheme for drone surveillance coordinated with the fifth generation (5G) synchronization signal block (SSB) cell-search procedure to simultaneously detect low-altitude drones within a volumetric surveillance grid. Herein, we consider a multistatic configuration where multiple access points (APs) collaboratively illuminate the volume while independently transmitting SSB broadcast signals. Both tasks are performed through a beam sweeping. In the proposed scheme, coordinated APs send sensing beams toward a grid of voxels within the volumetric surveillance region simultaneously with the 5G SSB burst. To prevent interference between communication and sensing signals, we propose a precoder design that guarantees orthogonality of the sensing beam and the SSB in order to maximize the sensing signal-to-interference-plus-noise ratio (SINR) while ensuring a specified SINR for users, as well as minimizing the impact of the direct link. The results demonstrate that the proposed precoder outperforms the non-coordinated precoder and is minimally affected by variations in drone altitude.

</details>


### [8] [Airborne Particle Communication Through Time-varying Diffusion-Advection Channels](https://arxiv.org/abs/2601.08534)
*Fatih Merdan,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 该论文研究了时变对流条件下的空气粒子通信，将其建模为线性时变信道，推导了信道冲激响应，提出了信道色散时间作为信道记忆度量，并通过仿真验证了波形设计对性能的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有粒子通信研究大多假设恒定流动条件，而真实宏观环境（如大气风）具有时变特性，需要建立更现实的时变对流扩散信道模型。

Method: 使用时变线性信道建模，采用移动坐标系方法推导时变信道冲激响应，通过功率延迟分布表征信道特性，定义信道色散时间作为信道记忆度量，并在时变风条件下进行系统级仿真。

Result: 推导出时变信道冲激响应的闭式解，建立了信道色散时间与符号持续时间选择的关系，仿真表明当色散得到充分控制时，使用单一粒子类型可实现多符号调制。

Conclusion: 时变扩散对流信道可以使用通信理论工具进行系统建模和设计，为复杂流动环境中的粒子通信提供了现实基础，波形设计对性能至关重要。

Abstract: Particle based communication using diffusion and advection has emerged as an alternative signaling paradigm recently. While most existing studies assume constant flow conditions, real macro scale environments such as atmospheric winds exhibit time varying behavior. In this work, airborne particle communication under time varying advection is modeled as a linear time varying (LTV) channel, and a closed form, time dependent channel impulse response is derived using the method of moving frames. Based on this formulation, the channel is characterized through its power delay profile, leading to the definition of channel dispersion time as a physically meaningful measure of channel memory and a guideline for symbol duration selection. System level simulations under directed, time varying wind conditions show that waveform design is critical for performance, enabling multi symbol modulation using a single particle type when dispersion is sufficiently controlled. The results demonstrate that time varying diffusion advection channels can be systematically modeled and engineered using communication theoretic tools, providing a realistic foundation for particle based communication in complex flow environments.

</details>


### [9] [Stable Filtering for Efficient Dimensionality Reduction of Streaming Manifold Data](https://arxiv.org/abs/2601.08685)
*Nicholas P. Bertrand,Eva Yezerets,Han Lun Yap,Adam S. Charles,Christopher J. Rozell*

Main category: eess.SP

TL;DR: 本文提出随机化滤波（RF）方法，利用随机化降维技术，无需训练即可高效处理高维流数据，同时保持数据在低维吸引子流形上的几何结构。


<details>
  <summary>Details</summary>
Motivation: 现代科学技术产生海量高维数据，传统存储、传输和处理面临巨大挑战。需要无需昂贵训练、能保持数据底层几何结构（特别是低维吸引子流形）的新型降维工具。

Method: 提出随机化滤波（RF）方法，基于随机化降维理论框架，通过特定实例化实现数据无关的高效计算，理论上保证非线性流形结构在嵌入空间中的保持。

Result: 开发了实用的RF方法，包括新颖的方法、分析和实验验证。在多个模拟和真实数据应用中展示了RF的实际效益，证明了其在保持流形结构的同时具有计算效率。

Conclusion: 随机化滤波为解决高维流数据处理提供了实用、高效且理论保证的解决方案，无需训练即可保持数据几何结构，适用于多种科学应用场景。

Abstract: Many areas in science and engineering now have access to technologies that enable the rapid collection of overwhelming data volumes. While these datasets are vital for understanding phenomena from physical to biological and social systems, the sheer magnitude of the data makes even simple storage, transmission, and basic processing highly challenging. To enable efficient and accurate execution of these data processing tasks, we require new dimensionality reduction tools that 1) do not need expensive, time-consuming training, and 2) preserve the underlying geometry of the data that has the information required to understand the measured system. Specifically, the geometry to be preserved is that induced by the fact that in many applications, streaming high-dimensional data evolves on a low-dimensional attractor manifold. Importantly, we may not know the exact structure of this manifold a priori. To solve these challenges, we present randomized filtering (RF), which leverages a specific instantiation of randomized dimensionality reduction to provably preserve non-linear manifold structure in the embedded space while remaining data-independent and computationally efficient. In this work we build on the rich theoretical promise of randomized dimensionality reduction to develop RF as a real, practical approach. We introduce novel methods, analysis, and experimental verification to illuminate the practicality of RF in diverse scientific applications, including several simulated and real-data examples that showcase the tangible benefits of RF.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [10] [Efficient Synthesis for Two-Dimensional Strand Arrays with Row Constraints](https://arxiv.org/abs/2601.07968)
*Boaz Moav,Ryan Gabrys,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 研究DNA合成中的空间约束问题，分析在每行每周期最多合成一条链的限制下，两条链在单行中的期望完成时间，提出最优策略和算法。


<details>
  <summary>Details</summary>
Motivation: 受大规模DNA合成技术的驱动，研究在空间约束下（阵列排列，每行每周期最多合成一条链）的DNA链合成理论问题。

Method: 将过程分解为马尔可夫链，推导期望合成时间的上下界；提出简单的滞后优先策略；对于二进制情况，研究单符号前瞻的改进；提出动态规划算法计算最优离线调度。

Result: 滞后优先策略在任意字母表大小q下达到渐近期望完成时间(q+3)L/2；无前瞻的在线策略无法超越此界限；二进制情况下，单符号前瞻可将时间改进为7L/3；动态规划算法能计算任意固定序列对的最优离线调度。

Conclusion: 首次为空间约束下的合成提供了分析界限，为未来研究此类设置中的最优合成策略奠定了基础。

Abstract: We study the theoretical problem of synthesizing multiple DNA strands under spatial constraints, motivated by large-scale DNA synthesis technologies. In this setting, strands are arranged in an array and synthesized according to a fixed global synthesis sequence, with the restriction that at most one strand per row may be synthesized in any synthesis cycle. We focus on the basic case of two strands in a single row and analyze the expected completion time under this row-constrained model. By decomposing the process into a Markov chain, we derive analytical upper and lower bounds on the expected synthesis time. We show that a simple laggard-first policy achieves an asymptotic expected completion time of (q+3)L/2 for any alphabet of size q, and that no online policy without look-ahead can asymptotically outperform this bound. For the binary case, we show that allowing a single-symbol look-ahead strictly improves performance, yielding an asymptotic expected completion time of 7L/3. Finally, we present a dynamic programming algorithm that computes the optimal offline schedule for any fixed pair of sequences. Together, these results provide the first analytical bounds for synthesis under spatial constraints and lay the groundwork for future studies of optimal synthesis policies in such settings.

</details>


### [11] [Distributed Detection under Stringent Resource Constraints](https://arxiv.org/abs/2601.07989)
*Abdelaziz Bounhar,Mireille Sarkiss,Michèle Wigger*

Main category: cs.IT

TL;DR: 论文研究了分布式检测中Stein指数在不同通信约束下的表现，发现信道结构（部分连接vs完全连接）对检测性能有决定性影响。


<details>
  <summary>Details</summary>
Motivation: 研究在严格通信约束下的分布式检测问题，包括：1)信道使用次数随观测数n亚线性增长；2)有n次信道使用但施加几乎确定的块输入成本约束；3)仅在期望上施加块输入约束。探索这些约束下Stein指数的变化规律。

Method: 采用理论分析方法，将Han的零速率编码策略适配到部分连接DMCs。对于完全连接DMCs，提出新的编码策略和基于测度变换的反向证明。

Result: 发现Stein指数存在二分现象：对于部分连接DMCs，Stein指数与Han和Kobayashi以及Shalaby和Papamarcou在无噪声零速率通信场景下的指数相同；对于完全连接DMCs，在前两种约束下Stein指数退化为本地测试，传感器变得无用；在第三种约束下传感器仍有帮助但性能下降。

Conclusion: 信道连接性结构对分布式检测性能有决定性影响。部分连接信道能保持零速率通信的性能优势，而完全连接信道在严格约束下可能导致传感器完全失效。期望约束相比确定约束能提供更好的性能。

Abstract: This paper identifies the Stein-exponent of distributed detection when the sensor communicates to the decision center over a discrete memoryless channel (DMC) subject to one of three stringent communication constraints: 1) The number of channel uses of the DMC grows sublinearly in the number of source observations n; 2) The number of channel uses is n but a block-input cost constraint is imposed almost surely, which grows sublinearly in n; 3) The block-input constraint is imposed only on expectation. We identify a dichotomy in the Stein-exponent of all these setups depending on the structure of the DMC's transition law. Under any of these three constraints, when the DMC is partially-connected (i.e., some outputs cannot be induced by certain inputs) the Stein-exponent matches the exponent identified by Han and Kobayashi and by Shalaby and Papamarcou for the scenario where communication is of zero-rate but over a noiseless link. We prove our result by adapting Han's zero-rate coding strategy to partially-connected DMCs.
  In contrast, for fully-connected DMCs, in our scenarios 1) and 2) the Stein-exponent collapses to that of a local test at the decision center, rendering the remote sensor and communication useless. %To prove this result, we propose new converse proofs relying on change of measure arguments.
  In scenario 3), the sensor remains beneficial even for fully-connected DMCs, however also collapses compared to the case of a partially-connected DMC. Moreover, the Stein-exponent is larger when the expectation constraint is imposed only under the null hypothesis compared to when it is imposed under both hypotheses. To prove these results, we propose both new coding strategies and new converse proofs.

</details>


### [12] [The many faces of multivariate information](https://arxiv.org/abs/2601.08030)
*Thomas F. Varley*

Main category: cs.IT

TL;DR: 提出一个统一框架Δ^k，将多种高阶信息度量（双总相关、S信息、O信息）统一为参数k的函数，揭示系统高阶协同与冗余的层次结构。


<details>
  <summary>Details</summary>
Motivation: 多元数据中的高阶结构提取对理解复杂系统至关重要，但现有信息论度量众多且分散，缺乏统一框架来系统描述高阶信息共享的不同方面。

Method: 提出参数化函数Δ^k，通过调整参数k可恢复不同已知度量：Δ^0对应S信息，Δ^1对应双总相关，Δ^2对应负O信息。同时利用熵共轭框架得到其共轭Γ^k。

Result: Δ^k形成高阶协同的层次结构：Δ^k>0表示系统以大于k阶的相互作用为主，Δ^k<0表示以小于k阶的相互作用为主，Δ^k=0表示系统完全由k阶协同组成。Γ^k则形成类似的高阶冗余层次。

Conclusion: 该统一框架为高阶冗余和协同相互作用提供了新见解，将现有分散的度量整合为更连贯的结构，有助于系统研究复杂系统中的高阶信息共享模式。

Abstract: Extracting higher-order structures from multivariate data has become an area of intensive study in complex systems science, as these multipartite interactions can reveal insights into fundamental features of complex systems like emergent phenomena. Information theory provides a natural language for exploring these interactions, as it elegantly formalizes the problem of comparing ``wholes" and ``parts" using joint, conditional, and marginal entropies. A large number of distinct statistics have been developed over the years, all aiming to capture different aspects of ``higher-order" information sharing. Here, we show that three of them (the dual total correlation, S-information, and O-information) are special cases of a more general function, $Δ^{k}$ which is parameterized by a free parameter $k$. For different values of $k$, we recover different measures: $Δ^{0}$ is equal to the S-information, $Δ^{1}$ is equal to the dual total correlation, and $Δ^{2}$ is equal to the negative O-information. Generally, the $Δ^{k}$ function is arranged into a hierarchy of increasingly high-order synergies; for a given value of $k$, if $Δ^{k}>0$, then the system is dominated by interactions with order greater than $k$, while if $Δ^{k}<0$, then the system is dominated by interactions with order lower than $k$. $Δ^{k}=0$ if the system is composed entirely of synergies of order-k. Using the entropic conjugation framework, we also find that the conjugate of $Δ^{k}$, which we term $Γ^{k}$ is arranged into a similar hierarchy of increasingly high-order redundancies. These results provide new insights into the nature of both higher-order redundant and synergistic interactions, and helps unify the existing zoo of measures into a more coherent structure.

</details>


### [13] [Cardinality-consistent flag codes with longer type vectors](https://arxiv.org/abs/2601.08144)
*Junfeng Jia,Yanxun Chang*

Main category: cs.IT

TL;DR: 本文提出了一种统一的旗码构造方法，生成两类旗码：最优距离旗码和具有更长类型向量的旗码，两者都达到相同的码字数量。


<details>
  <summary>Details</summary>
Motivation: 旗码将常维码推广到包含嵌套子空间序列的编码。现有构造方法分散，需要统一的框架来生成具有特定距离和类型向量的旗码。

Method: 提出综合构造方法，统一循环轨道旗码，在有限域F_q^n上生成两类旗码：1) 具有最长可能类型向量(1,2,...,k,n-k,...,n-1)的最优距离旗码；2) 具有更长类型向量(1,2,...,k+h,2k+h,...,(s-2)k+h,n-k,...,n-1)的旗码。

Result: 构造的旗码达到相同的码字数量∑_{i=1}^{s-1} q^{ik+h}+1，其中n=sk+h，s≥2，0≤h<k。两类旗码都在统一框架下生成。

Conclusion: 该综合构造方法统一了循环轨道旗码，生成了具有特定距离属性和类型向量的旗码，为旗码设计提供了系统化的框架。

Abstract: Flag codes generalize constant dimension codes by considering sequences of nested subspaces with prescribed dimensions as codewords. A comprehensive construction, which unites cyclic orbit flag codes, yields two families of flag codes on $\mathbb{F}^n_q$ (where $n=sk+h$ with $s\geq 2$ and $0\leq h < k$): optimum distance flag codes of the longest possible type vector $(1, 2, \ldots, k, n-k, \ldots, n-1)$ and flag codes with longer type vectors $(1, 2, \ldots, k+h, 2k+h, \ldots, (s-2)k+h, n-k, \ldots, n-1)$. These flag codes achieve the same cardinality $\sum^{s-1}_{i=1}q^{ik+h}+1$.

</details>


### [14] [From Antenna Abundance to Antenna Intelligence in 6G Gigantic MIMO Systems](https://arxiv.org/abs/2601.08326)
*Emil Björnson,Amna Irshad,Özlem Tugfe Demir,Giuseppe Thadeu Freitas de Abreu,Alva Kosasih,Vitaly Petrov*

Main category: cs.IT

TL;DR: 论文提出通过智能非均匀稀疏阵列设计替代传统大规模MIMO的均匀阵列，用更少天线实现更优性能，实现从天线数量到天线智能的范式转变。


<details>
  <summary>Details</summary>
Motivation: 当前大规模MIMO系统通过大量天线实现高频谱效率，但未来网络需要数百天线，带来硬件复杂度、成本和功耗问题。需要更智能的阵列设计来减少天线数量需求。

Method: 采用非均匀稀疏阵列设计，基于站点特定的天线布局：1）预优化的不规则阵列；2）实时可移动天线。这些设计原则借鉴了无线定位领域的研究，通过不均匀空间采样减少冗余。

Result: 数值模拟显示，这些概念可以显著提高平均和速率等通信指标，用更少天线实现更优的多用户MIMO性能。

Conclusion: 提出未来天线阵列设计的范式转变：用天线智能替代单纯的天线数量，为高效、适应性强、可持续的"巨型MIMO"系统开辟新机遇。

Abstract: Current cellular systems achieve high spectral efficiency through Massive MIMO, which leverages an abundance of antennas to create favorable propagation conditions for multiuser spatial multiplexing. Looking towards future networks, the extrapolation of this paradigm leads to systems with many hundreds of antennas per base station, raising concerns regarding hardware complexity, cost, and power consumption. This article suggests more intelligent array designs that reduce the need for excessive antenna numbers. We revisit classical uniform array design principles and explain how their uniform spatial sampling leads to unnecessary redundancies in practical deployment scenarios. By exploiting non-uniform sparse arrays with site-specific antenna placements -- based on either pre-optimized irregular arrays or real-time movable antennas -- we demonstrate how superior multiuser MIMO performance can be achieved with far fewer antennas. These principles are inspired by previous works on wireless localization. We explain and demonstrate numerically how these concepts can be adapted for communications to improve the average sum rate and similar metrics. The results suggest a paradigm shift for future antenna array design, where antenna intelligence replaces sheer antenna count. This opens new opportunities for efficient, adaptable, and sustainable Gigantic MIMO systems.

</details>


### [15] [Movable Antenna for Integrating Near-field Channel Estimation and Localization](https://arxiv.org/abs/2601.08357)
*Chongjia Sun,Ziwei Wan,Lipeng Zhu,Zhenyu Xiao,Zhen Gao,Rui Zhang*

Main category: cs.IT

TL;DR: 提出了一种用于宽带近场ISAC的多阶段设计框架，通过可移动天线实现高精度角度估计、散射体定位和信道估计


<details>
  <summary>Details</summary>
Motivation: 可移动天线为未来无线通信系统引入了新的自由度，其大范围移动使无线信道传输进入近场区域，这为集成感知与通信带来了新的性能增强机会

Method: 1) 将MA移动区域划分为多个子区域，使用NOMP算法在每个子区域实现高精度角度估计；2) 提出近场子区域射线聚类定位方法，通过联合处理所有子区域的角度估计来识别散射体位置；3) 基于估计的散射体位置，细化近场信道估计以提高通信性能

Result: 仿真结果表明，所提方案能显著提高MA感知精度和信道估计性能，为MA辅助的近场ISAC提供了高效解决方案

Conclusion: 提出的多阶段设计框架有效利用了可移动天线在近场ISAC中的潜力，通过创新的角度估计、散射体定位和信道估计方法，实现了感知和通信性能的协同提升

Abstract: Movable antenna (MA) introduces a new degree of freedom for future wireless communication systems by enabling the adaptive adjustment of antenna positions. Its large-range movement renders wireless channels transmission into the near-field region, which brings new performance enhancement for integrated sensing and communication (ISAC). This paper proposes a novel multi-stage design framework for broadband near-field ISAC assisted by MA. The framework first divides the MA movement area into multiple subregions, and employs the Newtonized orthogonal matching pursuit algorithm (NOMP) to achieve high-precision angle estimation in each subregion. Subsequently, a method called near-field localization via subregion ray clustering (LSRC) is proposed for identifying the positions of scatterers. This method finds the coordinates of each scatterer by jointly processing the angle estimates across all subregions. Finally, according to the estimated locations of the scatterers, the near-field channel estimation (CE) is refined for improving communication performance. Simulation results demonstrate that the proposed scheme can significantly enhance MA sensing accuracy and CE, providing an efficient solution for MA-aided near-field ISAC.

</details>


### [16] [On the Generalization Error of Differentially Private Algorithms Via Typicality](https://arxiv.org/abs/2601.08386)
*Yanxiao Liu,Chun Hei Michael Shiu,Lele Wang,Deniz Gündüz*

Main category: cs.IT

TL;DR: 本文从信息论视角研究随机学习算法的泛化误差，特别关注差分隐私算法的更紧致边界。通过典型性论证和隐私算法的稳定性，将互信息和最大泄漏上界化为显式易计算的公式，改进了现有结果并得到新的泛化误差保证。


<details>
  <summary>Details</summary>
Motivation: 现有研究已表明随机学习算法的泛化误差可以通过互信息和最大泄漏来界定，分别得到期望和高概率保证。但现有边界不够紧致，特别是对于差分隐私算法，需要更精确、易于计算的泛化误差边界。

Method: 采用信息论方法，利用典型性论证和差分隐私算法的稳定性特性，将互信息和最大泄漏上界化为显式易计算的公式。第一部分严格改进了Rodríguez-Gálvez等人的互信息边界；第二部分推导了学习算法最大泄漏的新上界。

Result: 获得了比现有结果更紧致的互信息边界，并推导了最大泄漏的新上界。这些信息度量的边界可以直接转化为泛化误差的保证，为差分隐私算法提供了更精确的泛化性能分析工具。

Conclusion: 通过信息论视角和典型性论证，本文为随机学习算法特别是差分隐私算法提供了更紧致、易计算的泛化误差边界，改进了现有理论结果，增强了算法泛化性能的理论保证。

Abstract: We study the generalization error of stochastic learning algorithms from an information-theoretic perspective, with a particular emphasis on deriving sharper bounds for differentially private algorithms. It is well known that the generalization error of stochastic learning algorithms can be bounded in terms of mutual information and maximal leakage, yielding in-expectation and high-probability guarantees, respectively. In this work, we further upper bound mutual information and maximal leakage by explicit, easily computable formulas, using typicality-based arguments and exploiting the stability properties of private algorithms. In the first part of the paper, we strictly improve the mutual-information bounds by Rodríguez-Gálvez et al. (IEEE Trans. Inf. Theory, 2021). In the second part, we derive new upper bounds on the maximal leakage of learning algorithms. In both cases, the resulting bounds on information measures translate directly into generalization error guarantees.

</details>


### [17] [An Efficient Algorithm to Sample Quantum Low-Density Parity-Check Codes](https://arxiv.org/abs/2601.08387)
*Paolo Santini*

Main category: cs.IT

TL;DR: 提出一种高效的随机稀疏矩阵采样算法，用于生成量子LDPC码的校验矩阵，该算法基于信息集解码(ISD)技术，是纯组合方法而非代数构造。


<details>
  <summary>Details</summary>
Motivation: 现有量子LDPC码构造方法多为代数方法（如准循环矩阵），缺乏足够随机性。需要一种更通用、更随机的稀疏自正交矩阵采样方法。

Method: 使用信息集解码(ISD)技术逐行采样稀疏矩阵H，确保H满足自正交条件HH^T=0。算法是纯组合方法，不依赖特定代数结构，可推广到非二进制有限域和更一般的量子稳定子LDPC码。

Result: 算法理论上确定了可采样的参数范围及其计算复杂度，数值模拟验证了方法的可行性和高效性。

Conclusion: 提出了一种简单而有效的组合算法，能够生成尽可能随机的稀疏自正交矩阵，为量子LDPC码的构造提供了新方法。

Abstract: In this paper, we present an efficient algorithm to sample random sparse matrices to be used as check matrices for quantum Low-Density Parity-Check (LDPC) codes. To ease the treatment, we mainly describe our algorithm as a technique to sample a dual-containing binary LDPC code, hence, a sparse matrix $\mathbf H\in\mathbb F_2^{r\times n}$ such that $\mathbf H\mathbf H^\top = \mathbf 0$. However, as we show, the algorithm can be easily generalized to sample dual-containing LDPC codes over non binary finite fields as well as more general quantum stabilizer LDPC codes.
  While several constructions already exist, all of them are somewhat algebraic as they impose some specific property (e.g., the matrix being quasi-cyclic). Instead, our algorithm is purely combinatorial as we do not require anything apart from the rows of $\mathbf H$ being sparse enough. In this sense, we can think of our algorithm as a way to sample sparse, self-orthogonal matrices that are as random as possible.
  Our algorithm is conceptually very simple and, as a key ingredient, uses Information Set Decoding (ISD) to sample the rows of $\mathbf H$, one at a time. The use of ISD is fundamental as, without it, efficient sampling would not be feasible. We give a theoretical characterization of our algorithm, determining which ranges of parameters can be sampled as well as the expected computational complexity. Numerical simulations and benchmarks confirm the feasibility and efficiency of our approach.

</details>


### [18] [LWM-Spectro: A Foundation Model for Wireless Baseband Signal Spectrograms](https://arxiv.org/abs/2601.08780)
*Namhyun Kim,Sadjad Alikhani,Ahmed Alkhateeb*

Main category: cs.IT

TL;DR: LWM-Spectro是一个基于Transformer的基础模型，通过在I/Q信号的时频谱图上进行大规模预训练，结合掩码建模、对比学习和MoE架构，学习通用的无线表示，在调制分类等下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 无线通信中的I/Q基带信号编码了物理层和信道特性，但由于通信系统异构、传播环境多样以及标记数据有限，直接从原始信号学习鲁棒且可迁移的表示仍然具有挑战性。

Method: 提出LWM-Spectro模型：1) 将I/Q数据表示为时频谱图；2) 使用Transformer架构；3) 结合自监督掩码建模和对比学习；4) 采用混合专家(MoE)架构；5) 在大规模I/Q数据上进行预训练。

Result: 模型在调制分类和联合SNR/移动性识别等下游任务中表现出色，在少样本和数据丰富的场景下均优于现有深度学习基线，提供了统一的无线学习基础。

Conclusion: LWM-Spectro通过学习通用的无线表示，有效解决了无线信号表示学习的挑战，为无线学习任务提供了强大的基础模型，在各种下游任务中展现出优异的迁移性能。

Abstract: The received in-phase and quadrature (I/Q) baseband signals inherently encode physical-layer and channel characteristics of wireless links. Learning robust and transferable representations directly from such raw signals, however, remains challenging due to heterogeneous communication systems, diverse propagation environments, and limited labeled data. To address this, we present LWM-Spectro, a transformer-based foundation model pretrained on large-scale I/Q data represented as time-frequency spectrograms. The model leverages self-supervised masked modeling, contrastive learning, and a mixture-of-experts (MoE) architecture to learn general-purpose wireless representations. These representations transfer effectively to downstream tasks such as modulation classification and joint SNR/mobility recognition, even with minimal supervision. Across tasks, LWM-Spectro consistently outperforms state-of-the-art deep learning baselines in both few-shot and data-rich regimes, providing a unified foundation for wireless learning.

</details>


### [19] [Distribution Estimation with Side Information](https://arxiv.org/abs/2601.08535)
*Haricharan Balasundaram,Andrew Thangaraj*

Main category: cs.IT

TL;DR: 该论文研究在具有额外侧信息的情况下进行离散分布估计的问题，特别针对大字母表数据集（如文本语料库），其中词嵌入相似性提供了语义侧信息。


<details>
  <summary>Details</summary>
Motivation: 在大字母表数据集（如文本语料库）中，传统的离散分布估计方法可能效率不高。然而，通过词嵌入等技术可以获得关于分布的先验知识（如词义相似性），这些侧信息可能显著改善估计精度。论文旨在探索如何利用这种侧信息来提升分布估计的性能。

Method: 论文提出了两种侧信息模型：局部模型（未知分布在已知分布的邻域内）和偏序模型（字母表被划分为已知的高概率和低概率集合）。针对这两种模型，作者从理论上分析了在平方误差风险方面的改进，并通过自然语言和合成数据的仿真验证了这些增益。

Result: 理论分析表明，在两种侧信息模型下，分布估计的平方误差风险都能得到显著改善。仿真实验在自然语言数据和合成数据上验证了这些理论增益，显示了利用侧信息在实际应用中的有效性。

Conclusion: 该研究表明，在离散分布估计中利用可用的侧信息（如通过词嵌入获得的语义信息）可以显著提高估计精度。提出的两种模型为处理不同类型的先验知识提供了理论框架，并在实际数据中展示了性能改进的潜力。

Abstract: We consider the classical problem of discrete distribution estimation using i.i.d. samples in a novel scenario where additional side information is available on the distribution. In large alphabet datasets such as text corpora, such side information arises naturally through word semantics/similarities that can be inferred by closeness of vector word embeddings, for instance. We consider two specific models for side information--a local model where the unknown distribution is in the neighborhood of a known distribution, and a partial ordering model where the alphabet is partitioned into known higher and lower probability sets. In both models, we theoretically characterize the improvement in a suitable squared-error risk because of the available side information. Simulations over natural language and synthetic data illustrate these gains.

</details>


### [20] [On the Optimality of Decode and Forward for Some Cooperative Broadcast Channels](https://arxiv.org/abs/2601.08592)
*Nicolas Le Gouic,Yossef Steinberg,Michèle Wigger*

Main category: cs.IT

TL;DR: 本文针对具有从强接收机到弱接收机单向协作的广播信道，提出了新的容量区域边界点，并通过简单的编码方案实现。


<details>
  <summary>Details</summary>
Motivation: 研究具有接收机间协作的广播信道容量区域，特别是当强接收机可以向弱接收机提供协作时，探索新的可达速率点。

Method: 采用发射机的叠加编码和强接收机的解码转发方案，构建简单的编码策略来实现新的边界点。

Result: 为高斯广播信道以及由二进制擦除信道（强接收机）和二进制对称信道（弱接收机）组成的广播信道，计算了新的容量区域边界点。

Conclusion: 提出的简单编码方案能够实现广播信道容量区域的新边界点，特别是在接收机间存在单向协作的情况下。

Abstract: This article characterizes new boundary points on the capacity region of certain classes of more capable broadcast channels (BC) with uni-directional cooperation from the stronger to the weaker receiver. The new boundary points are achieved by a simple coding scheme that employs superposition coding at the transmitter with decode and forward at the stronger receiver. We evaluate our general result for Gaussian BCs and for a BC consisting of a binary erasure channel (BEC) to the stronger receiver and a binary symmetric channel (BSC) to the weaker receiver.

</details>


### [21] [Quantum CSS LDPC Codes based on Dyadic Matrices for Belief Propagation-based Decoding](https://arxiv.org/abs/2601.08636)
*Alessio Baldelli,Massimo Battaglioni,Jonathan Mandelbaum,Sisi Miao,Laurent Schmalen*

Main category: cs.IT

TL;DR: 提出基于二元矩阵的代数构造方法，用于设计经典和量子LDPC码，通过兼容性条件确保所有不可避免的4环集中在单个变量节点，从而减轻其负面影响。


<details>
  <summary>Details</summary>
Motivation: 量子低密度奇偶校验码在量子纠错中提供了纠错能力和实现复杂度之间的实用平衡，需要设计既能满足性能要求又具有实现可行性的QLDPC码。

Method: 首先基于二元矩阵生成经典二进制准二元LDPC码（Tanner图围长为6），然后扩展到CSS框架，构建两个分量奇偶校验矩阵以满足CAMEL-ensemble四进制置信传播解码器所需的兼容性条件。

Result: 该方法能够设计出满足兼容性条件的QLDPC码，确保所有不可避免的长度为4的环都集中在单个变量节点中，从而可以通过对该变量节点进行消减来减轻其负面影响。

Conclusion: 提出的代数构造方法为设计高性能的经典和量子LDPC码提供了一种系统化的途径，特别适用于需要减轻短环负面影响的量子纠错应用场景。

Abstract: Quantum low-density parity-check (QLDPC) codes provide a practical balance between error-correction capability and implementation complexity in quantum error correction (QEC). In this paper, we propose an algebraic construction based on dyadic matrices for designing both classical and quantum LDPC codes. The method first generates classical binary quasi-dyadic LDPC codes whose Tanner graphs have girth 6. It is then extended to the Calderbank-Shor-Steane (CSS) framework, where the two component parity-check matrices are built to satisfy the compatibility condition required by the recently introduced CAMEL-ensemble quaternary belief propagation decoder. This compatibility condition ensures that all unavoidable cycles of length 4 are assembled in a single variable node, allowing the mitigation of their detrimental effects by decimating that variable node.

</details>


### [22] [Multivariate Polynomial Codes for Efficient Matrix Chain Multiplication in Distributed Systems](https://arxiv.org/abs/2601.08708)
*Jesús Gómez-Vilardebò*

Main category: cs.IT

TL;DR: 提出两种用于分布式矩阵链乘法的多元多项式编码方案，在计算与存储开销间取得平衡


<details>
  <summary>Details</summary>
Motivation: 现有编码计算策略主要针对两矩阵乘法，但实际应用中常涉及长矩阵链乘法；单变量多项式编码扩展到此场景会显著增加计算和存储开销，限制了可扩展性

Method: 提出两种专门为分布式环境设计的多元多项式编码方案，用于矩阵链乘法计算

Result: 多元编码虽然增加了计算成本，但能显著降低存储开销，揭示了计算效率与存储效率之间的基本权衡

Conclusion: 多元编码作为大规模分布式线性代数任务的实用解决方案具有潜力，在计算与存储开销间提供了更好的平衡

Abstract: We study the problem of computing matrix chain multiplications in a distributed computing cluster. In such systems, performance is often limited by the straggler problem, where the slowest worker dominates the overall computation latency. To resolve this issue, several coded computing strategies have been proposed, primarily focusing on the simplest case: the multiplication of two matrices. These approaches successfully alleviate the straggler effect, but they do so at the expense of higher computational complexity and increased storage needs at the workers. However, in many real-world applications, computations naturally involve long chains of matrix multiplications rather than just a single two-matrix product. Extending univariate polynomial coding to this setting has been shown to amplify the costs -- both computation and storage overheads grow significantly, limiting scalability. In this work, we propose two novel multivariate polynomial coding schemes specifically designed for matrix chain multiplication in distributed environments. Our results show that while multivariate codes introduce additional computational cost at the workers, they can dramatically reduce storage overhead compared to univariate extensions. This reveals a fundamental trade-off between computation and storage efficiency, and highlights the potential of multivariate codes as a practical solution for large-scale distributed linear algebra tasks.

</details>


### [23] [On the Algebraic Structure Underlying the Support Enumerators of Linear Codes](https://arxiv.org/abs/2601.08744)
*Nitin Kenjale,Anuradha S. Garge*

Main category: cs.IT

TL;DR: 论文引入了支持分布和支持枚举器作为经典重量分布和重量枚举器的细化，用于捕捉线性分组码中坐标级别的活动性，并建立了支持分布与对偶码之间的MacWilliams型恒等式。


<details>
  <summary>Details</summary>
Motivation: 经典重量分布和重量枚举器虽然有用，但无法提供坐标级别的详细信息。为了更精细地理解线性码的结构，特别是坐标级别的活动模式，需要引入更细粒度的分析工具。

Method: 引入支持分布和支持枚举器的概念，建立计算第i个坐标非零的码字数量的公式，推导支持分布与对偶码之间的MacWilliams型恒等式，并基于此推导自对偶码的条件。

Result: 1. 建立了计算线性码中第i个坐标非零码字数量的公式；2. 推导了线性码与其对偶码归一化支持枚举器之间的MacWilliams型恒等式；3. 基于支持分布相等性得到了自对偶码的条件。

Conclusion: 支持分布和支持枚举器提供了比经典重量分布更详细的码结构信息，补充了基于重量的对偶理论，为线性码的坐标级别分析提供了新工具。

Abstract: In this paper, we have introduced the concepts of support distribution and the support enumerator as refinements of the classical weight distribution and weight enumerator respectively, capturing coordinate level activity in linear block codes. More precisely, we have established formula for counting codewords in the linear code C whose i-th coordinate is nonzero. Moreover, we derived a MacWilliam's type identity, relating the normalized support enumerators of a linear code and its dual, explaining how coordinate information transforms under duality. Using this identity we deduce a condition for self duality based on the equality of support distributions. These results provide a more detailed understanding of code structure and complement classical weight based duality theory.

</details>


### [24] [Majority-Logic Decoding of Binary Locally Recoverable Codes: A Probabilistic Analysis](https://arxiv.org/abs/2601.08765)
*Hoang Ly,Emina Soljanin,Philip Whiting*

Main category: cs.IT

TL;DR: 本文研究了二进制线性局部可修复码在多数逻辑解码下的纠错性能，推导了在BEC和BSC信道上的解码失败概率上界，揭示了最坏情况保证与随机信道下典型性能之间的显著差距。


<details>
  <summary>Details</summary>
Motivation: 局部可修复码的结构特性已被广泛研究，但其在随机擦除和错误下的性能尚未得到充分探索。本文旨在分析LRC在多数逻辑解码下的纠错和擦除纠正性能。

Method: 研究固定局部性、可变可用性的二进制线性LRC，采用多数逻辑解码，推导在二进制擦除信道和二进制对称信道上的解码失败概率上界，分析比特错误率和块错误率随局部性和可用性参数的变化。

Result: 在可用性满足温和增长条件下，块解码失败概率渐近消失，多数逻辑解码能成功纠正几乎所有线性权重的错误和擦除模式。结果显示最坏情况保证与随机信道下典型性能存在显著差距。

Conclusion: 局部可修复码在随机信道模型下的典型性能远优于最坏情况保证，多数逻辑解码能有效处理线性权重的错误模式，为分布式存储系统的实际应用提供了理论依据。

Abstract: Locally repairable codes (LRCs) were originally introduced to enable efficient recovery from erasures in distributed storage systems by accessing only a small number of other symbols. While their structural properties-such as bounds and constructions-have been extensively studied, the performance of LRCs under random erasures and errors has remained largely unexplored. In this work, we study the error- and erasure-correction performance of binary linear LRCs under majority-logic decoding (MLD). Focusing on LRCs with fixed locality and varying availability, we derive explicit upper bounds on the probability of decoding failure over the memoryless Binary Erasure Channel (BEC) and Binary Symmetric Channel (BSC). Our analysis characterizes the behavior of the bit-error rate (BER) and block-error rate (BLER) as functions of the locality and availability parameters. We show that, under mild growth conditions on the availability, the block decoding failure probability vanishes asymptotically, and that majority-logic decoding can successfully correct virtually all of error and erasure patterns of weight linear in the blocklength. The results reveal a substantial gap between worst-case guarantees and typical performance under stochastic channel models.

</details>
